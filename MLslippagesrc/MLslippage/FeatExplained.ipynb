{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Mainly Edited for private usage by:  Ioanna Mitsioni\n",
    "                                        Ioannis Agriomallos\n",
    "License: BSD 3 clause\n",
    "\"\"\"\n",
    "import time\n",
    "start_time = time.time()\n",
    "from copy import deepcopy, copy\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import shutil\n",
    "import os\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "# from featext2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "#matplotlib qt\n",
    "# inline (suitable for ipython only, shown inside browser!) or qt (suitable in general, shown in external window!)\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mpl_toolkits.mplot3d import Axes3D #, axes3d\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, mutual_info_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import datetime\n",
    "import urllib\n",
    "import tarfile\n",
    "# import joblib\n",
    "# from joblib import Parallel, delayed, Memory\n",
    "from tempfile import mkdtemp\n",
    "import copy_reg\n",
    "import types\n",
    "import itertools\n",
    "from itertools import compress\n",
    "from collections import Counter\n",
    "\n",
    "#import multiprocessing\n",
    "def _pickle_method(m):\n",
    "    if m.im_self is None:\n",
    "        return getattr, (m.im_class, m.im_func.func_name)\n",
    "    else:\n",
    "        return getattr, (m.im_self, m.im_func.func_name)\n",
    "copy_reg.pickle(types.MethodType, _pickle_method)\n",
    "\n",
    "\n",
    "h = .2  # step size in the mesh\n",
    "window = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Feature Names ############\n",
    "\"\"\"features:                                                                       ||      if       \n",
    "   |--> time domain      :                                                         || samples = 1024\n",
    "   |----|---> phinyomark : 11+3{shist} --------------------------> = 14+0.0samples ||             14\n",
    "   |----|---> golz       : 10+samples{acrol} --------------------> = 10+1.0samples ||           1034\n",
    "   |--> frequency domain :                                                                          \n",
    "   |----|---> phinyomark : 3{arco}+4{mf}+2(samples/2+1){RF,IF} --> =  9+1.0samples ||           1033\n",
    "   |----|---> golz       : 2(samples/2+1){AF,PF} ----------------> =  2+1.0samples ||           1026\n",
    "   |----|----------------|-------alltogether---------------------> = 35+3.0samples || numfeat = 3107\n",
    "\"\"\"\n",
    "## Time Domain Phinyomark feats\n",
    "featnames = ['intsgnl', 'meanabs', 'meanabsslp', 'ssi', 'var', 'rms', 'rng', 'wavl', 'zerox', 'ssc', 'wamp', \n",
    "             'shist1', 'shist2', 'shist3']                                                   # 11+3{shist}\n",
    "## Frequency Domain Phinyomark feats\n",
    "featnames += ['arco1', 'arco2', 'arco3', 'mnf', 'mdf', 'mmnf', 'mmdf']                       # 3{arco}+4{mf}\n",
    "featnames += ['reFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{RF}\n",
    "featnames += ['imFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{IF}\n",
    "## Time Domain Golz feats\n",
    "featnames += ['meanv', 'stdr', 'mx', 'rngx', 'rngy', 'med', 'hjorth', 'sentr', 'se', 'ssk']  # 10\n",
    "featnames += ['acrol{:04d}'.format(i) for i in range(window)]                                # samples{acrol}\n",
    "## Frequency Domain Golz feats\n",
    "featnames += ['amFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{AF}\n",
    "featnames += ['phFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{PF}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Prepare the indeces for each feature ############\n",
    "def get_feat_id(feat_ind, printit=0, sample_window=window): \n",
    "    \"\"\"Find the corresponding indeces of the desired features inside feature vector,\n",
    "    and link them with their names and level of abstraction\n",
    "    -> feat_ind        : range of indeces\n",
    "    -> printit         : print output indeces (1) or not (0)\n",
    "    -> sample_window   : parameter for accurate computation of feature indeces\n",
    "    <- full_path_id    : indeces of all features\n",
    "    <- norm_time_feats : indeces of time features\n",
    "    <- norm_freq_feats : indeces of frequency features\n",
    "    \"\"\"\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "    norm_time_phin = range(0,14)\n",
    "    norm_freq_phin = range(norm_time_phin[-1] + 1, norm_time_phin[-1] + 9 + sample_window + 1)\n",
    "    norm_time_golz = range(norm_freq_phin[-1] + 1, norm_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    norm_freq_golz = range(norm_time_golz[-1] + 1, norm_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    norm_time_feats = norm_time_phin + norm_time_golz\n",
    "    norm_freq_feats = norm_freq_phin + norm_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    norm_feats = norm_time_feats + norm_freq_feats\n",
    "\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "    disp = norm_feats[-1]+1\n",
    "    ftfn_time_phin = range(disp ,disp + 14)\n",
    "    ftfn_freq_phin = range(ftfn_time_phin[-1] + 1, ftfn_time_phin[-1] + 9 + sample_window + 1)\n",
    "    ftfn_time_golz = range(ftfn_freq_phin[-1] + 1, ftfn_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    ftfn_freq_golz = range(ftfn_time_golz[-1] + 1, ftfn_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    ftfn_time_feats = ftfn_time_phin + ftfn_time_golz\n",
    "    ftfn_freq_feats = ftfn_freq_phin + ftfn_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    ftfn_feats = ftfn_time_feats + ftfn_freq_feats\n",
    "\n",
    "    # create the final \"reference dictionary\"\n",
    "    # 3 np.arrays, id_list[0] = level 1 etc\n",
    "    id_list = [np.zeros((len(ftfn_feats + norm_feats),1)) for i in range(3)]\n",
    "    id_list[0][:norm_feats[-1]+1] = 0 # 0 signifies norm / 1 signifies ft/fn\n",
    "    id_list[0][norm_feats[-1]+1:] = 1\n",
    "\n",
    "    id_list[1][:norm_time_phin[-1]+1] = 0 # 0 signifies time / 1 signifies freq\n",
    "    id_list[1][norm_time_phin[-1]+1:norm_freq_phin[-1]+1] = 1\n",
    "    id_list[1][norm_freq_phin[-1]+1:norm_time_golz[-1]+1] = 0\n",
    "    id_list[1][norm_time_golz[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[1][norm_freq_golz[-1]+1:ftfn_time_phin[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_phin[-1]+1:ftfn_freq_phin[-1]+1] = 1\n",
    "    id_list[1][ftfn_freq_phin[-1]+1:ftfn_time_golz[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_golz[-1]+1:] = 1\n",
    "\n",
    "    id_list[2][:norm_freq_phin[-1]+1] = 0 #0 signifies phinyomark / 1 signifies golz\n",
    "    id_list[2][norm_freq_phin[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[2][norm_freq_golz[-1]+1:ftfn_freq_phin[-1]+1] = 0\n",
    "    id_list[2][ftfn_freq_phin[-1]+1:] = 1 \n",
    "    \n",
    "    full_path_id = [np.zeros((len(feat_ind),5)) for i in range(len(feat_ind))]\n",
    "   \n",
    "    for ind, val in enumerate(feat_ind):\n",
    "        full_path_id[ind] = [val, id_list[2][val], id_list[1][val], id_list[0][val]]\n",
    "        if (printit==1):\n",
    "            if(full_path_id[ind][1]==0):\n",
    "                lvl3 = 'Phin'\n",
    "            else:\n",
    "                lvl3 = 'Golz'\n",
    "            if(full_path_id[ind][2]==0):\n",
    "                lvl2 = 'Time'\n",
    "            else:\n",
    "                lvl2 = 'Freq'\n",
    "            if(full_path_id[ind][3]==0):\n",
    "                lvl1 = 'Norm'\n",
    "            else:\n",
    "                lvl1 = 'Ft/Fn'\n",
    "            print(feat_ind[ind],featnames[val%(norm_feats[-1]+1)],lvl3,lvl2,lvl1)\n",
    "    \n",
    "    return(full_path_id,norm_time_feats,norm_freq_feats)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subfeat_inds(ofs=len(featnames)):\n",
    "    \"\"\"returns a subfeatures' indeces\n",
    "    -> ofs                     : number of features in total\n",
    "    <- amfft, freq, time, both : split featureset indeces for \n",
    "                                 amplitude of FFT, all time only,\n",
    "                                 all frequency only and all features\n",
    "    \"\"\"\n",
    "    _,time,freq = get_feat_id(range(ofs))\n",
    "    both = range(ofs)\n",
    "    amfft = []\n",
    "    for i in range(len(featnames)):\n",
    "        if (featnames[i].startswith('amFFT')):\n",
    "            amfft.append(i)\n",
    "    return amfft, freq, time, both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tot_feats(fs, subfs, r):\n",
    "    import glob\n",
    "     ###############################################################################################################\n",
    "    # Version 2, using the bool masks and keeping an array of 6x3000 feats \n",
    "    ###############################################################################################################\n",
    "    # If checking for FnormAll, you end up with 36 models of (trained_on, tested_on) combinations but TECHNICALLY\n",
    "    # the features are the same for every trained_on \"sixplet\" so there's no need to iterate over all the tested_on\n",
    "    # indeces. Therefore, ts = 2 is chosen arbitrarily \n",
    "    \n",
    "    filenames = glob.glob(\"data/results\" + str(r) + \"/fs_\" + str(fs) + \"_subfs_\" + str(subfs) + \"_*.npz\")\n",
    "    # the features kept for surface i will be stored in bool_tot_feats[i] (final size: 6x1000)\n",
    "    bool_tot_feats = []\n",
    "    \n",
    "    for filn in filenames:\n",
    "        # for every training surface     \n",
    "        model_file = np.load(filn)\n",
    "        model = model_file['model']\n",
    "        #keep a list of the 1000 features kept\n",
    "        model_feat_scores = list(model[0].named_steps['feature_selection'].scores_)\n",
    "        bool_model_features = list(model[0].named_steps['feature_selection'].get_support(indices = False))\n",
    "        if subfs<=2:\n",
    "            bool_model_features = np.logical_not(np.array(bool_model_features))\n",
    "            bool_model_features[np.array(model_feat_scores).argsort()[-1000:][::-1].tolist()] = True\n",
    "            bool_model_features = bool_model_features.tolist()\n",
    "#         plt.plot(model_feat_scores)\n",
    "        bool_tot_feats.append(bool_model_features)\n",
    "\n",
    "    return bool_tot_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freq_time_counter(full_names, subfs):\n",
    "    f_c = 0; t_c = 0\n",
    "    for i in range(len(full_names)):\n",
    "        if full_names[i][2] == 1:\n",
    "            if subfs!=2:\n",
    "                f_c += 1\n",
    "        else:\n",
    "            if subfs>=2:\n",
    "                t_c += 1\n",
    "    return (f_c, t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_common_feats(bool_tot_feats, subfs, skip_surf = 6, print_common_feats = 0):   \n",
    "    # skip_surf = 6 by default so you won't skip any surfaces.\n",
    "    # returns the list of inds for the common feats\n",
    "    trans_test_bools = []\n",
    "\n",
    "    for i in range(len(bool_tot_feats)):\n",
    "        if i != skip_surf:\n",
    "            trans_test_bools.append(bool_tot_feats[i])\n",
    "        else: \n",
    "            continue\n",
    "            \n",
    "    trans_test_bools = np.transpose(trans_test_bools)\n",
    "    common_feats = []\n",
    "    matches  =[]\n",
    "    for i in range(len(trans_test_bools)):\n",
    "        matches.append(np.all(trans_test_bools[i]))\n",
    "    for ind, val in enumerate(matches):\n",
    "        if val:\n",
    "            common_feats.append(ind)\n",
    "    print(\"===============================================================\")       \n",
    "    print(\"%d common feats, out of %d total\" %(len(common_feats),len(matches)))\n",
    "    full_names, _, _ = get_feat_id(common_feats, printit = print_common_feats)\n",
    "    freq_counter, time_counter = freq_time_counter(full_names, subfs)\n",
    "    print(\"of which, %d (%.2f%%) were Freq features and %d (%.2f%%) were Time features\" %(freq_counter, (float(freq_counter)/len(common_feats))*100, time_counter, (float(time_counter)/len(common_feats))*100 ))\n",
    "\n",
    "    print(\"===============================================================\")\n",
    "    \n",
    "    return common_feats, full_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================\n",
      "770 common feats, out of 1048 total\n",
      "of which, 0 (0.00%) were Freq features and 7 (0.91%) were Time features\n",
      "===============================================================\n"
     ]
    }
   ],
   "source": [
    "### Example \n",
    "\n",
    "subfs=2\n",
    "for r in range(1,2):\n",
    "    tot_feats = get_tot_feats(fs=0, subfs=subfs, r=r)\n",
    "#     print np.array(tot_feats).shape\n",
    "#     print tot_feats\n",
    "    common_feats, full_names = get_common_feats(bool_tot_feats=tot_feats, subfs=subfs, skip_surf=6, print_common_feats=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(770, 4)\n",
      "['intsgnl' 'meanabs' 'meanabsslp' 'ssi' 'var' 'rms' 'rng' 'arco1' 'arco2'\n",
      " 'arco3' 'mdf' 'mmnf' 'mmdf' 'reFFT001' 'reFFT003' 'reFFT004' 'reFFT005'\n",
      " 'reFFT006' 'reFFT007' 'reFFT008' 'reFFT009' 'reFFT010' 'reFFT011'\n",
      " 'reFFT012' 'reFFT013' 'reFFT014' 'reFFT015' 'reFFT016' 'reFFT017'\n",
      " 'reFFT018' 'reFFT019' 'reFFT020' 'reFFT021' 'reFFT022' 'reFFT023'\n",
      " 'reFFT024' 'reFFT025' 'reFFT026' 'reFFT027' 'reFFT028' 'reFFT029'\n",
      " 'reFFT030' 'reFFT031' 'reFFT032' 'reFFT033' 'reFFT034' 'reFFT035'\n",
      " 'reFFT036' 'reFFT037' 'reFFT038' 'reFFT039' 'reFFT040' 'reFFT041'\n",
      " 'reFFT042' 'reFFT043' 'reFFT044' 'reFFT045' 'reFFT046' 'reFFT047'\n",
      " 'reFFT048' 'reFFT049' 'reFFT050' 'reFFT051' 'reFFT052' 'reFFT053'\n",
      " 'reFFT054' 'reFFT055' 'reFFT056' 'reFFT057' 'reFFT058' 'reFFT059'\n",
      " 'reFFT060' 'reFFT061' 'reFFT062' 'reFFT063' 'reFFT064' 'reFFT065'\n",
      " 'reFFT066' 'reFFT067' 'reFFT068' 'reFFT069' 'reFFT070' 'reFFT071'\n",
      " 'reFFT072' 'reFFT073' 'reFFT074' 'reFFT075' 'reFFT076' 'reFFT077'\n",
      " 'reFFT078' 'reFFT079' 'reFFT080' 'reFFT081' 'reFFT082' 'reFFT083'\n",
      " 'reFFT084' 'reFFT085' 'reFFT086' 'reFFT087' 'reFFT088' 'reFFT089'\n",
      " 'reFFT090' 'reFFT091' 'reFFT092' 'reFFT093' 'reFFT094' 'reFFT095'\n",
      " 'reFFT096' 'reFFT097' 'reFFT098' 'reFFT099' 'reFFT100' 'reFFT101'\n",
      " 'reFFT102' 'reFFT103' 'reFFT104' 'reFFT105' 'reFFT106' 'reFFT107'\n",
      " 'reFFT108' 'reFFT109' 'reFFT110' 'reFFT111' 'reFFT112' 'reFFT113'\n",
      " 'reFFT114' 'reFFT115' 'reFFT116' 'reFFT117' 'reFFT118' 'reFFT119'\n",
      " 'reFFT120' 'reFFT121' 'reFFT122' 'reFFT123' 'reFFT124' 'reFFT125'\n",
      " 'reFFT126' 'reFFT127' 'reFFT128' 'reFFT129' 'reFFT130' 'reFFT131'\n",
      " 'reFFT132' 'reFFT133' 'reFFT134' 'reFFT135' 'reFFT136' 'reFFT137'\n",
      " 'reFFT138' 'reFFT139' 'reFFT140' 'reFFT141' 'reFFT142' 'reFFT143'\n",
      " 'reFFT144' 'reFFT145' 'reFFT146' 'reFFT147' 'reFFT148' 'reFFT149'\n",
      " 'reFFT150' 'reFFT151' 'reFFT152' 'reFFT153' 'reFFT154' 'reFFT155'\n",
      " 'reFFT156' 'reFFT157' 'reFFT158' 'reFFT159' 'reFFT160' 'reFFT161'\n",
      " 'reFFT162' 'reFFT163' 'reFFT164' 'reFFT165' 'reFFT166' 'reFFT167'\n",
      " 'reFFT168' 'reFFT169' 'reFFT170' 'reFFT171' 'reFFT172' 'reFFT173'\n",
      " 'reFFT174' 'reFFT175' 'reFFT176' 'reFFT177' 'reFFT178' 'reFFT181'\n",
      " 'reFFT182' 'reFFT183' 'reFFT184' 'reFFT185' 'reFFT186' 'reFFT187'\n",
      " 'reFFT188' 'reFFT189' 'reFFT190' 'reFFT191' 'reFFT192' 'reFFT193'\n",
      " 'reFFT195' 'reFFT196' 'reFFT197' 'reFFT198' 'reFFT199' 'reFFT200'\n",
      " 'reFFT201' 'reFFT202' 'reFFT203' 'reFFT204' 'reFFT205' 'reFFT206'\n",
      " 'reFFT214' 'reFFT215' 'reFFT216' 'reFFT217' 'reFFT218' 'reFFT219'\n",
      " 'reFFT220' 'reFFT221' 'reFFT222' 'reFFT223' 'reFFT224' 'reFFT225'\n",
      " 'reFFT226' 'reFFT227' 'reFFT228' 'reFFT229' 'reFFT230' 'reFFT231'\n",
      " 'reFFT232' 'reFFT233' 'reFFT234' 'reFFT235' 'reFFT236' 'reFFT237'\n",
      " 'reFFT238' 'reFFT239' 'reFFT240' 'reFFT241' 'reFFT242' 'reFFT243'\n",
      " 'reFFT244' 'reFFT245' 'reFFT246' 'reFFT247' 'reFFT248' 'reFFT249'\n",
      " 'reFFT250' 'reFFT251' 'reFFT252' 'reFFT253' 'reFFT254' 'reFFT255'\n",
      " 'reFFT256' 'reFFT257' 'reFFT258' 'reFFT259' 'reFFT260' 'reFFT261'\n",
      " 'reFFT262' 'reFFT263' 'reFFT264' 'reFFT265' 'reFFT266' 'reFFT267'\n",
      " 'reFFT268' 'reFFT269' 'reFFT270' 'reFFT271' 'reFFT272' 'reFFT273'\n",
      " 'reFFT274' 'reFFT275' 'reFFT276' 'reFFT277' 'reFFT279' 'reFFT280'\n",
      " 'reFFT281' 'reFFT282' 'reFFT283' 'reFFT284' 'reFFT285' 'reFFT286'\n",
      " 'reFFT287' 'reFFT288' 'reFFT289' 'reFFT290' 'reFFT291' 'reFFT292'\n",
      " 'reFFT293' 'reFFT294' 'reFFT295' 'reFFT296' 'reFFT297' 'reFFT298'\n",
      " 'reFFT299' 'reFFT300' 'reFFT301' 'reFFT302' 'reFFT303' 'reFFT304'\n",
      " 'reFFT305' 'reFFT306' 'reFFT307' 'reFFT308' 'reFFT309' 'reFFT310'\n",
      " 'reFFT311' 'reFFT312' 'reFFT313' 'reFFT314' 'reFFT315' 'reFFT316'\n",
      " 'reFFT317' 'reFFT318' 'reFFT320' 'reFFT327' 'reFFT328' 'reFFT329'\n",
      " 'reFFT330' 'reFFT331' 'reFFT332' 'reFFT333' 'reFFT334' 'reFFT335'\n",
      " 'reFFT336' 'reFFT337' 'reFFT338' 'reFFT339' 'reFFT340' 'reFFT341'\n",
      " 'reFFT342' 'reFFT343' 'reFFT344' 'reFFT345' 'reFFT346' 'reFFT347'\n",
      " 'reFFT348' 'reFFT349' 'reFFT350' 'reFFT351' 'reFFT352' 'reFFT353'\n",
      " 'reFFT354' 'reFFT355' 'reFFT356' 'reFFT357' 'reFFT358' 'reFFT359'\n",
      " 'reFFT360' 'reFFT361' 'reFFT362' 'reFFT363' 'reFFT364' 'reFFT365'\n",
      " 'reFFT366' 'reFFT367' 'reFFT368' 'reFFT369' 'reFFT370' 'reFFT371'\n",
      " 'reFFT372' 'reFFT373' 'reFFT374' 'reFFT375' 'reFFT376' 'reFFT377'\n",
      " 'reFFT378' 'reFFT379' 'reFFT380' 'reFFT381' 'reFFT382' 'reFFT383'\n",
      " 'reFFT384' 'reFFT385' 'reFFT386' 'reFFT387' 'reFFT388' 'reFFT389'\n",
      " 'reFFT390' 'reFFT391' 'reFFT392' 'reFFT393' 'reFFT394' 'reFFT395'\n",
      " 'reFFT396' 'reFFT397' 'reFFT398' 'reFFT399' 'reFFT400' 'reFFT401'\n",
      " 'reFFT402' 'reFFT403' 'reFFT404' 'reFFT405' 'reFFT406' 'reFFT407'\n",
      " 'reFFT408' 'reFFT409' 'reFFT410' 'reFFT411' 'reFFT412' 'reFFT413'\n",
      " 'reFFT414' 'reFFT415' 'reFFT416' 'reFFT417' 'reFFT418' 'reFFT419'\n",
      " 'reFFT420' 'reFFT421' 'reFFT422' 'reFFT423' 'reFFT424' 'reFFT425'\n",
      " 'reFFT426' 'reFFT427' 'reFFT428' 'reFFT429' 'reFFT430' 'reFFT431'\n",
      " 'reFFT432' 'reFFT433' 'reFFT434' 'reFFT435' 'reFFT436' 'reFFT437'\n",
      " 'reFFT438' 'reFFT439' 'reFFT440' 'reFFT441' 'reFFT442' 'reFFT443'\n",
      " 'reFFT444' 'reFFT445' 'reFFT446' 'reFFT447' 'reFFT448' 'reFFT449'\n",
      " 'reFFT450' 'reFFT451' 'reFFT452' 'reFFT453' 'reFFT454' 'reFFT455'\n",
      " 'reFFT456' 'reFFT457' 'reFFT458' 'reFFT459' 'reFFT460' 'reFFT461'\n",
      " 'reFFT462' 'reFFT463' 'reFFT464' 'reFFT465' 'reFFT466' 'reFFT467'\n",
      " 'reFFT468' 'reFFT469' 'reFFT470' 'reFFT471' 'reFFT478' 'reFFT479'\n",
      " 'reFFT480' 'reFFT486' 'reFFT487' 'reFFT488' 'reFFT489' 'reFFT490'\n",
      " 'reFFT491' 'reFFT492' 'reFFT493' 'reFFT494' 'reFFT495' 'reFFT496'\n",
      " 'reFFT497' 'reFFT498' 'reFFT499' 'reFFT500' 'reFFT501' 'reFFT502'\n",
      " 'reFFT503' 'reFFT504' 'reFFT505' 'reFFT506' 'reFFT507' 'reFFT508'\n",
      " 'reFFT509' 'reFFT510' 'reFFT511' 'reFFT512' 'imFFT000' 'imFFT001'\n",
      " 'imFFT002' 'imFFT003' 'imFFT004' 'imFFT005' 'imFFT006' 'imFFT007'\n",
      " 'imFFT008' 'imFFT009' 'imFFT010' 'imFFT011' 'imFFT012' 'imFFT013'\n",
      " 'imFFT014' 'imFFT015' 'imFFT016' 'imFFT017' 'imFFT018' 'imFFT019'\n",
      " 'imFFT021' 'imFFT022' 'imFFT023' 'imFFT024' 'imFFT025' 'imFFT026'\n",
      " 'imFFT027' 'imFFT028' 'imFFT029' 'imFFT030' 'imFFT031' 'imFFT032'\n",
      " 'imFFT033' 'imFFT034' 'imFFT035' 'imFFT036' 'imFFT037' 'imFFT038'\n",
      " 'imFFT039' 'imFFT040' 'imFFT041' 'imFFT042' 'imFFT043' 'imFFT044'\n",
      " 'imFFT046' 'imFFT047' 'imFFT048' 'imFFT050' 'imFFT051' 'imFFT052'\n",
      " 'imFFT053' 'imFFT054' 'imFFT055' 'imFFT056' 'imFFT057' 'imFFT058'\n",
      " 'imFFT059' 'imFFT060' 'imFFT061' 'imFFT062' 'imFFT063' 'imFFT064'\n",
      " 'imFFT065' 'imFFT066' 'imFFT067' 'imFFT068' 'imFFT069' 'imFFT070'\n",
      " 'imFFT071' 'imFFT072' 'imFFT073' 'imFFT074' 'imFFT075' 'imFFT076'\n",
      " 'imFFT077' 'imFFT078' 'imFFT079' 'imFFT080' 'imFFT081' 'imFFT082'\n",
      " 'imFFT083' 'imFFT084' 'imFFT085' 'imFFT086' 'imFFT087' 'imFFT088'\n",
      " 'imFFT089' 'imFFT090' 'imFFT091' 'imFFT092' 'imFFT093' 'imFFT094'\n",
      " 'imFFT095' 'imFFT096' 'imFFT097' 'imFFT098' 'imFFT099' 'imFFT100'\n",
      " 'imFFT101' 'imFFT102' 'imFFT103' 'imFFT104' 'imFFT105' 'imFFT106'\n",
      " 'imFFT107' 'imFFT108' 'imFFT109' 'imFFT110' 'imFFT111' 'imFFT112'\n",
      " 'imFFT113' 'imFFT114' 'imFFT115' 'imFFT116' 'imFFT117' 'imFFT118'\n",
      " 'imFFT119' 'imFFT120' 'imFFT121' 'imFFT122' 'imFFT123' 'imFFT124'\n",
      " 'imFFT125' 'imFFT126' 'imFFT127' 'imFFT128' 'imFFT129' 'imFFT130'\n",
      " 'imFFT131' 'imFFT132' 'imFFT133' 'imFFT134' 'imFFT135' 'imFFT136'\n",
      " 'imFFT137' 'imFFT138' 'imFFT139' 'imFFT140' 'imFFT142' 'imFFT143'\n",
      " 'imFFT144' 'imFFT145' 'imFFT146' 'imFFT157' 'imFFT158' 'imFFT159'\n",
      " 'imFFT160' 'imFFT161' 'imFFT162' 'imFFT163' 'imFFT165' 'imFFT166'\n",
      " 'imFFT167' 'imFFT168' 'imFFT169' 'imFFT170' 'imFFT171' 'imFFT172'\n",
      " 'imFFT173' 'imFFT174' 'imFFT175' 'imFFT176' 'imFFT177' 'imFFT181'\n",
      " 'imFFT182' 'imFFT188' 'imFFT189' 'imFFT190' 'imFFT191' 'imFFT192'\n",
      " 'imFFT193' 'imFFT194' 'imFFT195' 'imFFT196' 'imFFT197' 'imFFT198'\n",
      " 'imFFT199' 'imFFT201' 'imFFT204' 'imFFT205' 'imFFT206' 'imFFT207'\n",
      " 'imFFT208' 'imFFT209' 'imFFT210' 'imFFT218' 'imFFT219' 'imFFT225'\n",
      " 'imFFT226' 'imFFT231' 'imFFT232' 'imFFT233' 'imFFT234' 'imFFT235'\n",
      " 'imFFT236' 'imFFT237' 'imFFT238' 'imFFT239' 'imFFT240' 'imFFT241'\n",
      " 'imFFT242' 'imFFT243' 'imFFT244' 'imFFT245' 'imFFT246' 'imFFT247'\n",
      " 'imFFT248' 'imFFT250' 'imFFT252' 'imFFT276' 'imFFT277' 'imFFT278'\n",
      " 'imFFT279' 'imFFT280' 'imFFT281' 'imFFT290' 'imFFT291' 'imFFT292'\n",
      " 'imFFT311' 'imFFT312' 'imFFT313' 'imFFT322' 'imFFT330' 'imFFT357'\n",
      " 'imFFT358' 'imFFT359' 'imFFT360' 'imFFT361' 'imFFT362' 'imFFT363'\n",
      " 'imFFT364' 'imFFT365' 'imFFT366' 'imFFT367' 'imFFT368' 'imFFT369'\n",
      " 'imFFT370' 'imFFT371' 'imFFT372' 'imFFT373' 'imFFT374' 'imFFT375'\n",
      " 'imFFT376' 'imFFT377' 'imFFT378' 'imFFT379' 'imFFT380' 'imFFT381'\n",
      " 'imFFT382' 'imFFT383' 'imFFT385' 'imFFT386' 'imFFT387' 'imFFT391'\n",
      " 'imFFT393' 'imFFT394' 'imFFT399' 'imFFT400' 'imFFT401' 'imFFT402'\n",
      " 'imFFT403' 'imFFT404' 'imFFT405' 'imFFT406' 'imFFT407' 'imFFT408'\n",
      " 'imFFT409' 'imFFT410' 'imFFT411' 'imFFT485' 'imFFT487' 'imFFT488'\n",
      " 'imFFT491' 'imFFT492' 'imFFT496']\n"
     ]
    }
   ],
   "source": [
    "fn = np.array(full_names)\n",
    "print fn.shape\n",
    "tmp = fn[:,0].astype(int).tolist()\n",
    "# print tmp\n",
    "print np.array(featnames)[tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
