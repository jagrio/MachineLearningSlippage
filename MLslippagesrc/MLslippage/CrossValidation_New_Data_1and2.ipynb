{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "import time\n",
    "start_time = time.time()\n",
    "from copy import deepcopy, copy\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import shutil\n",
    "import os\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "# from featext2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "#matplotlib qt\n",
    "# inline (suitable for ipython only, shown inside browser!) or qt (suitable in general, shown in external window!)\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mpl_toolkits.mplot3d import Axes3D #, axes3d\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, ParameterGrid, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.decomposition import PCA, KernelPCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LassoCV, RandomizedLasso\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2, f_classif, mutual_info_classif, SelectFdr\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import datetime\n",
    "import urllib\n",
    "import tarfile\n",
    "import joblib\n",
    "from joblib import Parallel, delayed, Memory\n",
    "from tempfile import mkdtemp\n",
    "import copy_reg\n",
    "import types\n",
    "import itertools\n",
    "from itertools import compress\n",
    "from collections import Counter\n",
    "\n",
    "#import multiprocessing\n",
    "def _pickle_method(m):\n",
    "    if m.im_self is None:\n",
    "        return getattr, (m.im_class, m.im_func.func_name)\n",
    "    else:\n",
    "        return getattr, (m.im_self, m.im_func.func_name)\n",
    "copy_reg.pickle(types.MethodType, _pickle_method)\n",
    "\n",
    "h = .2  # step size in the mesh\n",
    "names = [\"NearNb\", \"RBFSVM1\", \"NaiveBayes\", \"MLP1\", \"Log.Regr\", \"RandFor\", \"AdaBoost\", \"EnsembleMLP\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    SVC(gamma='auto', C=1),\n",
    "    MLPClassifier(solver='lbfgs',alpha=1e-4,hidden_layer_sizes=(10,10),random_state=1,verbose=True),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "parameters_clf = [{'n_neighbors':range(3,10)},\n",
    "              {'kernel':['rbf'], 'C':[0.01,0.1,1,10,100,1000]},\n",
    "              {'solver':['lbfgs'], 'alpha':[1e-5,1e-2], 'hidden_layer_sizes':[(10,10),(50,50),(100,100)]},\n",
    "              {'max_depth':[4,7,10,20],'n_estimators':[5,10,20],'max_features':[20,35,50]},\n",
    "              {'solver':['lbfgs'], 'alpha':[1e-5], 'hidden_layer_sizes':[(len(names)-1,len(names)-1),(len(names)-1,2)]}\n",
    "             ]\n",
    "makepipe_parameters_clf = [{'classifier__'+key:p[key] for key in p} for p in parameters_clf]\n",
    "makepipe_parameters_clf += [{'feature_selection__k': (750,500,100), 'feature_selection__score_func': [mutual_info_classif]},\n",
    "                            {'decomp__n_components': (100,50)}]\n",
    "metric = ['accuracy','f1']\n",
    "dataset = 0 # all datasets (0), dataset 1-2 (1), dataset 3 (2), dataset4 (3)\n",
    "download = 1 # Download pre-computed (1) data or compute them anew (0)\n",
    "window = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pipe_clf(scaler,feature_selection,decomp,clf):\n",
    "    order = 1\n",
    "# order = 1 : first perform feature selection and then apply PCA\n",
    "# order = 0 : first apply PCA and then reduce the transformed features\n",
    "    if order:\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                    ('feature_selection', feature_selection),\n",
    "                    ('decomp', decomp),         \n",
    "                    ('classifier', clf) ])\n",
    "#     else:\n",
    "#         pipeline = Pipeline([('scaler', scaler),\n",
    "#                     ('decomp', decomp ),                 \n",
    "#                     ('feature_selection', feature_selection),        \n",
    "#                     ('classifier', clf) ])\n",
    "    return pipeline\n",
    "###########################################################################################\n",
    "def make_pipe(scaler,feature_selection,decomp,order):\n",
    "    if order:\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                    ('feature_selection', feature_selection),\n",
    "                    ('decomp', decomp),         \n",
    "                     ])\n",
    "    else:\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                    ('decomp', decomp ),                 \n",
    "                    ('feature_selection', feature_selection),        \n",
    "                     ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feat_id(feat_ind, printit = 0): \n",
    "    sample_window = 1024\n",
    "    ##  features:                                                                                  ||      if         ##\n",
    "##  |----------> time domain      :                                                            || samples = 1024  ##\n",
    "##  |------------|---> phinyomark : 11+3{shist} -----------------------------> = 14+0.0samples ||             14  ##\n",
    "##  |------------|---> golz       : 10+samples{acrol} -----------------------> = 10+1.0samples ||           1034  ##\n",
    "##  |----------> frequency domain :                                                                               ##\n",
    "##  |------------|---> phinyomark : 3{arco}+4{mf}+3(samples/2+1){RF,IF} -----> =  9+1.0samples ||           1033  ##\n",
    "##  |------------|---> golz       : 2(samples/2+1){AF,PF} -------------------> =  2+1.0samples ||           1027  ##\n",
    "##  |------------|--------|-------alltogether--------------------------------> = 35+3.0samples || numfeat = 3108  ##\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "    norm_time_phin = range(0,14)\n",
    "    norm_freq_phin = range(norm_time_phin[-1] + 1, norm_time_phin[-1] + 9 + sample_window + 1)\n",
    "    norm_time_golz = range(norm_freq_phin[-1] + 1, norm_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    norm_freq_golz = range(norm_time_golz[-1] + 1, norm_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    norm_time_feats = norm_time_phin + norm_time_golz\n",
    "    norm_freq_feats = norm_freq_phin + norm_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    norm_feats = norm_time_feats + norm_freq_feats\n",
    "#     print(norm_time_phin,norm_time_golz)\n",
    "\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "#     np.arange(norm_feats[-1]+1,norm_feats[-1]+1+len(norm_feats))\n",
    "    disp = norm_feats[-1]+1\n",
    "    ftfn_time_phin = range(disp ,disp + 14)\n",
    "    ftfn_freq_phin = range(ftfn_time_phin[-1] + 1, ftfn_time_phin[-1] + 9 + sample_window + 1)\n",
    "    ftfn_time_golz = range(ftfn_freq_phin[-1] + 1, ftfn_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    ftfn_freq_golz = range(ftfn_time_golz[-1] + 1, ftfn_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    ftfn_time_feats = ftfn_time_phin + ftfn_time_golz\n",
    "    ftfn_freq_feats = ftfn_freq_phin + ftfn_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    ftfn_feats = ftfn_time_feats + ftfn_freq_feats\n",
    "\n",
    "    # create the final \"reference dictionary\"\n",
    "    id_list = [np.zeros((len(ftfn_feats + norm_feats),1)) for i in range(3)] #3 np.arrays, id_list[0] = level 1 etc\n",
    "    id_list[0][:norm_feats[-1]+1] = 0 # 0 signifies norm / 1 signifies ft/fn\n",
    "    id_list[0][norm_feats[-1]+1:] = 1\n",
    "\n",
    "    id_list[1][:norm_time_phin[-1]+1] = 0 #0 signifies time / 1 signifies freq\n",
    "    id_list[1][norm_time_phin[-1]+1:norm_freq_phin[-1]+1] = 1\n",
    "    id_list[1][norm_freq_phin[-1]+1:norm_time_golz[-1]+1] = 0\n",
    "    id_list[1][norm_time_golz[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[1][norm_freq_golz[-1]+1:ftfn_time_phin[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_phin[-1]+1:ftfn_freq_phin[-1]+1] = 1\n",
    "    id_list[1][ftfn_freq_phin[-1]+1:ftfn_time_golz[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_golz[-1]+1:] = 1\n",
    "\n",
    "    id_list[2][:norm_freq_phin[-1]+1] = 0 #0 signifies phinyomark / 1 signifies golz\n",
    "    id_list[2][norm_freq_phin[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[2][norm_freq_golz[-1]+1:ftfn_freq_phin[-1]+1] = 0\n",
    "    id_list[2][ftfn_freq_phin[-1]+1:] = 1 \n",
    "    \n",
    "    full_path_id = [np.zeros((len(feat_ind),5)) for i in range(len(feat_ind))]\n",
    "   \n",
    "    for ind, val in enumerate(feat_ind):\n",
    "\n",
    "        full_path_id[ind] = [val, id_list[2][val], id_list[1][val], id_list[0][val]]\n",
    "\n",
    "        if (printit==1):\n",
    "            if(full_path_id[ind][1]==0):\n",
    "                lvl3 = 'Phin'\n",
    "            else:\n",
    "                lvl3 = 'Golz'\n",
    "            if(full_path_id[ind][2]==0):\n",
    "                lvl2 = 'Time'\n",
    "            else:\n",
    "                lvl2 = 'Freq'\n",
    "            if(full_path_id[ind][3]==0):\n",
    "                lvl1 = 'Norm'\n",
    "            else:\n",
    "                lvl1 = 'Ft/Fn'\n",
    "            print(feat_ind[ind],featnames[val%(norm_feats[-1]+1)],lvl3,lvl2,lvl1)\n",
    "    \n",
    "    return(full_path_id,norm_time_feats,norm_freq_feats)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feat_occ(feat_masks):\n",
    "    #get the number of occurences for each feature after SelectKbest\n",
    "#     print(\"If it ain't working, just make sure you're adding the lists instead of concatenating them,\")\n",
    "#     print(\"if the input isn't a single list you'll get the unhashable error\")\n",
    "    feat_occ = Counter(feat_masks)\n",
    "    return feat_occ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################## Feature Names ###########################################################\n",
    "####################################################################################################################\n",
    "##  features:                                                                                  ||      if         ##\n",
    "##  |----------> time domain      :                                                            || samples = 1024  ##\n",
    "##  |------------|---> phinyomark : 11+3{shist} -----------------------------> = 14+0.0samples ||             14  ##\n",
    "##  |------------|---> golz       : 10+samples{acrol} -----------------------> = 10+1.0samples ||           1034  ##\n",
    "##  |----------> frequency domain :                                                                               ##\n",
    "##  |------------|---> phinyomark : 3{arco}+4{mf}+3(samples/2+1){RF,IF} -----> =  9+1.0samples ||           1033  ##\n",
    "##  |------------|---> golz       : 2(samples/2+1){AF,PF} -------------------> =  2+1.0samples ||           1027  ##\n",
    "##  |------------|--------|-------alltogether--------------------------------> = 35+3.0samples || numfeat = 3108  ##\n",
    "####################################################################################################################\n",
    "## Time Domain Phinyomark feats\n",
    "featnames = ['intsgnl', 'meanabs', 'meanabsslp', 'ssi', 'var', 'rms', 'rng', 'wavl', 'zerox', 'ssc', 'wamp', \n",
    "             'shist1', 'shist2', 'shist3']                                                   # 11+3{shist}\n",
    "## Frequency Domain Phinyomark feats\n",
    "featnames += ['arco1', 'arco2', 'arco3', 'mnf', 'mdf', 'mmnf', 'mmdf']                       # 3{arco}+4{mf}\n",
    "featnames += ['reFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{RF}\n",
    "featnames += ['imFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{IF}\n",
    "## Time Domain Golz feats\n",
    "featnames += ['meanv', 'stdr', 'mx', 'rngx', 'rngy', 'med', 'hjorth', 'sentr', 'se', 'ssk']  # 10\n",
    "featnames += ['acrol{:04d}'.format(i) for i in range(window)]                                # samples{acrol}\n",
    "## Frequency Domain Golz feats\n",
    "featnames += ['amFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{AF}\n",
    "featnames += ['phFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{PF}\n",
    "# featnames += ['ffaf']                                                                        # 1{ffaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temps = range(len(featnames))\n",
    "_,tf,ff = get_feat_id(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8820, 3107) (8820,)\n",
      "(8820, 3107) (8820,)\n",
      "(8820, 6214) (8820,)\n"
     ]
    }
   ],
   "source": [
    "# datasets = np.load('newfeatures_newdata_NOsample_1024_20_10_10000_XYsplit.npz')\n",
    "# X = datasets['Xsp']\n",
    "# Y = datasets['Ysp']\n",
    "\n",
    "# ================ 21/07\n",
    "# filename = 'tmp/features/1024_20/newfeatures_testdata_NOsample_trans_1024_20_10_10000_XYsplit.npz'\n",
    "# filename1 = 'tmp/features/1024_20/newfeatures_newdata2_NOsample_trans_1024_20_10_10000_XYsplit.npz'\n",
    "# Xsp = np.load(filename)['Xsp'][0:2,:]\n",
    "# Ysp = np.load(filename)['Ysp'][0:2]\n",
    "# Xsp1 = np.load(filename1)['Xsp'][2,:]\n",
    "# Ysp1 = np.load(filename1)['Ysp'][2]\n",
    "# ================ 27/07\n",
    "filename = 'tmp/features/1024_20/newfeatures_newdata1and2_NOsample_1024_20_10_10000_XYsplit.npz'\n",
    "Xsp = np.load(filename)['Xsp'][1,:]\n",
    "Ysp = np.load(filename)['Ysp'][1][:-4]\n",
    "for i in range(len(Xsp)):\n",
    "    Xsp[i] = Xsp[i][:-4,:]\n",
    "    print Xsp[i].shape, Ysp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for j in range(Xsp1.shape[0]):\n",
    "#     Xsp1[j] = Xsp1[j][:8730,:]\n",
    "# Ysp1 = Ysp1[:8730]\n",
    "# print([ Xsp[i][j].shape for i in range(len(Xsp)) for j in range(len(Xsp[i]))])\n",
    "# print([ Xsp[i].shape for i in range(len(Xsp))])\n",
    "# print([ Xsp1[j].shape for j in range(len(Xsp1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================== 21/07 \n",
    "# X_new = {}\n",
    "# for i in range(Xsp.shape[1]):\n",
    "#     X_new[i] = np.concatenate((Xsp[0][i][::2,:],Xsp[1][i][::2,:]),axis=0)\n",
    "# X_new = [i for _,i in X_new.items()]\n",
    "# #X_new = np.array(X_new)\n",
    "# #print X_new.shape\n",
    "# for i in range(len(X_new)):\n",
    "#     print X_new[i].shape\n",
    "# Y_new = np.concatenate((Ysp[0][::2],Ysp[1][::2]),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newfile='2_fingers_6_surfaces.npz'\n",
    "# np.savez(newfile,X_new=X_new,Y_new=Y_new,Xsp1=Xsp1[2],Ysp1=Ysp1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def surface_split1(data_X, data_Y):\n",
    "    surfaces = np.split(data_X,6)\n",
    "    surf_labels = np.split(data_Y,6)\n",
    "#     surfaces = [np.empty_like(surfaces_pre[i]) for i in range(6)]\n",
    "#     surf_labels = [np.empty_like(surf_labels_pre[i]) for i in range(6)]\n",
    "\n",
    "#     for i in range(6):\n",
    "# #         inds = range(6)\n",
    "#         surfaces[i] = np.concatenate((surfaces_pre[i], surfaces_pre[inds[1]]), axis = 0)\n",
    "#         surf_labels[i] = np.concatenate((surf_labels_pre[i], surf_labels_pre[inds[1]]), axis = 0)\n",
    "    return surfaces, surf_labels\n",
    "\n",
    "def surface_split2(data_X, data_Y):\n",
    "    surfaces_pre = np.split(data_X,12)\n",
    "    surf_labels_pre = np.split(data_Y,12)\n",
    "    surfaces = [np.empty_like(surfaces_pre[i]) for i in range(6)]\n",
    "    surf_labels = [np.empty_like(surf_labels_pre[i]) for i in range(6)]\n",
    "\n",
    "    for i in range(6):\n",
    "        inds = range(i,12,6)\n",
    "        surfaces[inds[0]] = np.concatenate((surfaces_pre[inds[0]], surfaces_pre[inds[1]]), axis = 0)\n",
    "        surf_labels[inds[0]] = np.concatenate((surf_labels_pre[inds[0]], surf_labels_pre[inds[1]]), axis = 0)\n",
    "    return surfaces, surf_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#====== 25/07\n",
    "def feat_subsets(data,fs_ind):\n",
    "#     data = X_new[fs_ind]\n",
    "    _,tf,ff = get_feat_id(range(len(featnames)))\n",
    "    ofs = 3107\n",
    "    amfft_inds = []\n",
    "    temp1 = deepcopy(data)\n",
    "    \n",
    "    for i in range(len(featnames)):\n",
    "        if (featnames[i].startswith('amFFT')):\n",
    "            amfft_inds.append(i)\n",
    "\n",
    "    if (fs_ind == 2):\n",
    "        ff2 = [ff[i]+ofs for i in range(len(ff))]\n",
    "        tf2 = [tf[i]+ofs for i in range(len(tf))]\n",
    "        amfft2 = [amfft_inds[i]+ofs for i in range(len(amfft_inds))]\n",
    "        freqf = ff2 + ff\n",
    "        timef = tf2 + tf\n",
    "        amfft = amfft_inds + amfft2\n",
    "    else:\n",
    "        freqf = ff\n",
    "        timef = tf\n",
    "        amfft = amfft_inds\n",
    "\n",
    "    X_amfft = temp1[:,amfft]\n",
    "    X_time = np.delete(temp1,freqf,axis=1)\n",
    "    X_freq_all = np.delete(temp1,timef,axis=1)\n",
    "    X_both = data\n",
    "    return X_amfft, X_freq_all, X_time, X_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 6\n",
      "0 1 6\n",
      "0 2 6\n",
      "0 3 6\n",
      "0 4 6\n",
      "0 5 6\n",
      "0 6 6\n",
      "1 0 6\n",
      "1 1 6\n",
      "1 2 6\n",
      "1 3 6\n",
      "1 4 6\n",
      "1 5 6\n",
      "1 6 6\n",
      "2 0 6\n",
      "2 1 6\n",
      "2 2 6\n",
      "2 3 6\n",
      "2 4 6\n",
      "2 5 6\n",
      "2 6 6\n",
      "(4, 6, 3) (1470, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "# =================== 21/07\n",
    "# surf1, surflab1 = surface_split(Xsp1[2][2], Ysp1[2]) \n",
    "# surf, surfla = [], []\n",
    "# for i in range(Xsp1.shape[0]): # for each featureset\n",
    "#     surf1, surfla1 = surface_split(X_new[i], Y_new)\n",
    "#     surf2, surfla2 = surface_split(Xsp1[i], Ysp1)\n",
    "#     tmpsurf = surf1 + surf2\n",
    "#     tmpsurfla = surfla1 + surfla2\n",
    "#     tmpsurfsubfeat = []\n",
    "#     for j in range(len(tmpsurf)): # for each surface\n",
    "#         tmpsurfsubfeat.append(feat_subsets(tmpsurf[j],i)) # keep all subfeaturesets\n",
    "# #     surf.append(surf1 + surf2)\n",
    "#     surf.append(tmpsurfsubfeat)\n",
    "#     surfla.append(surfla1 + surfla2)\n",
    "# surf = np.array(surf).transpose() # array dims: (subfeaturesets, surfaces, featuresets)\n",
    "# surfla = np.array(surfla).transpose()\n",
    "# print surf.shape, surfla.shape\n",
    "\n",
    "# =================== 27/07\n",
    "surf, surfla = [], []\n",
    "for i in range(Xsp.shape[0]): # for each featureset\n",
    "    surf1, surfla1 = surface_split1(Xsp[i], Ysp)\n",
    "    tmpsurf = surf1\n",
    "    tmpsurfla = surfla1\n",
    "    tmpsurfsubfeat = []\n",
    "    for j in range(len(tmpsurf)+1): # for each surface\n",
    "        print i,j,len(surf1)\n",
    "        if j == len(tmpsurf):\n",
    "            tmpsurfsubfeat.append(feat_subsets(tmpsurf[j-1][:-1,:],i)) # keep all subfeaturesets\n",
    "        else:\n",
    "            tmpsurfsubfeat.append(feat_subsets(tmpsurf[j],i)) # keep all subfeaturesets\n",
    "#     surf.append(surf1 + surf2)\n",
    "    surf.append(tmpsurfsubfeat)\n",
    "    surfla.append(surfla1)\n",
    "# surf[-1][-1] = surf[-1][-1][:-1,:]\n",
    "# surfla[-1][-1] = surfla[-1][-1][:-1]\n",
    "surf = np.array(surf).transpose()[:,:-1,:] # array dims: (subfeaturesets, surfaces, featuresets)\n",
    "surfla = np.array(surfla).transpose()\n",
    "print surf.shape, surfla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surffile = '2_fingers_6_surfaces.npz'\n",
    "np.savez(surffile,surf=surf,surfla=surfla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 3) (1470, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "surf = np.load(surffile)['surf']\n",
    "surfla = np.load(surffile)['surfla']\n",
    "print surf.shape, surfla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1470, 6214) (1470,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f78a7d57190>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f789c6bb290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print surf[-1,-1,-1].shape, surfla[:,-1,-1].shape\n",
    "plt.plot(surf[-1,-1,-1][:,0]/np.max(surf[-1,-1,-1][:,0],axis=0))\n",
    "plt.hold\n",
    "plt.plot(surfla[:,-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "[[ 0.9171943   0.0828057 ]\n",
      " [ 0.08659248  0.91340752]]\n",
      "0 0 0 1\n",
      "[[ 0.96688742  0.03311258]\n",
      " [ 0.53313253  0.46686747]]\n",
      "0 0 0 2\n",
      "[[ 0.96907216  0.03092784]\n",
      " [ 0.33981337  0.66018663]]\n",
      "0 0 0 3\n",
      "[[ 0.80550344  0.19449656]\n",
      " [ 0.1395881   0.8604119 ]]\n",
      "0 0 0 4\n",
      "[[ 0.90955414  0.09044586]\n",
      " [ 0.46865672  0.53134328]]\n",
      "0 0 0 5\n",
      "[[ 0.80509554  0.19490446]\n",
      " [ 0.1380597   0.8619403 ]]\n",
      "0 0 1 0\n",
      "[[ 0.7414665   0.2585335 ]\n",
      " [ 0.00955414  0.99044586]]\n",
      "0 0 1 1\n",
      "[[ 0.89573954  0.10426046]\n",
      " [ 0.10922867  0.89077133]]\n",
      "0 0 1 2\n",
      "[[ 0.85438144  0.14561856]\n",
      " [ 0.04898911  0.95101089]]\n",
      "0 0 1 3\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'tmpresults2/fs_0_subfs_0_tr_1_fs_3.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-a823318bce8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mfileid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tmpresults2/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jagrio/.local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'tmpresults2/fs_0_subfs_0_tr_1_fs_3.npz'"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        for k in range(6):\n",
    "            for k2 in range(6):\n",
    "                fileid = 'tmpresults2/'+filename(i,j,k,k2)+'.npz'\n",
    "                print i,j,k,k2\n",
    "                print np.load(fileid)['cm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "[[ 0.9171943   0.0828057 ]\n",
      " [ 0.08659248  0.91340752]]\n",
      "0 0 0 1\n",
      "[[ 0.96688742  0.03311258]\n",
      " [ 0.53313253  0.46686747]]\n",
      "0 0 0 2\n",
      "[[ 0.96907216  0.03092784]\n",
      " [ 0.33981337  0.66018663]]\n",
      "0 0 0 3\n",
      "[[ 0.80550344  0.19449656]\n",
      " [ 0.1395881   0.8604119 ]]\n",
      "0 0 0 4\n",
      "[[ 0.90955414  0.09044586]\n",
      " [ 0.46865672  0.53134328]]\n",
      "0 0 0 5\n",
      "[[ 0.80509554  0.19490446]\n",
      " [ 0.1380597   0.8619403 ]]\n",
      "0 0 1 0\n",
      "[[ 0.7414665   0.2585335 ]\n",
      " [ 0.00955414  0.99044586]]\n",
      "0 0 1 1\n",
      "[[ 0.89573954  0.10426046]\n",
      " [ 0.10922867  0.89077133]]\n",
      "0 0 1 2\n",
      "[[ 0.85438144  0.14561856]\n",
      " [ 0.04898911  0.95101089]]\n",
      "0 0 1 3\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'tmpresults2/fs_0_subfs_0_tr_1_fs_3.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-a823318bce8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mfileid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tmpresults2/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jagrio/.local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'tmpresults2/fs_0_subfs_0_tr_1_fs_3.npz'"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        for k in range(6):\n",
    "            for k2 in range(6):\n",
    "                fileid = 'tmpresults2/'+filename(i,j,k,k2)+'.npz'\n",
    "                print i,j,k,k2\n",
    "                print np.load(fileid)['cm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "print surf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 2 0 0\n",
      "0 3 0 0\n",
      "0 0 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "0 0 0 2\n",
      "Fitting on 0, testing on 2...\n",
      "0 0 0 3\n",
      "Fitting on 0, testing on 3...\n",
      "0 0 0 4\n",
      "Fitting on 0, testing on 4...\n",
      "0 2 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "0 0 0 5\n",
      "Fitting on 0, testing on 5...\n",
      "0 0 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "0 2 0 2\n",
      "Fitting on 0, testing on 2...\n",
      "0 0 1 1\n",
      "0 2 0 3\n",
      "Fitting on 0, testing on 3...\n",
      "0 2 0 4\n",
      "Fitting on 0, testing on 4...\n",
      "0 0 1 2\n",
      "Fitting on 1, testing on 2...\n",
      "0 0 1 3\n",
      "Fitting on 1, testing on 3...\n",
      "0 2 0 5\n",
      "Fitting on 0, testing on 5...\n",
      "0 1 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "0 0 1 4\n",
      "Fitting on 1, testing on 4...\n",
      "0 2 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "0 0 1 5\n",
      "Fitting on 1, testing on 5...\n",
      "0 0 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "0 2 1 1\n",
      "0 0 2 1\n",
      "Fitting on 2, testing on 1...\n",
      "0 1 0 2\n",
      "Fitting on 0, testing on 2...\n",
      "0 0 2 2\n",
      "0 3 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "0 1 0 3\n",
      "Fitting on 0, testing on 3...\n",
      "0 0 2 3\n",
      "Fitting on 2, testing on 3...\n",
      "0 0 2 4\n",
      "Fitting on 2, testing on 4...\n",
      "0 0 2 5\n",
      "Fitting on 2, testing on 5...\n",
      "0 1 0 4\n",
      "Fitting on 0, testing on 4...\n",
      "0 2 1 2\n",
      "Fitting on 1, testing on 2...\n",
      "0 0 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "0 3 0 2\n",
      "Fitting on 0, testing on 2...\n",
      "0 0 3 1\n",
      "Fitting on 3, testing on 1...\n",
      "0 2 1 3\n",
      "Fitting on 1, testing on 3...\n",
      "0 0 3 2\n",
      "Fitting on 3, testing on 2...\n",
      "0 0 3 3\n",
      "0 1 0 5\n",
      "Fitting on 0, testing on 5...\n",
      "0 2 1 4\n",
      "Fitting on 1, testing on 4...\n",
      "0 2 1 5\n",
      "Fitting on 1, testing on 5...\n",
      "0 3 0 3\n",
      "Fitting on 0, testing on 3...\n",
      "0 1 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "0 0 3 4\n",
      "Fitting on 3, testing on 4...\n",
      "0 2 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "0 0 3 5\n",
      "Fitting on 3, testing on 5...\n",
      "0 0 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "0 2 2 1\n",
      "Fitting on 2, testing on 1...\n",
      "0 0 4 1\n",
      "Fitting on 4, testing on 1...\n",
      "0 1 1 1\n",
      "0 2 2 2\n",
      "0 0 4 2\n",
      "Fitting on 4, testing on 2...\n",
      "0 3 0 4\n",
      "Fitting on 0, testing on 4...\n",
      "0 0 4 3\n",
      "Fitting on 4, testing on 3...\n",
      "0 0 4 4\n",
      "0 0 4 5\n",
      "Fitting on 4, testing on 5...\n",
      "0 3 0 5\n",
      "Fitting on 0, testing on 5...\n",
      "0 0 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "0 2 2 3\n",
      "Fitting on 2, testing on 3...\n",
      "0 0 5 1\n",
      "Fitting on 5, testing on 1...\n",
      "0 0 5 2\n",
      "Fitting on 5, testing on 2...\n",
      "0 2 2 4\n",
      "Fitting on 2, testing on 4...\n",
      "0 0 5 3\n",
      "Fitting on 5, testing on 3...\n",
      "0 0 5 4\n",
      "Fitting on 5, testing on 4...\n",
      "0 2 2 5\n",
      "Fitting on 2, testing on 5...\n",
      "0 3 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "0 0 5 5\n",
      "0 2 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "0 1 1 2\n",
      "Fitting on 1, testing on 2...\n",
      "0 2 3 1\n",
      "Fitting on 3, testing on 1...\n",
      "0 3 1 1\n",
      "0 2 3 2\n",
      "Fitting on 3, testing on 2...\n",
      "0 1 1 3\n",
      "Fitting on 1, testing on 3...\n",
      "0 2 3 3\n",
      "0 1 1 4\n",
      "Fitting on 1, testing on 4...\n",
      "0 1 1 5\n",
      "Fitting on 1, testing on 5...\n",
      "0 2 3 4\n",
      "Fitting on 3, testing on 4...\n",
      "0 2 3 5\n",
      "Fitting on 3, testing on 5...\n",
      "0 1 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "0 2 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "0 2 4 1\n",
      "Fitting on 4, testing on 1...\n",
      "0 1 2 1\n",
      "Fitting on 2, testing on 1...\n",
      "0 2 4 2\n",
      "Fitting on 4, testing on 2...\n",
      "0 2 4 3\n",
      "Fitting on 4, testing on 3...\n",
      "0 1 2 2\n",
      "0 2 4 4\n",
      "0 3 1 2\n",
      "Fitting on 1, testing on 2...\n",
      "0 3 1 3\n",
      "Fitting on 1, testing on 3...\n",
      "0 2 4 5\n",
      "Fitting on 4, testing on 5...\n",
      "0 2 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "0 2 5 1\n",
      "Fitting on 5, testing on 1...\n",
      "0 3 1 4\n",
      "Fitting on 1, testing on 4...\n",
      "0 2 5 2\n",
      "Fitting on 5, testing on 2...\n",
      "0 1 2 3\n",
      "Fitting on 2, testing on 3...\n",
      "0 2 5 3\n",
      "Fitting on 5, testing on 3...\n",
      "0 2 5 4\n",
      "Fitting on 5, testing on 4...\n",
      "0 1 2 4\n",
      "Fitting on 2, testing on 4...\n",
      "0 3 1 5\n",
      "Fitting on 1, testing on 5...\n",
      "0 2 5 5\n",
      "0 1 2 5\n",
      "Fitting on 2, testing on 5...\n",
      "0 3 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "0 1 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "0 1 3 1\n",
      "Fitting on 3, testing on 1...\n",
      "0 3 2 1\n",
      "Fitting on 2, testing on 1...\n",
      "0 1 3 2\n",
      "Fitting on 3, testing on 2...\n",
      "0 3 2 2\n",
      "0 1 3 3\n",
      "0 1 3 4\n",
      "Fitting on 3, testing on 4...\n",
      "0 1 3 5\n",
      "Fitting on 3, testing on 5...\n",
      "0 3 2 3\n",
      "Fitting on 2, testing on 3...\n",
      "0 1 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "0 1 4 1\n",
      "Fitting on 4, testing on 1...\n",
      "0 3 2 4\n",
      "Fitting on 2, testing on 4...\n",
      "0 1 4 2\n",
      "Fitting on 4, testing on 2...\n",
      "0 3 2 5\n",
      "Fitting on 2, testing on 5...\n",
      "0 1 4 3\n",
      "Fitting on 4, testing on 3...\n",
      "0 1 4 4\n",
      "0 3 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "0 3 3 1\n",
      "Fitting on 3, testing on 1...\n",
      "0 3 3 2\n",
      "Fitting on 3, testing on 2...\n",
      "0 1 4 5\n",
      "Fitting on 4, testing on 5...\n",
      "0 3 3 3\n",
      "0 1 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "0 1 5 1\n",
      "Fitting on 5, testing on 1...\n",
      "0 1 5 2\n",
      "Fitting on 5, testing on 2...\n",
      "0 1 5 3\n",
      "Fitting on 5, testing on 3...\n",
      "0 1 5 4\n",
      "Fitting on 5, testing on 4...\n",
      "0 1 5 5\n",
      "0 3 3 4\n",
      "Fitting on 3, testing on 4...\n",
      "0 3 3 5\n",
      "Fitting on 3, testing on 5...\n",
      "0 3 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "0 3 4 1\n",
      "Fitting on 4, testing on 1...\n",
      "0 3 4 2\n",
      "Fitting on 4, testing on 2...\n",
      "0 3 4 3\n",
      "Fitting on 4, testing on 3...\n",
      "0 3 4 4\n",
      "0 3 4 5\n",
      "Fitting on 4, testing on 5...\n",
      "0 3 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "0 3 5 1\n",
      "Fitting on 5, testing on 1...\n",
      "0 3 5 2\n",
      "Fitting on 5, testing on 2...\n",
      "0 3 5 3\n",
      "Fitting on 5, testing on 3...\n",
      "0 3 5 4\n",
      "Fitting on 5, testing on 4...\n",
      "0 3 5 5\n",
      "1 0 0 0\n",
      "1 1 0 0\n",
      "1 2 0 0\n",
      "1 3 0 0\n",
      "1 0 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "1 0 0 2\n",
      "Fitting on 0, testing on 2...\n",
      "1 0 0 3\n",
      "Fitting on 0, testing on 3...\n",
      "1 0 0 4\n",
      "Fitting on 0, testing on 4...\n",
      "1 0 0 5\n",
      "Fitting on 0, testing on 5...\n",
      "1 2 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "1 0 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "1 2 0 2\n",
      "Fitting on 0, testing on 2...\n",
      "1 0 1 1\n",
      "1 2 0 3\n",
      "Fitting on 0, testing on 3...\n",
      "1 2 0 4\n",
      "Fitting on 0, testing on 4...\n",
      "1 0 1 2\n",
      "Fitting on 1, testing on 2...\n",
      "1 1 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "1 0 1 3\n",
      "Fitting on 1, testing on 3...\n",
      "1 2 0 5\n",
      "Fitting on 0, testing on 5...\n",
      "1 0 1 4\n",
      "Fitting on 1, testing on 4...\n",
      "1 0 1 5\n",
      "Fitting on 1, testing on 5...\n",
      "1 2 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "1 0 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "1 1 0 2\n",
      "Fitting on 0, testing on 2...\n",
      "1 0 2 1\n",
      "Fitting on 2, testing on 1...\n",
      "1 2 1 1\n",
      "1 0 2 2\n",
      "1 1 0 3\n",
      "Fitting on 0, testing on 3...\n",
      "1 3 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "1 0 2 3\n",
      "Fitting on 2, testing on 3...\n",
      "1 0 2 4\n",
      "Fitting on 2, testing on 4...\n",
      "1 1 0 4\n",
      "Fitting on 0, testing on 4...\n",
      "1 0 2 5\n",
      "Fitting on 2, testing on 5...\n",
      "1 0 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "1 2 1 2\n",
      "Fitting on 1, testing on 2...\n",
      "1 3 0 2\n",
      "Fitting on 0, testing on 2...\n",
      "1 0 3 1\n",
      "Fitting on 3, testing on 1...\n",
      "1 0 3 2\n",
      "Fitting on 3, testing on 2...\n",
      "1 2 1 3\n",
      "Fitting on 1, testing on 3...\n",
      "1 1 0 5\n",
      "Fitting on 0, testing on 5...\n",
      "1 0 3 3\n",
      "1 2 1 4\n",
      "Fitting on 1, testing on 4...\n",
      "1 2 1 5\n",
      "Fitting on 1, testing on 5...\n",
      "1 1 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "1 3 0 3\n",
      "Fitting on 0, testing on 3...\n",
      "1 0 3 4\n",
      "Fitting on 3, testing on 4...\n",
      "1 2 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "1 0 3 5\n",
      "Fitting on 3, testing on 5...\n",
      "1 0 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "1 2 2 1\n",
      "Fitting on 2, testing on 1...\n",
      "1 1 1 1\n",
      "1 0 4 1\n",
      "Fitting on 4, testing on 1...\n",
      "1 0 4 2\n",
      "Fitting on 4, testing on 2...\n",
      "1 2 2 2\n",
      "1 3 0 4\n",
      "Fitting on 0, testing on 4...\n",
      "1 0 4 3\n",
      "Fitting on 4, testing on 3...\n",
      "1 0 4 4\n",
      "1 3 0 5\n",
      "Fitting on 0, testing on 5...\n",
      "1 0 4 5\n",
      "Fitting on 4, testing on 5...\n",
      "1 0 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "1 2 2 3\n",
      "Fitting on 2, testing on 3...\n",
      "1 0 5 1\n",
      "Fitting on 5, testing on 1...\n",
      "1 0 5 2\n",
      "Fitting on 5, testing on 2...\n",
      "1 2 2 4\n",
      "Fitting on 2, testing on 4...\n",
      "1 0 5 3\n",
      "Fitting on 5, testing on 3...\n",
      "1 0 5 4\n",
      "Fitting on 5, testing on 4...\n",
      "1 3 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "1 2 2 5\n",
      "Fitting on 2, testing on 5...\n",
      "1 0 5 5\n",
      "1 2 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "1 1 1 2\n",
      "Fitting on 1, testing on 2...\n",
      "1 2 3 1\n",
      "Fitting on 3, testing on 1...\n",
      "1 3 1 1\n",
      "1 2 3 2\n",
      "Fitting on 3, testing on 2...\n",
      "1 1 1 3\n",
      "Fitting on 1, testing on 3...\n",
      "1 2 3 3\n",
      "1 1 1 4\n",
      "Fitting on 1, testing on 4...\n",
      "1 1 1 5\n",
      "Fitting on 1, testing on 5...\n",
      "1 2 3 4\n",
      "Fitting on 3, testing on 4...\n",
      "1 1 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "1 2 3 5\n",
      "Fitting on 3, testing on 5...\n",
      "1 2 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "1 1 2 1\n",
      "Fitting on 2, testing on 1...\n",
      "1 2 4 1\n",
      "Fitting on 4, testing on 1...\n",
      "1 2 4 2\n",
      "Fitting on 4, testing on 2...\n",
      "1 1 2 2\n",
      "1 2 4 3\n",
      "Fitting on 4, testing on 3...\n",
      "1 2 4 4\n",
      "1 3 1 2\n",
      "Fitting on 1, testing on 2...\n",
      "1 3 1 3\n",
      "Fitting on 1, testing on 3...\n",
      "1 2 4 5\n",
      "Fitting on 4, testing on 5...\n",
      "1 2 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "1 2 5 1\n",
      "Fitting on 5, testing on 1...\n",
      "1 3 1 4\n",
      "Fitting on 1, testing on 4...\n",
      "1 1 2 3\n",
      "Fitting on 2, testing on 3...\n",
      "1 2 5 2\n",
      "Fitting on 5, testing on 2...\n",
      "1 2 5 3\n",
      "Fitting on 5, testing on 3...\n",
      "1 1 2 4\n",
      "Fitting on 2, testing on 4...\n",
      "1 2 5 4\n",
      "Fitting on 5, testing on 4...\n",
      "1 3 1 5\n",
      "Fitting on 1, testing on 5...\n",
      "1 2 5 5\n",
      "1 1 2 5\n",
      "Fitting on 2, testing on 5...\n",
      "1 3 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "1 1 3 0\n",
      "Fitting on 3, testing on 0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 3 1\n",
      "Fitting on 3, testing on 1...\n",
      "1 3 2 1\n",
      "Fitting on 2, testing on 1...\n",
      "1 1 3 2\n",
      "Fitting on 3, testing on 2...\n",
      "1 3 2 2\n",
      "1 1 3 3\n",
      "1 1 3 4\n",
      "Fitting on 3, testing on 4...\n",
      "1 1 3 5\n",
      "Fitting on 3, testing on 5...\n",
      "1 3 2 3\n",
      "Fitting on 2, testing on 3...\n",
      "1 1 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "1 1 4 1\n",
      "Fitting on 4, testing on 1...\n",
      "1 3 2 4\n",
      "Fitting on 2, testing on 4...\n",
      "1 1 4 2\n",
      "Fitting on 4, testing on 2...\n",
      "1 3 2 5\n",
      "Fitting on 2, testing on 5...\n",
      "1 1 4 3\n",
      "Fitting on 4, testing on 3...\n",
      "1 1 4 4\n",
      "1 3 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "1 3 3 1\n",
      "Fitting on 3, testing on 1...\n",
      "1 3 3 2\n",
      "Fitting on 3, testing on 2...\n",
      "1 1 4 5\n",
      "Fitting on 4, testing on 5...\n",
      "1 3 3 3\n",
      "1 1 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "1 1 5 1\n",
      "Fitting on 5, testing on 1...\n",
      "1 1 5 2\n",
      "Fitting on 5, testing on 2...\n",
      "1 1 5 3\n",
      "Fitting on 5, testing on 3...\n",
      "1 1 5 4\n",
      "Fitting on 5, testing on 4...\n",
      "1 1 5 5\n",
      "1 3 3 4\n",
      "Fitting on 3, testing on 4...\n",
      "1 3 3 5\n",
      "Fitting on 3, testing on 5...\n",
      "1 3 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "1 3 4 1\n",
      "Fitting on 4, testing on 1...\n",
      "1 3 4 2\n",
      "Fitting on 4, testing on 2...\n",
      "1 3 4 3\n",
      "Fitting on 4, testing on 3...\n",
      "1 3 4 4\n",
      "1 3 4 5\n",
      "Fitting on 4, testing on 5...\n",
      "1 3 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "1 3 5 1\n",
      "Fitting on 5, testing on 1...\n",
      "1 3 5 2\n",
      "Fitting on 5, testing on 2...\n",
      "1 3 5 3\n",
      "Fitting on 5, testing on 3...\n",
      "1 3 5 4\n",
      "Fitting on 5, testing on 4...\n",
      "1 3 5 5\n",
      "2 0 0 0\n",
      "2 1 0 0\n",
      "2 2 0 0\n",
      "2 3 0 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c492e70ff466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#         init_steps(i,j,surf[j][:][i],surfla[:][i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for every subfeatureset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_steps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurfla\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;31m#         for k in range(surf.shape[1]): # for every training surface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m#             for l in range(surf.shape[1]): # for every testing surface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jagrio/.local/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jagrio/.local/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cross surface validation for 1 surface\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ;\n",
    "decomp = PCA(n_components=20)\n",
    "def filename(i,j,k,l):\n",
    "    return 'fs_'+str(i)+'_subfs_'+str(j)+'_tr_'+str(k)+'_ts_'+str(l)\n",
    "\n",
    "def cross_fit(i,j,k,l,data,labels,data2,labels2,pipe):\n",
    "    fileid = 'tmpresults1_2ndfinger/'+filename(i,j,k,l)+'.npz'\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k,l\n",
    "        if k==l: # perform K-fold                  \n",
    "#             data = surf[j][k][i][::100,:]\n",
    "#             labels = surfla[k][i][::100]\n",
    "            folds = cv.split(data, labels)\n",
    "            cm_all = np.zeros((2,2))\n",
    "            for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                x_train, x_test = data[train_ind], data[test_ind]\n",
    "                y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                model = pipe.fit(x_train,y_train)\n",
    "                y_pred = model.predict(x_test)\n",
    "                cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                cm_all += cm/5.\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "#             tr_data = surf[j][k][i]\n",
    "#             tr_labels = surfla[k][i]\n",
    "#             ts_data = surf[j][l][i]\n",
    "#             ts_labels = surfla[l][i]\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            print 'Fitting on '+str(k)+', testing on '+str(l)+'...'\n",
    "            model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps(i,j,jmax,surf,surfla):\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k in range(surf.shape[0]): # for every training surface\n",
    "        for l in range(surf.shape[0]): # for every testing surface\n",
    "#             cross_fit(i,j,k,l,surf[k][::100,:],surfla[k][::100],surf[l][::100,:],surfla[l][::100],pipe)\n",
    "            cross_fit(i,j,k,l,surf[k],surfla[:,k],surf[l],surfla[:,l],pipe)\n",
    "\n",
    "for i in range(surf.shape[2]): # for every featureset\n",
    "#     for j in range(surf.shape[0]): # for every subfeatureset\n",
    "#         if j==surf.shape[0]-1:\n",
    "#             featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "#         else:\n",
    "#             featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "#         pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "#         init_steps(i,j,surf[j][:][i],surfla[:][i])\n",
    "    # for every subfeatureset\n",
    "    [Parallel(n_jobs=-1)([delayed(init_steps) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) for j in range(surf.shape[0])])]\n",
    "#         for k in range(surf.shape[1]): # for every training surface\n",
    "#             for l in range(surf.shape[1]): # for every testing surface\n",
    "#                 cross_fit(i,j,k,l,surf,surfla,pipe)\n",
    "#             [Parallel(n_jobs=-1)([delayed(cross_fit) (i,j,k,l,surf,surfla,pipe) for l in range(surf.shape[1])])]\n",
    "            \n",
    "            \n",
    "\n",
    "# for i in range(surf.shape[2]): # for every featureset\n",
    "#     for j in range(surf.shape[0]): # for every subfeatureset\n",
    "#         if j==surf.shape[0]-1:\n",
    "#             featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "#         else:\n",
    "#             featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "#         pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "#         for k in range(surf.shape[1]): # for every training surface\n",
    "# #             for l in range(surf.shape[1]): # for every testing surface\n",
    "# #                 cross_fit(i,j,k,l,surf,surfla,pipe)\n",
    "# #             [Parallel(n_jobs=-1)([delayed(cross_fit) (i,j,k,l,surf,surfla,pipe) for l in range(surf.shape[1])])]\n",
    "#             [Parallel(n_jobs=-1)([delayed(cross_fit) (i,j,k,l,surf[j][k][i][::100,:],surfla[k][i][::100],surf[j][l][i][::100,:],surfla[l][i][::100],pipe) for l in range(surf.shape[1])])]\n",
    "    \n",
    "#     print(temp_surf[3].shape, i)\n",
    "#     X_amfft, X_freq_all, X_time, X_both = feat_subsets(surf[:,i],i)\n",
    "#     for j in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "0 1 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "0 2 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "0 3 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "0 0 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "0 2 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "0 0 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "0 0 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "0 1 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "0 2 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "0 0 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "0 0 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "0 3 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "0 2 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "0 0 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "0 0 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "0 1 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "0 2 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "0 0 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "0 0 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "0 2 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "0 0 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "0 0 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "0 1 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "0 2 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "0 3 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "0 0 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "0 0 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "0 2 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "0 0 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "0 0 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "0 1 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "0 2 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "0 0 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "0 0 0 5 2\n",
      "Fitting on 0-5, testing on 2...\n",
      "0 3 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "0 2 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "0 0 0 5 3\n",
      "Fitting on 0-5, testing on 3...\n",
      "0 1 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "0 0 0 5 4\n",
      "Fitting on 0-5, testing on 4...\n",
      "0 2 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "0 0 1 2 0\n",
      "Fitting on 1-2, testing on 0...\n",
      "0 0 1 2 3\n",
      "Fitting on 1-2, testing on 3...\n",
      "0 2 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "0 0 1 2 4\n",
      "Fitting on 1-2, testing on 4...\n",
      "0 1 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "0 0 1 2 5\n",
      "Fitting on 1-2, testing on 5...\n",
      "0 3 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "0 2 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "0 0 1 3 0\n",
      "Fitting on 1-3, testing on 0...\n",
      "0 0 1 3 2\n",
      "Fitting on 1-3, testing on 2...\n",
      "0 2 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "0 0 1 3 4\n",
      "Fitting on 1-3, testing on 4...\n",
      "0 1 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "0 0 1 3 5\n",
      "Fitting on 1-3, testing on 5...\n",
      "0 2 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "0 0 1 4 0\n",
      "Fitting on 1-4, testing on 0...\n",
      "0 3 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "0 0 1 4 2\n",
      "Fitting on 1-4, testing on 2...\n",
      "0 2 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "0 0 1 4 3\n",
      "Fitting on 1-4, testing on 3...\n",
      "0 1 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "0 2 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "0 0 1 4 5\n",
      "Fitting on 1-4, testing on 5...\n",
      "0 0 1 5 0\n",
      "Fitting on 1-5, testing on 0...\n",
      "0 2 0 5 2\n",
      "Fitting on 0-5, testing on 2...\n",
      "0 0 1 5 2\n",
      "Fitting on 1-5, testing on 2...\n",
      "0 1 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "0 0 1 5 3\n",
      "Fitting on 1-5, testing on 3...\n",
      "0 3 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "0 2 0 5 3\n",
      "Fitting on 0-5, testing on 3...\n",
      "0 0 1 5 4\n",
      "Fitting on 1-5, testing on 4...\n",
      "0 0 2 3 0\n",
      "Fitting on 2-3, testing on 0...\n",
      "0 2 0 5 4\n",
      "Fitting on 0-5, testing on 4...\n",
      "0 0 2 3 1\n",
      "Fitting on 2-3, testing on 1...\n",
      "0 1 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "0 0 2 3 4\n",
      "Fitting on 2-3, testing on 4...\n",
      "0 2 1 2 0\n",
      "Fitting on 1-2, testing on 0...\n",
      "0 0 2 3 5\n",
      "Fitting on 2-3, testing on 5...\n",
      "0 0 2 4 0\n",
      "Fitting on 2-4, testing on 0...\n",
      "0 3 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "0 2 1 2 3\n",
      "Fitting on 1-2, testing on 3...\n",
      "0 0 2 4 1\n",
      "Fitting on 2-4, testing on 1...\n",
      "0 1 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "0 0 2 4 3\n",
      "Fitting on 2-4, testing on 3...\n",
      "0 2 1 2 4\n",
      "Fitting on 1-2, testing on 4...\n",
      "0 0 2 4 5\n",
      "Fitting on 2-4, testing on 5...\n",
      "0 0 2 5 0\n",
      "Fitting on 2-5, testing on 0...\n",
      "0 2 1 2 5\n",
      "Fitting on 1-2, testing on 5...\n",
      "0 0 2 5 1\n",
      "Fitting on 2-5, testing on 1...\n",
      "0 1 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "0 3 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "0 0 2 5 3\n",
      "Fitting on 2-5, testing on 3...\n",
      "0 2 1 3 0\n",
      "Fitting on 1-3, testing on 0...\n",
      "0 0 2 5 4\n",
      "Fitting on 2-5, testing on 4...\n",
      "0 0 3 4 0\n",
      "Fitting on 3-4, testing on 0...\n",
      "0 2 1 3 2\n",
      "Fitting on 1-3, testing on 2...\n",
      "0 0 3 4 1\n",
      "Fitting on 3-4, testing on 1...\n",
      "0 1 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "0 0 3 4 2\n",
      "Fitting on 3-4, testing on 2...\n",
      "0 2 1 3 4\n",
      "Fitting on 1-3, testing on 4...\n",
      "0 0 3 4 5\n",
      "Fitting on 3-4, testing on 5...\n",
      "0 3 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "0 0 3 5 0\n",
      "Fitting on 3-5, testing on 0...\n",
      "0 2 1 3 5\n",
      "Fitting on 1-3, testing on 5...\n",
      "0 0 3 5 1\n",
      "Fitting on 3-5, testing on 1...\n",
      "0 1 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "0 0 3 5 2\n",
      "Fitting on 3-5, testing on 2...\n",
      "0 2 1 4 0\n",
      "Fitting on 1-4, testing on 0...\n",
      "0 0 3 5 4\n",
      "Fitting on 3-5, testing on 4...\n",
      "0 0 4 5 0\n",
      "Fitting on 4-5, testing on 0...\n",
      "0 2 1 4 2\n",
      "Fitting on 1-4, testing on 2...\n",
      "0 3 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "0 0 4 5 1\n",
      "Fitting on 4-5, testing on 1...\n",
      "0 1 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "0 2 1 4 3\n",
      "Fitting on 1-4, testing on 3...\n",
      "0 0 4 5 2\n",
      "Fitting on 4-5, testing on 2...\n",
      "0 0 4 5 3\n",
      "Fitting on 4-5, testing on 3...\n",
      "0 2 1 4 5\n",
      "Fitting on 1-4, testing on 5...\n",
      "0 1 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "0 2 1 5 0\n",
      "Fitting on 1-5, testing on 0...\n",
      "0 3 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "0 2 1 5 2\n",
      "Fitting on 1-5, testing on 2...\n",
      "0 1 0 5 2\n",
      "Fitting on 0-5, testing on 2...\n",
      "0 2 1 5 3\n",
      "Fitting on 1-5, testing on 3...\n",
      "0 2 1 5 4\n",
      "Fitting on 1-5, testing on 4...\n",
      "0 3 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "0 1 0 5 3\n",
      "Fitting on 0-5, testing on 3...\n",
      "0 2 2 3 0\n",
      "Fitting on 2-3, testing on 0...\n",
      "0 2 2 3 1\n",
      "Fitting on 2-3, testing on 1...\n",
      "0 1 0 5 4\n",
      "Fitting on 0-5, testing on 4...\n",
      "0 2 2 3 4\n",
      "Fitting on 2-3, testing on 4...\n",
      "0 3 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "0 2 2 3 5\n",
      "Fitting on 2-3, testing on 5...\n",
      "0 1 1 2 0\n",
      "Fitting on 1-2, testing on 0...\n",
      "0 2 2 4 0\n",
      "Fitting on 2-4, testing on 0...\n",
      "0 2 2 4 1\n",
      "Fitting on 2-4, testing on 1...\n",
      "0 3 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "0 1 1 2 3\n",
      "Fitting on 1-2, testing on 3...\n",
      "0 2 2 4 3\n",
      "Fitting on 2-4, testing on 3...\n",
      "0 2 2 4 5\n",
      "Fitting on 2-4, testing on 5...\n",
      "0 1 1 2 4\n",
      "Fitting on 1-2, testing on 4...\n",
      "0 2 2 5 0\n",
      "Fitting on 2-5, testing on 0...\n",
      "0 3 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "0 2 2 5 1\n",
      "Fitting on 2-5, testing on 1...\n",
      "0 1 1 2 5\n",
      "Fitting on 1-2, testing on 5...\n",
      "0 2 2 5 3\n",
      "Fitting on 2-5, testing on 3...\n",
      "0 2 2 5 4\n",
      "Fitting on 2-5, testing on 4...\n",
      "0 3 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "0 1 1 3 0\n",
      "Fitting on 1-3, testing on 0...\n",
      "0 2 3 4 0\n",
      "Fitting on 3-4, testing on 0...\n",
      "0 2 3 4 1\n",
      "Fitting on 3-4, testing on 1...\n",
      "0 1 1 3 2\n",
      "Fitting on 1-3, testing on 2...\n",
      "0 2 3 4 2\n",
      "Fitting on 3-4, testing on 2...\n",
      "0 3 0 5 2\n",
      "Fitting on 0-5, testing on 2...\n",
      "0 2 3 4 5\n",
      "Fitting on 3-4, testing on 5...\n",
      "0 1 1 3 4\n",
      "Fitting on 1-3, testing on 4...\n",
      "0 2 3 5 0\n",
      "Fitting on 3-5, testing on 0...\n",
      "0 2 3 5 1\n",
      "Fitting on 3-5, testing on 1...\n",
      "0 3 0 5 3\n",
      "Fitting on 0-5, testing on 3...\n",
      "0 1 1 3 5\n",
      "Fitting on 1-3, testing on 5...\n",
      "0 2 3 5 2\n",
      "Fitting on 3-5, testing on 2...\n",
      "0 2 3 5 4\n",
      "Fitting on 3-5, testing on 4...\n",
      "0 1 1 4 0\n",
      "Fitting on 1-4, testing on 0...\n",
      "0 2 4 5 0\n",
      "Fitting on 4-5, testing on 0...\n",
      "0 3 0 5 4\n",
      "Fitting on 0-5, testing on 4...\n",
      "0 2 4 5 1\n",
      "Fitting on 4-5, testing on 1...\n",
      "0 1 1 4 2\n",
      "Fitting on 1-4, testing on 2...\n",
      "0 2 4 5 2\n",
      "Fitting on 4-5, testing on 2...\n",
      "0 2 4 5 3\n",
      "Fitting on 4-5, testing on 3...\n",
      "0 3 1 2 0\n",
      "Fitting on 1-2, testing on 0...\n",
      "0 1 1 4 3\n",
      "Fitting on 1-4, testing on 3...\n",
      "0 1 1 4 5\n",
      "Fitting on 1-4, testing on 5...\n",
      "0 3 1 2 3\n",
      "Fitting on 1-2, testing on 3...\n",
      "0 1 1 5 0\n",
      "Fitting on 1-5, testing on 0...\n",
      "0 3 1 2 4\n",
      "Fitting on 1-2, testing on 4...\n",
      "0 1 1 5 2\n",
      "Fitting on 1-5, testing on 2...\n",
      "0 1 1 5 3\n",
      "Fitting on 1-5, testing on 3...\n",
      "0 3 1 2 5\n",
      "Fitting on 1-2, testing on 5...\n",
      "0 1 1 5 4\n",
      "Fitting on 1-5, testing on 4...\n",
      "0 3 1 3 0\n",
      "Fitting on 1-3, testing on 0...\n",
      "0 1 2 3 0\n",
      "Fitting on 2-3, testing on 0...\n",
      "0 1 2 3 1\n",
      "Fitting on 2-3, testing on 1...\n",
      "0 3 1 3 2\n",
      "Fitting on 1-3, testing on 2...\n",
      "0 1 2 3 4\n",
      "Fitting on 2-3, testing on 4...\n",
      "0 3 1 3 4\n",
      "Fitting on 1-3, testing on 4...\n",
      "0 1 2 3 5\n",
      "Fitting on 2-3, testing on 5...\n",
      "0 1 2 4 0\n",
      "Fitting on 2-4, testing on 0...\n",
      "0 3 1 3 5\n",
      "Fitting on 1-3, testing on 5...\n",
      "0 1 2 4 1\n",
      "Fitting on 2-4, testing on 1...\n",
      "0 3 1 4 0\n",
      "Fitting on 1-4, testing on 0...\n",
      "0 1 2 4 3\n",
      "Fitting on 2-4, testing on 3...\n",
      "0 1 2 4 5\n",
      "Fitting on 2-4, testing on 5...\n",
      "0 3 1 4 2\n",
      "Fitting on 1-4, testing on 2...\n",
      "0 1 2 5 0\n",
      "Fitting on 2-5, testing on 0...\n",
      "0 3 1 4 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting on 1-4, testing on 3...\n",
      "0 1 2 5 1\n",
      "Fitting on 2-5, testing on 1...\n",
      "0 1 2 5 3\n",
      "Fitting on 2-5, testing on 3...\n",
      "0 3 1 4 5\n",
      "Fitting on 1-4, testing on 5...\n",
      "0 1 2 5 4\n",
      "Fitting on 2-5, testing on 4...\n",
      "0 3 1 5 0\n",
      "Fitting on 1-5, testing on 0...\n",
      "0 1 3 4 0\n",
      "Fitting on 3-4, testing on 0...\n",
      "0 1 3 4 1\n",
      "Fitting on 3-4, testing on 1...\n",
      "0 3 1 5 2\n",
      "Fitting on 1-5, testing on 2...\n",
      "0 1 3 4 2\n",
      "Fitting on 3-4, testing on 2...\n",
      "0 3 1 5 3\n",
      "Fitting on 1-5, testing on 3...\n",
      "0 1 3 4 5\n",
      "Fitting on 3-4, testing on 5...\n",
      "0 1 3 5 0\n",
      "Fitting on 3-5, testing on 0...\n",
      "0 3 1 5 4\n",
      "Fitting on 1-5, testing on 4...\n",
      "0 1 3 5 1\n",
      "Fitting on 3-5, testing on 1...\n",
      "0 3 2 3 0\n",
      "Fitting on 2-3, testing on 0...\n",
      "0 1 3 5 2\n",
      "Fitting on 3-5, testing on 2...\n",
      "0 1 3 5 4\n",
      "Fitting on 3-5, testing on 4...\n",
      "0 3 2 3 1\n",
      "Fitting on 2-3, testing on 1...\n",
      "0 1 4 5 0\n",
      "Fitting on 4-5, testing on 0...\n",
      "0 3 2 3 4\n",
      "Fitting on 2-3, testing on 4...\n",
      "0 1 4 5 1\n",
      "Fitting on 4-5, testing on 1...\n",
      "0 1 4 5 2\n",
      "Fitting on 4-5, testing on 2...\n",
      "0 3 2 3 5\n",
      "Fitting on 2-3, testing on 5...\n",
      "0 1 4 5 3\n",
      "Fitting on 4-5, testing on 3...\n",
      "0 3 2 4 0\n",
      "Fitting on 2-4, testing on 0...\n",
      "0 3 2 4 1\n",
      "Fitting on 2-4, testing on 1...\n",
      "0 3 2 4 3\n",
      "Fitting on 2-4, testing on 3...\n",
      "0 3 2 4 5\n",
      "Fitting on 2-4, testing on 5...\n",
      "0 3 2 5 0\n",
      "Fitting on 2-5, testing on 0...\n",
      "0 3 2 5 1\n",
      "Fitting on 2-5, testing on 1...\n",
      "0 3 2 5 3\n",
      "Fitting on 2-5, testing on 3...\n",
      "0 3 2 5 4\n",
      "Fitting on 2-5, testing on 4...\n",
      "0 3 3 4 0\n",
      "Fitting on 3-4, testing on 0...\n",
      "0 3 3 4 1\n",
      "Fitting on 3-4, testing on 1...\n",
      "0 3 3 4 2\n",
      "Fitting on 3-4, testing on 2...\n",
      "0 3 3 4 5\n",
      "Fitting on 3-4, testing on 5...\n",
      "0 3 3 5 0\n",
      "Fitting on 3-5, testing on 0...\n",
      "0 3 3 5 1\n",
      "Fitting on 3-5, testing on 1...\n",
      "0 3 3 5 2\n",
      "Fitting on 3-5, testing on 2...\n",
      "0 3 3 5 4\n",
      "Fitting on 3-5, testing on 4...\n",
      "0 3 4 5 0\n",
      "Fitting on 4-5, testing on 0...\n",
      "0 3 4 5 1\n",
      "Fitting on 4-5, testing on 1...\n",
      "0 3 4 5 2\n",
      "Fitting on 4-5, testing on 2...\n",
      "0 3 4 5 3\n",
      "Fitting on 4-5, testing on 3...\n",
      "1 0 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "1 1 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "1 2 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "1 3 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "1 0 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "1 2 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "1 0 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "1 0 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "1 1 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "1 2 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "1 0 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "1 0 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "1 2 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "1 3 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "1 0 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "1 0 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "1 1 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "1 2 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "1 0 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "1 0 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "1 2 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "1 0 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "1 0 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "1 1 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "1 3 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "1 2 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "1 0 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "1 0 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "1 2 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "1 0 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "1 0 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "1 1 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "1 2 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "1 0 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "1 0 0 5 2\n",
      "Fitting on 0-5, testing on 2...\n",
      "1 3 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "1 2 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "1 0 0 5 3\n",
      "Fitting on 0-5, testing on 3...\n",
      "1 0 0 5 4\n",
      "Fitting on 0-5, testing on 4...\n",
      "1 1 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "1 2 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "1 0 1 2 0\n",
      "Fitting on 1-2, testing on 0...\n",
      "1 0 1 2 3\n",
      "Fitting on 1-2, testing on 3...\n",
      "1 2 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "1 0 1 2 4\n",
      "Fitting on 1-2, testing on 4...\n",
      "1 0 1 2 5\n",
      "Fitting on 1-2, testing on 5...\n",
      "1 3 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "1 1 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "1 2 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "1 0 1 3 0\n",
      "Fitting on 1-3, testing on 0...\n",
      "1 0 1 3 2\n",
      "Fitting on 1-3, testing on 2...\n",
      "1 2 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "1 0 1 3 4\n",
      "Fitting on 1-3, testing on 4...\n",
      "1 0 1 3 5\n",
      "Fitting on 1-3, testing on 5...\n",
      "1 1 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "1 2 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "1 0 1 4 0\n",
      "Fitting on 1-4, testing on 0...\n",
      "1 3 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "1 0 1 4 2\n",
      "Fitting on 1-4, testing on 2...\n",
      "1 2 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "1 0 1 4 3\n",
      "Fitting on 1-4, testing on 3...\n",
      "1 1 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "1 0 1 4 5\n",
      "Fitting on 1-4, testing on 5...\n",
      "1 2 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "1 0 1 5 0\n",
      "Fitting on 1-5, testing on 0...\n",
      "1 0 1 5 2\n",
      "Fitting on 1-5, testing on 2...\n",
      "1 2 0 5 2\n",
      "Fitting on 0-5, testing on 2...\n",
      "1 0 1 5 3\n",
      "Fitting on 1-5, testing on 3...\n",
      "1 1 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "1 3 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "1 0 1 5 4\n",
      "Fitting on 1-5, testing on 4...\n",
      "1 2 0 5 3\n",
      "Fitting on 0-5, testing on 3...\n",
      "1 0 2 3 0\n",
      "Fitting on 2-3, testing on 0...\n",
      "1 0 2 3 1\n",
      "Fitting on 2-3, testing on 1...\n",
      "1 2 0 5 4\n",
      "Fitting on 0-5, testing on 4...\n",
      "1 0 2 3 4\n",
      "Fitting on 2-3, testing on 4...\n",
      "1 1 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "1 0 2 3 5\n",
      "Fitting on 2-3, testing on 5...\n",
      "1 2 1 2 0\n",
      "Fitting on 1-2, testing on 0...\n",
      "1 0 2 4 0\n",
      "Fitting on 2-4, testing on 0...\n",
      "1 3 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "1 0 2 4 1\n",
      "Fitting on 2-4, testing on 1...\n",
      "1 2 1 2 3\n",
      "Fitting on 1-2, testing on 3...\n",
      "1 0 2 4 3\n",
      "Fitting on 2-4, testing on 3...\n",
      "1 1 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "1 0 2 4 5\n",
      "Fitting on 2-4, testing on 5...\n",
      "1 2 1 2 4\n",
      "Fitting on 1-2, testing on 4...\n",
      "1 0 2 5 0\n",
      "Fitting on 2-5, testing on 0...\n",
      "1 0 2 5 1\n",
      "Fitting on 2-5, testing on 1...\n",
      "1 2 1 2 5\n",
      "Fitting on 1-2, testing on 5...\n",
      "1 0 2 5 3\n",
      "Fitting on 2-5, testing on 3...\n",
      "1 3 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "1 1 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "1 0 2 5 4\n",
      "Fitting on 2-5, testing on 4...\n",
      "1 2 1 3 0\n",
      "Fitting on 1-3, testing on 0...\n",
      "1 0 3 4 0\n",
      "Fitting on 3-4, testing on 0...\n",
      "1 2 1 3 2\n",
      "Fitting on 1-3, testing on 2...\n",
      "1 0 3 4 1\n",
      "Fitting on 3-4, testing on 1...\n",
      "1 0 3 4 2\n",
      "Fitting on 3-4, testing on 2...\n",
      "1 1 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "1 2 1 3 4\n",
      "Fitting on 1-3, testing on 4...\n",
      "1 0 3 4 5\n",
      "Fitting on 3-4, testing on 5...\n",
      "1 0 3 5 0\n",
      "Fitting on 3-5, testing on 0...\n",
      "1 3 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "1 2 1 3 5\n",
      "Fitting on 1-3, testing on 5...\n",
      "1 0 3 5 1\n",
      "Fitting on 3-5, testing on 1...\n",
      "1 0 3 5 2\n",
      "Fitting on 3-5, testing on 2...\n",
      "1 1 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "1 2 1 4 0\n",
      "Fitting on 1-4, testing on 0...\n",
      "1 0 3 5 4\n",
      "Fitting on 3-5, testing on 4...\n",
      "1 0 4 5 0\n",
      "Fitting on 4-5, testing on 0...\n",
      "1 2 1 4 2\n",
      "Fitting on 1-4, testing on 2...\n",
      "1 0 4 5 1\n",
      "Fitting on 4-5, testing on 1...\n",
      "1 3 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "1 0 4 5 2\n",
      "Fitting on 4-5, testing on 2...\n",
      "1 1 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "1 2 1 4 3\n",
      "Fitting on 1-4, testing on 3...\n",
      "1 0 4 5 3\n",
      "Fitting on 4-5, testing on 3...\n",
      "1 2 1 4 5\n",
      "Fitting on 1-4, testing on 5...\n",
      "1 1 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "1 2 1 5 0\n",
      "Fitting on 1-5, testing on 0...\n",
      "1 3 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "1 2 1 5 2\n",
      "Fitting on 1-5, testing on 2...\n",
      "1 1 0 5 2\n",
      "Fitting on 0-5, testing on 2...\n",
      "1 2 1 5 3\n",
      "Fitting on 1-5, testing on 3...\n",
      "1 2 1 5 4\n",
      "Fitting on 1-5, testing on 4...\n",
      "1 3 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "1 1 0 5 3\n",
      "Fitting on 0-5, testing on 3...\n",
      "1 2 2 3 0\n",
      "Fitting on 2-3, testing on 0...\n",
      "1 2 2 3 1\n",
      "Fitting on 2-3, testing on 1...\n",
      "1 1 0 5 4\n",
      "Fitting on 0-5, testing on 4...\n",
      "1 2 2 3 4\n",
      "Fitting on 2-3, testing on 4...\n",
      "1 3 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "1 2 2 3 5\n",
      "Fitting on 2-3, testing on 5...\n",
      "1 1 1 2 0\n",
      "Fitting on 1-2, testing on 0...\n",
      "1 2 2 4 0\n",
      "Fitting on 2-4, testing on 0...\n",
      "1 2 2 4 1\n",
      "Fitting on 2-4, testing on 1...\n",
      "1 3 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "1 1 1 2 3\n",
      "Fitting on 1-2, testing on 3...\n",
      "1 2 2 4 3\n",
      "Fitting on 2-4, testing on 3...\n",
      "1 2 2 4 5\n",
      "Fitting on 2-4, testing on 5...\n",
      "1 1 1 2 4\n",
      "Fitting on 1-2, testing on 4...\n",
      "1 2 2 5 0\n",
      "Fitting on 2-5, testing on 0...\n",
      "1 3 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "1 2 2 5 1\n",
      "Fitting on 2-5, testing on 1...\n",
      "1 1 1 2 5\n",
      "Fitting on 1-2, testing on 5...\n",
      "1 2 2 5 3\n",
      "Fitting on 2-5, testing on 3...\n",
      "1 2 2 5 4\n",
      "Fitting on 2-5, testing on 4...\n",
      "1 3 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "1 1 1 3 0\n",
      "Fitting on 1-3, testing on 0...\n",
      "1 2 3 4 0\n",
      "Fitting on 3-4, testing on 0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 1\n",
      "Fitting on 3-4, testing on 1...\n",
      "1 1 1 3 2\n",
      "Fitting on 1-3, testing on 2...\n",
      "1 2 3 4 2\n",
      "Fitting on 3-4, testing on 2...\n",
      "1 3 0 5 2\n",
      "Fitting on 0-5, testing on 2...\n",
      "1 2 3 4 5\n",
      "Fitting on 3-4, testing on 5...\n",
      "1 1 1 3 4\n",
      "Fitting on 1-3, testing on 4...\n",
      "1 2 3 5 0\n",
      "Fitting on 3-5, testing on 0...\n",
      "1 2 3 5 1\n",
      "Fitting on 3-5, testing on 1...\n",
      "1 3 0 5 3\n",
      "Fitting on 0-5, testing on 3...\n",
      "1 1 1 3 5\n",
      "Fitting on 1-3, testing on 5...\n",
      "1 2 3 5 2\n",
      "Fitting on 3-5, testing on 2...\n",
      "1 2 3 5 4\n",
      "Fitting on 3-5, testing on 4...\n",
      "1 1 1 4 0\n",
      "Fitting on 1-4, testing on 0...\n",
      "1 2 4 5 0\n",
      "Fitting on 4-5, testing on 0...\n",
      "1 3 0 5 4\n",
      "Fitting on 0-5, testing on 4...\n",
      "1 2 4 5 1\n",
      "Fitting on 4-5, testing on 1...\n",
      "1 1 1 4 2\n",
      "Fitting on 1-4, testing on 2...\n",
      "1 2 4 5 2\n",
      "Fitting on 4-5, testing on 2...\n",
      "1 2 4 5 3\n",
      "Fitting on 4-5, testing on 3...\n",
      "1 3 1 2 0\n",
      "Fitting on 1-2, testing on 0...\n",
      "1 1 1 4 3\n",
      "Fitting on 1-4, testing on 3...\n",
      "1 1 1 4 5\n",
      "Fitting on 1-4, testing on 5...\n",
      "1 3 1 2 3\n",
      "Fitting on 1-2, testing on 3...\n",
      "1 1 1 5 0\n",
      "Fitting on 1-5, testing on 0...\n",
      "1 3 1 2 4\n",
      "Fitting on 1-2, testing on 4...\n",
      "1 1 1 5 2\n",
      "Fitting on 1-5, testing on 2...\n",
      "1 1 1 5 3\n",
      "Fitting on 1-5, testing on 3...\n",
      "1 3 1 2 5\n",
      "Fitting on 1-2, testing on 5...\n",
      "1 1 1 5 4\n",
      "Fitting on 1-5, testing on 4...\n",
      "1 3 1 3 0\n",
      "Fitting on 1-3, testing on 0...\n",
      "1 1 2 3 0\n",
      "Fitting on 2-3, testing on 0...\n",
      "1 1 2 3 1\n",
      "Fitting on 2-3, testing on 1...\n",
      "1 3 1 3 2\n",
      "Fitting on 1-3, testing on 2...\n",
      "1 1 2 3 4\n",
      "Fitting on 2-3, testing on 4...\n",
      "1 3 1 3 4\n",
      "Fitting on 1-3, testing on 4...\n",
      "1 1 2 3 5\n",
      "Fitting on 2-3, testing on 5...\n",
      "1 1 2 4 0\n",
      "Fitting on 2-4, testing on 0...\n",
      "1 3 1 3 5\n",
      "Fitting on 1-3, testing on 5...\n",
      "1 1 2 4 1\n",
      "Fitting on 2-4, testing on 1...\n",
      "1 3 1 4 0\n",
      "Fitting on 1-4, testing on 0...\n",
      "1 1 2 4 3\n",
      "Fitting on 2-4, testing on 3...\n",
      "1 1 2 4 5\n",
      "Fitting on 2-4, testing on 5...\n",
      "1 3 1 4 2\n",
      "Fitting on 1-4, testing on 2...\n",
      "1 1 2 5 0\n",
      "Fitting on 2-5, testing on 0...\n",
      "1 3 1 4 3\n",
      "Fitting on 1-4, testing on 3...\n",
      "1 1 2 5 1\n",
      "Fitting on 2-5, testing on 1...\n",
      "1 1 2 5 3\n",
      "Fitting on 2-5, testing on 3...\n",
      "1 3 1 4 5\n",
      "Fitting on 1-4, testing on 5...\n",
      "1 1 2 5 4\n",
      "Fitting on 2-5, testing on 4...\n",
      "1 3 1 5 0\n",
      "Fitting on 1-5, testing on 0...\n",
      "1 1 3 4 0\n",
      "Fitting on 3-4, testing on 0...\n",
      "1 1 3 4 1\n",
      "Fitting on 3-4, testing on 1...\n",
      "1 3 1 5 2\n",
      "Fitting on 1-5, testing on 2...\n",
      "1 1 3 4 2\n",
      "Fitting on 3-4, testing on 2...\n",
      "1 3 1 5 3\n",
      "Fitting on 1-5, testing on 3...\n",
      "1 1 3 4 5\n",
      "Fitting on 3-4, testing on 5...\n",
      "1 1 3 5 0\n",
      "Fitting on 3-5, testing on 0...\n",
      "1 3 1 5 4\n",
      "Fitting on 1-5, testing on 4...\n",
      "1 1 3 5 1\n",
      "Fitting on 3-5, testing on 1...\n",
      "1 3 2 3 0\n",
      "Fitting on 2-3, testing on 0...\n",
      "1 1 3 5 2\n",
      "Fitting on 3-5, testing on 2...\n",
      "1 1 3 5 4\n",
      "Fitting on 3-5, testing on 4...\n",
      "1 3 2 3 1\n",
      "Fitting on 2-3, testing on 1...\n",
      "1 1 4 5 0\n",
      "Fitting on 4-5, testing on 0...\n",
      "1 3 2 3 4\n",
      "Fitting on 2-3, testing on 4...\n",
      "1 1 4 5 1\n",
      "Fitting on 4-5, testing on 1...\n",
      "1 1 4 5 2\n",
      "Fitting on 4-5, testing on 2...\n",
      "1 3 2 3 5\n",
      "Fitting on 2-3, testing on 5...\n",
      "1 1 4 5 3\n",
      "Fitting on 4-5, testing on 3...\n",
      "1 3 2 4 0\n",
      "Fitting on 2-4, testing on 0...\n",
      "1 3 2 4 1\n",
      "Fitting on 2-4, testing on 1...\n",
      "1 3 2 4 3\n",
      "Fitting on 2-4, testing on 3...\n",
      "1 3 2 4 5\n",
      "Fitting on 2-4, testing on 5...\n",
      "1 3 2 5 0\n",
      "Fitting on 2-5, testing on 0...\n",
      "1 3 2 5 1\n",
      "Fitting on 2-5, testing on 1...\n",
      "1 3 2 5 3\n",
      "Fitting on 2-5, testing on 3...\n",
      "1 3 2 5 4\n",
      "Fitting on 2-5, testing on 4...\n",
      "1 3 3 4 0\n",
      "Fitting on 3-4, testing on 0...\n",
      "1 3 3 4 1\n",
      "Fitting on 3-4, testing on 1...\n",
      "1 3 3 4 2\n",
      "Fitting on 3-4, testing on 2...\n",
      "1 3 3 4 5\n",
      "Fitting on 3-4, testing on 5...\n",
      "1 3 3 5 0\n",
      "Fitting on 3-5, testing on 0...\n",
      "1 3 3 5 1\n",
      "Fitting on 3-5, testing on 1...\n",
      "1 3 3 5 2\n",
      "Fitting on 3-5, testing on 2...\n",
      "1 3 3 5 4\n",
      "Fitting on 3-5, testing on 4...\n",
      "1 3 4 5 0\n",
      "Fitting on 4-5, testing on 0...\n",
      "1 3 4 5 1\n",
      "Fitting on 4-5, testing on 1...\n",
      "1 3 4 5 2\n",
      "Fitting on 4-5, testing on 2...\n",
      "1 3 4 5 3\n",
      "Fitting on 4-5, testing on 3...\n",
      "2 0 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "2 1 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "2 2 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "2 3 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "2 0 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "2 0 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "2 2 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "2 0 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "2 0 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "2 1 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "2 2 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "2 0 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "2 0 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "2 2 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "2 3 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "2 0 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "2 1 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "2 0 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "2 2 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "2 0 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "2 2 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "2 0 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "2 0 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "2 1 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "2 0 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "2 2 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "2 3 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "2 0 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "2 0 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "2 2 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "2 0 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "2 1 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "2 2 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "2 0 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "2 0 0 5 2\n",
      "Fitting on 0-5, testing on 2...\n",
      "2 3 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "2 0 0 5 3\n",
      "Fitting on 0-5, testing on 3...\n",
      "2 2 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "2 0 0 5 4\n",
      "Fitting on 0-5, testing on 4...\n",
      "2 1 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "2 2 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "2 0 1 2 0\n",
      "Fitting on 1-2, testing on 0...\n",
      "2 0 1 2 3\n",
      "Fitting on 1-2, testing on 3...\n",
      "2 0 1 2 4\n",
      "Fitting on 1-2, testing on 4...\n",
      "2 2 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "2 0 1 2 5\n",
      "Fitting on 1-2, testing on 5...\n",
      "2 1 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "2 3 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "2 0 1 3 0\n",
      "Fitting on 1-3, testing on 0...\n",
      "2 2 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "2 0 1 3 2\n",
      "Fitting on 1-3, testing on 2...\n",
      "2 0 1 3 4\n",
      "Fitting on 1-3, testing on 4...\n",
      "2 2 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "2 0 1 3 5\n",
      "Fitting on 1-3, testing on 5...\n",
      "2 1 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "2 0 1 4 0\n",
      "Fitting on 1-4, testing on 0...\n",
      "2 2 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "2 0 1 4 2\n",
      "Fitting on 1-4, testing on 2...\n",
      "2 3 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "2 0 1 4 3\n",
      "Fitting on 1-4, testing on 3...\n",
      "2 2 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "2 0 1 4 5\n",
      "Fitting on 1-4, testing on 5...\n",
      "2 1 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "2 0 1 5 0\n",
      "Fitting on 1-5, testing on 0...\n",
      "2 2 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "2 0 1 5 2\n",
      "Fitting on 1-5, testing on 2...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-37d7d32807ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m#         init_steps(i,j,surf[j][:][i],surfla[:][i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# for every subfeatureset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_steps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurfla\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;31m#         for k in range(surf.shape[1]): # for every training surface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m#             for l in range(surf.shape[1]): # for every testing surface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jagrio/.local/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jagrio/.local/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Cross surface validation for 2 surfaces\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ;\n",
    "decomp = PCA(n_components=20)\n",
    "def filename(i,j,k1,k2,l):\n",
    "    return 'fs_'+str(i)+'_subfs_'+str(j)+'_tr1_'+str(k1)+'_tr2_'+str(k2)+'_ts_'+str(l)\n",
    "\n",
    "def cross_fit(i,j,k1,k2,l,data,labels,data2,labels2,pipe):\n",
    "    fileid = 'tmpresults2_trans/'+filename(i,j,k1,k2,l)+'.npz'\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k1,k2,l\n",
    "#         if k1==l or k2==l: # perform K-fold                  \n",
    "# #             data = surf[j][k][i][::100,:]\n",
    "# #             labels = surfla[k][i][::100]\n",
    "#             folds = cv.split(data, labels)\n",
    "#             cm_all = np.zeros((2,2))\n",
    "#             for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "#                 x_train, x_test = data[train_ind], data[test_ind]\n",
    "#                 y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "#                 pipe.fit(x_train,y_train)\n",
    "#                 y_pred = pipe.predict(x_test)\n",
    "#                 cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "#                 cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#                 cm_all += cm/5.\n",
    "#             np.savez(fileid,cm=cm_all)\n",
    "#         else: # perform cross-check\n",
    "#             tr_data = surf[j][k][i]\n",
    "#             tr_labels = surfla[k][i]\n",
    "#             ts_data = surf[j][l][i]\n",
    "#             ts_labels = surfla[l][i]\n",
    "        tr_data = data\n",
    "        tr_labels = labels\n",
    "        ts_data = data2\n",
    "        ts_labels = labels2\n",
    "        print 'Fitting on '+str(k1)+\"-\"+str(k2)+', testing on '+str(l)+'...'\n",
    "        pipe.fit(tr_data,tr_labels)\n",
    "        y_pred = pipe.predict(ts_data)\n",
    "        cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        np.savez(fileid,cm=cm)\n",
    "\n",
    "def init_steps(i,j,jmax,surf,surfla):\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k1 in range(surf.shape[0]): # for every training surface1\n",
    "        for k2 in range(surf.shape[0]): # for every training surface2\n",
    "            if k2 > k1:\n",
    "                for l in range(surf.shape[0]): # for every testing surface\n",
    "                    if l != k1 and l != k2:\n",
    "        #             cross_fit(i,j,k,l,surf[k][::100,:],surfla[k][::100],surf[l][::100,:],surfla[l][::100],pipe)\n",
    "                        tr_surf, tr_surfla = np.concatenate((surf[k1],surf[k2]),axis=0), np.concatenate((surfla[:,k1],surfla[:,k2]),axis=0)\n",
    "                        ts_surf, ts_surfla = surf[l], surfla[:,l]\n",
    "        #                 print tr_surf.shape, tr_surfla.shape\n",
    "                        cross_fit(i,j,k1,k2,l,tr_surf,tr_surfla,ts_surf,ts_surfla,pipe)\n",
    "\n",
    "for i in range(surf.shape[2]): # for every featureset\n",
    "#     for j in range(surf.shape[0]): # for every subfeatureset\n",
    "#         if j==surf.shape[0]-1:\n",
    "#             featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "#         else:\n",
    "#             featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "#         pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "#         init_steps(i,j,surf[j][:][i],surfla[:][i])\n",
    "    # for every subfeatureset\n",
    "    [Parallel(n_jobs=-1)([delayed(init_steps) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) for j in range(surf.shape[0])])]\n",
    "#         for k in range(surf.shape[1]): # for every training surface\n",
    "#             for l in range(surf.shape[1]): # for every testing surface\n",
    "#                 cross_fit(i,j,k,l,surf,surfla,pipe)\n",
    "#             [Parallel(n_jobs=-1)([delayed(cross_fit) (i,j,k,l,surf,surfla,pipe) for l in range(surf.shape[1])])]\n",
    "            \n",
    "            \n",
    "\n",
    "# for i in range(surf.shape[2]): # for every featureset\n",
    "#     for j in range(surf.shape[0]): # for every subfeatureset\n",
    "#         if j==surf.shape[0]-1:\n",
    "#             featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "#         else:\n",
    "#             featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "#         pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "#         for k in range(surf.shape[1]): # for every training surface\n",
    "# #             for l in range(surf.shape[1]): # for every testing surface\n",
    "# #                 cross_fit(i,j,k,l,surf,surfla,pipe)\n",
    "# #             [Parallel(n_jobs=-1)([delayed(cross_fit) (i,j,k,l,surf,surfla,pipe) for l in range(surf.shape[1])])]\n",
    "#             [Parallel(n_jobs=-1)([delayed(cross_fit) (i,j,k,l,surf[j][k][i][::100,:],surfla[k][i][::100],surf[j][l][i][::100,:],surfla[l][i][::100],pipe) for l in range(surf.shape[1])])]\n",
    "    \n",
    "#     print(temp_surf[3].shape, i)\n",
    "#     X_amfft, X_freq_all, X_time, X_both = feat_subsets(surf[:,i],i)\n",
    "#     for j in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = cv.split(data, labels)\n",
    "for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "    x_train, x_test = data[train_ind] data[test_ind]\n",
    "    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "    pipe.fit(x_train,y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "=============================================================\n",
      "Object : 0, classifier : KNei, 5-fold avg score = 0.903840\n",
      "[ 0.94168096  0.88507719  0.89690722  0.91752577  0.87800687]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   59.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : SVC(, 5-fold avg score = 0.921018\n",
      "[ 0.94339623  0.89536878  0.90893471  0.9467354   0.91065292]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   58.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : MLPC, 5-fold avg score = 0.934064\n",
      "[ 0.95883362  0.91595197  0.93298969  0.94501718  0.91752577]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : Rand, 5-fold avg score = 0.893896\n",
      "[ 0.93310463  0.83018868  0.895189    0.92783505  0.88316151]\n",
      "=============================================================\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   58.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : KNei, 5-fold avg score = 0.892178\n",
      "[ 0.90909091  0.8542024   0.90378007  0.88831615  0.90549828]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   58.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : SVC(, 5-fold avg score = 0.896980\n",
      "[ 0.91423671  0.87307033  0.90034364  0.91237113  0.88487973]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   60.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : MLPC, 5-fold avg score = 0.918593\n",
      "[ 0.95883362  0.9348199   0.89690722  0.90378007  0.89862543]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   59.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : Rand, 5-fold avg score = 0.864358\n",
      "[ 0.89365352  0.82332762  0.85223368  0.87800687  0.87457045]\n",
      "=============================================================\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   57.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : KNei, 5-fold avg score = 0.921365\n",
      "[ 0.92281304  0.90394511  0.94329897  0.90034364  0.93642612]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   57.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : SVC(, 5-fold avg score = 0.941272\n",
      "[ 0.95711835  0.93996569  0.93986254  0.92955326  0.93986254]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   55.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : MLPC, 5-fold avg score = 0.946764\n",
      "[ 0.95883362  0.95711835  0.95189003  0.94158076  0.92439863]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   56.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : Rand, 5-fold avg score = 0.883585\n",
      "[ 0.88850772  0.87821612  0.92268041  0.87628866  0.85223368]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   55.3s finished\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# ====================== 24/07  5-fold CV for the split datasets\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "scores = []\n",
    "\n",
    "for surf_ind, surf_data in enumerate(surfaces):\n",
    "    print(surf_ind)\n",
    "    data = surf_data\n",
    "    labels = surf_labels[surf_ind]\n",
    "    for pipe in pipe_list:\n",
    "        score = cross_val_score(estimator = pipe, X = data, y = labels, cv = cv, verbose = 1, n_jobs=-1)\n",
    "        scores.append(score)\n",
    "        print (\"=============================================================\")\n",
    "        print(\"Object : %d, classifier : %0.4s, 5-fold avg score = %f\" %(surf_ind, pipe.named_steps['classifier'], np.mean(score)))\n",
    "        print(score)\n",
    "        print (\"=============================================================\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on surface no. 0\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with KNei\n",
      "Prediction accuracy 0.800824\n",
      "[[ 0.96946565  0.03053435]\n",
      " [ 0.39701493  0.60298507]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.74      0.97      0.84      1572\n",
      "        1.0       0.94      0.60      0.74      1340\n",
      "\n",
      "avg / total       0.83      0.80      0.79      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with KNei\n",
      "Prediction accuracy 0.776786\n",
      "[[ 0.96882952  0.03117048]\n",
      " [ 0.44850746  0.55149254]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.72      0.97      0.82      1572\n",
      "        1.0       0.94      0.55      0.69      1340\n",
      "\n",
      "avg / total       0.82      0.78      0.76      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with SVC(\n",
      "Prediction accuracy 0.831044\n",
      "[[ 0.96882952  0.03117048]\n",
      " [ 0.33059701  0.66940299]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.77      0.97      0.86      1572\n",
      "        1.0       0.95      0.67      0.78      1340\n",
      "\n",
      "avg / total       0.85      0.83      0.83      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with SVC(\n",
      "Prediction accuracy 0.804602\n",
      "[[ 0.96183206  0.03816794]\n",
      " [ 0.37985075  0.62014925]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.75      0.96      0.84      1572\n",
      "        1.0       0.93      0.62      0.74      1340\n",
      "\n",
      "avg / total       0.83      0.80      0.80      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with MLPC\n",
      "Prediction accuracy 0.865385\n",
      "[[ 0.9764631   0.0235369 ]\n",
      " [ 0.26492537  0.73507463]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.81      0.98      0.89      1572\n",
      "        1.0       0.96      0.74      0.83      1340\n",
      "\n",
      "avg / total       0.88      0.87      0.86      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with MLPC\n",
      "Prediction accuracy 0.842033\n",
      "[[ 0.98918575  0.01081425]\n",
      " [ 0.33059701  0.66940299]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.78      0.99      0.87      1572\n",
      "        1.0       0.98      0.67      0.80      1340\n",
      "\n",
      "avg / total       0.87      0.84      0.84      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with Rand\n",
      "Prediction accuracy 0.728022\n",
      "[[ 0.98982188  0.01017812]\n",
      " [ 0.57910448  0.42089552]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.67      0.99      0.80      1572\n",
      "        1.0       0.97      0.42      0.59      1340\n",
      "\n",
      "avg / total       0.81      0.73      0.70      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with Rand\n",
      "Prediction accuracy 0.711882\n",
      "[[ 0.99109415  0.00890585]\n",
      " [ 0.61567164  0.38432836]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.65      0.99      0.79      1572\n",
      "        1.0       0.97      0.38      0.55      1340\n",
      "\n",
      "avg / total       0.80      0.71      0.68      2912\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 1\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with KNei\n",
      "Prediction accuracy 0.746909\n",
      "[[ 0.65667915  0.34332085]\n",
      " [ 0.14274809  0.85725191]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.66      0.74      1602\n",
      "        1.0       0.67      0.86      0.75      1310\n",
      "\n",
      "avg / total       0.77      0.75      0.75      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with KNei\n",
      "Prediction accuracy 0.878434\n",
      "[[ 0.94020356  0.05979644]\n",
      " [ 0.19402985  0.80597015]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.85      0.94      0.89      1572\n",
      "        1.0       0.92      0.81      0.86      1340\n",
      "\n",
      "avg / total       0.88      0.88      0.88      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with SVC(\n",
      "Prediction accuracy 0.766140\n",
      "[[ 0.58988764  0.41011236]\n",
      " [ 0.01832061  0.98167939]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.59      0.74      1602\n",
      "        1.0       0.66      0.98      0.79      1310\n",
      "\n",
      "avg / total       0.83      0.77      0.76      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with SVC(\n",
      "Prediction accuracy 0.926854\n",
      "[[ 0.93193384  0.06806616]\n",
      " [ 0.07910448  0.92089552]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.93      0.93      0.93      1572\n",
      "        1.0       0.92      0.92      0.92      1340\n",
      "\n",
      "avg / total       0.93      0.93      0.93      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with MLPC\n",
      "Prediction accuracy 0.825549\n",
      "[[ 0.77465668  0.22534332]\n",
      " [ 0.11221374  0.88778626]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.77      0.83      1602\n",
      "        1.0       0.76      0.89      0.82      1310\n",
      "\n",
      "avg / total       0.84      0.83      0.83      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with MLPC\n",
      "Prediction accuracy 0.944368\n",
      "[[ 0.96119593  0.03880407]\n",
      " [ 0.07537313  0.92462687]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.94      0.96      0.95      1572\n",
      "        1.0       0.95      0.92      0.94      1340\n",
      "\n",
      "avg / total       0.94      0.94      0.94      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with Rand\n",
      "Prediction accuracy 0.787775\n",
      "[[ 0.65043695  0.34956305]\n",
      " [ 0.04427481  0.95572519]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.65      0.77      1602\n",
      "        1.0       0.69      0.96      0.80      1310\n",
      "\n",
      "avg / total       0.83      0.79      0.79      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with Rand\n",
      "Prediction accuracy 0.857486\n",
      "[[ 0.90776081  0.09223919]\n",
      " [ 0.20149254  0.79850746]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.84      0.91      0.87      1572\n",
      "        1.0       0.88      0.80      0.84      1340\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2912\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 2\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with KNei\n",
      "Prediction accuracy 0.769231\n",
      "[[ 0.70349563  0.29650437]\n",
      " [ 0.15038168  0.84961832]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.70      0.77      1602\n",
      "        1.0       0.70      0.85      0.77      1310\n",
      "\n",
      "avg / total       0.78      0.77      0.77      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with KNei\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy 0.902473\n",
      "[[ 0.94274809  0.05725191]\n",
      " [ 0.14477612  0.85522388]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.88      0.94      0.91      1572\n",
      "        1.0       0.93      0.86      0.89      1340\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with SVC(\n",
      "Prediction accuracy 0.729396\n",
      "[[ 0.52496879  0.47503121]\n",
      " [ 0.02061069  0.97938931]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.52      0.68      1602\n",
      "        1.0       0.63      0.98      0.77      1310\n",
      "\n",
      "avg / total       0.82      0.73      0.72      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with SVC(\n",
      "Prediction accuracy 0.908310\n",
      "[[ 0.89949109  0.10050891]\n",
      " [ 0.08134328  0.91865672]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.93      0.90      0.91      1572\n",
      "        1.0       0.89      0.92      0.90      1340\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with MLPC\n",
      "Prediction accuracy 0.808036\n",
      "[[ 0.71410737  0.28589263]\n",
      " [ 0.07709924  0.92290076]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.71      0.80      1602\n",
      "        1.0       0.73      0.92      0.81      1310\n",
      "\n",
      "avg / total       0.83      0.81      0.81      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with MLPC\n",
      "Prediction accuracy 0.907967\n",
      "[[ 0.93002545  0.06997455]\n",
      " [ 0.11791045  0.88208955]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.90      0.93      0.92      1572\n",
      "        1.0       0.91      0.88      0.90      1340\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with Rand\n",
      "Prediction accuracy 0.675824\n",
      "[[ 0.4650437   0.5349563 ]\n",
      " [ 0.06641221  0.93358779]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.47      0.61      1602\n",
      "        1.0       0.59      0.93      0.72      1310\n",
      "\n",
      "avg / total       0.76      0.68      0.66      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with Rand\n",
      "Prediction accuracy 0.840316\n",
      "[[ 0.82061069  0.17938931]\n",
      " [ 0.13656716  0.86343284]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.88      0.82      0.85      1572\n",
      "        1.0       0.80      0.86      0.83      1340\n",
      "\n",
      "avg / total       0.84      0.84      0.84      2912\n",
      "\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# ====================== 24/07  cross-surf for the split datasets\n",
    "# feat_mask = []\n",
    "\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "pipe = pipe_list[2]\n",
    "\n",
    "for surf_ind, surf_dat in enumerate(surfaces):\n",
    "    print(\"Training on surface no. %d\" %surf_ind)\n",
    "    ind_mask = [True, True, True] \n",
    "    ind_mask[surf_ind] = False #  the training dataset is flagged by False\n",
    "    solely_for_printing_mask = [i for i, x in enumerate(ind_mask) if x == True]\n",
    "    train_x = surf_dat#[::100]\n",
    "    train_y = surf_labels[surf_ind]#[::100]\n",
    "    test_x = list(compress(surfaces, ind_mask)) # the rest splits, flagged by True, are kept for testing\n",
    "    test_y = list(compress(surf_labels,ind_mask))\n",
    "    \n",
    "#     for pipe_ind,pipe in enumerate(pipe_list):\n",
    "#     print(\"Fitting classifier no. %d...\" %pipe_ind)\n",
    "    pipe.fit(train_x,train_y) # fit the pipeline for every train set and every clf\n",
    "    print (\"...done fitting\")\n",
    "    feat = list(pipe.named_steps['feature_selection'].get_support(indices = True))\n",
    "    feat_mask+=feat\n",
    "    for test_ind, test_d in enumerate(test_x):\n",
    "        y_pred = pipe.predict(test_d)\n",
    "        y_true = test_y[test_ind]\n",
    "        cm = confusion_matrix(y_pred=y_pred, y_true=y_true)\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print (\"=============================================================\")\n",
    "        print(\"Trained on %d, testing on %d with %0.4s\" %(surf_ind, solely_for_printing_mask[test_ind], pipe.named_steps['classifier']))\n",
    "        print(\"Prediction accuracy %f\" %pipe.score(test_d,y_true))\n",
    "        print(cm)\n",
    "        print(classification_report(y_pred=y_pred, y_true = y_true))        \n",
    "        print (\"=============================================================\")\n",
    "\n",
    "tot_occs = get_feat_occ(feat_mask)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "Started fitting...\n",
      "...done fitting\n",
      "1\n",
      "Started fitting...\n",
      "...done fitting\n",
      "2\n",
      "Started fitting...\n",
      "...done fitting\n",
      "3\n",
      "Started fitting...\n",
      "...done fitting\n",
      "1\n",
      "0\n",
      "Started fitting...\n",
      "...done fitting\n",
      "1\n",
      "Started fitting...\n",
      "...done fitting\n",
      "2\n",
      "Started fitting...\n",
      "...done fitting\n",
      "3\n",
      "Started fitting...\n",
      "...done fitting\n",
      "2\n",
      "0\n",
      "Started fitting...\n",
      "...done fitting\n",
      "1\n",
      "Started fitting...\n",
      "...done fitting\n",
      "2\n",
      "Started fitting...\n",
      "...done fitting\n",
      "3\n",
      "Started fitting...\n",
      "...done fitting\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# ====================== 21/07 MONO AMFFT \n",
    "datapath = 'AMFFT_pipes_1b1/'\n",
    "for surf in range(len(surfaces)):\n",
    "    print(surf)\n",
    "    train_x = surfaces[surf]\n",
    "    for pipe_id, pipe in enumerate(pipe_list):\n",
    "        filename = 'surf'+'_'+str(surf)+'_'+'clf'+'_'+str(pipe_id)+'_'+'fs'+str(fs)\n",
    "        print(pipe_id)\n",
    "        pipefile = datapath+filename+'.npz'\n",
    "        print(\"Started fitting...\")\n",
    "        model = pipe.fit(train_x, surf_labels[surf])\n",
    "#         models.append(model)\n",
    "        print(\"...done fitting\")\n",
    "        np.savez(pipefile,model=np.array([model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.996479, total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.994709, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.992958, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.1min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.992958, total= 4.1min\n",
      "[CV] ................................. , score=0.996473, total= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : KNei, 5-fold avg score = 0.994715\n",
      "[ 0.99295775  0.99295775  0.99647887  0.99470899  0.99647266]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.984155, total= 4.1min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.991182, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.985915, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.1min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.987676, total= 4.1min\n",
      "[CV] ................................. , score=0.971781, total= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : SVC(, 5-fold avg score = 0.984142\n",
      "[ 0.98591549  0.98415493  0.98767606  0.99118166  0.97178131]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.989437, total= 4.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.996479, total= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.2min remaining:  6.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.994709, total= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.3min remaining:  2.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.998239, total= 4.3min\n",
      "[CV] ................................. , score=0.998236, total= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : MLPC, 5-fold avg score = 0.995420\n",
      "[ 0.99823944  0.98943662  0.99647887  0.99470899  0.99823633]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.992958, total= 5.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.992945, total= 5.2min\n",
      "[CV] ................................. , score=0.961268, total= 5.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  5.2min remaining:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  5.2min remaining:  3.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.984155, total= 5.2min\n",
      "[CV] ................................. , score=0.989418, total= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  7.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : Rand, 5-fold avg score = 0.984149\n",
      "[ 0.96126761  0.98415493  0.99295775  0.99294533  0.98941799]\n",
      "=============================================================\n",
      "1\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.996479, total= 4.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.991197, total= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.3min remaining:  6.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.998239, total= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.3min remaining:  2.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.994709, total= 4.3min\n",
      "[CV] ................................. , score=1.000000, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : KNei, 5-fold avg score = 0.996125\n",
      "[ 0.99647887  0.99823944  0.99119718  0.99470899  1.        ]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.994718, total= 4.4min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.989437, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.5min remaining:  6.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.989437, total= 4.5min\n",
      "[CV] ................................. , score=0.987654, total= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.5min remaining:  3.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.982363, total= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : SVC(, 5-fold avg score = 0.988722\n",
      "[ 0.99471831  0.98943662  0.98943662  0.98765432  0.98236332]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.994709, total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.998239, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.994718, total= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.2min remaining:  2.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.994718, total= 4.2min\n",
      "[CV] ................................. , score=0.991182, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : MLPC, 5-fold avg score = 0.994713\n",
      "[ 0.99823944  0.99471831  0.99471831  0.99470899  0.99118166]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.982363, total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.982394, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.985915, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.1min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.985915, total= 4.1min\n",
      "[CV] ................................. , score=0.989418, total= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : Rand, 5-fold avg score = 0.985201\n",
      "[ 0.98591549  0.98591549  0.98239437  0.98236332  0.98941799]\n",
      "=============================================================\n",
      "2\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.971831, total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.998239, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.998236, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.1min remaining:  2.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.947183, total= 4.2min\n",
      "[CV] ................................. , score=0.998236, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : KNei, 5-fold avg score = 0.982745\n",
      "[ 0.99823944  0.97183099  0.9471831   0.99823633  0.99823633]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.933099, total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.947183, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.0min remaining:  6.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.933099, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.0min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.925926, total= 4.0min\n",
      "[CV] ................................. , score=0.954145, total= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : SVC(, 5-fold avg score = 0.938690\n",
      "[ 0.93309859  0.9471831   0.93309859  0.92592593  0.95414462]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.982394, total= 4.1min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.936620, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.982363, total= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.2min remaining:  2.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.952465, total= 4.2min\n",
      "[CV] ................................. , score=0.996473, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : MLPC, 5-fold avg score = 0.970063\n",
      "[ 0.98239437  0.95246479  0.93661972  0.98236332  0.99647266]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.961268, total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.998236, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.941901, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.1min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.941901, total= 4.1min\n",
      "[CV] ................................. , score=0.998236, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : Rand, 5-fold avg score = 0.968309\n",
      "[ 0.94190141  0.96126761  0.94190141  0.99823633  0.99823633]\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============ 21/07\n",
    "\n",
    "# cross-validate on the different objects using the dataset from both fingers\n",
    "\n",
    "# data_X = deepcopy(X[2][2]) # choose the featureset\n",
    "# data_Y = deepcopy(Y[2])\n",
    "# surfaces = np.split(data_X,3)\n",
    "# surf_labels = np.split(data_Y,3)\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "scores = []\n",
    "\n",
    "for surf_ind, surf_data in enumerate(surfaces):\n",
    "    print(surf_ind)\n",
    "    data = surf_data\n",
    "    labels = surf_labels[surf_ind]\n",
    "    for pipe in pipe_list:\n",
    "        score = cross_val_score(estimator = pipe, X = data, y = labels, cv = cv, verbose = 10, n_jobs=-1)\n",
    "        scores.append(score)\n",
    "        print (\"=============================================================\")\n",
    "        print(\"Object : %d, classifier : %0.4s, 5-fold avg score = %f\" %(surf_ind, pipe.named_steps['classifier'], np.mean(score)))\n",
    "        print(score)\n",
    "        print (\"=============================================================\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on surface no. 0\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with KNei\n",
      "Prediction accuracy 0.987667\n",
      "[[ 0.9986755  0.0013245]\n",
      " [ 0.0248494  0.9751506]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      1510\n",
      "        1.0       1.00      0.98      0.99      1328\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with KNei\n",
      "Prediction accuracy 0.976744\n",
      "[[ 0.97100515  0.02899485]\n",
      " [ 0.0163297   0.9836703 ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.97      0.98      1552\n",
      "        1.0       0.97      0.98      0.97      1286\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with SVC(\n",
      "Prediction accuracy 0.986258\n",
      "[[ 0.9807947   0.0192053 ]\n",
      " [ 0.00753012  0.99246988]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.98      0.99      1510\n",
      "        1.0       0.98      0.99      0.99      1328\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with SVC(\n",
      "Prediction accuracy 0.967935\n",
      "[[ 0.94780928  0.05219072]\n",
      " [ 0.00777605  0.99222395]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.95      0.97      1552\n",
      "        1.0       0.94      0.99      0.97      1286\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with MLPC\n",
      "Prediction accuracy 0.980973\n",
      "[[ 0.99801325  0.00198675]\n",
      " [ 0.03840361  0.96159639]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98      1510\n",
      "        1.0       1.00      0.96      0.98      1328\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with MLPC\n",
      "Prediction accuracy 0.982030\n",
      "[[ 0.99162371  0.00837629]\n",
      " [ 0.02954899  0.97045101]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.98      1552\n",
      "        1.0       0.99      0.97      0.98      1286\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with Rand\n",
      "Prediction accuracy 0.991543\n",
      "[[ 0.98874172  0.01125828]\n",
      " [ 0.00527108  0.99472892]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      0.99      1510\n",
      "        1.0       0.99      0.99      0.99      1328\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with Rand\n",
      "Prediction accuracy 0.965469\n",
      "[[ 0.94201031  0.05798969]\n",
      " [ 0.00622084  0.99377916]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.94      0.97      1552\n",
      "        1.0       0.93      0.99      0.96      1286\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2838\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 1\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with KNei\n",
      "Prediction accuracy 0.990134\n",
      "[[ 0.98672566  0.01327434]\n",
      " [ 0.00557325  0.99442675]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      0.99      1582\n",
      "        1.0       0.98      0.99      0.99      1256\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with KNei\n",
      "Prediction accuracy 0.979915\n",
      "[[ 0.96585052  0.03414948]\n",
      " [ 0.00311042  0.99688958]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.97      0.98      1552\n",
      "        1.0       0.96      1.00      0.98      1286\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with SVC(\n",
      "Prediction accuracy 0.985201\n",
      "[[ 0.97914033  0.02085967]\n",
      " [ 0.00716561  0.99283439]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.98      0.99      1582\n",
      "        1.0       0.97      0.99      0.98      1256\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with SVC(\n",
      "Prediction accuracy 0.972868\n",
      "[[ 0.95489691  0.04510309]\n",
      " [ 0.00544323  0.99455677]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.95      0.97      1552\n",
      "        1.0       0.95      0.99      0.97      1286\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with MLPC\n",
      "Prediction accuracy 0.991543\n",
      "[[ 0.99051833  0.00948167]\n",
      " [ 0.00716561  0.99283439]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      1582\n",
      "        1.0       0.99      0.99      0.99      1256\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with MLPC\n",
      "Prediction accuracy 0.994715\n",
      "[[ 0.99420103  0.00579897]\n",
      " [ 0.00466563  0.99533437]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00      1552\n",
      "        1.0       0.99      1.00      0.99      1286\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with Rand\n",
      "Prediction accuracy 0.979915\n",
      "[[ 0.96523388  0.03476612]\n",
      " [ 0.00159236  0.99840764]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.97      0.98      1582\n",
      "        1.0       0.96      1.00      0.98      1256\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with Rand\n",
      "Prediction accuracy 0.966526\n",
      "[[ 0.94072165  0.05927835]\n",
      " [ 0.00233281  0.99766719]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.94      0.97      1552\n",
      "        1.0       0.93      1.00      0.96      1286\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2838\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 2\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with KNei\n",
      "Prediction accuracy 0.924947\n",
      "[[ 0.90834387  0.09165613]\n",
      " [ 0.05414013  0.94585987]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.91      0.93      1582\n",
      "        1.0       0.89      0.95      0.92      1256\n",
      "\n",
      "avg / total       0.93      0.92      0.93      2838\n",
      "\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Trained on 2, testing on 1 with KNei\n",
      "Prediction accuracy 0.961945\n",
      "[[ 0.96490066  0.03509934]\n",
      " [ 0.04141566  0.95858434]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.96      0.96      1510\n",
      "        1.0       0.96      0.96      0.96      1328\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with SVC(\n",
      "Prediction accuracy 0.955250\n",
      "[[ 0.97281922  0.02718078]\n",
      " [ 0.06687898  0.93312102]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.97      0.96      1582\n",
      "        1.0       0.96      0.93      0.95      1256\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with SVC(\n",
      "Prediction accuracy 0.945736\n",
      "[[ 0.97417219  0.02582781]\n",
      " [ 0.08659639  0.91340361]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.97      0.95      1510\n",
      "        1.0       0.97      0.91      0.94      1328\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with MLPC\n",
      "Prediction accuracy 0.952079\n",
      "[[ 0.96144121  0.03855879]\n",
      " [ 0.05971338  0.94028662]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.96      0.96      1582\n",
      "        1.0       0.95      0.94      0.95      1256\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with MLPC\n",
      "Prediction accuracy 0.948203\n",
      "[[ 0.9602649   0.0397351 ]\n",
      " [ 0.06551205  0.93448795]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.96      0.95      1510\n",
      "        1.0       0.95      0.93      0.94      1328\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with Rand\n",
      "Prediction accuracy 0.955250\n",
      "[[ 0.94247788  0.05752212]\n",
      " [ 0.02866242  0.97133758]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.94      0.96      1582\n",
      "        1.0       0.93      0.97      0.95      1256\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with Rand\n",
      "Prediction accuracy 0.959479\n",
      "[[ 0.95165563  0.04834437]\n",
      " [ 0.03162651  0.96837349]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.95      0.96      1510\n",
      "        1.0       0.95      0.97      0.96      1328\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2838\n",
      "\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# =========================== 21/07\n",
    "\n",
    "\n",
    "\n",
    "# %%time\n",
    "# validate between the different objects using the dataset from both fingers\n",
    "\n",
    "# Version 1: keep alternatively one for training and test on the rest\n",
    "\n",
    "\n",
    "# data_X = deepcopy(X[2][1]) #[:-1]\n",
    "# data_Y = deepcopy(Y[2]) #[:-1]\n",
    "# print(data_X.shape)\n",
    "# surfaces = np.split(data_X,3)\n",
    "# surf_labels = np.split(data_Y,3) \n",
    "feat_mask = []\n",
    "\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "\n",
    "for surf_ind, surf_dat in enumerate(surfaces):\n",
    "    print(\"Training on surface no. %d\" %surf_ind)\n",
    "    ind_mask = [True, True, True] \n",
    "    ind_mask[surf_ind] = False #  the training dataset is flagged by False\n",
    "    solely_for_printing_mask = [i for i, x in enumerate(ind_mask) if x == True]\n",
    "    train_x = surf_dat#[::100]\n",
    "    train_y = surf_labels[surf_ind]#[::100]\n",
    "    test_x = list(compress(surfaces, ind_mask)) # the rest splits, flagged by True, are kept for testing\n",
    "    test_y = list(compress(surf_labels,ind_mask))\n",
    "    \n",
    "    for pipe_ind,pipe in enumerate(pipe_list):\n",
    "        print(\"Fitting classifier no. %d...\" %pipe_ind)\n",
    "        pipe.fit(train_x,train_y) # fit the pipeline for every train set and every clf\n",
    "        print (\"...done fitting\")\n",
    "        feat = list(pipe.named_steps['feature_selection'].get_support(indices = True))\n",
    "        feat_mask+=feat\n",
    "        for test_ind, test_d in enumerate(test_x):\n",
    "            y_pred = pipe.predict(test_d)\n",
    "            y_true = test_y[test_ind]\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=y_true)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print (\"=============================================================\")\n",
    "            print(\"Trained on %d, testing on %d with %0.4s\" %(surf_ind, solely_for_printing_mask[test_ind], pipe.named_steps['classifier']))\n",
    "            print(\"Prediction accuracy %f\" %pipe.score(test_d,y_true))\n",
    "            print(cm)\n",
    "            print(classification_report(y_pred=y_pred, y_true = y_true))        \n",
    "            print (\"=============================================================\")\n",
    "    \n",
    "tot_occs = get_feat_occ(feat_mask)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.895564, total= 6.5min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  6.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3302bd8c3db1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpipe_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"=============================================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mscore_func_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/mutual_info_.pyc\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     return _estimate_mi(X, y, discrete_features, True, n_neighbors,\n\u001b[0;32m--> 438\u001b[0;31m                         copy, random_state)\n\u001b[0m",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/mutual_info_.pyc\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target) for\n\u001b[0;32m--> 285\u001b[0;31m           x, discrete_feature in moves.zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/mutual_info_.pyc\u001b[0m in \u001b[0;36m_compute_mi\u001b[0;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx_discrete\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my_discrete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/mutual_info_.pyc\u001b[0m in \u001b[0;36m_compute_mi_cd\u001b[0;34m(c, d, n_neighbors)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kd_tree'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0mm_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mradius_neighbors\u001b[0;34m(self, X, radius, return_distance)\u001b[0m\n\u001b[1;32m    619\u001b[0m                     \"or set algorithm='brute'\" % self._fit_method)\n\u001b[1;32m    620\u001b[0m             results = self._tree.query_radius(X, radius,\n\u001b[0;32m--> 621\u001b[0;31m                                               return_distance=return_distance)\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# i: iterating over finger, j: over featureset \n",
    "# (consider keeping only the second featureset and discarding the rest to save some space)\n",
    "# Performing cross validation for each finger on the second feature set \n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "# set the pipeline\n",
    "# def make_pipe_clf(scaler,feature_selection,decomp,clf):\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "scores = []\n",
    "for i in range(len(X)):\n",
    "    data = deepcopy(X[i][2])\n",
    "    print(i)\n",
    "    labels = deepcopy(Y[i])\n",
    "    for pipe in pipe_list:\n",
    "        score = cross_val_score(estimator = pipe, X = data, y = labels, cv = cv, verbose = 100)\n",
    "        scores.append(score)\n",
    "        print (\"=============================================================\")\n",
    "        print(\"Datasets : %d, classifier : %0.4s, 5-fold avg score = %f\" %(i, pipe.named_steps['classifier'], np.mean(score)))\n",
    "        print(score)\n",
    "        print (\"=============================================================\")\n",
    "        \n",
    "# print pipe_list[1].named_steps['classifier']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.887205, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.924115, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.9min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.905565, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.3min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.934233, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.7min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.881956, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.1min finished\n",
      "=============================================================\n",
      "Object : 0, classifier : KNei, 5-fold avg score = 0.906615\n",
      "[ 0.88720539  0.92411467  0.90556492  0.93423272  0.88195616]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.932660, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.913997, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.951096, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.2min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.961214, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.7min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.890388, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min finished\n",
      "=============================================================\n",
      "Object : 0, classifier : SVC(, 5-fold avg score = 0.929871\n",
      "[ 0.93265993  0.91399663  0.95109612  0.96121417  0.89038786]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.957912, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.939292, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.905565, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.2min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.981450, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.915683, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.0min finished\n",
      "=============================================================\n",
      "Object : 0, classifier : MLPC, 5-fold avg score = 0.939980\n",
      "[ 0.95791246  0.93929174  0.90556492  0.98145025  0.91568297]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.919192, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.927487, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.954469, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.2min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.989882, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.919056, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min finished\n",
      "=============================================================\n",
      "Object : 0, classifier : Rand, 5-fold avg score = 0.942017\n",
      "[ 0.91919192  0.92748735  0.9544688   0.98988196  0.91905565]\n",
      "=============================================================\n",
      "1\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.627946, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.895447, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.767285, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.7min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.893761, total= 3.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 10.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.902192, total= 4.2min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 15.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 15.0min finished\n",
      "=============================================================\n",
      "Object : 1, classifier : KNei, 5-fold avg score = 0.817326\n",
      "[ 0.62794613  0.89544688  0.76728499  0.89376054  0.90219224]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.638047, total= 4.2min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.2min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.947723, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.770658, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 10.3min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.890388, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 12.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.883642, total= 2.2min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 14.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 14.9min finished\n",
      "=============================================================\n",
      "Object : 1, classifier : SVC(, 5-fold avg score = 0.826092\n",
      "[ 0.63804714  0.94772344  0.77065767  0.89038786  0.8836425 ]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.784512, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.967960, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.777403, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.917369, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.920742, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.9min finished\n",
      "=============================================================\n",
      "Object : 1, classifier : MLPC, 5-fold avg score = 0.873597\n",
      "[ 0.78451178  0.96795953  0.77740304  0.91736931  0.92074199]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.969697, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.966273, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.772344, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.903879, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.915683, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.9min finished\n",
      "=============================================================\n",
      "Object : 1, classifier : Rand, 5-fold avg score = 0.905575\n",
      "[ 0.96969697  0.96627319  0.77234401  0.90387858  0.91568297]\n",
      "=============================================================\n",
      "2\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.764310, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.951096, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.856661, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.961214, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.770658, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min finished\n",
      "=============================================================\n",
      "Object : 2, classifier : KNei, 5-fold avg score = 0.860788\n",
      "[ 0.76430976  0.95109612  0.85666105  0.96121417  0.77065767]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.695286, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.929174, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.905565, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.984823, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.775717, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min finished\n",
      "=============================================================\n",
      "Object : 2, classifier : SVC(, 5-fold avg score = 0.858113\n",
      "[ 0.6952862   0.92917369  0.90556492  0.98482293  0.77571669]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.818182, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.946037, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.915683, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.964587, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.812816, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min finished\n",
      "=============================================================\n",
      "Object : 2, classifier : MLPC, 5-fold avg score = 0.891461\n",
      "[ 0.81818182  0.9460371   0.91568297  0.96458685  0.81281619]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.966330, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.974705, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.915683, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.984823, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.770658, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min finished\n",
      "=============================================================\n",
      "Object : 2, classifier : Rand, 5-fold avg score = 0.922440\n",
      "[ 0.96632997  0.97470489  0.91568297  0.98482293  0.77065767]\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# cross-validate on the different objects using the dataset from both fingers\n",
    "data_X = deepcopy(X[2][2]) # choose the featureset\n",
    "data_Y = deepcopy(Y[2])\n",
    "surfaces = np.split(data_X,3)\n",
    "surf_labels = np.split(data_Y,3)\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "scores = []\n",
    "\n",
    "for surf_ind, surf_data in enumerate(surfaces):\n",
    "    print(surf_ind)\n",
    "    data = surf_data\n",
    "    labels = surf_labels[surf_ind]\n",
    "    for pipe in pipe_list:\n",
    "        score = cross_val_score(estimator = pipe, X = data, y = labels, cv = cv, verbose = 100)\n",
    "        scores.append(score)\n",
    "        print (\"=============================================================\")\n",
    "        print(\"Object : %d, classifier : %0.4s, 5-fold avg score = %f\" %(surf_ind, pipe.named_steps['classifier'], np.mean(score)))\n",
    "        print(score)\n",
    "        print (\"=============================================================\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started fitting...\n",
      "...done fitting\n",
      "Started fitting...\n",
      "...done fitting\n",
      "Started fitting...\n",
      "...done fitting\n"
     ]
    }
   ],
   "source": [
    "data_X = deepcopy(X[2][1]) # choose the featureset\n",
    "data_Y = deepcopy(Y[2])\n",
    "surfaces = np.split(data_X,3)\n",
    "surf_labels = np.split(data_Y,3)\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "clf = pipe_list[2]\n",
    "datapath = 'surf_pipe/'\n",
    "\n",
    "for surf_ind, surf_data in enumerate(surfaces):\n",
    "    data = surf_data\n",
    "    labels = surf_labels[surf_ind]\n",
    "    print(\"Started fitting...\")\n",
    "    surf_model = clf.fit(data,labels)\n",
    "    filename = 'surf_pipe'+'_'+str(surf_ind)\n",
    "    pipefile = datapath+filename+'.npz'\n",
    "    print(\"...done fitting\")\n",
    "    np.savez(pipefile,surf_model=np.array([surf_model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8898, 3107)\n",
      "Training on surface no. 0\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with KNei\n",
      "Prediction accuracy 0.860081\n",
      "[[ 0.92158134  0.07841866]\n",
      " [ 0.20660576  0.79339424]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.92      0.87      1543\n",
      "        1.0       0.90      0.79      0.84      1423\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with KNei\n",
      "Prediction accuracy 0.827040\n",
      "[[ 0.92875318  0.07124682]\n",
      " [ 0.28766141  0.71233859]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.93      0.85      1572\n",
      "        1.0       0.90      0.71      0.79      1394\n",
      "\n",
      "avg / total       0.84      0.83      0.82      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with SVC(\n",
      "Prediction accuracy 0.913014\n",
      "[[ 0.96759559  0.03240441]\n",
      " [ 0.14617006  0.85382994]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.97      0.92      1543\n",
      "        1.0       0.96      0.85      0.90      1423\n",
      "\n",
      "avg / total       0.92      0.91      0.91      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with SVC(\n",
      "Prediction accuracy 0.879299\n",
      "[[ 0.99236641  0.00763359]\n",
      " [ 0.2482066   0.7517934 ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.99      0.90      1572\n",
      "        1.0       0.99      0.75      0.85      1394\n",
      "\n",
      "avg / total       0.90      0.88      0.88      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with MLPC\n",
      "Prediction accuracy 0.880647\n",
      "[[ 0.80622165  0.19377835]\n",
      " [ 0.03865074  0.96134926]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.81      0.88      1543\n",
      "        1.0       0.82      0.96      0.89      1423\n",
      "\n",
      "avg / total       0.89      0.88      0.88      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with MLPC\n",
      "Prediction accuracy 0.891773\n",
      "[[ 0.87531807  0.12468193]\n",
      " [ 0.08967001  0.91032999]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.88      0.90      1572\n",
      "        1.0       0.87      0.91      0.89      1394\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with Rand\n",
      "Prediction accuracy 0.894808\n",
      "[[ 0.91315619  0.08684381]\n",
      " [ 0.12508784  0.87491216]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.91      0.90      1543\n",
      "        1.0       0.90      0.87      0.89      1423\n",
      "\n",
      "avg / total       0.90      0.89      0.89      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with Rand\n",
      "Prediction accuracy 0.903574\n",
      "[[ 0.9586514   0.0413486 ]\n",
      " [ 0.15853659  0.84146341]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.96      0.91      1572\n",
      "        1.0       0.95      0.84      0.89      1394\n",
      "\n",
      "avg / total       0.91      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 1\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with KNei\n",
      "Prediction accuracy 0.911666\n",
      "[[ 0.99085565  0.00914435]\n",
      " [ 0.1728223   0.8271777 ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.99      0.92      1531\n",
      "        1.0       0.99      0.83      0.90      1435\n",
      "\n",
      "avg / total       0.92      0.91      0.91      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with KNei\n",
      "Prediction accuracy 0.839852\n",
      "[[ 0.94338422  0.05661578]\n",
      " [ 0.276901    0.723099  ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.94      0.86      1572\n",
      "        1.0       0.92      0.72      0.81      1394\n",
      "\n",
      "avg / total       0.85      0.84      0.84      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with SVC(\n",
      "Prediction accuracy 0.909643\n",
      "[[ 0.96080993  0.03919007]\n",
      " [ 0.14494774  0.85505226]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.96      0.92      1531\n",
      "        1.0       0.95      0.86      0.90      1435\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with SVC(\n",
      "Prediction accuracy 0.859744\n",
      "[[ 0.9980916   0.0019084 ]\n",
      " [ 0.29626973  0.70373027]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      1.00      0.88      1572\n",
      "        1.0       1.00      0.70      0.83      1394\n",
      "\n",
      "avg / total       0.89      0.86      0.86      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with MLPC\n",
      "Prediction accuracy 0.925152\n",
      "[[ 0.97452645  0.02547355]\n",
      " [ 0.12752613  0.87247387]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.97      0.93      1531\n",
      "        1.0       0.97      0.87      0.92      1435\n",
      "\n",
      "avg / total       0.93      0.93      0.92      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with MLPC\n",
      "Prediction accuracy 0.864464\n",
      "[[ 0.94083969  0.05916031]\n",
      " [ 0.22166428  0.77833572]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.94      0.88      1572\n",
      "        1.0       0.92      0.78      0.84      1394\n",
      "\n",
      "avg / total       0.87      0.86      0.86      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with Rand\n",
      "Prediction accuracy 0.922117\n",
      "[[ 0.9268452   0.0731548 ]\n",
      " [ 0.08292683  0.91707317]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.93      0.92      1531\n",
      "        1.0       0.92      0.92      0.92      1435\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with Rand\n",
      "Prediction accuracy 0.906608\n",
      "[[ 0.96819338  0.03180662]\n",
      " [ 0.16284075  0.83715925]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.97      0.92      1572\n",
      "        1.0       0.96      0.84      0.89      1394\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2966\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 2\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with KNei\n",
      "Prediction accuracy 0.899865\n",
      "[[ 0.910516    0.089484  ]\n",
      " [ 0.11149826  0.88850174]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.91      0.90      1531\n",
      "        1.0       0.90      0.89      0.90      1435\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Trained on 2, testing on 1 with KNei\n",
      "Prediction accuracy 0.863452\n",
      "[[ 0.8198315   0.1801685 ]\n",
      " [ 0.08924807  0.91075193]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.82      0.86      1543\n",
      "        1.0       0.82      0.91      0.86      1423\n",
      "\n",
      "avg / total       0.87      0.86      0.86      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with SVC(\n",
      "Prediction accuracy 0.889751\n",
      "[[ 0.86348792  0.13651208]\n",
      " [ 0.08222997  0.91777003]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.86      0.89      1531\n",
      "        1.0       0.86      0.92      0.89      1435\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with SVC(\n",
      "Prediction accuracy 0.866150\n",
      "[[ 0.78742709  0.21257291]\n",
      " [ 0.04848911  0.95151089]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.79      0.86      1543\n",
      "        1.0       0.80      0.95      0.87      1423\n",
      "\n",
      "avg / total       0.88      0.87      0.87      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with MLPC\n",
      "Prediction accuracy 0.887728\n",
      "[[ 0.89353364  0.10646636]\n",
      " [ 0.1184669   0.8815331 ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.89      0.89      1531\n",
      "        1.0       0.89      0.88      0.88      1435\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with MLPC\n",
      "Prediction accuracy 0.867161\n",
      "[[ 0.83279326  0.16720674]\n",
      " [ 0.09557273  0.90442727]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.83      0.87      1543\n",
      "        1.0       0.83      0.90      0.87      1423\n",
      "\n",
      "avg / total       0.87      0.87      0.87      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with Rand\n",
      "Prediction accuracy 0.899191\n",
      "[[ 0.87459177  0.12540823]\n",
      " [ 0.07456446  0.92543554]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.87      0.90      1531\n",
      "        1.0       0.87      0.93      0.90      1435\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with Rand\n",
      "Prediction accuracy 0.876264\n",
      "[[ 0.808814    0.191186  ]\n",
      " [ 0.05059733  0.94940267]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.81      0.87      1543\n",
      "        1.0       0.82      0.95      0.88      1423\n",
      "\n",
      "avg / total       0.89      0.88      0.88      2966\n",
      "\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# validate between the different objects using the dataset from both fingers\n",
    "\n",
    "# Version 1: keep alternatively one for training and test on the rest\n",
    "\n",
    "\n",
    "data_X = deepcopy(X[2][1]) #[:-1]\n",
    "data_Y = deepcopy(Y[2]) #[:-1]\n",
    "print(data_X.shape)\n",
    "surfaces = np.split(data_X,3)\n",
    "surf_labels = np.split(data_Y,3) \n",
    "feat_mask = []\n",
    "\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "\n",
    "for surf_ind, surf_dat in enumerate(surfaces):\n",
    "    print(\"Training on surface no. %d\" %surf_ind)\n",
    "    ind_mask = [True, True, True] \n",
    "    ind_mask[surf_ind] = False #  the training dataset is flagged by False\n",
    "    solely_for_printing_mask = [i for i, x in enumerate(ind_mask) if x == True]\n",
    "    train_x = surf_dat#[::100]\n",
    "    train_y = surf_labels[surf_ind]#[::100]\n",
    "    test_x = list(compress(surfaces, ind_mask)) # the rest splits, flagged by True, are kept for testing\n",
    "    test_y = list(compress(surf_labels,ind_mask))\n",
    "    \n",
    "    for pipe_ind,pipe in enumerate(pipe_list):\n",
    "        print(\"Fitting classifier no. %d...\" %pipe_ind)\n",
    "        pipe.fit(train_x,train_y) # fit the pipeline for every train set and every clf\n",
    "        print (\"...done fitting\")\n",
    "        feat = list(pipe.named_steps['feature_selection'].get_support(indices = True))\n",
    "        feat_mask+=feat\n",
    "        for test_ind, test_d in enumerate(test_x):\n",
    "            y_pred = pipe.predict(test_d)\n",
    "            y_true = test_y[test_ind]\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=y_true)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print (\"=============================================================\")\n",
    "            print(\"Trained on %d, testing on %d with %0.4s\" %(surf_ind, solely_for_printing_mask[test_ind], pipe.named_steps['classifier']))\n",
    "            print(\"Prediction accuracy %f\" %pipe.score(test_d,y_true))\n",
    "            print(cm)\n",
    "            print(classification_report(y_pred=y_pred, y_true = y_true))        \n",
    "            print (\"=============================================================\")\n",
    "    \n",
    "tot_occs = get_feat_occ(feat_mask)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n",
      "(3111, 'var', 'Phin', 'Time', 'Ft/Fn')\n",
      "(3112, 'rms', 'Phin', 'Time', 'Ft/Fn')\n",
      "(3113, 'rng', 'Phin', 'Time', 'Ft/Fn')\n",
      "(3114, 'wavl', 'Phin', 'Time', 'Ft/Fn')\n",
      "(3127, 'mmdf', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3128, 'reFFT000', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3130, 'reFFT002', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3131, 'reFFT003', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3132, 'reFFT004', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3133, 'reFFT005', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3134, 'reFFT006', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3135, 'reFFT007', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3136, 'reFFT008', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3137, 'reFFT009', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3138, 'reFFT010', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3139, 'reFFT011', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3140, 'reFFT012', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3141, 'reFFT013', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3146, 'reFFT018', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3148, 'reFFT020', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3644, 'imFFT003', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3649, 'imFFT008', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3651, 'imFFT010', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3665, 'imFFT024', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(4156, 'mx', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4157, 'rngx', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4159, 'med', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4160, 'hjorth', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4163, 'ssk', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4165, 'acrol0001', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4166, 'acrol0002', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4167, 'acrol0003', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4168, 'acrol0004', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4169, 'acrol0005', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4170, 'acrol0006', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4171, 'acrol0007', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4172, 'acrol0008', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4173, 'acrol0009', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4174, 'acrol0010', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4175, 'acrol0011', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4176, 'acrol0012', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4177, 'acrol0013', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4178, 'acrol0014', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4179, 'acrol0015', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4180, 'acrol0016', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4181, 'acrol0017', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4182, 'acrol0018', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4183, 'acrol0019', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4184, 'acrol0020', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4185, 'acrol0021', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4186, 'acrol0022', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4187, 'acrol0023', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4188, 'acrol0024', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4194, 'acrol0030', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4195, 'acrol0031', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4197, 'acrol0033', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4198, 'acrol0034', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4199, 'acrol0035', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4200, 'acrol0036', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4201, 'acrol0037', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4202, 'acrol0038', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4203, 'acrol0039', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4204, 'acrol0040', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4205, 'acrol0041', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4206, 'acrol0042', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4207, 'acrol0043', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4208, 'acrol0044', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4209, 'acrol0045', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4210, 'acrol0046', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4211, 'acrol0047', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4212, 'acrol0048', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4213, 'acrol0049', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4214, 'acrol0050', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4215, 'acrol0051', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4216, 'acrol0052', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4217, 'acrol0053', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4218, 'acrol0054', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4219, 'acrol0055', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4220, 'acrol0056', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4221, 'acrol0057', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4222, 'acrol0058', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4223, 'acrol0059', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4224, 'acrol0060', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4225, 'acrol0061', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4226, 'acrol0062', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4227, 'acrol0063', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4228, 'acrol0064', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4229, 'acrol0065', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4230, 'acrol0066', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4231, 'acrol0067', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4232, 'acrol0068', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4233, 'acrol0069', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4234, 'acrol0070', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4235, 'acrol0071', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4236, 'acrol0072', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4237, 'acrol0073', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4238, 'acrol0074', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4239, 'acrol0075', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4240, 'acrol0076', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4241, 'acrol0077', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4242, 'acrol0078', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4243, 'acrol0079', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4244, 'acrol0080', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4245, 'acrol0081', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4246, 'acrol0082', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4247, 'acrol0083', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4248, 'acrol0084', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4249, 'acrol0085', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4250, 'acrol0086', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4251, 'acrol0087', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4252, 'acrol0088', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4253, 'acrol0089', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4254, 'acrol0090', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4255, 'acrol0091', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4256, 'acrol0092', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4257, 'acrol0093', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4258, 'acrol0094', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4259, 'acrol0095', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4260, 'acrol0096', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4261, 'acrol0097', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4262, 'acrol0098', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4263, 'acrol0099', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4264, 'acrol0100', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4265, 'acrol0101', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4266, 'acrol0102', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4267, 'acrol0103', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4268, 'acrol0104', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4269, 'acrol0105', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4270, 'acrol0106', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4271, 'acrol0107', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4272, 'acrol0108', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4273, 'acrol0109', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4274, 'acrol0110', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4275, 'acrol0111', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4276, 'acrol0112', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4277, 'acrol0113', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4278, 'acrol0114', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4279, 'acrol0115', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4280, 'acrol0116', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4281, 'acrol0117', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4282, 'acrol0118', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4283, 'acrol0119', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4284, 'acrol0120', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4285, 'acrol0121', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4286, 'acrol0122', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4287, 'acrol0123', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4288, 'acrol0124', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4289, 'acrol0125', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4290, 'acrol0126', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4291, 'acrol0127', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4292, 'acrol0128', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4293, 'acrol0129', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4294, 'acrol0130', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4295, 'acrol0131', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4296, 'acrol0132', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4297, 'acrol0133', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4298, 'acrol0134', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4299, 'acrol0135', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4300, 'acrol0136', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4301, 'acrol0137', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4302, 'acrol0138', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4303, 'acrol0139', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4304, 'acrol0140', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4305, 'acrol0141', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4306, 'acrol0142', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4307, 'acrol0143', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4308, 'acrol0144', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4309, 'acrol0145', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4310, 'acrol0146', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4311, 'acrol0147', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4312, 'acrol0148', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4313, 'acrol0149', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4314, 'acrol0150', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4315, 'acrol0151', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4316, 'acrol0152', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4317, 'acrol0153', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4318, 'acrol0154', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4319, 'acrol0155', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4320, 'acrol0156', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4321, 'acrol0157', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4322, 'acrol0158', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4323, 'acrol0159', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4324, 'acrol0160', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4325, 'acrol0161', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4326, 'acrol0162', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4327, 'acrol0163', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4328, 'acrol0164', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4329, 'acrol0165', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4330, 'acrol0166', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4331, 'acrol0167', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4332, 'acrol0168', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4333, 'acrol0169', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4334, 'acrol0170', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4335, 'acrol0171', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4336, 'acrol0172', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4337, 'acrol0173', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4338, 'acrol0174', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4339, 'acrol0175', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4340, 'acrol0176', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4341, 'acrol0177', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4342, 'acrol0178', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4343, 'acrol0179', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4344, 'acrol0180', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4345, 'acrol0181', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4346, 'acrol0182', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4347, 'acrol0183', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4348, 'acrol0184', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4349, 'acrol0185', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4350, 'acrol0186', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4351, 'acrol0187', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4352, 'acrol0188', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4353, 'acrol0189', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4354, 'acrol0190', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4355, 'acrol0191', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4356, 'acrol0192', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4357, 'acrol0193', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4358, 'acrol0194', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4361, 'acrol0197', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4362, 'acrol0198', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4363, 'acrol0199', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4364, 'acrol0200', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4365, 'acrol0201', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4366, 'acrol0202', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4367, 'acrol0203', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4368, 'acrol0204', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4369, 'acrol0205', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4370, 'acrol0206', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4371, 'acrol0207', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4375, 'acrol0211', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4376, 'acrol0212', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4377, 'acrol0213', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4378, 'acrol0214', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4379, 'acrol0215', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4380, 'acrol0216', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4381, 'acrol0217', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4394, 'acrol0230', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4395, 'acrol0231', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4396, 'acrol0232', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4397, 'acrol0233', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4398, 'acrol0234', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4399, 'acrol0235', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4400, 'acrol0236', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4401, 'acrol0237', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4402, 'acrol0238', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4403, 'acrol0239', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4404, 'acrol0240', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4405, 'acrol0241', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4406, 'acrol0242', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4408, 'acrol0244', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4409, 'acrol0245', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4411, 'acrol0247', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4412, 'acrol0248', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4413, 'acrol0249', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4414, 'acrol0250', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4415, 'acrol0251', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4416, 'acrol0252', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4417, 'acrol0253', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4418, 'acrol0254', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4419, 'acrol0255', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4420, 'acrol0256', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4422, 'acrol0258', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4423, 'acrol0259', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4424, 'acrol0260', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4428, 'acrol0264', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4429, 'acrol0265', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4430, 'acrol0266', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4431, 'acrol0267', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4432, 'acrol0268', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4433, 'acrol0269', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4434, 'acrol0270', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4435, 'acrol0271', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4437, 'acrol0273', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4441, 'acrol0277', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4442, 'acrol0278', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4443, 'acrol0279', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4482, 'acrol0318', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4484, 'acrol0320', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4485, 'acrol0321', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4486, 'acrol0322', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4487, 'acrol0323', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4535, 'acrol0371', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4536, 'acrol0372', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4537, 'acrol0373', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4538, 'acrol0374', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4539, 'acrol0375', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4540, 'acrol0376', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4546, 'acrol0382', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4547, 'acrol0383', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4548, 'acrol0384', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4549, 'acrol0385', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4550, 'acrol0386', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4551, 'acrol0387', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4553, 'acrol0389', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4554, 'acrol0390', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4555, 'acrol0391', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4556, 'acrol0392', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4558, 'acrol0394', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4559, 'acrol0395', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4565, 'acrol0401', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4573, 'acrol0409', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4574, 'acrol0410', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4575, 'acrol0411', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4576, 'acrol0412', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4577, 'acrol0413', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4578, 'acrol0414', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4579, 'acrol0415', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4580, 'acrol0416', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4581, 'acrol0417', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4582, 'acrol0418', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4583, 'acrol0419', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4584, 'acrol0420', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4585, 'acrol0421', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4586, 'acrol0422', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4587, 'acrol0423', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4588, 'acrol0424', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4589, 'acrol0425', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4590, 'acrol0426', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4591, 'acrol0427', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4592, 'acrol0428', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4593, 'acrol0429', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4594, 'acrol0430', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4595, 'acrol0431', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4596, 'acrol0432', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4597, 'acrol0433', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4601, 'acrol0437', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4602, 'acrol0438', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4603, 'acrol0439', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4604, 'acrol0440', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4605, 'acrol0441', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4606, 'acrol0442', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4607, 'acrol0443', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4608, 'acrol0444', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4610, 'acrol0446', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4611, 'acrol0447', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4612, 'acrol0448', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4613, 'acrol0449', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4614, 'acrol0450', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4615, 'acrol0451', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4616, 'acrol0452', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4617, 'acrol0453', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4618, 'acrol0454', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4619, 'acrol0455', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4620, 'acrol0456', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4624, 'acrol0460', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4626, 'acrol0462', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4627, 'acrol0463', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4632, 'acrol0468', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4633, 'acrol0469', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4635, 'acrol0471', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4638, 'acrol0474', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4639, 'acrol0475', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4640, 'acrol0476', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4641, 'acrol0477', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4642, 'acrol0478', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4643, 'acrol0479', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4644, 'acrol0480', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4646, 'acrol0482', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4651, 'acrol0487', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4658, 'acrol0494', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4663, 'acrol0499', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4664, 'acrol0500', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4665, 'acrol0501', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4666, 'acrol0502', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4667, 'acrol0503', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4669, 'acrol0505', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4673, 'acrol0509', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4674, 'acrol0510', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4675, 'acrol0511', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4676, 'acrol0512', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4677, 'acrol0513', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4678, 'acrol0514', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4679, 'acrol0515', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4680, 'acrol0516', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4681, 'acrol0517', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4682, 'acrol0518', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4683, 'acrol0519', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4684, 'acrol0520', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4685, 'acrol0521', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4686, 'acrol0522', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4688, 'acrol0524', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4689, 'acrol0525', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4690, 'acrol0526', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4699, 'acrol0535', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4726, 'acrol0562', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4727, 'acrol0563', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4728, 'acrol0564', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4729, 'acrol0565', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4730, 'acrol0566', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4731, 'acrol0567', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4732, 'acrol0568', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4734, 'acrol0570', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4736, 'acrol0572', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4808, 'acrol0644', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4817, 'acrol0653', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4818, 'acrol0654', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4821, 'acrol0657', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4822, 'acrol0658', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4823, 'acrol0659', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4824, 'acrol0660', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4825, 'acrol0661', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4826, 'acrol0662', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4844, 'acrol0680', 'Golz', 'Time', 'Ft/Fn')\n",
      "(5043, 'acrol0879', 'Golz', 'Time', 'Ft/Fn')\n",
      "(5183, 'acrol1019', 'Golz', 'Time', 'Ft/Fn')\n",
      "(5198, 'amFFT010', 'Golz', 'Freq', 'Ft/Fn')\n",
      "(5199, 'amFFT011', 'Golz', 'Freq', 'Ft/Fn')\n",
      "(5200, 'amFFT012', 'Golz', 'Freq', 'Ft/Fn')\n",
      "(5711, 'phFFT010', 'Golz', 'Freq', 'Ft/Fn')\n",
      "(5712, 'phFFT011', 'Golz', 'Freq', 'Ft/Fn')\n",
      "(5713, 'phFFT012', 'Golz', 'Freq', 'Ft/Fn')\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################################\n",
    "# ==================== use this with Ft/Fn datasets ====================\n",
    "voi = 12   \n",
    "always_there = []\n",
    "offset = 3108\n",
    "off_feats = [feat_mask[i]+offset for i in range(len(feat_mask))]\n",
    "off_occs = get_feat_occ(off_feats)\n",
    "feat_list = []\n",
    "# print(off_occs)\n",
    "off_ordered = OrderedDict(sorted(off_occs.items(), key=lambda off_occs: off_occs[1]))\n",
    "for k,v in off_ordered.items():\n",
    "    feat_list.append(k)\n",
    "off_ids = get_feat_id(feat_list,printit = 0)\n",
    "\n",
    "for k, v in off_ordered.items():\n",
    "    if v == voi:\n",
    "        always_there.append(k)\n",
    "print(len(always_there))\n",
    "always_there_ids = get_feat_id(always_there, printit = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049, 'acrol0992', 'Golz', 'Time', 'Norm')\n",
      "(2057, 'acrol1000', 'Golz', 'Time', 'Norm')\n",
      "(2058, 'acrol1001', 'Golz', 'Time', 'Norm')\n",
      "(2059, 'acrol1002', 'Golz', 'Time', 'Norm')\n",
      "(2060, 'acrol1003', 'Golz', 'Time', 'Norm')\n",
      "(2061, 'acrol1004', 'Golz', 'Time', 'Norm')\n",
      "(2063, 'acrol1006', 'Golz', 'Time', 'Norm')\n",
      "(18, 'mdf', 'Phin', 'Freq', 'Norm')\n",
      "(34, 'reFFT013', 'Phin', 'Freq', 'Norm')\n",
      "(37, 'reFFT016', 'Phin', 'Freq', 'Norm')\n",
      "(38, 'reFFT017', 'Phin', 'Freq', 'Norm')\n",
      "(40, 'reFFT019', 'Phin', 'Freq', 'Norm')\n",
      "(41, 'reFFT020', 'Phin', 'Freq', 'Norm')\n",
      "(42, 'reFFT021', 'Phin', 'Freq', 'Norm')\n",
      "(43, 'reFFT022', 'Phin', 'Freq', 'Norm')\n",
      "(2105, 'amFFT024', 'Golz', 'Freq', 'Norm')\n",
      "(2106, 'amFFT025', 'Golz', 'Freq', 'Norm')\n",
      "(2107, 'amFFT026', 'Golz', 'Freq', 'Norm')\n",
      "(2108, 'amFFT027', 'Golz', 'Freq', 'Norm')\n",
      "(2109, 'amFFT028', 'Golz', 'Freq', 'Norm')\n",
      "(2110, 'amFFT029', 'Golz', 'Freq', 'Norm')\n",
      "(2111, 'amFFT030', 'Golz', 'Freq', 'Norm')\n",
      "(2112, 'amFFT031', 'Golz', 'Freq', 'Norm')\n",
      "(2113, 'amFFT032', 'Golz', 'Freq', 'Norm')\n",
      "(2, 'meanabsslp', 'Phin', 'Time', 'Norm')\n",
      "(2115, 'amFFT034', 'Golz', 'Freq', 'Norm')\n",
      "(2116, 'amFFT035', 'Golz', 'Freq', 'Norm')\n",
      "(2117, 'amFFT036', 'Golz', 'Freq', 'Norm')\n",
      "(2118, 'amFFT037', 'Golz', 'Freq', 'Norm')\n",
      "(2119, 'amFFT038', 'Golz', 'Freq', 'Norm')\n",
      "(2120, 'amFFT039', 'Golz', 'Freq', 'Norm')\n",
      "(2121, 'amFFT040', 'Golz', 'Freq', 'Norm')\n",
      "(2122, 'amFFT041', 'Golz', 'Freq', 'Norm')\n",
      "(2123, 'amFFT042', 'Golz', 'Freq', 'Norm')\n",
      "(2124, 'amFFT043', 'Golz', 'Freq', 'Norm')\n",
      "(2125, 'amFFT044', 'Golz', 'Freq', 'Norm')\n",
      "(2126, 'amFFT045', 'Golz', 'Freq', 'Norm')\n",
      "(2127, 'amFFT046', 'Golz', 'Freq', 'Norm')\n",
      "(2128, 'amFFT047', 'Golz', 'Freq', 'Norm')\n",
      "(2129, 'amFFT048', 'Golz', 'Freq', 'Norm')\n",
      "(2130, 'amFFT049', 'Golz', 'Freq', 'Norm')\n",
      "(2131, 'amFFT050', 'Golz', 'Freq', 'Norm')\n",
      "(2132, 'amFFT051', 'Golz', 'Freq', 'Norm')\n",
      "(2133, 'amFFT052', 'Golz', 'Freq', 'Norm')\n",
      "(2134, 'amFFT053', 'Golz', 'Freq', 'Norm')\n",
      "(2065, 'acrol1008', 'Golz', 'Time', 'Norm')\n",
      "(2067, 'acrol1010', 'Golz', 'Time', 'Norm')\n",
      "(2069, 'acrol1012', 'Golz', 'Time', 'Norm')\n",
      "(2070, 'acrol1013', 'Golz', 'Time', 'Norm')\n",
      "(550, 'imFFT016', 'Phin', 'Freq', 'Norm')\n",
      "(2074, 'acrol1017', 'Golz', 'Time', 'Norm')\n",
      "(2076, 'acrol1019', 'Golz', 'Time', 'Norm')\n",
      "(2077, 'acrol1020', 'Golz', 'Time', 'Norm')\n",
      "(2078, 'acrol1021', 'Golz', 'Time', 'Norm')\n",
      "(2052, 'acrol0995', 'Golz', 'Time', 'Norm')\n",
      "(2080, 'acrol1023', 'Golz', 'Time', 'Norm')\n",
      "(2053, 'acrol0996', 'Golz', 'Time', 'Norm')\n",
      "(2054, 'acrol0997', 'Golz', 'Time', 'Norm')\n",
      "(2055, 'acrol0998', 'Golz', 'Time', 'Norm')\n",
      "(555, 'imFFT021', 'Phin', 'Freq', 'Norm')\n",
      "(2114, 'amFFT033', 'Golz', 'Freq', 'Norm')\n",
      "(559, 'imFFT025', 'Phin', 'Freq', 'Norm')\n",
      "(560, 'imFFT026', 'Phin', 'Freq', 'Norm')\n",
      "(563, 'imFFT029', 'Phin', 'Freq', 'Norm')\n",
      "(535, 'imFFT001', 'Phin', 'Freq', 'Norm')\n",
      "(2618, 'phFFT024', 'Golz', 'Freq', 'Norm')\n",
      "(2619, 'phFFT025', 'Golz', 'Freq', 'Norm')\n",
      "(2620, 'phFFT026', 'Golz', 'Freq', 'Norm')\n",
      "(2621, 'phFFT027', 'Golz', 'Freq', 'Norm')\n",
      "(2622, 'phFFT028', 'Golz', 'Freq', 'Norm')\n",
      "(2623, 'phFFT029', 'Golz', 'Freq', 'Norm')\n",
      "(2624, 'phFFT030', 'Golz', 'Freq', 'Norm')\n",
      "(2625, 'phFFT031', 'Golz', 'Freq', 'Norm')\n",
      "(2626, 'phFFT032', 'Golz', 'Freq', 'Norm')\n",
      "(2627, 'phFFT033', 'Golz', 'Freq', 'Norm')\n",
      "(2628, 'phFFT034', 'Golz', 'Freq', 'Norm')\n",
      "(2629, 'phFFT035', 'Golz', 'Freq', 'Norm')\n",
      "(2630, 'phFFT036', 'Golz', 'Freq', 'Norm')\n",
      "(2631, 'phFFT037', 'Golz', 'Freq', 'Norm')\n",
      "(2632, 'phFFT038', 'Golz', 'Freq', 'Norm')\n",
      "(2633, 'phFFT039', 'Golz', 'Freq', 'Norm')\n",
      "(2634, 'phFFT040', 'Golz', 'Freq', 'Norm')\n",
      "(2635, 'phFFT041', 'Golz', 'Freq', 'Norm')\n",
      "(2636, 'phFFT042', 'Golz', 'Freq', 'Norm')\n",
      "(2637, 'phFFT043', 'Golz', 'Freq', 'Norm')\n",
      "(2638, 'phFFT044', 'Golz', 'Freq', 'Norm')\n",
      "(2639, 'phFFT045', 'Golz', 'Freq', 'Norm')\n",
      "(2640, 'phFFT046', 'Golz', 'Freq', 'Norm')\n",
      "(2641, 'phFFT047', 'Golz', 'Freq', 'Norm')\n",
      "(2642, 'phFFT048', 'Golz', 'Freq', 'Norm')\n",
      "(2643, 'phFFT049', 'Golz', 'Freq', 'Norm')\n",
      "(2644, 'phFFT050', 'Golz', 'Freq', 'Norm')\n",
      "(2645, 'phFFT051', 'Golz', 'Freq', 'Norm')\n",
      "(2646, 'phFFT052', 'Golz', 'Freq', 'Norm')\n",
      "(2647, 'phFFT053', 'Golz', 'Freq', 'Norm')\n",
      "(566, 'imFFT032', 'Phin', 'Freq', 'Norm')\n",
      "(567, 'imFFT033', 'Phin', 'Freq', 'Norm')\n",
      "(568, 'imFFT034', 'Phin', 'Freq', 'Norm')\n",
      "(564, 'imFFT030', 'Phin', 'Freq', 'Norm')\n",
      "(551, 'imFFT017', 'Phin', 'Freq', 'Norm')\n",
      "(1514, 'acrol0457', 'Golz', 'Time', 'Norm')\n",
      "(1620, 'acrol0563', 'Golz', 'Time', 'Norm')\n",
      "(1621, 'acrol0564', 'Golz', 'Time', 'Norm')\n",
      "(1623, 'acrol0566', 'Golz', 'Time', 'Norm')\n",
      "(1632, 'acrol0575', 'Golz', 'Time', 'Norm')\n",
      "(1636, 'acrol0579', 'Golz', 'Time', 'Norm')\n",
      "(1699, 'acrol0642', 'Golz', 'Time', 'Norm')\n",
      "(1704, 'acrol0647', 'Golz', 'Time', 'Norm')\n",
      "(1887, 'acrol0830', 'Golz', 'Time', 'Norm')\n",
      "(1904, 'acrol0847', 'Golz', 'Time', 'Norm')\n",
      "(1905, 'acrol0848', 'Golz', 'Time', 'Norm')\n",
      "(1914, 'acrol0857', 'Golz', 'Time', 'Norm')\n",
      "(1922, 'acrol0865', 'Golz', 'Time', 'Norm')\n",
      "(1960, 'acrol0903', 'Golz', 'Time', 'Norm')\n",
      "(1967, 'acrol0910', 'Golz', 'Time', 'Norm')\n",
      "(1968, 'acrol0911', 'Golz', 'Time', 'Norm')\n",
      "(553, 'imFFT019', 'Phin', 'Freq', 'Norm')\n",
      "(1984, 'acrol0927', 'Golz', 'Time', 'Norm')\n",
      "(1988, 'acrol0931', 'Golz', 'Time', 'Norm')\n",
      "(1989, 'acrol0932', 'Golz', 'Time', 'Norm')\n",
      "(1990, 'acrol0933', 'Golz', 'Time', 'Norm')\n",
      "(1998, 'acrol0941', 'Golz', 'Time', 'Norm')\n",
      "(1999, 'acrol0942', 'Golz', 'Time', 'Norm')\n",
      "(2000, 'acrol0943', 'Golz', 'Time', 'Norm')\n",
      "(2002, 'acrol0945', 'Golz', 'Time', 'Norm')\n",
      "(2008, 'acrol0951', 'Golz', 'Time', 'Norm')\n",
      "(2009, 'acrol0952', 'Golz', 'Time', 'Norm')\n",
      "(2010, 'acrol0953', 'Golz', 'Time', 'Norm')\n",
      "(2011, 'acrol0954', 'Golz', 'Time', 'Norm')\n",
      "(2012, 'acrol0955', 'Golz', 'Time', 'Norm')\n",
      "(2013, 'acrol0956', 'Golz', 'Time', 'Norm')\n",
      "(2014, 'acrol0957', 'Golz', 'Time', 'Norm')\n",
      "(2015, 'acrol0958', 'Golz', 'Time', 'Norm')\n",
      "(2016, 'acrol0959', 'Golz', 'Time', 'Norm')\n",
      "(2017, 'acrol0960', 'Golz', 'Time', 'Norm')\n",
      "(2018, 'acrol0961', 'Golz', 'Time', 'Norm')\n",
      "(2019, 'acrol0962', 'Golz', 'Time', 'Norm')\n",
      "(2020, 'acrol0963', 'Golz', 'Time', 'Norm')\n",
      "(2021, 'acrol0964', 'Golz', 'Time', 'Norm')\n",
      "(2025, 'acrol0968', 'Golz', 'Time', 'Norm')\n",
      "(2026, 'acrol0969', 'Golz', 'Time', 'Norm')\n",
      "(2028, 'acrol0971', 'Golz', 'Time', 'Norm')\n",
      "(2029, 'acrol0972', 'Golz', 'Time', 'Norm')\n",
      "(2030, 'acrol0973', 'Golz', 'Time', 'Norm')\n",
      "(2032, 'acrol0975', 'Golz', 'Time', 'Norm')\n",
      "(2033, 'acrol0976', 'Golz', 'Time', 'Norm')\n",
      "(2036, 'acrol0979', 'Golz', 'Time', 'Norm')\n",
      "(2041, 'acrol0984', 'Golz', 'Time', 'Norm')\n",
      "(2044, 'acrol0987', 'Golz', 'Time', 'Norm')\n",
      "(2045, 'acrol0988', 'Golz', 'Time', 'Norm')\n",
      "(2046, 'acrol0989', 'Golz', 'Time', 'Norm')\n",
      "(2047, 'acrol0990', 'Golz', 'Time', 'Norm')\n",
      "(2050, 'acrol0993', 'Golz', 'Time', 'Norm')\n",
      "(2056, 'acrol0999', 'Golz', 'Time', 'Norm')\n",
      "(2084, 'amFFT003', 'Golz', 'Freq', 'Norm')\n",
      "(39, 'reFFT018', 'Phin', 'Freq', 'Norm')\n",
      "(2099, 'amFFT018', 'Golz', 'Freq', 'Norm')\n",
      "(2100, 'amFFT019', 'Golz', 'Freq', 'Norm')\n",
      "(2101, 'amFFT020', 'Golz', 'Freq', 'Norm')\n",
      "(546, 'imFFT012', 'Phin', 'Freq', 'Norm')\n",
      "(2595, 'phFFT001', 'Golz', 'Freq', 'Norm')\n",
      "(2051, 'acrol0994', 'Golz', 'Time', 'Norm')\n",
      "(2075, 'acrol1018', 'Golz', 'Time', 'Norm')\n",
      "(2597, 'phFFT003', 'Golz', 'Freq', 'Norm')\n",
      "(2082, 'amFFT001', 'Golz', 'Freq', 'Norm')\n",
      "(539, 'imFFT005', 'Phin', 'Freq', 'Norm')\n",
      "(540, 'imFFT006', 'Phin', 'Freq', 'Norm')\n",
      "(547, 'imFFT013', 'Phin', 'Freq', 'Norm')\n",
      "(549, 'imFFT015', 'Phin', 'Freq', 'Norm')\n",
      "(556, 'imFFT022', 'Phin', 'Freq', 'Norm')\n",
      "(557, 'imFFT023', 'Phin', 'Freq', 'Norm')\n",
      "(561, 'imFFT027', 'Phin', 'Freq', 'Norm')\n",
      "(2612, 'phFFT018', 'Golz', 'Freq', 'Norm')\n",
      "(2613, 'phFFT019', 'Golz', 'Freq', 'Norm')\n",
      "(2614, 'phFFT020', 'Golz', 'Freq', 'Norm')\n",
      "(1052, 'med', 'Golz', 'Time', 'Norm')\n",
      "(1056, 'ssk', 'Golz', 'Time', 'Norm')\n",
      "(1199, 'acrol0142', 'Golz', 'Time', 'Norm')\n",
      "(1200, 'acrol0143', 'Golz', 'Time', 'Norm')\n",
      "(1203, 'acrol0146', 'Golz', 'Time', 'Norm')\n",
      "(1204, 'acrol0147', 'Golz', 'Time', 'Norm')\n",
      "(1205, 'acrol0148', 'Golz', 'Time', 'Norm')\n",
      "(1251, 'acrol0194', 'Golz', 'Time', 'Norm')\n",
      "(1253, 'acrol0196', 'Golz', 'Time', 'Norm')\n",
      "(1340, 'acrol0283', 'Golz', 'Time', 'Norm')\n",
      "(1344, 'acrol0287', 'Golz', 'Time', 'Norm')\n",
      "(1345, 'acrol0288', 'Golz', 'Time', 'Norm')\n",
      "(1349, 'acrol0292', 'Golz', 'Time', 'Norm')\n",
      "(1351, 'acrol0294', 'Golz', 'Time', 'Norm')\n",
      "(1353, 'acrol0296', 'Golz', 'Time', 'Norm')\n",
      "(1354, 'acrol0297', 'Golz', 'Time', 'Norm')\n",
      "(1355, 'acrol0298', 'Golz', 'Time', 'Norm')\n",
      "(1356, 'acrol0299', 'Golz', 'Time', 'Norm')\n",
      "(1357, 'acrol0300', 'Golz', 'Time', 'Norm')\n",
      "(1358, 'acrol0301', 'Golz', 'Time', 'Norm')\n",
      "(1359, 'acrol0302', 'Golz', 'Time', 'Norm')\n",
      "(1360, 'acrol0303', 'Golz', 'Time', 'Norm')\n",
      "(1381, 'acrol0324', 'Golz', 'Time', 'Norm')\n",
      "(1395, 'acrol0338', 'Golz', 'Time', 'Norm')\n",
      "(1401, 'acrol0344', 'Golz', 'Time', 'Norm')\n",
      "(1404, 'acrol0347', 'Golz', 'Time', 'Norm')\n",
      "(1405, 'acrol0348', 'Golz', 'Time', 'Norm')\n",
      "(1406, 'acrol0349', 'Golz', 'Time', 'Norm')\n",
      "(1442, 'acrol0385', 'Golz', 'Time', 'Norm')\n",
      "(1473, 'acrol0416', 'Golz', 'Time', 'Norm')\n",
      "(1482, 'acrol0425', 'Golz', 'Time', 'Norm')\n",
      "(1483, 'acrol0426', 'Golz', 'Time', 'Norm')\n",
      "(1487, 'acrol0430', 'Golz', 'Time', 'Norm')\n",
      "(1490, 'acrol0433', 'Golz', 'Time', 'Norm')\n",
      "(1496, 'acrol0439', 'Golz', 'Time', 'Norm')\n",
      "(1497, 'acrol0440', 'Golz', 'Time', 'Norm')\n",
      "(1498, 'acrol0441', 'Golz', 'Time', 'Norm')\n",
      "(1499, 'acrol0442', 'Golz', 'Time', 'Norm')\n",
      "(1500, 'acrol0443', 'Golz', 'Time', 'Norm')\n",
      "(1507, 'acrol0450', 'Golz', 'Time', 'Norm')\n",
      "(1508, 'acrol0451', 'Golz', 'Time', 'Norm')\n",
      "(1511, 'acrol0454', 'Golz', 'Time', 'Norm')\n",
      "(1513, 'acrol0456', 'Golz', 'Time', 'Norm')\n",
      "(1515, 'acrol0458', 'Golz', 'Time', 'Norm')\n",
      "(1517, 'acrol0460', 'Golz', 'Time', 'Norm')\n",
      "(1518, 'acrol0461', 'Golz', 'Time', 'Norm')\n",
      "(1519, 'acrol0462', 'Golz', 'Time', 'Norm')\n",
      "(1520, 'acrol0463', 'Golz', 'Time', 'Norm')\n",
      "(1521, 'acrol0464', 'Golz', 'Time', 'Norm')\n",
      "(1522, 'acrol0465', 'Golz', 'Time', 'Norm')\n",
      "(1523, 'acrol0466', 'Golz', 'Time', 'Norm')\n",
      "(1524, 'acrol0467', 'Golz', 'Time', 'Norm')\n",
      "(1525, 'acrol0468', 'Golz', 'Time', 'Norm')\n",
      "(1526, 'acrol0469', 'Golz', 'Time', 'Norm')\n",
      "(1528, 'acrol0471', 'Golz', 'Time', 'Norm')\n",
      "(1532, 'acrol0475', 'Golz', 'Time', 'Norm')\n",
      "(1533, 'acrol0476', 'Golz', 'Time', 'Norm')\n",
      "(1535, 'acrol0478', 'Golz', 'Time', 'Norm')\n",
      "(1537, 'acrol0480', 'Golz', 'Time', 'Norm')\n",
      "(1538, 'acrol0481', 'Golz', 'Time', 'Norm')\n",
      "(1539, 'acrol0482', 'Golz', 'Time', 'Norm')\n",
      "(1541, 'acrol0484', 'Golz', 'Time', 'Norm')\n",
      "(1542, 'acrol0485', 'Golz', 'Time', 'Norm')\n",
      "(1543, 'acrol0486', 'Golz', 'Time', 'Norm')\n",
      "(1544, 'acrol0487', 'Golz', 'Time', 'Norm')\n",
      "(1545, 'acrol0488', 'Golz', 'Time', 'Norm')\n",
      "(1573, 'acrol0516', 'Golz', 'Time', 'Norm')\n",
      "(1575, 'acrol0518', 'Golz', 'Time', 'Norm')\n",
      "(1579, 'acrol0522', 'Golz', 'Time', 'Norm')\n",
      "(1589, 'acrol0532', 'Golz', 'Time', 'Norm')\n",
      "(1600, 'acrol0543', 'Golz', 'Time', 'Norm')\n",
      "(1601, 'acrol0544', 'Golz', 'Time', 'Norm')\n",
      "(1614, 'acrol0557', 'Golz', 'Time', 'Norm')\n",
      "(1622, 'acrol0565', 'Golz', 'Time', 'Norm')\n",
      "(1624, 'acrol0567', 'Golz', 'Time', 'Norm')\n",
      "(1626, 'acrol0569', 'Golz', 'Time', 'Norm')\n",
      "(1628, 'acrol0571', 'Golz', 'Time', 'Norm')\n",
      "(1631, 'acrol0574', 'Golz', 'Time', 'Norm')\n",
      "(1635, 'acrol0578', 'Golz', 'Time', 'Norm')\n",
      "(1638, 'acrol0581', 'Golz', 'Time', 'Norm')\n",
      "(1640, 'acrol0583', 'Golz', 'Time', 'Norm')\n",
      "(1643, 'acrol0586', 'Golz', 'Time', 'Norm')\n",
      "(1647, 'acrol0590', 'Golz', 'Time', 'Norm')\n",
      "(1648, 'acrol0591', 'Golz', 'Time', 'Norm')\n",
      "(1649, 'acrol0592', 'Golz', 'Time', 'Norm')\n",
      "(1651, 'acrol0594', 'Golz', 'Time', 'Norm')\n",
      "(1653, 'acrol0596', 'Golz', 'Time', 'Norm')\n",
      "(1657, 'acrol0600', 'Golz', 'Time', 'Norm')\n",
      "(1658, 'acrol0601', 'Golz', 'Time', 'Norm')\n",
      "(1662, 'acrol0605', 'Golz', 'Time', 'Norm')\n",
      "(1663, 'acrol0606', 'Golz', 'Time', 'Norm')\n",
      "(1664, 'acrol0607', 'Golz', 'Time', 'Norm')\n",
      "(1669, 'acrol0612', 'Golz', 'Time', 'Norm')\n",
      "(1670, 'acrol0613', 'Golz', 'Time', 'Norm')\n",
      "(1671, 'acrol0614', 'Golz', 'Time', 'Norm')\n",
      "(1674, 'acrol0617', 'Golz', 'Time', 'Norm')\n",
      "(1690, 'acrol0633', 'Golz', 'Time', 'Norm')\n",
      "(1691, 'acrol0634', 'Golz', 'Time', 'Norm')\n",
      "(1692, 'acrol0635', 'Golz', 'Time', 'Norm')\n",
      "(1693, 'acrol0636', 'Golz', 'Time', 'Norm')\n",
      "(1694, 'acrol0637', 'Golz', 'Time', 'Norm')\n",
      "(1695, 'acrol0638', 'Golz', 'Time', 'Norm')\n",
      "(1696, 'acrol0639', 'Golz', 'Time', 'Norm')\n",
      "(1697, 'acrol0640', 'Golz', 'Time', 'Norm')\n",
      "(1698, 'acrol0641', 'Golz', 'Time', 'Norm')\n",
      "(1700, 'acrol0643', 'Golz', 'Time', 'Norm')\n",
      "(1703, 'acrol0646', 'Golz', 'Time', 'Norm')\n",
      "(1705, 'acrol0648', 'Golz', 'Time', 'Norm')\n",
      "(1724, 'acrol0667', 'Golz', 'Time', 'Norm')\n",
      "(1726, 'acrol0669', 'Golz', 'Time', 'Norm')\n",
      "(1729, 'acrol0672', 'Golz', 'Time', 'Norm')\n",
      "(1730, 'acrol0673', 'Golz', 'Time', 'Norm')\n",
      "(1734, 'acrol0677', 'Golz', 'Time', 'Norm')\n",
      "(1736, 'acrol0679', 'Golz', 'Time', 'Norm')\n",
      "(1743, 'acrol0686', 'Golz', 'Time', 'Norm')\n",
      "(1745, 'acrol0688', 'Golz', 'Time', 'Norm')\n",
      "(1747, 'acrol0690', 'Golz', 'Time', 'Norm')\n",
      "(1749, 'acrol0692', 'Golz', 'Time', 'Norm')\n",
      "(1751, 'acrol0694', 'Golz', 'Time', 'Norm')\n",
      "(1758, 'acrol0701', 'Golz', 'Time', 'Norm')\n",
      "(1778, 'acrol0721', 'Golz', 'Time', 'Norm')\n",
      "(1779, 'acrol0722', 'Golz', 'Time', 'Norm')\n",
      "(1780, 'acrol0723', 'Golz', 'Time', 'Norm')\n",
      "(1781, 'acrol0724', 'Golz', 'Time', 'Norm')\n",
      "(1784, 'acrol0727', 'Golz', 'Time', 'Norm')\n",
      "(1786, 'acrol0729', 'Golz', 'Time', 'Norm')\n",
      "(1789, 'acrol0732', 'Golz', 'Time', 'Norm')\n",
      "(1790, 'acrol0733', 'Golz', 'Time', 'Norm')\n",
      "(1792, 'acrol0735', 'Golz', 'Time', 'Norm')\n",
      "(1800, 'acrol0743', 'Golz', 'Time', 'Norm')\n",
      "(1802, 'acrol0745', 'Golz', 'Time', 'Norm')\n",
      "(1807, 'acrol0750', 'Golz', 'Time', 'Norm')\n",
      "(1808, 'acrol0751', 'Golz', 'Time', 'Norm')\n",
      "(1810, 'acrol0753', 'Golz', 'Time', 'Norm')\n",
      "(1811, 'acrol0754', 'Golz', 'Time', 'Norm')\n",
      "(1813, 'acrol0756', 'Golz', 'Time', 'Norm')\n",
      "(1814, 'acrol0757', 'Golz', 'Time', 'Norm')\n",
      "(1818, 'acrol0761', 'Golz', 'Time', 'Norm')\n",
      "(1822, 'acrol0765', 'Golz', 'Time', 'Norm')\n",
      "(1824, 'acrol0767', 'Golz', 'Time', 'Norm')\n",
      "(1827, 'acrol0770', 'Golz', 'Time', 'Norm')\n",
      "(1828, 'acrol0771', 'Golz', 'Time', 'Norm')\n",
      "(1829, 'acrol0772', 'Golz', 'Time', 'Norm')\n",
      "(1831, 'acrol0774', 'Golz', 'Time', 'Norm')\n",
      "(1834, 'acrol0777', 'Golz', 'Time', 'Norm')\n",
      "(1835, 'acrol0778', 'Golz', 'Time', 'Norm')\n",
      "(1836, 'acrol0779', 'Golz', 'Time', 'Norm')\n",
      "(1837, 'acrol0780', 'Golz', 'Time', 'Norm')\n",
      "(1838, 'acrol0781', 'Golz', 'Time', 'Norm')\n",
      "(1843, 'acrol0786', 'Golz', 'Time', 'Norm')\n",
      "(1889, 'acrol0832', 'Golz', 'Time', 'Norm')\n",
      "(1896, 'acrol0839', 'Golz', 'Time', 'Norm')\n",
      "(1899, 'acrol0842', 'Golz', 'Time', 'Norm')\n",
      "(1902, 'acrol0845', 'Golz', 'Time', 'Norm')\n",
      "(1906, 'acrol0849', 'Golz', 'Time', 'Norm')\n",
      "(1907, 'acrol0850', 'Golz', 'Time', 'Norm')\n",
      "(1908, 'acrol0851', 'Golz', 'Time', 'Norm')\n",
      "(1909, 'acrol0852', 'Golz', 'Time', 'Norm')\n",
      "(1912, 'acrol0855', 'Golz', 'Time', 'Norm')\n",
      "(1913, 'acrol0856', 'Golz', 'Time', 'Norm')\n",
      "(1923, 'acrol0866', 'Golz', 'Time', 'Norm')\n",
      "(1929, 'acrol0872', 'Golz', 'Time', 'Norm')\n",
      "(1934, 'acrol0877', 'Golz', 'Time', 'Norm')\n",
      "(1936, 'acrol0879', 'Golz', 'Time', 'Norm')\n",
      "(1942, 'acrol0885', 'Golz', 'Time', 'Norm')\n",
      "(1943, 'acrol0886', 'Golz', 'Time', 'Norm')\n",
      "(1945, 'acrol0888', 'Golz', 'Time', 'Norm')\n",
      "(1946, 'acrol0889', 'Golz', 'Time', 'Norm')\n",
      "(1947, 'acrol0890', 'Golz', 'Time', 'Norm')\n",
      "(1948, 'acrol0891', 'Golz', 'Time', 'Norm')\n",
      "(1949, 'acrol0892', 'Golz', 'Time', 'Norm')\n",
      "(1950, 'acrol0893', 'Golz', 'Time', 'Norm')\n",
      "(1951, 'acrol0894', 'Golz', 'Time', 'Norm')\n",
      "(1952, 'acrol0895', 'Golz', 'Time', 'Norm')\n",
      "(1953, 'acrol0896', 'Golz', 'Time', 'Norm')\n",
      "(1954, 'acrol0897', 'Golz', 'Time', 'Norm')\n",
      "(1955, 'acrol0898', 'Golz', 'Time', 'Norm')\n",
      "(1961, 'acrol0904', 'Golz', 'Time', 'Norm')\n",
      "(1962, 'acrol0905', 'Golz', 'Time', 'Norm')\n",
      "(1965, 'acrol0908', 'Golz', 'Time', 'Norm')\n",
      "(1970, 'acrol0913', 'Golz', 'Time', 'Norm')\n",
      "(1971, 'acrol0914', 'Golz', 'Time', 'Norm')\n",
      "(1972, 'acrol0915', 'Golz', 'Time', 'Norm')\n",
      "(1979, 'acrol0922', 'Golz', 'Time', 'Norm')\n",
      "(1981, 'acrol0924', 'Golz', 'Time', 'Norm')\n",
      "(1982, 'acrol0925', 'Golz', 'Time', 'Norm')\n",
      "(1985, 'acrol0928', 'Golz', 'Time', 'Norm')\n",
      "(1994, 'acrol0937', 'Golz', 'Time', 'Norm')\n",
      "(1995, 'acrol0938', 'Golz', 'Time', 'Norm')\n",
      "(1996, 'acrol0939', 'Golz', 'Time', 'Norm')\n",
      "(1997, 'acrol0940', 'Golz', 'Time', 'Norm')\n",
      "(2001, 'acrol0944', 'Golz', 'Time', 'Norm')\n",
      "(2031, 'acrol0974', 'Golz', 'Time', 'Norm')\n",
      "(2037, 'acrol0980', 'Golz', 'Time', 'Norm')\n",
      "(2038, 'acrol0981', 'Golz', 'Time', 'Norm')\n",
      "(2039, 'acrol0982', 'Golz', 'Time', 'Norm')\n",
      "(2040, 'acrol0983', 'Golz', 'Time', 'Norm')\n",
      "(2042, 'acrol0985', 'Golz', 'Time', 'Norm')\n",
      "(0, 'intsgnl', 'Phin', 'Time', 'Norm')\n",
      "(1, 'meanabs', 'Phin', 'Time', 'Norm')\n",
      "(3, 'ssi', 'Phin', 'Time', 'Norm')\n",
      "(4, 'var', 'Phin', 'Time', 'Norm')\n",
      "(5, 'rms', 'Phin', 'Time', 'Norm')\n",
      "(6, 'rng', 'Phin', 'Time', 'Norm')\n",
      "(17, 'mnf', 'Phin', 'Freq', 'Norm')\n",
      "(19, 'mmnf', 'Phin', 'Freq', 'Norm')\n",
      "(20, 'mmdf', 'Phin', 'Freq', 'Norm')\n",
      "(21, 'reFFT000', 'Phin', 'Freq', 'Norm')\n",
      "(22, 'reFFT001', 'Phin', 'Freq', 'Norm')\n",
      "(23, 'reFFT002', 'Phin', 'Freq', 'Norm')\n",
      "(24, 'reFFT003', 'Phin', 'Freq', 'Norm')\n",
      "(25, 'reFFT004', 'Phin', 'Freq', 'Norm')\n",
      "(26, 'reFFT005', 'Phin', 'Freq', 'Norm')\n",
      "(27, 'reFFT006', 'Phin', 'Freq', 'Norm')\n",
      "(28, 'reFFT007', 'Phin', 'Freq', 'Norm')\n",
      "(29, 'reFFT008', 'Phin', 'Freq', 'Norm')\n",
      "(30, 'reFFT009', 'Phin', 'Freq', 'Norm')\n",
      "(31, 'reFFT010', 'Phin', 'Freq', 'Norm')\n",
      "(32, 'reFFT011', 'Phin', 'Freq', 'Norm')\n",
      "(33, 'reFFT012', 'Phin', 'Freq', 'Norm')\n",
      "(35, 'reFFT014', 'Phin', 'Freq', 'Norm')\n",
      "(2092, 'amFFT011', 'Golz', 'Freq', 'Norm')\n",
      "(2093, 'amFFT012', 'Golz', 'Freq', 'Norm')\n",
      "(2094, 'amFFT013', 'Golz', 'Freq', 'Norm')\n",
      "(2095, 'amFFT014', 'Golz', 'Freq', 'Norm')\n",
      "(2096, 'amFFT015', 'Golz', 'Freq', 'Norm')\n",
      "(2097, 'amFFT016', 'Golz', 'Freq', 'Norm')\n",
      "(2098, 'amFFT017', 'Golz', 'Freq', 'Norm')\n",
      "(2102, 'amFFT021', 'Golz', 'Freq', 'Norm')\n",
      "(2103, 'amFFT022', 'Golz', 'Freq', 'Norm')\n",
      "(2104, 'amFFT023', 'Golz', 'Freq', 'Norm')\n",
      "(2596, 'phFFT002', 'Golz', 'Freq', 'Norm')\n",
      "(2081, 'amFFT000', 'Golz', 'Freq', 'Norm')\n",
      "(2083, 'amFFT002', 'Golz', 'Freq', 'Norm')\n",
      "(2085, 'amFFT004', 'Golz', 'Freq', 'Norm')\n",
      "(2086, 'amFFT005', 'Golz', 'Freq', 'Norm')\n",
      "(2087, 'amFFT006', 'Golz', 'Freq', 'Norm')\n",
      "(2088, 'amFFT007', 'Golz', 'Freq', 'Norm')\n",
      "(2089, 'amFFT008', 'Golz', 'Freq', 'Norm')\n",
      "(2090, 'amFFT009', 'Golz', 'Freq', 'Norm')\n",
      "(2091, 'amFFT010', 'Golz', 'Freq', 'Norm')\n",
      "(2600, 'phFFT006', 'Golz', 'Freq', 'Norm')\n",
      "(2602, 'phFFT008', 'Golz', 'Freq', 'Norm')\n",
      "(2604, 'phFFT010', 'Golz', 'Freq', 'Norm')\n",
      "(2605, 'phFFT011', 'Golz', 'Freq', 'Norm')\n",
      "(2609, 'phFFT015', 'Golz', 'Freq', 'Norm')\n",
      "(536, 'imFFT002', 'Phin', 'Freq', 'Norm')\n",
      "(537, 'imFFT003', 'Phin', 'Freq', 'Norm')\n",
      "(538, 'imFFT004', 'Phin', 'Freq', 'Norm')\n",
      "(541, 'imFFT007', 'Phin', 'Freq', 'Norm')\n",
      "(542, 'imFFT008', 'Phin', 'Freq', 'Norm')\n",
      "(543, 'imFFT009', 'Phin', 'Freq', 'Norm')\n",
      "(544, 'imFFT010', 'Phin', 'Freq', 'Norm')\n",
      "(545, 'imFFT011', 'Phin', 'Freq', 'Norm')\n",
      "(2594, 'phFFT000', 'Golz', 'Freq', 'Norm')\n",
      "(548, 'imFFT014', 'Phin', 'Freq', 'Norm')\n",
      "(2598, 'phFFT004', 'Golz', 'Freq', 'Norm')\n",
      "(2599, 'phFFT005', 'Golz', 'Freq', 'Norm')\n",
      "(552, 'imFFT018', 'Phin', 'Freq', 'Norm')\n",
      "(2601, 'phFFT007', 'Golz', 'Freq', 'Norm')\n",
      "(554, 'imFFT020', 'Phin', 'Freq', 'Norm')\n",
      "(2603, 'phFFT009', 'Golz', 'Freq', 'Norm')\n",
      "(2606, 'phFFT012', 'Golz', 'Freq', 'Norm')\n",
      "(2607, 'phFFT013', 'Golz', 'Freq', 'Norm')\n",
      "(2608, 'phFFT014', 'Golz', 'Freq', 'Norm')\n",
      "(2610, 'phFFT016', 'Golz', 'Freq', 'Norm')\n",
      "(2611, 'phFFT017', 'Golz', 'Freq', 'Norm')\n",
      "(2615, 'phFFT021', 'Golz', 'Freq', 'Norm')\n",
      "(2616, 'phFFT022', 'Golz', 'Freq', 'Norm')\n",
      "(2617, 'phFFT023', 'Golz', 'Freq', 'Norm')\n",
      "(1047, 'meanv', 'Golz', 'Time', 'Norm')\n",
      "(1048, 'stdr', 'Golz', 'Time', 'Norm')\n",
      "(1049, 'mx', 'Golz', 'Time', 'Norm')\n",
      "(1051, 'rngy', 'Golz', 'Time', 'Norm')\n",
      "(1053, 'hjorth', 'Golz', 'Time', 'Norm')\n",
      "(1055, 'se', 'Golz', 'Time', 'Norm')\n",
      "(1057, 'acrol0000', 'Golz', 'Time', 'Norm')\n",
      "(1058, 'acrol0001', 'Golz', 'Time', 'Norm')\n",
      "(1059, 'acrol0002', 'Golz', 'Time', 'Norm')\n",
      "(1060, 'acrol0003', 'Golz', 'Time', 'Norm')\n",
      "(1061, 'acrol0004', 'Golz', 'Time', 'Norm')\n",
      "(1062, 'acrol0005', 'Golz', 'Time', 'Norm')\n",
      "(1063, 'acrol0006', 'Golz', 'Time', 'Norm')\n",
      "(1064, 'acrol0007', 'Golz', 'Time', 'Norm')\n",
      "(1065, 'acrol0008', 'Golz', 'Time', 'Norm')\n",
      "(1066, 'acrol0009', 'Golz', 'Time', 'Norm')\n",
      "(1067, 'acrol0010', 'Golz', 'Time', 'Norm')\n",
      "(1068, 'acrol0011', 'Golz', 'Time', 'Norm')\n",
      "(1069, 'acrol0012', 'Golz', 'Time', 'Norm')\n",
      "(1070, 'acrol0013', 'Golz', 'Time', 'Norm')\n",
      "(1071, 'acrol0014', 'Golz', 'Time', 'Norm')\n",
      "(1072, 'acrol0015', 'Golz', 'Time', 'Norm')\n",
      "(1073, 'acrol0016', 'Golz', 'Time', 'Norm')\n",
      "(1074, 'acrol0017', 'Golz', 'Time', 'Norm')\n",
      "(1075, 'acrol0018', 'Golz', 'Time', 'Norm')\n",
      "(1076, 'acrol0019', 'Golz', 'Time', 'Norm')\n",
      "(1077, 'acrol0020', 'Golz', 'Time', 'Norm')\n",
      "(1078, 'acrol0021', 'Golz', 'Time', 'Norm')\n",
      "(1079, 'acrol0022', 'Golz', 'Time', 'Norm')\n",
      "(1080, 'acrol0023', 'Golz', 'Time', 'Norm')\n",
      "(1081, 'acrol0024', 'Golz', 'Time', 'Norm')\n",
      "(1082, 'acrol0025', 'Golz', 'Time', 'Norm')\n",
      "(1083, 'acrol0026', 'Golz', 'Time', 'Norm')\n",
      "(1084, 'acrol0027', 'Golz', 'Time', 'Norm')\n",
      "(1085, 'acrol0028', 'Golz', 'Time', 'Norm')\n",
      "(1086, 'acrol0029', 'Golz', 'Time', 'Norm')\n",
      "(1087, 'acrol0030', 'Golz', 'Time', 'Norm')\n",
      "(1088, 'acrol0031', 'Golz', 'Time', 'Norm')\n",
      "(1089, 'acrol0032', 'Golz', 'Time', 'Norm')\n",
      "(1090, 'acrol0033', 'Golz', 'Time', 'Norm')\n",
      "(1091, 'acrol0034', 'Golz', 'Time', 'Norm')\n",
      "(1092, 'acrol0035', 'Golz', 'Time', 'Norm')\n",
      "(1093, 'acrol0036', 'Golz', 'Time', 'Norm')\n",
      "(1094, 'acrol0037', 'Golz', 'Time', 'Norm')\n",
      "(1095, 'acrol0038', 'Golz', 'Time', 'Norm')\n",
      "(1096, 'acrol0039', 'Golz', 'Time', 'Norm')\n",
      "(1097, 'acrol0040', 'Golz', 'Time', 'Norm')\n",
      "(1098, 'acrol0041', 'Golz', 'Time', 'Norm')\n",
      "(1099, 'acrol0042', 'Golz', 'Time', 'Norm')\n",
      "(1100, 'acrol0043', 'Golz', 'Time', 'Norm')\n",
      "(1101, 'acrol0044', 'Golz', 'Time', 'Norm')\n",
      "(1102, 'acrol0045', 'Golz', 'Time', 'Norm')\n",
      "(1103, 'acrol0046', 'Golz', 'Time', 'Norm')\n",
      "(1104, 'acrol0047', 'Golz', 'Time', 'Norm')\n",
      "(1105, 'acrol0048', 'Golz', 'Time', 'Norm')\n",
      "(1106, 'acrol0049', 'Golz', 'Time', 'Norm')\n",
      "(1107, 'acrol0050', 'Golz', 'Time', 'Norm')\n",
      "(1108, 'acrol0051', 'Golz', 'Time', 'Norm')\n",
      "(1109, 'acrol0052', 'Golz', 'Time', 'Norm')\n",
      "(1110, 'acrol0053', 'Golz', 'Time', 'Norm')\n",
      "(1111, 'acrol0054', 'Golz', 'Time', 'Norm')\n",
      "(1112, 'acrol0055', 'Golz', 'Time', 'Norm')\n",
      "(1113, 'acrol0056', 'Golz', 'Time', 'Norm')\n",
      "(1114, 'acrol0057', 'Golz', 'Time', 'Norm')\n",
      "(1115, 'acrol0058', 'Golz', 'Time', 'Norm')\n",
      "(1116, 'acrol0059', 'Golz', 'Time', 'Norm')\n",
      "(1117, 'acrol0060', 'Golz', 'Time', 'Norm')\n",
      "(1118, 'acrol0061', 'Golz', 'Time', 'Norm')\n",
      "(1119, 'acrol0062', 'Golz', 'Time', 'Norm')\n",
      "(1120, 'acrol0063', 'Golz', 'Time', 'Norm')\n",
      "(1121, 'acrol0064', 'Golz', 'Time', 'Norm')\n",
      "(1122, 'acrol0065', 'Golz', 'Time', 'Norm')\n",
      "(1123, 'acrol0066', 'Golz', 'Time', 'Norm')\n",
      "(1124, 'acrol0067', 'Golz', 'Time', 'Norm')\n",
      "(1125, 'acrol0068', 'Golz', 'Time', 'Norm')\n",
      "(1126, 'acrol0069', 'Golz', 'Time', 'Norm')\n",
      "(1127, 'acrol0070', 'Golz', 'Time', 'Norm')\n",
      "(1128, 'acrol0071', 'Golz', 'Time', 'Norm')\n",
      "(1129, 'acrol0072', 'Golz', 'Time', 'Norm')\n",
      "(1130, 'acrol0073', 'Golz', 'Time', 'Norm')\n",
      "(1131, 'acrol0074', 'Golz', 'Time', 'Norm')\n",
      "(1132, 'acrol0075', 'Golz', 'Time', 'Norm')\n",
      "(1133, 'acrol0076', 'Golz', 'Time', 'Norm')\n",
      "(1134, 'acrol0077', 'Golz', 'Time', 'Norm')\n",
      "(1135, 'acrol0078', 'Golz', 'Time', 'Norm')\n",
      "(1136, 'acrol0079', 'Golz', 'Time', 'Norm')\n",
      "(1137, 'acrol0080', 'Golz', 'Time', 'Norm')\n",
      "(1138, 'acrol0081', 'Golz', 'Time', 'Norm')\n",
      "(1139, 'acrol0082', 'Golz', 'Time', 'Norm')\n",
      "(1140, 'acrol0083', 'Golz', 'Time', 'Norm')\n",
      "(1141, 'acrol0084', 'Golz', 'Time', 'Norm')\n",
      "(1142, 'acrol0085', 'Golz', 'Time', 'Norm')\n",
      "(1143, 'acrol0086', 'Golz', 'Time', 'Norm')\n",
      "(1144, 'acrol0087', 'Golz', 'Time', 'Norm')\n",
      "(1145, 'acrol0088', 'Golz', 'Time', 'Norm')\n",
      "(1146, 'acrol0089', 'Golz', 'Time', 'Norm')\n",
      "(1147, 'acrol0090', 'Golz', 'Time', 'Norm')\n",
      "(1148, 'acrol0091', 'Golz', 'Time', 'Norm')\n",
      "(1149, 'acrol0092', 'Golz', 'Time', 'Norm')\n",
      "(1150, 'acrol0093', 'Golz', 'Time', 'Norm')\n",
      "(1151, 'acrol0094', 'Golz', 'Time', 'Norm')\n",
      "(1152, 'acrol0095', 'Golz', 'Time', 'Norm')\n",
      "(1153, 'acrol0096', 'Golz', 'Time', 'Norm')\n",
      "(1154, 'acrol0097', 'Golz', 'Time', 'Norm')\n",
      "(1155, 'acrol0098', 'Golz', 'Time', 'Norm')\n",
      "(1156, 'acrol0099', 'Golz', 'Time', 'Norm')\n",
      "(1157, 'acrol0100', 'Golz', 'Time', 'Norm')\n",
      "(1158, 'acrol0101', 'Golz', 'Time', 'Norm')\n",
      "(1159, 'acrol0102', 'Golz', 'Time', 'Norm')\n",
      "(1160, 'acrol0103', 'Golz', 'Time', 'Norm')\n",
      "(1161, 'acrol0104', 'Golz', 'Time', 'Norm')\n",
      "(1162, 'acrol0105', 'Golz', 'Time', 'Norm')\n",
      "(1163, 'acrol0106', 'Golz', 'Time', 'Norm')\n",
      "(1164, 'acrol0107', 'Golz', 'Time', 'Norm')\n",
      "(1165, 'acrol0108', 'Golz', 'Time', 'Norm')\n",
      "(1166, 'acrol0109', 'Golz', 'Time', 'Norm')\n",
      "(1167, 'acrol0110', 'Golz', 'Time', 'Norm')\n",
      "(1168, 'acrol0111', 'Golz', 'Time', 'Norm')\n",
      "(1169, 'acrol0112', 'Golz', 'Time', 'Norm')\n",
      "(1170, 'acrol0113', 'Golz', 'Time', 'Norm')\n",
      "(1171, 'acrol0114', 'Golz', 'Time', 'Norm')\n",
      "(1172, 'acrol0115', 'Golz', 'Time', 'Norm')\n",
      "(1173, 'acrol0116', 'Golz', 'Time', 'Norm')\n",
      "(1174, 'acrol0117', 'Golz', 'Time', 'Norm')\n",
      "(1175, 'acrol0118', 'Golz', 'Time', 'Norm')\n",
      "(1176, 'acrol0119', 'Golz', 'Time', 'Norm')\n",
      "(1177, 'acrol0120', 'Golz', 'Time', 'Norm')\n",
      "(1178, 'acrol0121', 'Golz', 'Time', 'Norm')\n",
      "(1179, 'acrol0122', 'Golz', 'Time', 'Norm')\n",
      "(1180, 'acrol0123', 'Golz', 'Time', 'Norm')\n",
      "(1181, 'acrol0124', 'Golz', 'Time', 'Norm')\n",
      "(1182, 'acrol0125', 'Golz', 'Time', 'Norm')\n",
      "(1183, 'acrol0126', 'Golz', 'Time', 'Norm')\n",
      "(1184, 'acrol0127', 'Golz', 'Time', 'Norm')\n",
      "(1185, 'acrol0128', 'Golz', 'Time', 'Norm')\n",
      "(1186, 'acrol0129', 'Golz', 'Time', 'Norm')\n",
      "(1187, 'acrol0130', 'Golz', 'Time', 'Norm')\n",
      "(1188, 'acrol0131', 'Golz', 'Time', 'Norm')\n",
      "(1189, 'acrol0132', 'Golz', 'Time', 'Norm')\n",
      "(1190, 'acrol0133', 'Golz', 'Time', 'Norm')\n",
      "(1191, 'acrol0134', 'Golz', 'Time', 'Norm')\n",
      "(1192, 'acrol0135', 'Golz', 'Time', 'Norm')\n",
      "(1193, 'acrol0136', 'Golz', 'Time', 'Norm')\n",
      "(1194, 'acrol0137', 'Golz', 'Time', 'Norm')\n",
      "(1195, 'acrol0138', 'Golz', 'Time', 'Norm')\n",
      "(1196, 'acrol0139', 'Golz', 'Time', 'Norm')\n",
      "(1197, 'acrol0140', 'Golz', 'Time', 'Norm')\n",
      "(1198, 'acrol0141', 'Golz', 'Time', 'Norm')\n",
      "(1201, 'acrol0144', 'Golz', 'Time', 'Norm')\n",
      "(1202, 'acrol0145', 'Golz', 'Time', 'Norm')\n",
      "(1206, 'acrol0149', 'Golz', 'Time', 'Norm')\n",
      "(1207, 'acrol0150', 'Golz', 'Time', 'Norm')\n",
      "(1208, 'acrol0151', 'Golz', 'Time', 'Norm')\n",
      "(1209, 'acrol0152', 'Golz', 'Time', 'Norm')\n",
      "(1210, 'acrol0153', 'Golz', 'Time', 'Norm')\n",
      "(1211, 'acrol0154', 'Golz', 'Time', 'Norm')\n",
      "(1212, 'acrol0155', 'Golz', 'Time', 'Norm')\n",
      "(1213, 'acrol0156', 'Golz', 'Time', 'Norm')\n",
      "(1214, 'acrol0157', 'Golz', 'Time', 'Norm')\n",
      "(1215, 'acrol0158', 'Golz', 'Time', 'Norm')\n",
      "(1216, 'acrol0159', 'Golz', 'Time', 'Norm')\n",
      "(1217, 'acrol0160', 'Golz', 'Time', 'Norm')\n",
      "(1218, 'acrol0161', 'Golz', 'Time', 'Norm')\n",
      "(1219, 'acrol0162', 'Golz', 'Time', 'Norm')\n",
      "(1220, 'acrol0163', 'Golz', 'Time', 'Norm')\n",
      "(1221, 'acrol0164', 'Golz', 'Time', 'Norm')\n",
      "(1222, 'acrol0165', 'Golz', 'Time', 'Norm')\n",
      "(1223, 'acrol0166', 'Golz', 'Time', 'Norm')\n",
      "(1224, 'acrol0167', 'Golz', 'Time', 'Norm')\n",
      "(1225, 'acrol0168', 'Golz', 'Time', 'Norm')\n",
      "(1226, 'acrol0169', 'Golz', 'Time', 'Norm')\n",
      "(1227, 'acrol0170', 'Golz', 'Time', 'Norm')\n",
      "(1228, 'acrol0171', 'Golz', 'Time', 'Norm')\n",
      "(1229, 'acrol0172', 'Golz', 'Time', 'Norm')\n",
      "(1230, 'acrol0173', 'Golz', 'Time', 'Norm')\n",
      "(1231, 'acrol0174', 'Golz', 'Time', 'Norm')\n",
      "(1232, 'acrol0175', 'Golz', 'Time', 'Norm')\n",
      "(1233, 'acrol0176', 'Golz', 'Time', 'Norm')\n",
      "(1234, 'acrol0177', 'Golz', 'Time', 'Norm')\n",
      "(1235, 'acrol0178', 'Golz', 'Time', 'Norm')\n",
      "(1236, 'acrol0179', 'Golz', 'Time', 'Norm')\n",
      "(1237, 'acrol0180', 'Golz', 'Time', 'Norm')\n",
      "(1238, 'acrol0181', 'Golz', 'Time', 'Norm')\n",
      "(1239, 'acrol0182', 'Golz', 'Time', 'Norm')\n",
      "(1240, 'acrol0183', 'Golz', 'Time', 'Norm')\n",
      "(1241, 'acrol0184', 'Golz', 'Time', 'Norm')\n",
      "(1242, 'acrol0185', 'Golz', 'Time', 'Norm')\n",
      "(1243, 'acrol0186', 'Golz', 'Time', 'Norm')\n",
      "(1244, 'acrol0187', 'Golz', 'Time', 'Norm')\n",
      "(1245, 'acrol0188', 'Golz', 'Time', 'Norm')\n",
      "(1246, 'acrol0189', 'Golz', 'Time', 'Norm')\n",
      "(1247, 'acrol0190', 'Golz', 'Time', 'Norm')\n",
      "(1248, 'acrol0191', 'Golz', 'Time', 'Norm')\n",
      "(1249, 'acrol0192', 'Golz', 'Time', 'Norm')\n",
      "(1250, 'acrol0193', 'Golz', 'Time', 'Norm')\n",
      "(1252, 'acrol0195', 'Golz', 'Time', 'Norm')\n",
      "(1254, 'acrol0197', 'Golz', 'Time', 'Norm')\n",
      "(1255, 'acrol0198', 'Golz', 'Time', 'Norm')\n",
      "(1256, 'acrol0199', 'Golz', 'Time', 'Norm')\n",
      "(1257, 'acrol0200', 'Golz', 'Time', 'Norm')\n",
      "(1258, 'acrol0201', 'Golz', 'Time', 'Norm')\n",
      "(1259, 'acrol0202', 'Golz', 'Time', 'Norm')\n",
      "(1260, 'acrol0203', 'Golz', 'Time', 'Norm')\n",
      "(1261, 'acrol0204', 'Golz', 'Time', 'Norm')\n",
      "(1262, 'acrol0205', 'Golz', 'Time', 'Norm')\n",
      "(1263, 'acrol0206', 'Golz', 'Time', 'Norm')\n",
      "(1264, 'acrol0207', 'Golz', 'Time', 'Norm')\n",
      "(1265, 'acrol0208', 'Golz', 'Time', 'Norm')\n",
      "(1266, 'acrol0209', 'Golz', 'Time', 'Norm')\n",
      "(1267, 'acrol0210', 'Golz', 'Time', 'Norm')\n",
      "(1268, 'acrol0211', 'Golz', 'Time', 'Norm')\n",
      "(1269, 'acrol0212', 'Golz', 'Time', 'Norm')\n",
      "(1270, 'acrol0213', 'Golz', 'Time', 'Norm')\n",
      "(1271, 'acrol0214', 'Golz', 'Time', 'Norm')\n",
      "(1272, 'acrol0215', 'Golz', 'Time', 'Norm')\n",
      "(1273, 'acrol0216', 'Golz', 'Time', 'Norm')\n",
      "(1274, 'acrol0217', 'Golz', 'Time', 'Norm')\n",
      "(1275, 'acrol0218', 'Golz', 'Time', 'Norm')\n",
      "(1276, 'acrol0219', 'Golz', 'Time', 'Norm')\n",
      "(1277, 'acrol0220', 'Golz', 'Time', 'Norm')\n",
      "(1278, 'acrol0221', 'Golz', 'Time', 'Norm')\n",
      "(1279, 'acrol0222', 'Golz', 'Time', 'Norm')\n",
      "(1280, 'acrol0223', 'Golz', 'Time', 'Norm')\n",
      "(1281, 'acrol0224', 'Golz', 'Time', 'Norm')\n",
      "(1282, 'acrol0225', 'Golz', 'Time', 'Norm')\n",
      "(1283, 'acrol0226', 'Golz', 'Time', 'Norm')\n",
      "(1284, 'acrol0227', 'Golz', 'Time', 'Norm')\n",
      "(1285, 'acrol0228', 'Golz', 'Time', 'Norm')\n",
      "(1286, 'acrol0229', 'Golz', 'Time', 'Norm')\n",
      "(1287, 'acrol0230', 'Golz', 'Time', 'Norm')\n",
      "(1288, 'acrol0231', 'Golz', 'Time', 'Norm')\n",
      "(1289, 'acrol0232', 'Golz', 'Time', 'Norm')\n",
      "(1290, 'acrol0233', 'Golz', 'Time', 'Norm')\n",
      "(1291, 'acrol0234', 'Golz', 'Time', 'Norm')\n",
      "(1292, 'acrol0235', 'Golz', 'Time', 'Norm')\n",
      "(1293, 'acrol0236', 'Golz', 'Time', 'Norm')\n",
      "(1294, 'acrol0237', 'Golz', 'Time', 'Norm')\n",
      "(1295, 'acrol0238', 'Golz', 'Time', 'Norm')\n",
      "(1296, 'acrol0239', 'Golz', 'Time', 'Norm')\n",
      "(1297, 'acrol0240', 'Golz', 'Time', 'Norm')\n",
      "(1298, 'acrol0241', 'Golz', 'Time', 'Norm')\n",
      "(1299, 'acrol0242', 'Golz', 'Time', 'Norm')\n",
      "(1300, 'acrol0243', 'Golz', 'Time', 'Norm')\n",
      "(1301, 'acrol0244', 'Golz', 'Time', 'Norm')\n",
      "(1302, 'acrol0245', 'Golz', 'Time', 'Norm')\n",
      "(1303, 'acrol0246', 'Golz', 'Time', 'Norm')\n",
      "(1304, 'acrol0247', 'Golz', 'Time', 'Norm')\n",
      "(1305, 'acrol0248', 'Golz', 'Time', 'Norm')\n",
      "(1306, 'acrol0249', 'Golz', 'Time', 'Norm')\n",
      "(1307, 'acrol0250', 'Golz', 'Time', 'Norm')\n",
      "(1308, 'acrol0251', 'Golz', 'Time', 'Norm')\n",
      "(1309, 'acrol0252', 'Golz', 'Time', 'Norm')\n",
      "(1310, 'acrol0253', 'Golz', 'Time', 'Norm')\n",
      "(1311, 'acrol0254', 'Golz', 'Time', 'Norm')\n",
      "(1312, 'acrol0255', 'Golz', 'Time', 'Norm')\n",
      "(1313, 'acrol0256', 'Golz', 'Time', 'Norm')\n",
      "(1314, 'acrol0257', 'Golz', 'Time', 'Norm')\n",
      "(1315, 'acrol0258', 'Golz', 'Time', 'Norm')\n",
      "(1316, 'acrol0259', 'Golz', 'Time', 'Norm')\n",
      "(1317, 'acrol0260', 'Golz', 'Time', 'Norm')\n",
      "(1318, 'acrol0261', 'Golz', 'Time', 'Norm')\n",
      "(1319, 'acrol0262', 'Golz', 'Time', 'Norm')\n",
      "(1320, 'acrol0263', 'Golz', 'Time', 'Norm')\n",
      "(1321, 'acrol0264', 'Golz', 'Time', 'Norm')\n",
      "(1322, 'acrol0265', 'Golz', 'Time', 'Norm')\n",
      "(1323, 'acrol0266', 'Golz', 'Time', 'Norm')\n",
      "(1324, 'acrol0267', 'Golz', 'Time', 'Norm')\n",
      "(1325, 'acrol0268', 'Golz', 'Time', 'Norm')\n",
      "(1326, 'acrol0269', 'Golz', 'Time', 'Norm')\n",
      "(1327, 'acrol0270', 'Golz', 'Time', 'Norm')\n",
      "(1328, 'acrol0271', 'Golz', 'Time', 'Norm')\n",
      "(1329, 'acrol0272', 'Golz', 'Time', 'Norm')\n",
      "(1330, 'acrol0273', 'Golz', 'Time', 'Norm')\n",
      "(1331, 'acrol0274', 'Golz', 'Time', 'Norm')\n",
      "(1332, 'acrol0275', 'Golz', 'Time', 'Norm')\n",
      "(1333, 'acrol0276', 'Golz', 'Time', 'Norm')\n",
      "(1334, 'acrol0277', 'Golz', 'Time', 'Norm')\n",
      "(1335, 'acrol0278', 'Golz', 'Time', 'Norm')\n",
      "(1336, 'acrol0279', 'Golz', 'Time', 'Norm')\n",
      "(1337, 'acrol0280', 'Golz', 'Time', 'Norm')\n",
      "(1338, 'acrol0281', 'Golz', 'Time', 'Norm')\n",
      "(1339, 'acrol0282', 'Golz', 'Time', 'Norm')\n",
      "(1341, 'acrol0284', 'Golz', 'Time', 'Norm')\n",
      "(1342, 'acrol0285', 'Golz', 'Time', 'Norm')\n",
      "(1343, 'acrol0286', 'Golz', 'Time', 'Norm')\n",
      "(1346, 'acrol0289', 'Golz', 'Time', 'Norm')\n",
      "(1347, 'acrol0290', 'Golz', 'Time', 'Norm')\n",
      "(1348, 'acrol0291', 'Golz', 'Time', 'Norm')\n",
      "(1350, 'acrol0293', 'Golz', 'Time', 'Norm')\n",
      "(1352, 'acrol0295', 'Golz', 'Time', 'Norm')\n",
      "(1361, 'acrol0304', 'Golz', 'Time', 'Norm')\n",
      "(1362, 'acrol0305', 'Golz', 'Time', 'Norm')\n",
      "(1363, 'acrol0306', 'Golz', 'Time', 'Norm')\n",
      "(1364, 'acrol0307', 'Golz', 'Time', 'Norm')\n",
      "(1365, 'acrol0308', 'Golz', 'Time', 'Norm')\n",
      "(1366, 'acrol0309', 'Golz', 'Time', 'Norm')\n",
      "(1367, 'acrol0310', 'Golz', 'Time', 'Norm')\n",
      "(1368, 'acrol0311', 'Golz', 'Time', 'Norm')\n",
      "(1369, 'acrol0312', 'Golz', 'Time', 'Norm')\n",
      "(1370, 'acrol0313', 'Golz', 'Time', 'Norm')\n",
      "(1371, 'acrol0314', 'Golz', 'Time', 'Norm')\n",
      "(1372, 'acrol0315', 'Golz', 'Time', 'Norm')\n",
      "(1373, 'acrol0316', 'Golz', 'Time', 'Norm')\n",
      "(1374, 'acrol0317', 'Golz', 'Time', 'Norm')\n",
      "(1375, 'acrol0318', 'Golz', 'Time', 'Norm')\n",
      "(1376, 'acrol0319', 'Golz', 'Time', 'Norm')\n",
      "(1377, 'acrol0320', 'Golz', 'Time', 'Norm')\n",
      "(1378, 'acrol0321', 'Golz', 'Time', 'Norm')\n",
      "(1379, 'acrol0322', 'Golz', 'Time', 'Norm')\n",
      "(1380, 'acrol0323', 'Golz', 'Time', 'Norm')\n",
      "(1382, 'acrol0325', 'Golz', 'Time', 'Norm')\n",
      "(1383, 'acrol0326', 'Golz', 'Time', 'Norm')\n",
      "(1384, 'acrol0327', 'Golz', 'Time', 'Norm')\n",
      "(1385, 'acrol0328', 'Golz', 'Time', 'Norm')\n",
      "(1386, 'acrol0329', 'Golz', 'Time', 'Norm')\n",
      "(1387, 'acrol0330', 'Golz', 'Time', 'Norm')\n",
      "(1388, 'acrol0331', 'Golz', 'Time', 'Norm')\n",
      "(1389, 'acrol0332', 'Golz', 'Time', 'Norm')\n",
      "(1390, 'acrol0333', 'Golz', 'Time', 'Norm')\n",
      "(1391, 'acrol0334', 'Golz', 'Time', 'Norm')\n",
      "(1392, 'acrol0335', 'Golz', 'Time', 'Norm')\n",
      "(1393, 'acrol0336', 'Golz', 'Time', 'Norm')\n",
      "(1394, 'acrol0337', 'Golz', 'Time', 'Norm')\n",
      "(1396, 'acrol0339', 'Golz', 'Time', 'Norm')\n",
      "(1397, 'acrol0340', 'Golz', 'Time', 'Norm')\n",
      "(1398, 'acrol0341', 'Golz', 'Time', 'Norm')\n",
      "(1399, 'acrol0342', 'Golz', 'Time', 'Norm')\n",
      "(1400, 'acrol0343', 'Golz', 'Time', 'Norm')\n",
      "(1402, 'acrol0345', 'Golz', 'Time', 'Norm')\n",
      "(1403, 'acrol0346', 'Golz', 'Time', 'Norm')\n",
      "(1407, 'acrol0350', 'Golz', 'Time', 'Norm')\n",
      "(1408, 'acrol0351', 'Golz', 'Time', 'Norm')\n",
      "(1409, 'acrol0352', 'Golz', 'Time', 'Norm')\n",
      "(1410, 'acrol0353', 'Golz', 'Time', 'Norm')\n",
      "(1411, 'acrol0354', 'Golz', 'Time', 'Norm')\n",
      "(1412, 'acrol0355', 'Golz', 'Time', 'Norm')\n",
      "(1413, 'acrol0356', 'Golz', 'Time', 'Norm')\n",
      "(1414, 'acrol0357', 'Golz', 'Time', 'Norm')\n",
      "(1415, 'acrol0358', 'Golz', 'Time', 'Norm')\n",
      "(1416, 'acrol0359', 'Golz', 'Time', 'Norm')\n",
      "(1417, 'acrol0360', 'Golz', 'Time', 'Norm')\n",
      "(1418, 'acrol0361', 'Golz', 'Time', 'Norm')\n",
      "(1419, 'acrol0362', 'Golz', 'Time', 'Norm')\n",
      "(1420, 'acrol0363', 'Golz', 'Time', 'Norm')\n",
      "(1421, 'acrol0364', 'Golz', 'Time', 'Norm')\n",
      "(1422, 'acrol0365', 'Golz', 'Time', 'Norm')\n",
      "(1423, 'acrol0366', 'Golz', 'Time', 'Norm')\n",
      "(1424, 'acrol0367', 'Golz', 'Time', 'Norm')\n",
      "(1425, 'acrol0368', 'Golz', 'Time', 'Norm')\n",
      "(1426, 'acrol0369', 'Golz', 'Time', 'Norm')\n",
      "(1427, 'acrol0370', 'Golz', 'Time', 'Norm')\n",
      "(1428, 'acrol0371', 'Golz', 'Time', 'Norm')\n",
      "(1429, 'acrol0372', 'Golz', 'Time', 'Norm')\n",
      "(1430, 'acrol0373', 'Golz', 'Time', 'Norm')\n",
      "(1431, 'acrol0374', 'Golz', 'Time', 'Norm')\n",
      "(1432, 'acrol0375', 'Golz', 'Time', 'Norm')\n",
      "(1433, 'acrol0376', 'Golz', 'Time', 'Norm')\n",
      "(1434, 'acrol0377', 'Golz', 'Time', 'Norm')\n",
      "(1435, 'acrol0378', 'Golz', 'Time', 'Norm')\n",
      "(1436, 'acrol0379', 'Golz', 'Time', 'Norm')\n",
      "(1437, 'acrol0380', 'Golz', 'Time', 'Norm')\n",
      "(1438, 'acrol0381', 'Golz', 'Time', 'Norm')\n",
      "(1439, 'acrol0382', 'Golz', 'Time', 'Norm')\n",
      "(1440, 'acrol0383', 'Golz', 'Time', 'Norm')\n",
      "(1441, 'acrol0384', 'Golz', 'Time', 'Norm')\n",
      "(1443, 'acrol0386', 'Golz', 'Time', 'Norm')\n",
      "(1444, 'acrol0387', 'Golz', 'Time', 'Norm')\n",
      "(1445, 'acrol0388', 'Golz', 'Time', 'Norm')\n",
      "(1446, 'acrol0389', 'Golz', 'Time', 'Norm')\n",
      "(1447, 'acrol0390', 'Golz', 'Time', 'Norm')\n",
      "(1448, 'acrol0391', 'Golz', 'Time', 'Norm')\n",
      "(1449, 'acrol0392', 'Golz', 'Time', 'Norm')\n",
      "(1450, 'acrol0393', 'Golz', 'Time', 'Norm')\n",
      "(1451, 'acrol0394', 'Golz', 'Time', 'Norm')\n",
      "(1452, 'acrol0395', 'Golz', 'Time', 'Norm')\n",
      "(1453, 'acrol0396', 'Golz', 'Time', 'Norm')\n",
      "(1454, 'acrol0397', 'Golz', 'Time', 'Norm')\n",
      "(1455, 'acrol0398', 'Golz', 'Time', 'Norm')\n",
      "(1456, 'acrol0399', 'Golz', 'Time', 'Norm')\n",
      "(1457, 'acrol0400', 'Golz', 'Time', 'Norm')\n",
      "(1458, 'acrol0401', 'Golz', 'Time', 'Norm')\n",
      "(1459, 'acrol0402', 'Golz', 'Time', 'Norm')\n",
      "(1460, 'acrol0403', 'Golz', 'Time', 'Norm')\n",
      "(1461, 'acrol0404', 'Golz', 'Time', 'Norm')\n",
      "(1462, 'acrol0405', 'Golz', 'Time', 'Norm')\n",
      "(1463, 'acrol0406', 'Golz', 'Time', 'Norm')\n",
      "(1464, 'acrol0407', 'Golz', 'Time', 'Norm')\n",
      "(1465, 'acrol0408', 'Golz', 'Time', 'Norm')\n",
      "(1466, 'acrol0409', 'Golz', 'Time', 'Norm')\n",
      "(1467, 'acrol0410', 'Golz', 'Time', 'Norm')\n",
      "(1468, 'acrol0411', 'Golz', 'Time', 'Norm')\n",
      "(1469, 'acrol0412', 'Golz', 'Time', 'Norm')\n",
      "(1470, 'acrol0413', 'Golz', 'Time', 'Norm')\n",
      "(1471, 'acrol0414', 'Golz', 'Time', 'Norm')\n",
      "(1472, 'acrol0415', 'Golz', 'Time', 'Norm')\n",
      "(1474, 'acrol0417', 'Golz', 'Time', 'Norm')\n",
      "(1475, 'acrol0418', 'Golz', 'Time', 'Norm')\n",
      "(1476, 'acrol0419', 'Golz', 'Time', 'Norm')\n",
      "(1477, 'acrol0420', 'Golz', 'Time', 'Norm')\n",
      "(1478, 'acrol0421', 'Golz', 'Time', 'Norm')\n",
      "(1479, 'acrol0422', 'Golz', 'Time', 'Norm')\n",
      "(1480, 'acrol0423', 'Golz', 'Time', 'Norm')\n",
      "(1481, 'acrol0424', 'Golz', 'Time', 'Norm')\n",
      "(1484, 'acrol0427', 'Golz', 'Time', 'Norm')\n",
      "(1485, 'acrol0428', 'Golz', 'Time', 'Norm')\n",
      "(1486, 'acrol0429', 'Golz', 'Time', 'Norm')\n",
      "(1488, 'acrol0431', 'Golz', 'Time', 'Norm')\n",
      "(1489, 'acrol0432', 'Golz', 'Time', 'Norm')\n",
      "(1491, 'acrol0434', 'Golz', 'Time', 'Norm')\n",
      "(1492, 'acrol0435', 'Golz', 'Time', 'Norm')\n",
      "(1493, 'acrol0436', 'Golz', 'Time', 'Norm')\n",
      "(1494, 'acrol0437', 'Golz', 'Time', 'Norm')\n",
      "(1495, 'acrol0438', 'Golz', 'Time', 'Norm')\n",
      "(1501, 'acrol0444', 'Golz', 'Time', 'Norm')\n",
      "(1502, 'acrol0445', 'Golz', 'Time', 'Norm')\n",
      "(1503, 'acrol0446', 'Golz', 'Time', 'Norm')\n",
      "(1504, 'acrol0447', 'Golz', 'Time', 'Norm')\n",
      "(1505, 'acrol0448', 'Golz', 'Time', 'Norm')\n",
      "(1506, 'acrol0449', 'Golz', 'Time', 'Norm')\n",
      "(1509, 'acrol0452', 'Golz', 'Time', 'Norm')\n",
      "(1510, 'acrol0453', 'Golz', 'Time', 'Norm')\n",
      "(1512, 'acrol0455', 'Golz', 'Time', 'Norm')\n",
      "(1516, 'acrol0459', 'Golz', 'Time', 'Norm')\n",
      "(1527, 'acrol0470', 'Golz', 'Time', 'Norm')\n",
      "(1529, 'acrol0472', 'Golz', 'Time', 'Norm')\n",
      "(1530, 'acrol0473', 'Golz', 'Time', 'Norm')\n",
      "(1531, 'acrol0474', 'Golz', 'Time', 'Norm')\n",
      "(1534, 'acrol0477', 'Golz', 'Time', 'Norm')\n",
      "(1536, 'acrol0479', 'Golz', 'Time', 'Norm')\n",
      "(1540, 'acrol0483', 'Golz', 'Time', 'Norm')\n",
      "(1546, 'acrol0489', 'Golz', 'Time', 'Norm')\n",
      "(1547, 'acrol0490', 'Golz', 'Time', 'Norm')\n",
      "(1548, 'acrol0491', 'Golz', 'Time', 'Norm')\n",
      "(1549, 'acrol0492', 'Golz', 'Time', 'Norm')\n",
      "(1550, 'acrol0493', 'Golz', 'Time', 'Norm')\n",
      "(1551, 'acrol0494', 'Golz', 'Time', 'Norm')\n",
      "(1552, 'acrol0495', 'Golz', 'Time', 'Norm')\n",
      "(1553, 'acrol0496', 'Golz', 'Time', 'Norm')\n",
      "(1554, 'acrol0497', 'Golz', 'Time', 'Norm')\n",
      "(1555, 'acrol0498', 'Golz', 'Time', 'Norm')\n",
      "(1556, 'acrol0499', 'Golz', 'Time', 'Norm')\n",
      "(1557, 'acrol0500', 'Golz', 'Time', 'Norm')\n",
      "(1558, 'acrol0501', 'Golz', 'Time', 'Norm')\n",
      "(1559, 'acrol0502', 'Golz', 'Time', 'Norm')\n",
      "(1560, 'acrol0503', 'Golz', 'Time', 'Norm')\n",
      "(1561, 'acrol0504', 'Golz', 'Time', 'Norm')\n",
      "(1562, 'acrol0505', 'Golz', 'Time', 'Norm')\n",
      "(1563, 'acrol0506', 'Golz', 'Time', 'Norm')\n",
      "(1564, 'acrol0507', 'Golz', 'Time', 'Norm')\n",
      "(1565, 'acrol0508', 'Golz', 'Time', 'Norm')\n",
      "(1566, 'acrol0509', 'Golz', 'Time', 'Norm')\n",
      "(1567, 'acrol0510', 'Golz', 'Time', 'Norm')\n",
      "(1568, 'acrol0511', 'Golz', 'Time', 'Norm')\n",
      "(1569, 'acrol0512', 'Golz', 'Time', 'Norm')\n",
      "(1570, 'acrol0513', 'Golz', 'Time', 'Norm')\n",
      "(1571, 'acrol0514', 'Golz', 'Time', 'Norm')\n",
      "(1572, 'acrol0515', 'Golz', 'Time', 'Norm')\n",
      "(1574, 'acrol0517', 'Golz', 'Time', 'Norm')\n",
      "(1576, 'acrol0519', 'Golz', 'Time', 'Norm')\n",
      "(1577, 'acrol0520', 'Golz', 'Time', 'Norm')\n",
      "(1578, 'acrol0521', 'Golz', 'Time', 'Norm')\n",
      "(1580, 'acrol0523', 'Golz', 'Time', 'Norm')\n",
      "(1581, 'acrol0524', 'Golz', 'Time', 'Norm')\n",
      "(1582, 'acrol0525', 'Golz', 'Time', 'Norm')\n",
      "(1583, 'acrol0526', 'Golz', 'Time', 'Norm')\n",
      "(1584, 'acrol0527', 'Golz', 'Time', 'Norm')\n",
      "(1585, 'acrol0528', 'Golz', 'Time', 'Norm')\n",
      "(1586, 'acrol0529', 'Golz', 'Time', 'Norm')\n",
      "(1587, 'acrol0530', 'Golz', 'Time', 'Norm')\n",
      "(1588, 'acrol0531', 'Golz', 'Time', 'Norm')\n",
      "(1590, 'acrol0533', 'Golz', 'Time', 'Norm')\n",
      "(1591, 'acrol0534', 'Golz', 'Time', 'Norm')\n",
      "(1592, 'acrol0535', 'Golz', 'Time', 'Norm')\n",
      "(1593, 'acrol0536', 'Golz', 'Time', 'Norm')\n",
      "(1594, 'acrol0537', 'Golz', 'Time', 'Norm')\n",
      "(1595, 'acrol0538', 'Golz', 'Time', 'Norm')\n",
      "(1596, 'acrol0539', 'Golz', 'Time', 'Norm')\n",
      "(1597, 'acrol0540', 'Golz', 'Time', 'Norm')\n",
      "(1598, 'acrol0541', 'Golz', 'Time', 'Norm')\n",
      "(1599, 'acrol0542', 'Golz', 'Time', 'Norm')\n",
      "(1602, 'acrol0545', 'Golz', 'Time', 'Norm')\n",
      "(1603, 'acrol0546', 'Golz', 'Time', 'Norm')\n",
      "(1604, 'acrol0547', 'Golz', 'Time', 'Norm')\n",
      "(1605, 'acrol0548', 'Golz', 'Time', 'Norm')\n",
      "(1606, 'acrol0549', 'Golz', 'Time', 'Norm')\n",
      "(1607, 'acrol0550', 'Golz', 'Time', 'Norm')\n",
      "(1608, 'acrol0551', 'Golz', 'Time', 'Norm')\n",
      "(1609, 'acrol0552', 'Golz', 'Time', 'Norm')\n",
      "(1610, 'acrol0553', 'Golz', 'Time', 'Norm')\n",
      "(1611, 'acrol0554', 'Golz', 'Time', 'Norm')\n",
      "(1612, 'acrol0555', 'Golz', 'Time', 'Norm')\n",
      "(1613, 'acrol0556', 'Golz', 'Time', 'Norm')\n",
      "(1615, 'acrol0558', 'Golz', 'Time', 'Norm')\n",
      "(1616, 'acrol0559', 'Golz', 'Time', 'Norm')\n",
      "(1617, 'acrol0560', 'Golz', 'Time', 'Norm')\n",
      "(1618, 'acrol0561', 'Golz', 'Time', 'Norm')\n",
      "(1619, 'acrol0562', 'Golz', 'Time', 'Norm')\n",
      "(1625, 'acrol0568', 'Golz', 'Time', 'Norm')\n",
      "(1627, 'acrol0570', 'Golz', 'Time', 'Norm')\n",
      "(1629, 'acrol0572', 'Golz', 'Time', 'Norm')\n",
      "(1630, 'acrol0573', 'Golz', 'Time', 'Norm')\n",
      "(1633, 'acrol0576', 'Golz', 'Time', 'Norm')\n",
      "(1634, 'acrol0577', 'Golz', 'Time', 'Norm')\n",
      "(1637, 'acrol0580', 'Golz', 'Time', 'Norm')\n",
      "(1639, 'acrol0582', 'Golz', 'Time', 'Norm')\n",
      "(1641, 'acrol0584', 'Golz', 'Time', 'Norm')\n",
      "(1642, 'acrol0585', 'Golz', 'Time', 'Norm')\n",
      "(1644, 'acrol0587', 'Golz', 'Time', 'Norm')\n",
      "(1645, 'acrol0588', 'Golz', 'Time', 'Norm')\n",
      "(1646, 'acrol0589', 'Golz', 'Time', 'Norm')\n",
      "(1650, 'acrol0593', 'Golz', 'Time', 'Norm')\n",
      "(1652, 'acrol0595', 'Golz', 'Time', 'Norm')\n",
      "(1654, 'acrol0597', 'Golz', 'Time', 'Norm')\n",
      "(1655, 'acrol0598', 'Golz', 'Time', 'Norm')\n",
      "(1656, 'acrol0599', 'Golz', 'Time', 'Norm')\n",
      "(1659, 'acrol0602', 'Golz', 'Time', 'Norm')\n",
      "(1660, 'acrol0603', 'Golz', 'Time', 'Norm')\n",
      "(1661, 'acrol0604', 'Golz', 'Time', 'Norm')\n",
      "(1665, 'acrol0608', 'Golz', 'Time', 'Norm')\n",
      "(1666, 'acrol0609', 'Golz', 'Time', 'Norm')\n",
      "(1667, 'acrol0610', 'Golz', 'Time', 'Norm')\n",
      "(1668, 'acrol0611', 'Golz', 'Time', 'Norm')\n",
      "(1672, 'acrol0615', 'Golz', 'Time', 'Norm')\n",
      "(1673, 'acrol0616', 'Golz', 'Time', 'Norm')\n",
      "(1675, 'acrol0618', 'Golz', 'Time', 'Norm')\n",
      "(1676, 'acrol0619', 'Golz', 'Time', 'Norm')\n",
      "(1677, 'acrol0620', 'Golz', 'Time', 'Norm')\n",
      "(1678, 'acrol0621', 'Golz', 'Time', 'Norm')\n",
      "(1679, 'acrol0622', 'Golz', 'Time', 'Norm')\n",
      "(1680, 'acrol0623', 'Golz', 'Time', 'Norm')\n",
      "(1681, 'acrol0624', 'Golz', 'Time', 'Norm')\n",
      "(1682, 'acrol0625', 'Golz', 'Time', 'Norm')\n",
      "(1683, 'acrol0626', 'Golz', 'Time', 'Norm')\n",
      "(1684, 'acrol0627', 'Golz', 'Time', 'Norm')\n",
      "(1685, 'acrol0628', 'Golz', 'Time', 'Norm')\n",
      "(1686, 'acrol0629', 'Golz', 'Time', 'Norm')\n",
      "(1687, 'acrol0630', 'Golz', 'Time', 'Norm')\n",
      "(1688, 'acrol0631', 'Golz', 'Time', 'Norm')\n",
      "(1689, 'acrol0632', 'Golz', 'Time', 'Norm')\n",
      "(1701, 'acrol0644', 'Golz', 'Time', 'Norm')\n",
      "(1702, 'acrol0645', 'Golz', 'Time', 'Norm')\n",
      "(1706, 'acrol0649', 'Golz', 'Time', 'Norm')\n",
      "(1707, 'acrol0650', 'Golz', 'Time', 'Norm')\n",
      "(1708, 'acrol0651', 'Golz', 'Time', 'Norm')\n",
      "(1709, 'acrol0652', 'Golz', 'Time', 'Norm')\n",
      "(1710, 'acrol0653', 'Golz', 'Time', 'Norm')\n",
      "(1711, 'acrol0654', 'Golz', 'Time', 'Norm')\n",
      "(1712, 'acrol0655', 'Golz', 'Time', 'Norm')\n",
      "(1713, 'acrol0656', 'Golz', 'Time', 'Norm')\n",
      "(1714, 'acrol0657', 'Golz', 'Time', 'Norm')\n",
      "(1715, 'acrol0658', 'Golz', 'Time', 'Norm')\n",
      "(1716, 'acrol0659', 'Golz', 'Time', 'Norm')\n",
      "(1717, 'acrol0660', 'Golz', 'Time', 'Norm')\n",
      "(1718, 'acrol0661', 'Golz', 'Time', 'Norm')\n",
      "(1719, 'acrol0662', 'Golz', 'Time', 'Norm')\n",
      "(1720, 'acrol0663', 'Golz', 'Time', 'Norm')\n",
      "(1721, 'acrol0664', 'Golz', 'Time', 'Norm')\n",
      "(1722, 'acrol0665', 'Golz', 'Time', 'Norm')\n",
      "(1723, 'acrol0666', 'Golz', 'Time', 'Norm')\n",
      "(1725, 'acrol0668', 'Golz', 'Time', 'Norm')\n",
      "(1727, 'acrol0670', 'Golz', 'Time', 'Norm')\n",
      "(1728, 'acrol0671', 'Golz', 'Time', 'Norm')\n",
      "(1731, 'acrol0674', 'Golz', 'Time', 'Norm')\n",
      "(1732, 'acrol0675', 'Golz', 'Time', 'Norm')\n",
      "(1733, 'acrol0676', 'Golz', 'Time', 'Norm')\n",
      "(1735, 'acrol0678', 'Golz', 'Time', 'Norm')\n",
      "(1737, 'acrol0680', 'Golz', 'Time', 'Norm')\n",
      "(1738, 'acrol0681', 'Golz', 'Time', 'Norm')\n",
      "(1739, 'acrol0682', 'Golz', 'Time', 'Norm')\n",
      "(1740, 'acrol0683', 'Golz', 'Time', 'Norm')\n",
      "(1741, 'acrol0684', 'Golz', 'Time', 'Norm')\n",
      "(1742, 'acrol0685', 'Golz', 'Time', 'Norm')\n",
      "(1744, 'acrol0687', 'Golz', 'Time', 'Norm')\n",
      "(1746, 'acrol0689', 'Golz', 'Time', 'Norm')\n",
      "(1748, 'acrol0691', 'Golz', 'Time', 'Norm')\n",
      "(1750, 'acrol0693', 'Golz', 'Time', 'Norm')\n",
      "(1752, 'acrol0695', 'Golz', 'Time', 'Norm')\n",
      "(1753, 'acrol0696', 'Golz', 'Time', 'Norm')\n",
      "(1754, 'acrol0697', 'Golz', 'Time', 'Norm')\n",
      "(1755, 'acrol0698', 'Golz', 'Time', 'Norm')\n",
      "(1756, 'acrol0699', 'Golz', 'Time', 'Norm')\n",
      "(1757, 'acrol0700', 'Golz', 'Time', 'Norm')\n",
      "(1759, 'acrol0702', 'Golz', 'Time', 'Norm')\n",
      "(1760, 'acrol0703', 'Golz', 'Time', 'Norm')\n",
      "(1761, 'acrol0704', 'Golz', 'Time', 'Norm')\n",
      "(1762, 'acrol0705', 'Golz', 'Time', 'Norm')\n",
      "(1763, 'acrol0706', 'Golz', 'Time', 'Norm')\n",
      "(1764, 'acrol0707', 'Golz', 'Time', 'Norm')\n",
      "(1765, 'acrol0708', 'Golz', 'Time', 'Norm')\n",
      "(1766, 'acrol0709', 'Golz', 'Time', 'Norm')\n",
      "(1767, 'acrol0710', 'Golz', 'Time', 'Norm')\n",
      "(1768, 'acrol0711', 'Golz', 'Time', 'Norm')\n",
      "(1769, 'acrol0712', 'Golz', 'Time', 'Norm')\n",
      "(1770, 'acrol0713', 'Golz', 'Time', 'Norm')\n",
      "(1771, 'acrol0714', 'Golz', 'Time', 'Norm')\n",
      "(1772, 'acrol0715', 'Golz', 'Time', 'Norm')\n",
      "(1773, 'acrol0716', 'Golz', 'Time', 'Norm')\n",
      "(1774, 'acrol0717', 'Golz', 'Time', 'Norm')\n",
      "(1775, 'acrol0718', 'Golz', 'Time', 'Norm')\n",
      "(1776, 'acrol0719', 'Golz', 'Time', 'Norm')\n",
      "(1777, 'acrol0720', 'Golz', 'Time', 'Norm')\n",
      "(1782, 'acrol0725', 'Golz', 'Time', 'Norm')\n",
      "(1783, 'acrol0726', 'Golz', 'Time', 'Norm')\n",
      "(1785, 'acrol0728', 'Golz', 'Time', 'Norm')\n",
      "(1787, 'acrol0730', 'Golz', 'Time', 'Norm')\n",
      "(1788, 'acrol0731', 'Golz', 'Time', 'Norm')\n",
      "(1791, 'acrol0734', 'Golz', 'Time', 'Norm')\n",
      "(1793, 'acrol0736', 'Golz', 'Time', 'Norm')\n",
      "(1794, 'acrol0737', 'Golz', 'Time', 'Norm')\n",
      "(1795, 'acrol0738', 'Golz', 'Time', 'Norm')\n",
      "(1796, 'acrol0739', 'Golz', 'Time', 'Norm')\n",
      "(1797, 'acrol0740', 'Golz', 'Time', 'Norm')\n",
      "(1798, 'acrol0741', 'Golz', 'Time', 'Norm')\n",
      "(1799, 'acrol0742', 'Golz', 'Time', 'Norm')\n",
      "(1801, 'acrol0744', 'Golz', 'Time', 'Norm')\n",
      "(1803, 'acrol0746', 'Golz', 'Time', 'Norm')\n",
      "(1804, 'acrol0747', 'Golz', 'Time', 'Norm')\n",
      "(1805, 'acrol0748', 'Golz', 'Time', 'Norm')\n",
      "(1806, 'acrol0749', 'Golz', 'Time', 'Norm')\n",
      "(1809, 'acrol0752', 'Golz', 'Time', 'Norm')\n",
      "(1812, 'acrol0755', 'Golz', 'Time', 'Norm')\n",
      "(1815, 'acrol0758', 'Golz', 'Time', 'Norm')\n",
      "(1816, 'acrol0759', 'Golz', 'Time', 'Norm')\n",
      "(1817, 'acrol0760', 'Golz', 'Time', 'Norm')\n",
      "(1819, 'acrol0762', 'Golz', 'Time', 'Norm')\n",
      "(1820, 'acrol0763', 'Golz', 'Time', 'Norm')\n",
      "(1821, 'acrol0764', 'Golz', 'Time', 'Norm')\n",
      "(1823, 'acrol0766', 'Golz', 'Time', 'Norm')\n",
      "(1825, 'acrol0768', 'Golz', 'Time', 'Norm')\n",
      "(1826, 'acrol0769', 'Golz', 'Time', 'Norm')\n",
      "(1832, 'acrol0775', 'Golz', 'Time', 'Norm')\n",
      "(1833, 'acrol0776', 'Golz', 'Time', 'Norm')\n",
      "(1839, 'acrol0782', 'Golz', 'Time', 'Norm')\n",
      "(1840, 'acrol0783', 'Golz', 'Time', 'Norm')\n",
      "(1841, 'acrol0784', 'Golz', 'Time', 'Norm')\n",
      "(1842, 'acrol0785', 'Golz', 'Time', 'Norm')\n",
      "(1844, 'acrol0787', 'Golz', 'Time', 'Norm')\n",
      "(1845, 'acrol0788', 'Golz', 'Time', 'Norm')\n",
      "(1846, 'acrol0789', 'Golz', 'Time', 'Norm')\n",
      "(1847, 'acrol0790', 'Golz', 'Time', 'Norm')\n",
      "(1848, 'acrol0791', 'Golz', 'Time', 'Norm')\n",
      "(1849, 'acrol0792', 'Golz', 'Time', 'Norm')\n",
      "(1850, 'acrol0793', 'Golz', 'Time', 'Norm')\n",
      "(1851, 'acrol0794', 'Golz', 'Time', 'Norm')\n",
      "(1852, 'acrol0795', 'Golz', 'Time', 'Norm')\n",
      "(1853, 'acrol0796', 'Golz', 'Time', 'Norm')\n",
      "(1854, 'acrol0797', 'Golz', 'Time', 'Norm')\n",
      "(1855, 'acrol0798', 'Golz', 'Time', 'Norm')\n",
      "(1856, 'acrol0799', 'Golz', 'Time', 'Norm')\n",
      "(1857, 'acrol0800', 'Golz', 'Time', 'Norm')\n",
      "(1858, 'acrol0801', 'Golz', 'Time', 'Norm')\n",
      "(1859, 'acrol0802', 'Golz', 'Time', 'Norm')\n",
      "(1860, 'acrol0803', 'Golz', 'Time', 'Norm')\n",
      "(1861, 'acrol0804', 'Golz', 'Time', 'Norm')\n",
      "(1862, 'acrol0805', 'Golz', 'Time', 'Norm')\n",
      "(1863, 'acrol0806', 'Golz', 'Time', 'Norm')\n",
      "(1864, 'acrol0807', 'Golz', 'Time', 'Norm')\n",
      "(1865, 'acrol0808', 'Golz', 'Time', 'Norm')\n",
      "(1866, 'acrol0809', 'Golz', 'Time', 'Norm')\n",
      "(1867, 'acrol0810', 'Golz', 'Time', 'Norm')\n",
      "(1868, 'acrol0811', 'Golz', 'Time', 'Norm')\n",
      "(1869, 'acrol0812', 'Golz', 'Time', 'Norm')\n",
      "(1870, 'acrol0813', 'Golz', 'Time', 'Norm')\n",
      "(1871, 'acrol0814', 'Golz', 'Time', 'Norm')\n",
      "(1872, 'acrol0815', 'Golz', 'Time', 'Norm')\n",
      "(1873, 'acrol0816', 'Golz', 'Time', 'Norm')\n",
      "(1874, 'acrol0817', 'Golz', 'Time', 'Norm')\n",
      "(1875, 'acrol0818', 'Golz', 'Time', 'Norm')\n",
      "(1876, 'acrol0819', 'Golz', 'Time', 'Norm')\n",
      "(1877, 'acrol0820', 'Golz', 'Time', 'Norm')\n",
      "(1878, 'acrol0821', 'Golz', 'Time', 'Norm')\n",
      "(1879, 'acrol0822', 'Golz', 'Time', 'Norm')\n",
      "(1880, 'acrol0823', 'Golz', 'Time', 'Norm')\n",
      "(1881, 'acrol0824', 'Golz', 'Time', 'Norm')\n",
      "(1882, 'acrol0825', 'Golz', 'Time', 'Norm')\n",
      "(1883, 'acrol0826', 'Golz', 'Time', 'Norm')\n",
      "(1884, 'acrol0827', 'Golz', 'Time', 'Norm')\n",
      "(1885, 'acrol0828', 'Golz', 'Time', 'Norm')\n",
      "(1886, 'acrol0829', 'Golz', 'Time', 'Norm')\n",
      "(1888, 'acrol0831', 'Golz', 'Time', 'Norm')\n",
      "(1890, 'acrol0833', 'Golz', 'Time', 'Norm')\n",
      "(1891, 'acrol0834', 'Golz', 'Time', 'Norm')\n",
      "(1892, 'acrol0835', 'Golz', 'Time', 'Norm')\n",
      "(1893, 'acrol0836', 'Golz', 'Time', 'Norm')\n",
      "(1894, 'acrol0837', 'Golz', 'Time', 'Norm')\n",
      "(1895, 'acrol0838', 'Golz', 'Time', 'Norm')\n",
      "(1897, 'acrol0840', 'Golz', 'Time', 'Norm')\n",
      "(1898, 'acrol0841', 'Golz', 'Time', 'Norm')\n",
      "(1900, 'acrol0843', 'Golz', 'Time', 'Norm')\n",
      "(1901, 'acrol0844', 'Golz', 'Time', 'Norm')\n",
      "(1903, 'acrol0846', 'Golz', 'Time', 'Norm')\n",
      "(1910, 'acrol0853', 'Golz', 'Time', 'Norm')\n",
      "(1911, 'acrol0854', 'Golz', 'Time', 'Norm')\n",
      "(1915, 'acrol0858', 'Golz', 'Time', 'Norm')\n",
      "(1916, 'acrol0859', 'Golz', 'Time', 'Norm')\n",
      "(1917, 'acrol0860', 'Golz', 'Time', 'Norm')\n",
      "(1918, 'acrol0861', 'Golz', 'Time', 'Norm')\n",
      "(1919, 'acrol0862', 'Golz', 'Time', 'Norm')\n",
      "(1920, 'acrol0863', 'Golz', 'Time', 'Norm')\n",
      "(1921, 'acrol0864', 'Golz', 'Time', 'Norm')\n",
      "(1924, 'acrol0867', 'Golz', 'Time', 'Norm')\n",
      "(1925, 'acrol0868', 'Golz', 'Time', 'Norm')\n",
      "(1926, 'acrol0869', 'Golz', 'Time', 'Norm')\n",
      "(1927, 'acrol0870', 'Golz', 'Time', 'Norm')\n",
      "(1930, 'acrol0873', 'Golz', 'Time', 'Norm')\n",
      "(1931, 'acrol0874', 'Golz', 'Time', 'Norm')\n",
      "(1932, 'acrol0875', 'Golz', 'Time', 'Norm')\n",
      "(1933, 'acrol0876', 'Golz', 'Time', 'Norm')\n",
      "(1935, 'acrol0878', 'Golz', 'Time', 'Norm')\n",
      "(1937, 'acrol0880', 'Golz', 'Time', 'Norm')\n",
      "(1938, 'acrol0881', 'Golz', 'Time', 'Norm')\n",
      "(1939, 'acrol0882', 'Golz', 'Time', 'Norm')\n",
      "(1940, 'acrol0883', 'Golz', 'Time', 'Norm')\n",
      "(1941, 'acrol0884', 'Golz', 'Time', 'Norm')\n",
      "(1944, 'acrol0887', 'Golz', 'Time', 'Norm')\n",
      "(1956, 'acrol0899', 'Golz', 'Time', 'Norm')\n",
      "(1957, 'acrol0900', 'Golz', 'Time', 'Norm')\n",
      "(1958, 'acrol0901', 'Golz', 'Time', 'Norm')\n",
      "(1959, 'acrol0902', 'Golz', 'Time', 'Norm')\n",
      "(1963, 'acrol0906', 'Golz', 'Time', 'Norm')\n",
      "(1964, 'acrol0907', 'Golz', 'Time', 'Norm')\n",
      "(1966, 'acrol0909', 'Golz', 'Time', 'Norm')\n",
      "(1973, 'acrol0916', 'Golz', 'Time', 'Norm')\n",
      "(1974, 'acrol0917', 'Golz', 'Time', 'Norm')\n",
      "(1975, 'acrol0918', 'Golz', 'Time', 'Norm')\n",
      "(1976, 'acrol0919', 'Golz', 'Time', 'Norm')\n",
      "(1977, 'acrol0920', 'Golz', 'Time', 'Norm')\n",
      "(1978, 'acrol0921', 'Golz', 'Time', 'Norm')\n",
      "(1980, 'acrol0923', 'Golz', 'Time', 'Norm')\n",
      "(1983, 'acrol0926', 'Golz', 'Time', 'Norm')\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "# they're sorted in ascending order !!!!\n",
    "\n",
    "feat_list = []\n",
    "asd = OrderedDict(sorted(tot_occs.items(), key=lambda tot_occs: tot_occs[1]))\n",
    "for k,v in asd.items():\n",
    "    feat_list.append(k)\n",
    "nio = get_feat_id(feat_list,printit = 1)\n",
    "# print feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_self_file = 'feat_sel_1_2.npz'\n",
    "np.savez(feat_self_file,ids = nio, feat_mask = feat_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8898, 3107)\n",
      "(5932, 3107)\n",
      "...done fitting\n",
      "=============================================================\n",
      "Testing with classifier KNei\n",
      "Prediction accuracy 0.876601\n",
      "[[ 0.88917693  0.11082307]\n",
      " [ 0.13703443  0.86296557]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.89      0.88      1543\n",
      "        1.0       0.88      0.86      0.87      1423\n",
      "\n",
      "avg / total       0.88      0.88      0.88      2966\n",
      "\n",
      "=============================================================\n",
      "...done fitting\n",
      "=============================================================\n",
      "Testing with classifier SVC(\n",
      "Prediction accuracy 0.903574\n",
      "[[ 0.94426442  0.05573558]\n",
      " [ 0.14054814  0.85945186]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.94      0.91      1543\n",
      "        1.0       0.93      0.86      0.90      1423\n",
      "\n",
      "avg / total       0.91      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n",
      "...done fitting\n",
      "=============================================================\n",
      "Testing with classifier MLPC\n",
      "Prediction accuracy 0.915374\n",
      "[[ 0.94491251  0.05508749]\n",
      " [ 0.11665495  0.88334505]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.94      0.92      1543\n",
      "        1.0       0.94      0.88      0.91      1423\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2966\n",
      "\n",
      "=============================================================\n",
      "...done fitting\n",
      "=============================================================\n",
      "Testing with classifier Rand\n",
      "Prediction accuracy 0.918746\n",
      "[[ 0.96824368  0.03175632]\n",
      " [ 0.13492621  0.86507379]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.97      0.93      1543\n",
      "        1.0       0.96      0.87      0.91      1423\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2966\n",
      "\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# validate between the different objects using the dataset from both fingers\n",
    "\n",
    "# Version 2: keep alternatively one for testing and train on the rest\n",
    "\n",
    "# ===================================== Hard-code this shit\n",
    "\n",
    "data_X = deepcopy(X[2][0]) #[:-1]\n",
    "data_Y = deepcopy(Y[2]) #[:-1]\n",
    "print(data_X.shape)\n",
    "surfaces = np.split(data_X,3)\n",
    "surf_labels = np.split(data_Y,3) \n",
    "# feat_mask = []\n",
    "temp1 = surfaces[0] \n",
    "train_x = np.concatenate((surfaces[2], surfaces[0]), axis = 0) ; test_x = surfaces[1]\n",
    "train_y = np.concatenate((surf_labels[2], surf_labels[0]), axis = 0) ; test_y = surf_labels[1]\n",
    "print(train_x.shape)\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "\n",
    "for pipe_ind, pipe in enumerate(pipe_list):\n",
    "    pipe.fit(train_x, train_y)\n",
    "    print(\"...done fitting\")\n",
    "    y_pred = pipe.predict(test_x)\n",
    "    y_true = test_y\n",
    "    cm = confusion_matrix(y_pred=y_pred, y_true=y_true)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print (\"=============================================================\")\n",
    "    print(\"Testing with classifier %0.4s\" %pipe.named_steps['classifier'])\n",
    "    print(\"Prediction accuracy %f\" %pipe.score(test_x,y_true))\n",
    "    print(cm)\n",
    "    print(classification_report(y_pred=y_pred, y_true = y_true))        \n",
    "    print (\"=============================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for surf_ind, surf_dat in enumerate(surfaces):\n",
    "#     print(\"Testing on surface no. %d\" %surf_ind)\n",
    "#     ind_mask = [True, True, True] \n",
    "#     ind_mask[surf_ind] = False #  the testing dataset is flagged by False\n",
    "#     solely_for_printing_mask = [i for i, x in enumerate(ind_mask) if x == True]\n",
    "#     test_x = surf_dat\n",
    "#     test_y = surf_labels[surf_ind]\n",
    "# #     print(ind_mask)\n",
    "#     train_x = list(compress(surfaces, ind_mask)) # the rest splits, flagged by True, are kept for training\n",
    "#     train_y = list(compress(surf_labels,ind_mask))\n",
    "#     train_d = np.vstack((train_x[0],train_x[1])) ; train_d = train_d[::200]\n",
    "#     train_l = np.hstack((train_y[0], train_y[1])) ; train_l = train_l[::200]\n",
    "# #     print(train_d.shape, surf_dat.shape, train_l.shape)\n",
    "#     for pipe_ind,pipe in enumerate(pipe_list):\n",
    "        \n",
    "# #         for train_ind, train_d in enumerate(train_x):\n",
    "# #             print(\"Fitting classifier no. %d...\" %solely_for_printing_mask[train_ind])\n",
    "#             pipe.fit(train_d,train_l) # fit the pipeline for every train set and every clf\n",
    "#             print (\"...done fitting\")\n",
    "#             feat = list(pipe.named_steps['feature_selection'].get_support(indices = True))\n",
    "#             feat_mask+=feat\n",
    "#             y_pred = pipe.predict(test_x)\n",
    "#             y_true = test_y\n",
    "#             cm = confusion_matrix(y_pred=y_pred, y_true=y_true)\n",
    "#             cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#             print (\"=============================================================\")\n",
    "# #             print(\"Trained on %d, testing on %d with %0.4s\" %(surf_ind, solely_for_printing_mask[test_ind], pipe.named_steps['classifier']))\n",
    "#             print(\"Prediction accuracy %f\" %pipe.score(test_x,y_true))\n",
    "#             print(cm)\n",
    "#             print(classification_report(y_pred=y_pred, y_true = y_true))        \n",
    "#             print (\"=============================================================\")\n",
    "    \n",
    "# # tot_occs = get_feat_occ(feat_mask)\n",
    "# # ids = get_feat_id(tot_occs[:20],printit=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[(8902, 3107), (8902, 3107), (8902, 6214), (8898, 3107), (8898, 3107), (8898, 6214)]\n",
      "[(8902, 3107), (8902, 3107), (8902, 6214), (8902, 3107), (8902, 3107), (8902, 6214), (8898, 3107), (8898, 3107), (8898, 6214)]\n"
     ]
    }
   ],
   "source": [
    "ind_list = [1,0,1]\n",
    "bool_ind = [bool(ind_list[i]) for i in range(len(ind_list))]\n",
    "bool_result = X[bool_ind]\n",
    "print (len(X),len(bool_result))\n",
    "print([ bool_result[i][j].shape for i in range(len(bool_result)) for j in range(len(bool_result[i]))])\n",
    "print([ X[i][j].shape for i in range(len(X)) for j in range(len(X[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started fitting...\n",
      "...done fitting\n"
     ]
    }
   ],
   "source": [
    "# Training the classifiers for the real time validation \n",
    "data_X = deepcopy(X[2]) #[:-1]\n",
    "data_Y = deepcopy(Y[2]) #[:-1]\n",
    "datapath = 'trained_pipes/'\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "\n",
    "for fs in range(len(data_X)):\n",
    "    print(fs)\n",
    "    train_x = data_X[fs]\n",
    "    for pipe_id, pipe in enumerate(pipe_list):\n",
    "        print(pipe_id)\n",
    "        filename = 'fs1'+'_'+str(fs)+'_'+str(pipe_id)\n",
    "        pipefile = datapath+filename+'.npz'\n",
    "        print(\"Started fitting...\")\n",
    "        model = pipe.fit(train_x, data_Y)\n",
    "        print(\"...done fitting\")\n",
    "#         masdas = model.predict(train_x)\n",
    "        np.savez(pipefile,model=np.array([model]))\n",
    "# train_x = data_X[1]\n",
    "# filename = 'fs1'+'_'+str(11)+'_'+str(11)\n",
    "# pipefile = datapath+filename+'.npz'\n",
    "# print(\"Started fitting...\")\n",
    "# model = pipe_list[3].fit(train_x, data_Y)\n",
    "# print(\"...done fitting\")\n",
    "# #         masdas = model.predict(train_x)\n",
    "# np.savez(pipefile,model=np.array([model]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 3107) (1500,)\n",
      "Started fitting...\n",
      "...done fitting\n"
     ]
    }
   ],
   "source": [
    "# Training the classifiers for the real time validation \n",
    "data_X = deepcopy(surf[3,0,1]) #[:-1]\n",
    "data_Y = deepcopy(surfla[:,0,1]) #[:-1]\n",
    "print data_X.shape, data_Y.shape\n",
    "datapath = 'tmp/trained_pipes_trans_1b1/'\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "filename2 = 'overall_models'\n",
    "models = []\n",
    "# for fs in range(len(data_X)):\n",
    "#     print(fs)\n",
    "#     train_x = data_X[fs]\n",
    "#     for pipe_id, pipe in enumerate(pipe_list):\n",
    "pipe = pipe_list[2]\n",
    "filename = 'fs'+'_'+str(1)+'_'+str(2)\n",
    "#     print(pipe_id)\n",
    "pipefile = datapath+filename+'.npz'\n",
    "print(\"Started fitting...\")\n",
    "model = pipe.fit(data_X, data_Y)\n",
    "models.append(model)\n",
    "print(\"...done fitting\")\n",
    "np.savez(pipefile,model=np.array([model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file2 = datapath + filename2 + '.npz'\n",
    "np.savez(file2, models = np.array(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8898,3107) (6214,) (8898,3107) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-e6c01426a181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# lasttry = [last + [mdl[i]] for i in range(len(mdl))]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# anot[1].predict(trmp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0manot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/utils/metaestimators.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y, copy)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (8898,3107) (6214,) (8898,3107) "
     ]
    }
   ],
   "source": [
    "anot = np.load(file2)['models']\n",
    "# print[mdl[i] for i in range(len(mdl))]\n",
    "# lasttry = [last + [mdl[i]] for i in range(len(mdl))]\n",
    "# anot[1].predict(trmp)\n",
    "anot[1].predict(trmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5dd5560c10>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIsAAAJCCAYAAABAuEcoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5e0c5d9110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nasougamhsw = np.load('trained_pipes2/fs_2_2.npz')\n",
    "clf = nasougamhsw['model']\n",
    "# clf2 = np.array([gamhmene['model']])\n",
    "feat = list(clf[0].named_steps['feature_selection'].get_support(indices = True))\n",
    "\n",
    "feat_score = list(clf[0].named_steps['feature_selection'].scores_)\n",
    "# print(feat_score)\n",
    "plt.figure(figsize= (20,10))\n",
    "plt.plot(feat_score)\n",
    "\n",
    "# asd = get_feat_id(feat,1)\n",
    "# ftfn =[]\n",
    "# for i in range(len(feat)):\n",
    "#     if feat[i]>=3107:\n",
    "#         ftfn.append(feat[i])\n",
    "# print(len(ftfn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('feature_selection', SelectKBest(k=1000,\n",
      "      score_func=<function mutual_info_classif at 0x7fa94e82d410>)), ('decomp', PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'))])\n",
      "[ 0.  0.  0. ...,  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "data_X = deepcopy(X[2]) ; data_Y = deepcopy(Y[2])\n",
    "trmp = data_X[1]\n",
    "# trmp.shape\n",
    "# asda = clf[0].predict(trmp)\n",
    "print clf[0]\n",
    "print clf[0].predict(trmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
