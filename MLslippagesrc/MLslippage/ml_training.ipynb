{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mainly Edited for private usage by:  Ioannis Agriomallos\n",
      "                                        Ioanna Mitsioni\n",
      "License: BSD 3 clause\n",
      "\n",
      "============= CURRENT CODE USAGE =============\n",
      "Current code trains MLP Classifiers, to classify force input samples as stable (0) or slip (1)\n",
      "---- Input\n",
      "-> Input samples originate from optoforce sensors and are 3D (fx,fy,fz) and come from 2 different datasets, \n",
      "   one training, containing several surfaces as well as slip-stable occurrences, \n",
      "   and one validation, containing 1 surface with slip-stable occurrences on a completely unseen task-setup.\n",
      "---- Input transformation\n",
      "-> Several pre-features can be taken from these inputs, but here |f| is kept.\n",
      "-> Several time and frequency domain features are extracted from pre-feature windows. \n",
      "  (implemented in 'featext.py') These windows have size w and are shifted by s on each sample\n",
      "-> Then a feature selection-ranking is performed using MutualVariableInformation\n",
      "-> Finally PCA is performed to keep a reduced set among the best selected features\n",
      "---- Training of ML Classifiers\n",
      "-> Several MLP Classifiers are trained for all combinations of selected featuresets-datasets\n",
      "---- Results\n",
      "-> Stats of classification results are kept inside each .npz along with the respective trained model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Mainly Edited for private usage by:  Ioannis Agriomallos\n",
    "                                        Ioanna Mitsioni\n",
    "License: BSD 3 clause\n",
    "\n",
    "============= CURRENT CODE USAGE =============\n",
    "Current code trains MLP Classifiers, to classify force input samples as stable (0) or slip (1)\n",
    "---- Input\n",
    "-> Input samples originate from optoforce sensors and are 3D (fx,fy,fz) and come from 2 different datasets, \n",
    "   one training, containing several surfaces as well as slip-stable occurrences, \n",
    "   and one validation, containing 1 surface with slip-stable occurrences on a completely unseen task-setup.\n",
    "---- Input transformation\n",
    "-> Several pre-features can be taken from these inputs, but here |f| is kept.\n",
    "-> Several time and frequency domain features are extracted from pre-feature windows. \n",
    "  (implemented in 'featext.py') These windows have size w and are shifted by s on each sample\n",
    "-> Then a feature selection-ranking is performed using MutualVariableInformation\n",
    "-> Finally PCA is performed to keep a reduced set among the best selected features\n",
    "---- Training of ML Classifiers\n",
    "-> Several MLP Classifiers are trained for all combinations of selected featuresets-datasets\n",
    "---- Results\n",
    "-> Stats of classification results are kept inside each .npz along with the respective trained model\n",
    "\"\"\"\n",
    "print(__doc__)\n",
    "import time\n",
    "start_time = time.time()\n",
    "from copy import deepcopy, copy\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import shutil\n",
    "import os, errno\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "from featext import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# %matplotlib qt\n",
    "# inline (suitable for ipython only, shown inside browser!) or qt (suitable in general, shown in external window!)\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import re\n",
    "import datetime\n",
    "import urllib\n",
    "import tarfile\n",
    "import zipfile\n",
    "import joblib\n",
    "from subprocess import call, check_output\n",
    "from joblib import Parallel, delayed, Memory\n",
    "from tempfile import mkdtemp\n",
    "import copy_reg\n",
    "import types\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "def _pickle_method(m):\n",
    "    \"\"\"Useful function for successful convertion from directories and lists to numpy arrays\"\"\"\n",
    "    if m.im_self is None:\n",
    "        return getattr, (m.im_class, m.im_func.func_name)\n",
    "    else:\n",
    "        return getattr, (m.im_self, m.im_func.func_name)\n",
    "copy_reg.pickle(types.MethodType, _pickle_method)\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    \"\"\"Useful function for creating directory only if not existent\"\"\"\n",
    "    try:\n",
    "        os.makedirs(directory)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "h = .2  # step size in the mesh\n",
    "\n",
    "######## TRAINING DEFAULTS\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ;\n",
    "decomp = PCA(n_components=20)\n",
    "names = [\"NearNb\", \"RBFSVM1\", \"MLP1\", \"RandFor\"]\n",
    "classifiers = [KNeighborsClassifier(5),\n",
    "               SVC(gamma='auto', C=1),\n",
    "               MLPClassifier(solver='lbfgs',alpha=1e-4,hidden_layer_sizes=(10,10),random_state=1,verbose=True),\n",
    "               RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)]\n",
    "\n",
    "download = 1            # Download pre-computed (1) data or compute them all anew (0)\n",
    "delete_big_features = 0 # Delete (1) or keep (0) computed big-in-size features, \n",
    "                        # helping mainly to avoid several computations when recomputing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ INITIALISATION PARAMETERS ############\n",
    "window, shift = 1024, 20\n",
    "samplesperdataset = 10000\n",
    "havelabel = 1\n",
    "returntime = 0\n",
    "featlabel = 0         # 0: all features, 1: temporal, 2: frequency, 3: FFT only\n",
    "magnFFT = 0           # 0: FFT in magnitude format, 1: FFT in real and imag format, \n",
    "featall = 0           # 0: all, 1: feat1 (phinyomark's), 2: feat2 (golz's)\n",
    "featparam = [havelabel,featlabel,magnFFT,featall,returntime]\n",
    "CV = 5                # cross validation checks\n",
    "numfeat = 10          # number of features to show\n",
    "nfeat = 1000          # number of features to keep\n",
    "###### Initialize necessary names and paths\n",
    "datapath = 'data/'\n",
    "ensure_dir(datapath)\n",
    "datafile = datapath+'dataset.npz'\n",
    "validfile = datapath+'validation.mat'\n",
    "featpath = datapath+'features/'+str(window)+'_'+str(shift)+'/'\n",
    "ensure_dir(featpath)\n",
    "allfeatpath = featpath+'AllFeatures/'\n",
    "ensure_dir(allfeatpath)\n",
    "prefeatname = 'prefeatures'+'_'+str(window)+'_'+str(shift)+'_'+str(samplesperdataset)\n",
    "prefeatfile = featpath+prefeatname+'.npz'\n",
    "featname = 'features'+'_'+str(window)+'_'+str(shift)+'_'+str(samplesperdataset)\n",
    "featfile = featpath+featname+'.npz'\n",
    "validfeatname = 'valid'+featname\n",
    "validfeatfile = featpath+validfeatname+'.npz'\n",
    "surffile = featpath+featname+'_2fing_6surf.npz'\n",
    "XYfile = featpath+featname+'_XY.npz'\n",
    "XYsplitfile = featpath+featname+'_XYsplit.npz'\n",
    "validsurffile = featpath+validfeatname+'_2fing_6surf.npz'\n",
    "validXYfile = featpath+validfeatname+'_XY.npz'\n",
    "validXYsplitfile = featpath+validfeatname+'_XYsplit.npz'\n",
    "respath = datapath+'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Feature Names ############\n",
    "\"\"\"features:                                                                       ||      if       \n",
    "   |--> time domain      :                                                         || samples = 1024\n",
    "   |----|---> phinyomark : 11+3{shist} --------------------------> = 14+0.0samples ||             14\n",
    "   |----|---> golz       : 10+samples{acrol} --------------------> = 10+1.0samples ||           1034\n",
    "   |--> frequency domain :                                                                          \n",
    "   |----|---> phinyomark : 3{arco}+4{mf}+2(samples/2+1){RF,IF} --> =  9+1.0samples ||           1033\n",
    "   |----|---> golz       : 2(samples/2+1){AF,PF} ----------------> =  2+1.0samples ||           1026\n",
    "   |----|----------------|-------alltogether---------------------> = 35+3.0samples || numfeat = 3107\n",
    "\"\"\"\n",
    "## Time Domain Phinyomark feats\n",
    "featnames = ['intsgnl', 'meanabs', 'meanabsslp', 'ssi', 'var', 'rms', 'rng', 'wavl', 'zerox', 'ssc', 'wamp', \n",
    "             'shist1', 'shist2', 'shist3']                                                   # 11+3{shist}\n",
    "## Frequency Domain Phinyomark feats\n",
    "featnames += ['arco1', 'arco2', 'arco3', 'mnf', 'mdf', 'mmnf', 'mmdf']                       # 3{arco}+4{mf}\n",
    "featnames += ['reFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{RF}\n",
    "featnames += ['imFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{IF}\n",
    "## Time Domain Golz feats\n",
    "featnames += ['meanv', 'stdr', 'mx', 'rngx', 'rngy', 'med', 'hjorth', 'sentr', 'se', 'ssk']  # 10\n",
    "featnames += ['acrol{:04d}'.format(i) for i in range(window)]                                # samples{acrol}\n",
    "## Frequency Domain Golz feats\n",
    "featnames += ['amFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{AF}\n",
    "featnames += ['phFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{PF}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessary  data/dataset.npz  already here!\n",
      "Necessary  data/validation.mat  already here!\n",
      "Necessary  data/features/1024_20/features_1024_20_10000.npz  already here!\n",
      "Necessary  data/features/1024_20/validfeatures_1024_20_10000.npz  already here!\n",
      "Desired trained models for 1 surface found!\n",
      "Desired trained models for 2 surface found!\n",
      "Desired trained models for 3 surface found!\n",
      "Desired trained models for 4 surface found!\n",
      "Desired trained models for 5 surface found!\n",
      "Downloaded 1.2 GB of content in total!\n"
     ]
    }
   ],
   "source": [
    "############ Download necessary files ############\n",
    "def convert_bytes(num):\n",
    "    \"\"\"this function will convert bytes to MB.... GB... etc\"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "def file_size(file_path):\n",
    "    \"\"\"this function will return the file size\"\"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        file_info = os.stat(file_path)\n",
    "        return file_info.st_size\n",
    "    \n",
    "def download_file(datafile, targetlink):\n",
    "    \"\"\"Function for checking if targetfile exists, else downloading it from targetlink to targetpath+targetfile\"\"\"\n",
    "    if not os.path.isfile(datafile):\n",
    "        print 'Necessary ', datafile, ' not here! Downloading...'\n",
    "        u = urllib.urlopen(targetlink)\n",
    "        data = u.read()\n",
    "        print 'Completed downloading ','{:.2f}'.format(len(data)*1./(1024**2)),'MB of ',datafile,'!'\n",
    "        u.close()\n",
    "        with open(datafile, \"wb\") as f :\n",
    "            f.write(data)\n",
    "        print 'Necessary ', datafile, ' completed saving!'\n",
    "    else:\n",
    "        print 'Necessary ', datafile, ' already here!'\n",
    "    return file_size(datafile)\n",
    "\n",
    "def extract_file(source,destination='.'):\n",
    "    \"\"\"Decompress source zip, tar or tgz file to destination folder\"\"\"\n",
    "    print \"Extracting compressed file...\"\n",
    "    if (source.endswith('tar.gz') or source.endswith('tgz')):\n",
    "        with tarfile.open(source, 'r:gz' ) as tgz_ref:\n",
    "            tgz_ref.extractall(destination)\n",
    "        print \"Done!\"\n",
    "    elif (source.endswith('tar')):\n",
    "        with tarfile.open(source, 'r:' ) as tar_ref:\n",
    "            tar_ref.extractall(destination)\n",
    "        print \"Done!\"\n",
    "    elif (source.endswith('zip')):\n",
    "        with zipfile.ZipFile(source, 'r') as zip_ref:\n",
    "            zip_ref.extractall(destination)\n",
    "        print \"Done!\"\n",
    "    else:\n",
    "        print \"Unsupported extension for decompressing. Supported extensions are .zip, .tgz, .tar.gz, .tar\"\n",
    "        \n",
    "####### Download necessary dataset\n",
    "total_size_of_downloads = 0\n",
    "datafile = datapath+'dataset.npz'\n",
    "validfile = datapath+'validation.mat'\n",
    "datalink = 'https://www.dropbox.com/s/j88wmtx1vvpik1m/dataset.npz?dl=1'\n",
    "validlink = 'https://www.dropbox.com/s/r8jl57lij28ljrw/validation.mat?dl=1'\n",
    "total_size_of_downloads += download_file(datafile, datalink)\n",
    "total_size_of_downloads += download_file(validfile, validlink)\n",
    "####### Download bargraph tool if not already downloaded (by Derek Bruening)\n",
    "toollink = 'https://github.com/derekbruening/bargraph/archive/rel_4_8.zip'\n",
    "toolfile = datapath+'bargraph.zip'\n",
    "toolpath = datapath+'bargraph-rel_4_8/'\n",
    "if not os.path.isdir(toolpath):\n",
    "    total_size_of_downloads += download_file(toolfile, toollink)\n",
    "    if os.path.isfile(toolfile):\n",
    "        extract_file(toolfile,datapath+'.')\n",
    "tool = './'+toolpath+'bargraph.pl'\n",
    "call(['chmod','+x',tool]) # make tool executable\n",
    "call(['rm',toolfile]) # delete zip file\n",
    "####### Download features and trained models, if not wanting to compute them and not already there\n",
    "if download==1:\n",
    "    featlink = 'https://www.dropbox.com/s/qvk9pcvlir06zse/features_1024_20_10000.npz?dl=1'\n",
    "    validfeatlink = 'https://www.dropbox.com/s/sghqwifo8rxwbcs/validfeatures_1024_20_10000.npz?dl=1'\n",
    "    total_size_of_downloads += download_file(featfile, featlink)\n",
    "    total_size_of_downloads += download_file(validfeatfile, validfeatlink)\n",
    "    reslink = {}\n",
    "    reslink[0] = 'https://www.dropbox.com/sh/mib7wk4sfv6eye3/AACUWSOgQjBD9i2sChtNisNKa?dl=1'\n",
    "    reslink[1] = 'https://www.dropbox.com/sh/y6js9ha585n4zam/AACARvB8krZnC3VPsOjWTaRra?dl=1'\n",
    "    reslink[2] = 'https://www.dropbox.com/sh/fc9jgi2cs7d0dzg/AADfw42xG0XtiUOYWo7cmmtUa?dl=1'\n",
    "    reslink[3] = 'https://www.dropbox.com/sh/mx6e7jcxzbcr5s4/AACkVMPatRd2UZfyUkxvP_tLa?dl=1'\n",
    "    reslink[4] = 'https://www.dropbox.com/sh/88itj3b4nwpe0f1/AACceO9FsZp5w55n7PKlVnWSa?dl=1'\n",
    "    for i in range(len(reslink)):\n",
    "        resfold = datapath+'results'+str(i+1)\n",
    "        if not os.path.isdir(resfold):\n",
    "            resfile = resfold+'.zip'\n",
    "            total_size_of_downloads += download_file(resfile, reslink[i]) # download\n",
    "            extract_file(resfile, resfold) # extract\n",
    "            call(['rm',resfile]) # delete zip\n",
    "        else:\n",
    "            print \"Desired trained models for \"+str(i+1)+\" surface found!\"\n",
    "print \"Downloaded \"+convert_bytes(total_size_of_downloads)+\" of content in total!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############ READ THE DATASET ############\n",
    "def data_prep(datafile,step=1,k=2):\n",
    "    \"\"\"Prepare dataset, from each of the k fingers for all n surfaces (see fd for details)\n",
    "    -> datafile : input file either in .npz or in .mat form\n",
    "    -> step     : increasing sampling step, decreases sampling frequency of input, which is 1KHz initially\n",
    "    -> k        : number of fingers logging data\n",
    "    ----- input format ----- either 'fi', 'li', 'fdi', with i in {1,...,k} for each finger\n",
    "                             or     'f', 'l', 'fd' for a finger\n",
    "                             corresponding to force, label and details respectively\n",
    "    <- f,l,fd   : output force, label and details for each experiment in the dataset\n",
    "    <- member   : how much each dataset is represented, \n",
    "                  to skip samples effectively and keep dimensions correct\n",
    "    <- m1, m2   : portion of data belonging to finger1 and finger2\n",
    "    \"\"\"\n",
    "    print \"---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\"\n",
    "    if datafile[-3:]=='mat':\n",
    "        inp = sio.loadmat(datafile,struct_as_record=True)\n",
    "    elif datafile[-3:]=='npz':\n",
    "        inp = np.load(datafile)\n",
    "    else:\n",
    "        print \"Unsupported input file format. Supported types: .npz .mat\"\n",
    "        return -1\n",
    "    if k==2:\n",
    "        f1, f2, l1, l2, fd1, fd2 = inp['f1'], inp['f2'], inp['l1'], inp['l2'], inp['fd1'], inp['fd2']\n",
    "        print 1, '-> f1:', f1.shape, l1.shape, fd1.shape\n",
    "        print 2, '-> f2:', f2.shape, l2.shape, fd2.shape\n",
    "        ####### MERGE THE DATASETS\n",
    "        f = np.concatenate((f1,f2),axis=0)\n",
    "        l = np.concatenate((l1,l2),axis=0)\n",
    "        fd = np.concatenate((fd2,fd2),axis=0)\n",
    "    elif k==1:\n",
    "        f, l, fd = inp['f'], inp['l'], inp['fd']\n",
    "    else:\n",
    "        print \"Unsupported number of fingers k. Should be k in {1,2}\"\n",
    "    print 3, '-> f:', f.shape, l.shape, fd.shape\n",
    "    # membership of each sample, representing its portion in the dataset \n",
    "    # (first half finger1 and second half finger2)\n",
    "    member = np.zeros(len(f))\n",
    "    m1,m2 = len(f)/2, len(f)/2\n",
    "    member[:m1] = np.ones(m1)*1./m1\n",
    "    member[-m2:] = np.ones(m2)*1./m2\n",
    "    print 4, '-> m1,m2:', m1, m2, sum(member[:m1]), sum(member[-m2:])\n",
    "    ####### MERGE f and l\n",
    "    while f.ndim>1:\n",
    "        f = f[:,0]\n",
    "        l = l[:,0]\n",
    "    for i in range(len(f)):\n",
    "        while l[i].ndim<2:\n",
    "            l[i] = l[i][:,np.newaxis]\n",
    "    f = np.array([np.concatenate((f[i],l[i]),axis=1) for i in range(len(f))])\n",
    "    print 5, '-> f=f+l:', f.shape, \":\", [fi.shape for fi in f]\n",
    "    ####### SUBSAMPLING\n",
    "    # step = 1 # NO SAMPLING\n",
    "    if step!=1:\n",
    "        f = np.array([fi[::step,:] for fi in f])\n",
    "        print 6, '-> fsampled:',f.shape, \":\", [fi.shape for fi in f]\n",
    "    return f,l,fd,member,m1,m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ PRE-FEATURES ############\n",
    "###### DEFINITION\n",
    "# featnum 0 : sf    = (fx^2+fy^2+fz^2)^0.5\n",
    "#         1 : ft    = (fx^2+fy^2)^0.5\n",
    "#         2 : fn    = |fz|\n",
    "#         3 : ft/fn = (fx^2+fy^2)^0.5/|fz|\n",
    "# input (nxm) -> keep (nx3) -> compute pre-feature and return (nx1)\n",
    "\n",
    "def sf(f):\n",
    "    \"\"\"Computation of norm (sf) of force (f)\"\"\"\n",
    "    return np.power(np.sum(np.power(f[:,:3],2),axis=1),0.5)\n",
    "def ft(f):\n",
    "    \"\"\"Computation of tangential (ft) of force (f)\"\"\"\n",
    "    return np.power(np.sum(np.power(f[:,:2],2),axis=1),0.5)\n",
    "def fn(f):\n",
    "    \"\"\"Computation of normal (fn) of force (f)\"\"\"\n",
    "    return np.abs(f[:,2])\n",
    "def ftn(f):\n",
    "    \"\"\"Computation of tangential (ft) to normal (fn) ratio of force (f), \n",
    "    corresponding to the friction cone boundary\n",
    "    \"\"\"\n",
    "    retft = ft(f)\n",
    "    retfn = fn(f)\n",
    "    retft[retfn<=1e-2] = 0\n",
    "    return np.divide(retft,retfn+np.finfo(float).eps)\n",
    "def lab(f):\n",
    "    \"\"\"Label embedded in input f\"\"\"\n",
    "    return np.abs(f[:,-1])\n",
    "###### COMPUTATION\n",
    "prefeatfn = np.array([sf,ft,fn,ftn,lab]) # convert to np.array to be easily indexed by a list\n",
    "prefeatnames = np.array(['fnorm','ft','fn','ftdivfn','label'])\n",
    "prefeatid = [0,4]     # only the prefeatures with corresponding ids will be computed\n",
    "def compute_prefeat(f):\n",
    "    \"\"\"Prefeature computation\n",
    "    -> f       : input force as an i by n by 4 matrix\n",
    "    <- prefeat : corresponding force profiles\n",
    "    \"\"\"\n",
    "    print \"--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\"\n",
    "    prefeat = [np.array([prfn(f[i]) for prfn in prefeatfn[prefeatid]]).transpose() for i in range(len(f))]\n",
    "    prefeat.append(prefeat[-1][:-1])\n",
    "    prefeat = np.array(prefeat)[:-1]\n",
    "    print prefeat.shape,\":\",[p.shape for p in prefeat]\n",
    "    return prefeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ AVG Computation time of ALL features in secs ############\n",
    "def avg_feat_comp_time(prefeat):\n",
    "    \"\"\"Average computation time for feature extraction\n",
    "    -> prefeat : desired prefeature input\n",
    "    \"\"\"\n",
    "    print \"------------------------------------ AVG FEATURE COMPUTATION TIME ------------------------------------\"\n",
    "    t1 = time.time()\n",
    "    m = int(ceil(0.2*len(prefeat)))\n",
    "    # avg over m*100 times\n",
    "    tmpfeat = [feat(prefeat[k][i:i+window,:2],*featparam) for k in range(m) for i in range(100)]\n",
    "    print 'Avg feature computation time (millisec): ', (time.time() - t1) / (100 * m) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ FEATURE COMPUTATION ############\n",
    "def tmpfeatfilename(p,name,mode='all'):\n",
    "    \"\"\"Filename for feature computation and intermittent saving\n",
    "    -> p    : prefeat id\n",
    "    -> name : desired prefix name for tmp filenames\n",
    "    -> mode : whether keeping whole feature matrix ('all') or sampling rows ('red') to reduce size\n",
    "    <- corresponding output filename\n",
    "    \"\"\"\n",
    "    if mode == 'all':\n",
    "        return allfeatpath+name+str(p)+'.pkl.z'\n",
    "    elif mode == 'red':\n",
    "        return allfeatpath+name+str(p)+'_red'+str(samplesperdataset)+'.pkl.z'\n",
    "    \n",
    "def feature_extraction(prefeat, member, featfile=featfile, name='feat_'):\n",
    "    \"\"\"Computation of all features in parallel or loading if already computed\n",
    "    -> prefeat          : computed prefeatures\n",
    "    -> member           : how much each dataset is represented, \n",
    "                          to skip samples effectively and keep dimensions correct\n",
    "    -> featfile         : desired final feature filename             \n",
    "    -> name             : desired per dataset feature temporary filenames\n",
    "    <- features, labels : computed features and corresponding labels\n",
    "    \"\"\"\n",
    "    print \"---------------------------------------- FEATURE EXTRACTION ------------------------------------------\"\n",
    "    if os.path.isfile(featfile):\n",
    "        start_time = time.time()\n",
    "        features = np.load(featfile)['features']\n",
    "        labels = np.load(featfile)['labels']\n",
    "        print(\"Features FOUND PRECOMPUTED! Feature Loading DONE in: %s seconds \" % (time.time() - start_time))\n",
    "        if delete_big_features:\n",
    "            for j in glob.glob(allfeatpath+\"*\"):\n",
    "                if 'red' not in j:\n",
    "                    call(['rm',j]) # delete big feature file, after reducing its size to desired\n",
    "    else:\n",
    "        start_time = time.time()\n",
    "        features = []\n",
    "        labels = []\n",
    "        for ixp in range(len(prefeat)):\n",
    "            p = prefeat[ixp]\n",
    "            now = time.time()\n",
    "            tmpfn = tmpfeatfilename(ixp,name)\n",
    "            tmpfnred = tmpfeatfilename(ixp,name,'red')\n",
    "            if not os.path.isfile(tmpfnred):\n",
    "                if not os.path.isfile(tmpfn):\n",
    "                    # Computation of all features in PARALLEL by ALL cores\n",
    "                    tmp = np.array([Parallel(n_jobs=-1)([delayed(feat) (p[k:k+window],*featparam) \n",
    "                                                         for k in range(0,len(p)-window,shift)])])\n",
    "                    with open(tmpfn,'wb') as fo:\n",
    "                        joblib.dump(tmp,fo)\n",
    "                    print 'sample:', ixp, ', time(sec):', '{:.2f}'.format(time.time()-now), tmpfn \\\n",
    "                                                        , ' computing... ', tmp.shape\n",
    "                else:\n",
    "                    with open(tmpfn,'rb') as fo:\n",
    "                        tmp = joblib.load(fo)\n",
    "                    print 'sample:', ixp, ', time(sec):', '{:.2f}'.format(time.time()-now), tmpfn \\\n",
    "                                                        , ' already here!', tmp.shape\n",
    "                # keep less from each feature vector but keep number of samples for each dataset almost equal\n",
    "                tmpskip = int(round(tmp.shape[1]/(member[ixp]*samplesperdataset)))\n",
    "                if tmpskip == 0: \n",
    "                    tmpskip = 1\n",
    "                # Save reduced size features\n",
    "                tmp = tmp[0,::tmpskip,:,:]\n",
    "                with open(tmpfnred,'wb') as fo:\n",
    "                    joblib.dump(tmp,fo)\n",
    "                print 'sample:',ixp, ', time(sec):', '{:.2f}'.format(time.time()-now), tmpfnred, tmp.shape\n",
    "                if delete_big_features:\n",
    "                    call(['rm',tmpfn]) # delete big feature file, after reducing its size to desired\n",
    "        for ixp in range(len(prefeat)):\n",
    "            if delete_big_features:\n",
    "                tmpfn = tmpfeatfilename(ixp,name)\n",
    "                call(['rm',tmpfn]) # delete big feature file if still here for some reason\n",
    "            tmpfnred = tmpfeatfilename(ixp,name,'red')\n",
    "            with open(tmpfnred,'rb') as fo:\n",
    "                tmp = joblib.load(fo)\n",
    "            print 'sample:', ixp, ', time(sec):', '{:.2f}'.format(time.time()-now), tmpfnred, 'already here!' \\\n",
    "                                                                                  , tmp.shape\n",
    "            features.append(tmp[:,:,:-1])\n",
    "            labels.append(tmp[:,0,-1])\n",
    "        print(\"Features NOT FOUND PRECOMPUTED! Feature Computation DONE in: %s sec \" % (time.time() - start_time))\n",
    "        features.append(tmp[:-1,:,:-1])\n",
    "        features = np.array(features)[:-1]\n",
    "        labels.append(tmp[:-1,0,-1])\n",
    "        labels = np.array(labels)[:-1]\n",
    "        print 'features: ',features.shape,[ftmp.shape for ftmp in features]\n",
    "        print 'labels: ', labels.shape,[l.shape for l in labels]\n",
    "        np.savez(featfile,features=features,labels=labels)\n",
    "    print 'features: ', features.shape, ', labels: ', labels.shape\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ LABEL TRIMMING ############\n",
    "def label_cleaning(prefeat,labels,member,history=500):\n",
    "    \"\"\"Keep the purely stable and slip parts of label, thus omitting some samples around sign change points\n",
    "    -> prefeat    : computed prefeatures\n",
    "    -> labels     : main structure, where the trimming will be performed around change points\n",
    "    -> member     : how much each dataset is represented, to skip samples effectively and keep dimensions correct\n",
    "    -> history    : how much samples to throw away around change points\n",
    "    <- new_labels : the trimmed labels\n",
    "    \"\"\"\n",
    "    print \"----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\"\n",
    "    lbl_approx = []\n",
    "    for i in range(len(prefeat)):\n",
    "        tmpd = np.abs(np.diff(prefeat[i][:,-1].astype(int),n=1,axis=0))\n",
    "        if np.sum(tmpd) > 0:\n",
    "            tmpind = np.array(range(len(tmpd)))[tmpd > 0]   # find the sign change points\n",
    "            tmpindrng = []\n",
    "            for j in range(len(tmpind)):\n",
    "                length = history                # keep/throw a portion of the signal's length around change points\n",
    "                tmprng = np.array(range(tmpind[j]-length,tmpind[j]+length))\n",
    "                tmprng = tmprng[tmprng>=0]      # make sure inside singal's x-range\n",
    "                tmprng = tmprng[tmprng<prefeat[i].shape[0]]\n",
    "                tmpindrng += tmprng.tolist()\n",
    "            tmpindrng = np.array(tmpindrng).flatten()\n",
    "            tmp_lbl = deepcopy(prefeat[i][:,-1])\n",
    "            tmp_lbl[tmpindrng] = -1\n",
    "            lbl_approx.append(tmp_lbl)\n",
    "        else:\n",
    "            lbl_approx.append(prefeat[i][:,-1])\n",
    "    new_labels = deepcopy(labels)\n",
    "    for ixp in range(len(lbl_approx)):\n",
    "        p = lbl_approx[ixp]\n",
    "        tmp = np.array([p[k+window] for k in range(0,len(p)-window,shift)])\n",
    "        tmpskip = int(round(tmp.shape[0]/(member[ixp]*samplesperdataset)))\n",
    "        if tmpskip == 0: \n",
    "            tmpskip = 1\n",
    "        # Sampling appropriately\n",
    "        tmp = tmp[::tmpskip]\n",
    "        if len(tmp) > len(labels[ixp]):\n",
    "            tmp = tmp[:-1]\n",
    "        new_labels[ixp] = tmp\n",
    "    print 'new_labels: ', new_labels.shape\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ GATHERING into complete arrays ready for FITTING ############\n",
    "def computeXY(features,labels,new_labels,m1,m2,XYfile=XYfile,XYsplitfile=XYsplitfile):\n",
    "    \"\"\"\n",
    "    -> features       : computed features as input data\n",
    "    -> labels         : corresponding labels\n",
    "    -> new_labels     : labels trimmed around change point\n",
    "    -> m1, m2         : portion of data belonging to finger1 and finger2\n",
    "    -> XY[split]file  : desired output filenames\n",
    "    <- X,Y,Yn,Xsp,Ysp : X corresponds to the data, Y the label, and *sp to the trimmed label's versions\n",
    "    \"\"\"\n",
    "    print \"----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\"\n",
    "    if os.path.isfile(XYfile) and os.path.isfile(XYsplitfile):\n",
    "        X = np.load(XYfile)['X']\n",
    "        Y = np.load(XYfile)['Y']\n",
    "        Yn = np.load(XYfile)['Yn']\n",
    "        Xsp = np.load(XYsplitfile)['X']\n",
    "        Ysp = np.load(XYsplitfile)['Y']\n",
    "        print(\"XY files FOUND PRECOMPUTED!\")\n",
    "    else:\n",
    "        # gathering features X,Xsp and labels Y,Ysp,Yn into one array each\n",
    "        ind,X,Xsp,Y,Ysp,Yn = {},{},{},{},{},{}\n",
    "        ind[2] = range(features.shape[0])                                      # indeces for both fingers\n",
    "        ind[0] = range(features.shape[0])[:m1]                                 # indeces for finger1\n",
    "        ind[1] = range(features.shape[0])[-m2:]                                # indeces for finger2\n",
    "        ind = np.array([i for _,i in ind.items()])                             # convert to array\n",
    "        for k in range(len(ind)):\n",
    "            X[k] = features[ind[k]]                                            # input feature matrix\n",
    "            Y[k] = labels[ind[k]]                                              # output label vector\n",
    "            Yn[k] = new_labels[ind[k]]                                         # output new_label vector\n",
    "            print 'Before -> X[',k,']: ',X[k].shape,', Y[',k,']: ',Y[k].shape,', Yn[',k,']: ',Yn[k].shape\n",
    "            X[k] = np.concatenate(X[k],axis=0)\n",
    "            Y[k] = np.concatenate(Y[k],axis=0)\n",
    "            Yn[k] = np.concatenate(Yn[k],axis=0)\n",
    "            print 'Gathered -> X[',k,']: ',X[k].shape,', Y[',k,']: ',Y[k].shape,', Yn[',k,']: ',Yn[k].shape\n",
    "            X[k] = np.array([X[k][:,:,i] for i in range(X[k].shape[2])])\n",
    "            tmp_sampling = int(round(X[k].shape[1]*1./samplesperdataset))\n",
    "            if tmp_sampling == 0:\n",
    "                tmp_sampling = 1\n",
    "            X[k] = X[k][0,::tmp_sampling,:]\n",
    "            Y[k] = Y[k][::tmp_sampling]\n",
    "            Yn[k] = Yn[k][::tmp_sampling]\n",
    "            print 'Gathered, sampled to max ', samplesperdataset, ' -> X[', k,']: ', X[k].shape, ', Y[', k \\\n",
    "                                             , ']: ', Y[k].shape, ', Yn[', k,']: ', Yn[k].shape\n",
    "            keepind = Yn[k]>=0\n",
    "            Xsp[k] = X[k][keepind,:]\n",
    "            Ysp[k] = Yn[k][keepind]\n",
    "            print 'Split -> Xsp[',k,']: ',Xsp[k].shape,', Ysp[',k,']: ',Ysp[k].shape\n",
    "        X = np.array([i for _,i in X.items()])\n",
    "        Xsp = np.array([i for _,i in Xsp.items()])\n",
    "        Y = np.array([i for _,i in Y.items()])\n",
    "        Ysp = np.array([i for _,i in Ysp.items()])\n",
    "        Yn = np.array([i for _,i in Yn.items()])\n",
    "        np.savez(XYfile,X=X,Y=Y,Yn=Yn)\n",
    "        np.savez(XYsplitfile, X=Xsp, Y=Ysp)\n",
    "    print 'X,Y [0,1,2]: ', X[0].shape, Y[0].shape, X[1].shape, Y[1].shape, X[2].shape, Y[2].shape\n",
    "    print 'Xsp,Ysp [0,1,2]: ', Xsp[0].shape, Ysp[0].shape, Xsp[1].shape, Ysp[1].shape, Xsp[2].shape, Ysp[2].shape\n",
    "    return X,Y,Yn,Xsp,Ysp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Prepare the indeces for each feature ############\n",
    "def get_feat_id(feat_ind, printit=0, sample_window=window): \n",
    "    \"\"\"Find the corresponding indeces of the desired features inside feature vector,\n",
    "    and link them with their names and level of abstraction\n",
    "    -> feat_ind        : range of indeces\n",
    "    -> printit         : print output indeces (1) or not (0)\n",
    "    -> sample_window   : parameter for accurate computation of feature indeces\n",
    "    <- full_path_id    : indeces of all features\n",
    "    <- norm_time_feats : indeces of time features\n",
    "    <- norm_freq_feats : indeces of frequency features\n",
    "    \"\"\"\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "    norm_time_phin = range(0,14)\n",
    "    norm_freq_phin = range(norm_time_phin[-1] + 1, norm_time_phin[-1] + 9 + sample_window + 1)\n",
    "    norm_time_golz = range(norm_freq_phin[-1] + 1, norm_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    norm_freq_golz = range(norm_time_golz[-1] + 1, norm_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    norm_time_feats = norm_time_phin + norm_time_golz\n",
    "    norm_freq_feats = norm_freq_phin + norm_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    norm_feats = norm_time_feats + norm_freq_feats\n",
    "\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "    disp = norm_feats[-1]+1\n",
    "    ftfn_time_phin = range(disp ,disp + 14)\n",
    "    ftfn_freq_phin = range(ftfn_time_phin[-1] + 1, ftfn_time_phin[-1] + 9 + sample_window + 1)\n",
    "    ftfn_time_golz = range(ftfn_freq_phin[-1] + 1, ftfn_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    ftfn_freq_golz = range(ftfn_time_golz[-1] + 1, ftfn_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    ftfn_time_feats = ftfn_time_phin + ftfn_time_golz\n",
    "    ftfn_freq_feats = ftfn_freq_phin + ftfn_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    ftfn_feats = ftfn_time_feats + ftfn_freq_feats\n",
    "\n",
    "    # create the final \"reference dictionary\"\n",
    "    # 3 np.arrays, id_list[0] = level 1 etc\n",
    "    id_list = [np.zeros((len(ftfn_feats + norm_feats),1)) for i in range(3)]\n",
    "    id_list[0][:norm_feats[-1]+1] = 0 # 0 signifies norm / 1 signifies ft/fn\n",
    "    id_list[0][norm_feats[-1]+1:] = 1\n",
    "\n",
    "    id_list[1][:norm_time_phin[-1]+1] = 0 # 0 signifies time / 1 signifies freq\n",
    "    id_list[1][norm_time_phin[-1]+1:norm_freq_phin[-1]+1] = 1\n",
    "    id_list[1][norm_freq_phin[-1]+1:norm_time_golz[-1]+1] = 0\n",
    "    id_list[1][norm_time_golz[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[1][norm_freq_golz[-1]+1:ftfn_time_phin[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_phin[-1]+1:ftfn_freq_phin[-1]+1] = 1\n",
    "    id_list[1][ftfn_freq_phin[-1]+1:ftfn_time_golz[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_golz[-1]+1:] = 1\n",
    "\n",
    "    id_list[2][:norm_freq_phin[-1]+1] = 0 #0 signifies phinyomark / 1 signifies golz\n",
    "    id_list[2][norm_freq_phin[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[2][norm_freq_golz[-1]+1:ftfn_freq_phin[-1]+1] = 0\n",
    "    id_list[2][ftfn_freq_phin[-1]+1:] = 1 \n",
    "    \n",
    "    full_path_id = [np.zeros((len(feat_ind),5)) for i in range(len(feat_ind))]\n",
    "   \n",
    "    for ind, val in enumerate(feat_ind):\n",
    "        full_path_id[ind] = [val, id_list[2][val], id_list[1][val], id_list[0][val]]\n",
    "        if (printit==1):\n",
    "            if(full_path_id[ind][1]==0):\n",
    "                lvl3 = 'Phin'\n",
    "            else:\n",
    "                lvl3 = 'Golz'\n",
    "            if(full_path_id[ind][2]==0):\n",
    "                lvl2 = 'Time'\n",
    "            else:\n",
    "                lvl2 = 'Freq'\n",
    "            if(full_path_id[ind][3]==0):\n",
    "                lvl1 = 'Norm'\n",
    "            else:\n",
    "                lvl1 = 'Ft/Fn'\n",
    "            print(feat_ind[ind],featnames[val%(norm_feats[-1]+1)],lvl3,lvl2,lvl1)\n",
    "    \n",
    "    return(full_path_id,norm_time_feats,norm_freq_feats)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Surface Splitting ############\n",
    "def surface_split(data_X, data_Y, n=6, k=2):\n",
    "    \"\"\"Split input data in k*n equal slices which represent n different surfaces sampled from k fingers.\n",
    "    Indexes 0:n:(k-1)*n, 1:n:(k-1)*n+1, 2:n:(k-1)*n+2, ... correspond to the same surface (finger1 upto fingerk)\n",
    "    Assuming k=2, namely 2 fingers case, unless stated differently\n",
    "    -> data_X, data_Y        : input data and labels, with the convention that data_X contains k*n almost \n",
    "                               equally sized data, where the n first are acquired from finger1 ... \n",
    "                               and the n last from fingerk. \n",
    "    -> n                     : number of different surfaces\n",
    "    -> k                     : number of fingers logging data\n",
    "    <- surfaces, surf_labels : corresponding output data and labels\n",
    "    \"\"\"\n",
    "    keep = data_X.shape[0]-np.mod(data_X.shape[0],k*n)\n",
    "    surfaces_pre = np.array(np.split(data_X[:keep,:],k*n))\n",
    "    surf_labels_pre = np.array(np.split(data_Y[:keep],k*n))\n",
    "    surfaces, surf_labels = {},{}\n",
    "    for i in range(n):\n",
    "        inds = range(i,k*n,n)\n",
    "        surfaces[inds[0]] = np.concatenate((surfaces_pre[inds[0]], surfaces_pre[inds[1]]), axis = 0)\n",
    "        surf_labels[inds[0]] = np.concatenate((surf_labels_pre[inds[0]], surf_labels_pre[inds[1]]), axis = 0)\n",
    "    surfaces = np.array([i for _,i in surfaces.items()])\n",
    "    surf_labels = np.array([i for _,i in surf_labels.items()])\n",
    "    return surfaces, surf_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Featureset Splitting ############\n",
    "subfeats = ['AFFT','FREQ','TIME','BOTH']\n",
    "def feat_subsets(data,fs_ind,ofs=len(featnames)):\n",
    "    \"\"\"returns a splitting per featureset of input features\n",
    "    -> data                                : input data X\n",
    "    -> fs_ind                              : prefeature id\n",
    "    -> ofs                                 : number of features in total\n",
    "    <- X_amfft, X_freq_all, X_time, X_both : split featuresets amplitude of FFT, all time only,\n",
    "                                                               all frequency only and all features\n",
    "    \"\"\"\n",
    "    _,tf,ff = get_feat_id(range(ofs))\n",
    "    amfft_inds = []\n",
    "    temp1 = deepcopy(data)\n",
    "    \n",
    "    for i in range(len(featnames)):\n",
    "        if (featnames[i].startswith('amFFT')):\n",
    "            amfft_inds.append(i)\n",
    "\n",
    "    if (fs_ind == 2):\n",
    "        ff2 = [ff[i]+ofs for i in range(len(ff))]\n",
    "        tf2 = [tf[i]+ofs for i in range(len(tf))]\n",
    "        amfft2 = [amfft_inds[i]+ofs for i in range(len(amfft_inds))]\n",
    "        freqf = ff2 + ff\n",
    "        timef = tf2 + tf\n",
    "        amfft = amfft_inds + amfft2\n",
    "    else:\n",
    "        freqf = ff\n",
    "        timef = tf\n",
    "        amfft = amfft_inds\n",
    "\n",
    "    X_amfft = temp1[:,amfft]\n",
    "    X_time = np.delete(temp1,freqf,axis=1)\n",
    "    X_freq_all = np.delete(temp1,timef,axis=1)\n",
    "    X_both = data\n",
    "    return X_amfft, X_freq_all, X_time, X_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Prepare the dataset split for each surface ############\n",
    "def computeXY_persurf(Xsp,Ysp,surffile=surffile):\n",
    "    \"\"\"returns a split per surface data and label of inputs\n",
    "    -> Xsp, Ysp     : input data and labels, after having trimmed data around the label's change points\n",
    "    -> surffile     : desired output's filename for saving\n",
    "    <- surf, surfla : output data and label, split per surface\n",
    "    \"\"\"\n",
    "    print \"------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\"\n",
    "    if os.path.isfile(surffile):\n",
    "        surf = np.load(surffile)['surf']       # input array containing computed features for each surface\n",
    "        surfla = np.load(surffile)['surfla']   # corresponding label\n",
    "    else:\n",
    "        surf, surfla = [], []\n",
    "        for i in range(len(prefeatid)-1): # for each featureset (corresponding to each prefeature, here only |f|)\n",
    "            surf1, surfla1 = surface_split(Xsp[2], Ysp[2])\n",
    "            tmpsurf = deepcopy(surf1)\n",
    "            tmpsurfla = deepcopy(surfla1)\n",
    "            tmpsurfsubfeat = []\n",
    "            for j in range(tmpsurf.shape[0]+1): # for each surface\n",
    "                print i,j,surf1.shape\n",
    "                if j == tmpsurf.shape[0]:\n",
    "                    # ommit a sample for converting to array\n",
    "                    tmpsurfsubfeat.append(feat_subsets(tmpsurf[j-1,:-1,:],i))\n",
    "                else:\n",
    "                    # keep all subfeaturesets\n",
    "                    tmpsurfsubfeat.append(feat_subsets(tmpsurf[j],i))\n",
    "            surf.append(tmpsurfsubfeat)\n",
    "            surfla.append(surfla1)\n",
    "        # surf dims: (featuresets, surfaces, prefeaturesets) with each one enclosing (samples, features)\n",
    "        surf = np.array(surf).transpose()[:,:-1,:]\n",
    "        # surfla dims: (samples, surfaces, prefeaturesets)\n",
    "        surfla = np.array(surfla).transpose()\n",
    "        np.savez(surffile,surf=surf,surfla=surfla)\n",
    "    print surf.shape, surfla.shape\n",
    "    return surf, surfla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ PIPELINE OF TRANSFORMATIONS ############\n",
    "def make_pipe_clf(scaler,feature_selection,decomp,clf):\n",
    "    \"\"\"returns a pipeline of inputs: \n",
    "    -> scaler            : first normalize\n",
    "    -> feature_selection : then perform feature selection\n",
    "    -> decomp            : followed by PCA \n",
    "    -> clf               : and finally the desired classifier\n",
    "    <- pipeline          : output pipeline\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline([('scaler', scaler),\n",
    "                         ('feature_selection', feature_selection),\n",
    "                         ('decomp', decomp),         \n",
    "                         ('classifier', clf) ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comb(n,r):\n",
    "    \"\"\"Combinations of n objects by r, namely picking r among n possible.\n",
    "    comb(n,r) = n!/(r!(n-r)!)\n",
    "    \"\"\"\n",
    "    return math.factorial(n)/(math.factorial(r)*math.factorial(n-r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ TRAINING with 1 surface each time, out of 6 surfaces in total ##############\n",
    "def filename1(i,j,k,l,retpath=0):\n",
    "    \"\"\"function for the filename of the selected combination for training per 1 surface\n",
    "    -> i : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> k : surface id trained on\n",
    "    -> l : surface id tested on\n",
    "    <- filename\n",
    "    \"\"\"\n",
    "    filepath = respath+'1/'\n",
    "    ensure_dir(filepath)\n",
    "    if retpath:\n",
    "        return filepath\n",
    "    else:\n",
    "        return filepath+'fs_'+str(i)+'_subfs_'+str(j)+'_tr_'+str(k)+'_ts_'+str(l)+'.npz'\n",
    "\n",
    "def cross_fit1(i,j,k,kmax,l,data,labels,data2,labels2,pipe):\n",
    "    \"\"\"function for fitting model per 1 surface\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> k              : surface id trained on\n",
    "    -> kmax           : maximum surfaces\n",
    "    -> l              : surface id tested on\n",
    "    -> data, labels   : training data and labels\n",
    "    -> data2, labels2 : testing data and labels\n",
    "    -> pipe           : the desired pipeline configuration\n",
    "    <- no output, saved model and confusion matrix in corresponding filename.npz\n",
    "    \"\"\"\n",
    "    fileid = filename1(i,j,k,l)\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k,l\n",
    "        if k==l: # perform K-fold cross-validation       \n",
    "            folds = cv.split(data, labels)\n",
    "            cm_all = np.zeros((2,2))\n",
    "            for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                x_train, x_test = data[train_ind], data[test_ind]\n",
    "                y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                model = pipe.fit(x_train,y_train)\n",
    "                y_pred = model.predict(x_test)\n",
    "                cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                cm_all += cm/5.\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            # Check if model already existent, but not the cross-validated one (on the same surface)\n",
    "            model = []\n",
    "            for m in range(kmax):\n",
    "                tmpcopyfileid = filepath+filename1(i,j,k,m)+'.npz'\n",
    "                if k!=m and os.path.isfile(tmpcopyfileid):\n",
    "                    print 'Found precomputed model of '+str(k)+', tested on '+str(m)+'. Testing on '+str(l)+'...'\n",
    "                    model = np.load(tmpcopyfileid)['model'][0]\n",
    "                    break\n",
    "            if model==[]: # model not found precomputed\n",
    "                print 'Fitting on '+str(k)+', testing on '+str(l)+'...'\n",
    "                model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps1(i,j,jmax,surf,surfla):\n",
    "    \"\"\"function for helping parallelization of computations per 1 surface\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> jmax           : number of all subfeaturesets\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    \"\"\"\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k in range(surf.shape[0]): # for every training surface\n",
    "        for l in range(surf.shape[0]): # for every testing surface\n",
    "            cross_fit1(i,j,k,surf.shape[0],l,surf[k],surfla[:,k],surf[l],surfla[:,l],pipe)\n",
    "\n",
    "def train_1_surface(surf,surfla,n=-1):\n",
    "    \"\"\"Parallel training -on surface level- of all combinations on 1 surface\n",
    "    -> n              : number of cores to run in parallel, \n",
    "                        input of joblib's Parallel (n=-1 means all available cores)\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    *** Cross surface validation, TRAINING with 1 surface each time, out of 6 surfaces in total\n",
    "    total= 4 (featuresets) * [comb(6,1)*6] (surface combinations: trained on 1, tested on 1) * 1 (prefeatureset)\n",
    "         = 4*6*6*1 = 144 different runs-files.\n",
    "    Note that comb(n,r) = n!/(r!(n-r)!)\n",
    "    \"\"\"\n",
    "    print \"-------------------------- TRAINING all combinations per 1 surface -----------------------------------\"\n",
    "    for i in range(len(prefeatid)-1):\n",
    "        _ = [Parallel(n_jobs=n)([delayed(init_steps1) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) \n",
    "                                  for j in range(surf.shape[0])])]\n",
    "        \n",
    "def bargraph_perf_gen1(maxsurf):\n",
    "    \"\"\"Perf file for bargraph generation using bargraph tool, for 1 surface\"\"\"\n",
    "    print \"---------------------------- Generating perf files for 1 surface -------------------------------------\"\n",
    "    prefeats = prefeatnames[prefeatid][:-1]\n",
    "    # prefeatures, subfeatures, trained, tested, (TP,TN,FN,FP)\n",
    "    acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,4))\n",
    "    # prefeatures, subfeatures, trained, cross_val_self_accuracy, (TP,TN,FN,FP)\n",
    "    self_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,1,4))\n",
    "    # features, subfeatures, trained, (tested avg, tested std), (TP,TN,FN,FP)\n",
    "    cross_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,2,4))    \n",
    "    initial_str = \"\"\"# clustered and stacked graph data\n",
    "=stackcluster;TP;TN;FN;FP\n",
    "colors=med_blue,dark_green,yellow,red\n",
    "=nogridy\n",
    "=noupperright\n",
    "fontsz=5\n",
    "legendx=right\n",
    "legendy=center\n",
    "datascale=50\n",
    "yformat=%g%%\n",
    "xlabel=TrainedON-TestedON\n",
    "ylabel=Metrics\n",
    "=table\"\"\"\n",
    "    respath = filename1(_,_,_,_,1)\n",
    "    for i in range(len(prefeats)):\n",
    "        outname = respath+prefeats[i]\n",
    "        outfile = outname+'.perf'\n",
    "        outfile1 = outname+'_selfaccuracy.perf'\n",
    "        outfile2 = outname+'_crossaccuracy.perf'\n",
    "        out = open(outfile,'w+')\n",
    "        out.write(initial_str+\"\\n\")\n",
    "        out1 = open(outfile1,'w+')\n",
    "        out1.write(initial_str+\"\\n\")\n",
    "        out2 = open(outfile2,'w+')\n",
    "        out2.write(initial_str+\"\\n\")\n",
    "        for k in range(maxsurf):\n",
    "            for k2 in range(maxsurf):\n",
    "                out.write(\"multimulti=\"+str(k)+\"-\"+str(k2)+\"\\n\")\n",
    "                for j in range(len(subfeats)):\n",
    "                    fileid = filename1(i,j,k,k2)\n",
    "                    tmp = np.load(fileid)['cm']\n",
    "                    # print to outfile\n",
    "                    acc[i,j,k,k2,0] = round(tmp[1,1],2) # TP\n",
    "                    acc[i,j,k,k2,1] = round(tmp[0,0],2) # TN\n",
    "                    acc[i,j,k,k2,2] = 1-round(tmp[1,1],2) # FN\n",
    "                    acc[i,j,k,k2,3] = 1-round(tmp[0,0],2) # FP\n",
    "                    out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],acc[i,j,k,k2,0],acc[i,j,k,k2,1],\n",
    "                                                                        acc[i,j,k,k2,2],acc[i,j,k,k2,3]))\n",
    "                    # prepare and print to outfile1\n",
    "                    if k == k2:\n",
    "                        if j == 0:\n",
    "                            out1.write(\"multimulti=\"+str(k)+\"-\"+str(k2)+\"\\n\")\n",
    "                        self_acc[i,j,k,0,:] = acc[i,j,k,k2,:]\n",
    "                        out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],self_acc[i,j,k,0,0],\n",
    "                                                                 self_acc[i,j,k,0,1],self_acc[i,j,k,0,2],\n",
    "                                                                 self_acc[i,j,k,0,3]))\n",
    "                    # prepare and print to outfile2\n",
    "                    if k != k2:\n",
    "                        # all values of corresponding subfeatureset j have been filled to compute avg and std\n",
    "                        if (k < maxsurf-1 and k2 == maxsurf-1) or (k == maxsurf-1 and k2 == maxsurf-2):\n",
    "                            if j == 0:\n",
    "                                out2.write(\"multimulti=\"+str(k)+\"\\n\")\n",
    "                            t = range(maxsurf)\n",
    "                            t.remove(k)\n",
    "                            cross_acc[i,j,k,0,:] = np.mean(acc[i,j,k,t,:], axis=0) # avg\n",
    "                            # cross_acc[i,j,k,1,:] = np.std(acc[i,j,k,t,:], axis=0) # std\n",
    "                            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j], cross_acc[i,j,k,0,0],\n",
    "                                                                     cross_acc[i,j,k,0,1], cross_acc[i,j,k,0,2],\n",
    "                                                                     cross_acc[i,j,k,0,3]))\n",
    "        out.write(\"multimulti=AVG\\n\")\n",
    "        out1.write(\"multimulti=AVG\\n\")\n",
    "        out2.write(\"multimulti=AVG\\n\")\n",
    "        for j in range(4):\n",
    "            avgacc = np.mean(np.mean(acc[i,j,:,:,:], axis=0), axis=0)\n",
    "            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j], avgacc[0], avgacc[1], avgacc[2], avgacc[3]))\n",
    "            avgselfacc = np.mean(self_acc[i,j,:,0,:], axis=0)\n",
    "            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j], avgselfacc[0], avgselfacc[1],\n",
    "                                                                  avgselfacc[2], avgselfacc[3]))\n",
    "            avgcrossacc0 = np.mean(cross_acc[i,j,:,0,:], axis=0)\n",
    "            # avgcrossacc1 = np.std(cross_acc[i,j,:,0,:], axis=0)\n",
    "            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j], avgcrossacc0[0], avgcrossacc0[1],\n",
    "                                                                  avgcrossacc0[2], avgcrossacc0[3]))\n",
    "        out.close()\n",
    "        out1.close()\n",
    "        out2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ TRAINING with 2 surfaces each time, out of 6 surfaces in total ##############\n",
    "def filename2(i,j,k1,k2,l,retpath=0):\n",
    "    \"\"\"function for the filename of the selected combination for training per 2 surfaces\n",
    "    -> i  : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j  : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki : surface ids trained on\n",
    "    -> l  : surface id tested on\n",
    "    <- filename\n",
    "    \"\"\"\n",
    "    filepath = respath+'2/'\n",
    "    ensure_dir(filepath)\n",
    "    if retpath:\n",
    "        return filepath\n",
    "    else:\n",
    "        return filepath+'fs_'+str(i)+'_subfs_'+str(j)+'_tr1_'+str(k1)+'_tr2_'+str(k2)+'_ts_'+str(l)+'.npz'\n",
    "\n",
    "def cross_fit2(i,j,k1,k2,kmax,l,data,labels,data2,labels2,pipe):\n",
    "    \"\"\"function for fitting model per 2 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki             : surface ids trained on\n",
    "    -> kmax           : maximum surfaces\n",
    "    -> l              : surface id tested on\n",
    "    -> data, labels   : training data and labels\n",
    "    -> data2, labels2 : testing data and labels\n",
    "    -> pipe           : the desired pipeline configuration\n",
    "    <- no output, saved model and confusion matrix in corresponding filename.npz\n",
    "    \"\"\"\n",
    "    fileid = filename2(i,j,k1,k2,l)\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k1,k2,l\n",
    "        if k1==l or k2==l: # perform K-fold      \n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+', cross-validating on '+str(l)+'...'\n",
    "            if l == k1: # copy if existent from the other sibling file\n",
    "                tmpcopyfileid = filepath+filename2(i,j,k1,k2,k2)+'.npz'\n",
    "            else:   # same as above\n",
    "                tmpcopyfileid = filepath+filename2(i,j,k1,k2,k1)+'.npz'                \n",
    "            if not os.path.isfile(tmpcopyfileid):\n",
    "                folds = cv.split(data, labels)\n",
    "                cm_all = np.zeros((2,2))\n",
    "                for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                    x_train, x_test = data[train_ind], data[test_ind]\n",
    "                    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                    model = pipe.fit(x_train,y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                    cm_all += cm/5.\n",
    "            else:\n",
    "                cm_all = np.load(tmpcopyfileid)['cm']\n",
    "                model = np.load(tmpcopyfileid)['model'][0]\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            model = []\n",
    "            for m in range(kmax):\n",
    "                tmpcopyfileid = filepath+filename2(i,j,k1,k2,m)+'.npz'\n",
    "                if k1!=m and k2!=m and os.path.isfile(tmpcopyfileid):\n",
    "                    print 'Found precomputed model of '+str(k1)+str(k2)+', tested on '+str(m) \\\n",
    "                                                                       +'. Testing on '+str(l)+'...'\n",
    "                    model = np.load(tmpcopyfileid)['model'][0]\n",
    "                    break\n",
    "            if model==[]: # model not found precomputed\n",
    "                print 'Fitting on '+str(k1)+\"-\"+str(k2)+', testing on '+str(l)+'...'\n",
    "                model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps2(i,j,jmax,surf,surfla):\n",
    "    \"\"\"function for helping parallelization of computations per 2 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> jmax           : number of all subfeaturesets\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    \"\"\"\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k1 in range(surf.shape[0]): # for every training surface1\n",
    "        for k2 in range(surf.shape[0]): # for every training surface2\n",
    "            if k2 > k1:\n",
    "                for l in range(surf.shape[0]): # for every testing surface\n",
    "                    tr_surf = np.concatenate((surf[k1],surf[k2]),axis=0)\n",
    "                    tr_surfla = np.concatenate((surfla[:,k1],surfla[:,k2]),axis=0)\n",
    "                    ts_surf, ts_surfla = surf[l], surfla[:,l]\n",
    "                    cross_fit2(i,j,k1,k2,surf.shape[0],l,tr_surf,tr_surfla,ts_surf,ts_surfla,pipe)\n",
    "\n",
    "def train_2_surface(surf,surfla,n=-1):\n",
    "    \"\"\"Parallel training -on surface level- of all combinations on 2 surfaces\n",
    "    -> n              : number of cores to run in parallel, \n",
    "                        input of joblib's Parallel (n=-1 means all available cores)\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    *** Cross surface validation, TRAINING with 2 surfaces each time, out of 6 surfaces in total\n",
    "    total= 4 (featuresets) * [comb(6,2)*6] (surface combinations: trained on 2, tested on 1) * 1 (prefeatureset)\n",
    "         = 4*15*6*1 = 360 different runs-files.\n",
    "    Note that comb(n,r) = n!/(r!(n-r)!)\n",
    "    \"\"\"\n",
    "    print \"-------------------------- TRAINING all combinations per 2 surfaces ----------------------------------\"    \n",
    "    for i in range(len(prefeatid)-1):\n",
    "        _ = [Parallel(n_jobs=n)([delayed(init_steps2) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) \n",
    "                                 for j in range(surf.shape[0])])]\n",
    "\n",
    "def bargraph_perf_gen2(maxsurf):\n",
    "    \"\"\"Perf file for bargraph generation using bargraph tool, for 2 surfaces\"\"\"\n",
    "    print \"---------------------------- Generating perf files for 2 surfaces ------------------------------------\"\n",
    "    prefeats = prefeatnames[prefeatid][:-1]\n",
    "    # prefeatures, subfeatures, trained, tested, (TP,TN,FN,FP)\n",
    "    acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all tested surfaces\n",
    "    avg = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # prefeatures, subfeatures, trained, cross_val_self_accuracy, (TP,TN,FN,FP)\n",
    "    self_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,1,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all self tested surfaces\n",
    "    avgs = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # features, subfeatures, trained, (tested avg, tested std), (TP,TN,FN,FP)\n",
    "    cross_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,2,4))\n",
    "     # features, subfeatures, (TP,TN,FN,FP) -> avg over all cross tested surfaces\n",
    "    avgc = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    initial_str = \"\"\"# clustered and stacked graph bogus data\n",
    "=stackcluster;TP;TN;FN;FP\n",
    "colors=med_blue,dark_green,yellow,red\n",
    "=nogridy\n",
    "=noupperright\n",
    "fontsz=5\n",
    "legendx=right\n",
    "legendy=center\n",
    "datascale=50\n",
    "yformat=%g%%\n",
    "xlabel=TrainedON-TestedON\n",
    "ylabel=Metrics\n",
    "=table\"\"\"\n",
    "    respath = filename2(_,_,_,_,_,1)\n",
    "    for i in range(len(prefeats)):\n",
    "        outname = respath+prefeats[i]\n",
    "        outfile = outname+'.perf'\n",
    "        outfile1 = outname+'_selfaccuracy.perf'\n",
    "        outfile2 = outname+'_crossaccuracy.perf'\n",
    "        out = open(outfile,'w+')\n",
    "        out.write(initial_str+\"\\n\")\n",
    "        out1 = open(outfile1,'w+')\n",
    "        out1.write(initial_str+\"\\n\")\n",
    "        out2 = open(outfile2,'w+')\n",
    "        out2.write(initial_str+\"\\n\")\n",
    "        for k1 in range(maxsurf):\n",
    "            for k2 in range(maxsurf):\n",
    "                if k2 > k1:\n",
    "                    for l in range(maxsurf):\n",
    "                        out.write(\"multimulti=\"+str(k1)+str(k2)+\"-\"+str(l)+\"\\n\")\n",
    "                        for j in range(len(subfeats)):\n",
    "                            fileid = filename2(i,j,k1,k2,l)\n",
    "                            tmp = np.load(fileid)['cm']\n",
    "                            acc[i,j,k1,k2,l,0] = round(tmp[1,1],2) # TP\n",
    "                            acc[i,j,k1,k2,l,1] = round(tmp[0,0],2) # TN\n",
    "                            acc[i,j,k1,k2,l,2] = 1-round(tmp[1,1],2) # FN\n",
    "                            acc[i,j,k1,k2,l,3] = 1-round(tmp[0,0],2) # FP\n",
    "                            avg[i,j,:] += acc[i,j,k1,k2,l,:]\n",
    "                            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],acc[i,j,k1,k2,l,0],\n",
    "                                                                    acc[i,j,k1,k2,l,1],acc[i,j,k1,k2,l,2],\n",
    "                                                                    acc[i,j,k1,k2,l,3]))\n",
    "                            if l == k1 or l == k2: # selc accuracy\n",
    "                                if j == 0 and l == k2:\n",
    "                                    out1.write(\"multimulti=\"+str(k1)+str(k2)+\"-\"+str(l)+\"\\n\")\n",
    "                                self_acc[i,j,k1,k2,0,:] = acc[i,j,k1,k2,l]\n",
    "                                avgs[i,j,:] += self_acc[i,j,k1,k2,0,:]\n",
    "                                if l == k2:\n",
    "                                    out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],\n",
    "                                                                             self_acc[i,j,k1,k2,0,0],\n",
    "                                                                             self_acc[i,j,k1,k2,0,1],\n",
    "                                                                             self_acc[i,j,k1,k2,0,2],\n",
    "                                                                             self_acc[i,j,k1,k2,0,3]))\n",
    "                            if l != k1 and l != k2:\n",
    "                                t = range(maxsurf)\n",
    "                                t.remove(k1)\n",
    "                                t.remove(k2)\n",
    "                                if (l == t[-1]):\n",
    "                                    if j == 0:\n",
    "                                        out2.write(\"multimulti=\"+str(k1)+str(k2)+\"\\n\")\n",
    "                                    cross_acc[i,j,k1,k2,0,:] = np.mean(acc[i,j,k1,k2,t,:], axis=0) # avg\n",
    "                                    # cross_acc[i,j,k1,k2,1,:] = np.std(acc[i,j,k1,k2,t,:], axis=0) # std\n",
    "                                    avgc[i,j,:] += cross_acc[i,j,k1,k2,0,:]\n",
    "                                    out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],\n",
    "                                                                             cross_acc[i,j,k1,k2,0,0],\n",
    "                                                                             cross_acc[i,j,k1,k2,0,1],\n",
    "                                                                             cross_acc[i,j,k1,k2,0,2],\n",
    "                                                                             cross_acc[i,j,k1,k2,0,3]))\n",
    "        out.write(\"multimulti=AVG\\n\")\n",
    "        out1.write(\"multimulti=AVG\\n\")\n",
    "        out2.write(\"multimulti=AVG\\n\")\n",
    "        avg /= comb(maxsurf,2)*maxsurf*1.\n",
    "        avgs /= comb(maxsurf,2)*2.\n",
    "        avgc /= comb(maxsurf,2)*1.\n",
    "        for j in range(len(subfeats)):\n",
    "            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avg[i,j,0],avg[i,j,1],avg[i,j,2],avg[i,j,3]))\n",
    "            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgs[i,j,0],avgs[i,j,1],avgs[i,j,2],avgs[i,j,3]))\n",
    "            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgc[i,j,0],avgc[i,j,1],avgc[i,j,2],avgc[i,j,3]))\n",
    "        out.close()\n",
    "        out1.close()\n",
    "        out2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ TRAINING with 3 surfaces each time, out of 6 surfaces in total ##############\n",
    "def filename3(i,j,k1,k2,k3,l,retpath=0):\n",
    "    \"\"\"function for the filename of the selected combination for training per 3 surfaces\n",
    "    -> i  : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j  : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki : surface ids trained on\n",
    "    -> l  : surface id tested on\n",
    "    <- filename\n",
    "    \"\"\"\n",
    "    filepath = respath+'3/'\n",
    "    ensure_dir(filepath)\n",
    "    if retpath:\n",
    "        return filepath\n",
    "    else:\n",
    "        return filepath+'fs_'+str(i)+'_subfs_'+str(j)+'_tr1_'+str(k1)+'_tr2_'+str(k2)+'_tr3_'+str(k3)\\\n",
    "                                                                  +'_ts_'+str(l)+'.npz'\n",
    "\n",
    "def cross_fit3(i,j,k1,k2,k3,kmax,l,data,labels,data2,labels2,pipe):\n",
    "    \"\"\"function for fitting model per 3 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki             : surface ids trained on\n",
    "    -> kmax           : maximum surfaces\n",
    "    -> l              : surface id tested on\n",
    "    -> data, labels   : training data and labels\n",
    "    -> data2, labels2 : testing data and labels\n",
    "    -> pipe           : the desired pipeline configuration\n",
    "    <- no output, saved model and confusion matrix in corresponding filename.npz\n",
    "    \"\"\"\n",
    "    fileid = filename3(i,j,k1,k2,k3,l)\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k1,k2,k3,l\n",
    "        if k1==l or k2==l or k3==l: # perform K-fold      \n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+', cross-validating on '+str(l)+'...'\n",
    "            if l == k1: # copy if existent from the other sibling file\n",
    "                tmpcopyfileid1 = filepath+filename3(i,j,k1,k2,k3,k2)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename3(i,j,k1,k2,k3,k3)+'.npz'\n",
    "            elif l == k2:   # same as above\n",
    "                tmpcopyfileid1 = filepath+filename3(i,j,k1,k2,k3,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename3(i,j,k1,k2,k3,k3)+'.npz'\n",
    "            else:\n",
    "                tmpcopyfileid1 = filepath+filename3(i,j,k1,k2,k3,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename3(i,j,k1,k2,k3,k2)+'.npz'\n",
    "            if not os.path.isfile(tmpcopyfileid1) and not os.path.isfile(tmpcopyfileid2):\n",
    "                folds = cv.split(data, labels)\n",
    "                cm_all = np.zeros((2,2))\n",
    "                for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                    x_train, x_test = data[train_ind], data[test_ind]\n",
    "                    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                    model = pipe.fit(x_train,y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                    cm_all += cm/5.\n",
    "            else:\n",
    "                if os.path.isfile(tmpcopyfileid1):\n",
    "                    cm_all = np.load(tmpcopyfileid1)['cm']\n",
    "                    model = np.load(tmpcopyfileid1)['model'][0]\n",
    "                else:\n",
    "                    cm_all = np.load(tmpcopyfileid2)['cm']\n",
    "                    model = np.load(tmpcopyfileid2)['model'][0]\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            model = []\n",
    "            for m in range(kmax):\n",
    "                tmpcopyfileid = filepath+filename3(i,j,k1,k2,k3,m)+'.npz'\n",
    "                if k1!=m and k2!=m and k3!=m and os.path.isfile(tmpcopyfileid):\n",
    "                    print 'Found precomputed model of '+str(k1)+str(k2)+str(k3)+', tested on '+str(m) \\\n",
    "                                                                               +'. Testing on '+str(l)+'...'\n",
    "                    model = np.load(tmpcopyfileid)['model'][0]\n",
    "                    break\n",
    "            if model==[]: # model not found precomputed\n",
    "                print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+', testing on '+str(l)+'...'\n",
    "                model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps3(i,j,jmax,surf,surfla):\n",
    "    \"\"\"function for helping parallelization of computations per 3 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> jmax           : number of all subfeaturesets\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    \"\"\"\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k1 in range(surf.shape[0]): # for every training surface1\n",
    "        for k2 in range(surf.shape[0]): # for every training surface2\n",
    "            if k2 > k1:\n",
    "                for k3 in range(surf.shape[0]):\n",
    "                    if k3 > k2:\n",
    "                        for l in range(surf.shape[0]): # for every testing surface\n",
    "                            tr_surf = np.concatenate((surf[k1],surf[k2],surf[k3]),axis=0)\n",
    "                            tr_surfla = np.concatenate((surfla[:,k1],surfla[:,k2],surfla[:,k3]),axis=0)\n",
    "                            ts_surf, ts_surfla = surf[l], surfla[:,l]\n",
    "                            cross_fit3(i,j,k1,k2,k3,surf.shape[0],l,tr_surf,tr_surfla,ts_surf,ts_surfla,pipe)\n",
    "\n",
    "def train_3_surface(surf,surfla,n=-1):\n",
    "    \"\"\"Parallel training -on surface level- of all combinations on 3 surfaces\n",
    "    -> n              : number of cores to run in parallel, \n",
    "                        input of joblib's Parallel (n=-1 means all available cores)\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    *** Cross surface validation, TRAINING with 3 surfaces each time, out of 6 surfaces in total\n",
    "    total= 4 (featuresets) * [comb(6,3)*6] (surface combinations: trained on 3, tested on 1) * 1 (prefeatureset)\n",
    "         = 4*20*6*1 = 480 different runs-files.\n",
    "    Note that comb(n,r) = n!/(r!(n-r)!)\n",
    "    \"\"\"\n",
    "    print \"-------------------------- TRAINING all combinations per 3 surfaces ----------------------------------\"\n",
    "    for i in range(len(prefeatid)-1):\n",
    "        _ = [Parallel(n_jobs=n)([delayed(init_steps3) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) \n",
    "                                 for j in range(surf.shape[0])])]\n",
    "        \n",
    "def bargraph_perf_gen3(maxsurf):\n",
    "    \"\"\"Perf file for bargraph generation using bargraph tool, for 3 surfaces\"\"\"\n",
    "    print \"---------------------------- Generating perf files for 3 surfaces ------------------------------------\"\n",
    "    prefeats = prefeatnames[prefeatid][:-1]\n",
    "    # prefeatures, subfeatures, trained, tested, (TP,TN,FN,FP)\n",
    "    acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all tested surfaces\n",
    "    avg = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # prefeatures, subfeatures, trained, cross_val_self_accuracy, (TP,TN,FN,FP)\n",
    "    self_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,1,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all self tested surfaces\n",
    "    avgs = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # features, subfeatures, trained, (tested avg, tested std), (TP,TN,FN,FP)\n",
    "    cross_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,2,4))\n",
    "     # features, subfeatures, (TP,TN,FN,FP) -> avg over all cross tested surfaces\n",
    "    avgc = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    initial_str = \"\"\"# clustered and stacked graph bogus data\n",
    "=stackcluster;TP;TN;FN;FP\n",
    "colors=med_blue,dark_green,yellow,red\n",
    "=nogridy\n",
    "=noupperright\n",
    "fontsz=5\n",
    "legendx=right\n",
    "legendy=center\n",
    "datascale=50\n",
    "yformat=%g%%\n",
    "xlabel=TrainedON-TestedON\n",
    "ylabel=Metrics\n",
    "=table\"\"\"\n",
    "    respath = filename3(_,_,_,_,_,_,1)\n",
    "    for i in range(len(prefeats)):\n",
    "        outname = respath+prefeats[i]\n",
    "        outfile = outname+'.perf'\n",
    "        outfile1 = outname+'_selfaccuracy.perf'\n",
    "        outfile2 = outname+'_crossaccuracy.perf'\n",
    "        out = open(outfile,'w+')\n",
    "        out.write(initial_str+\"\\n\")\n",
    "        out1 = open(outfile1,'w+')\n",
    "        out1.write(initial_str+\"\\n\")\n",
    "        out2 = open(outfile2,'w+')\n",
    "        out2.write(initial_str+\"\\n\")\n",
    "        for k1 in range(maxsurf):\n",
    "            for k2 in range(maxsurf):\n",
    "                if k2 > k1:\n",
    "                    for k3 in range(maxsurf):\n",
    "                        if k3 > k2:\n",
    "                            for l in range(maxsurf):\n",
    "                                out.write(\"multimulti=\"+str(k1)+str(k2)+str(k3)+\"-\"+str(l)+\"\\n\")\n",
    "                                for j in range(len(subfeats)):\n",
    "                                    fileid = filename3(i,j,k1,k2,k3,l)\n",
    "                                    tmp = np.load(fileid)['cm']\n",
    "                                    acc[i,j,k1,k2,k3,l,0] = round(tmp[1,1],2) # TP\n",
    "                                    acc[i,j,k1,k2,k3,l,1] = round(tmp[0,0],2) # TN\n",
    "                                    acc[i,j,k1,k2,k3,l,2] = 1-round(tmp[1,1],2) # FN\n",
    "                                    acc[i,j,k1,k2,k3,l,3] = 1-round(tmp[0,0],2) # FP\n",
    "                                    avg[i,j,:] += acc[i,j,k1,k2,k3,l,:]\n",
    "                                    out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],acc[i,j,k1,k2,k3,l,0],\n",
    "                                                                            acc[i,j,k1,k2,k3,l,1],\n",
    "                                                                            acc[i,j,k1,k2,k3,l,2],\n",
    "                                                                            acc[i,j,k1,k2,k3,l,3]))\n",
    "                                    if l == k1 or l == k2 or l == k3: # selc accuracy\n",
    "                                        if j == 0 and l == k3:\n",
    "                                            out1.write(\"multimulti=\"+str(k1)+str(k2)+str(k3)+\"-\"+str(l)+\"\\n\")\n",
    "                                        self_acc[i,j,k1,k2,k3,0,:] = acc[i,j,k1,k2,k3,l]\n",
    "                                        avgs[i,j,:] += self_acc[i,j,k1,k2,k3,0,:]\n",
    "                                        if l == k3:\n",
    "                                            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],\n",
    "                                                                                     self_acc[i,j,k1,k2,k3,0,0],\n",
    "                                                                                     self_acc[i,j,k1,k2,k3,0,1],\n",
    "                                                                                     self_acc[i,j,k1,k2,k3,0,2],\n",
    "                                                                                     self_acc[i,j,k1,k2,k3,0,3]))\n",
    "                                    if l != k1 and l != k2 and l != k3:\n",
    "                                        t = range(maxsurf)\n",
    "                                        t.remove(k1)\n",
    "                                        t.remove(k2)\n",
    "                                        t.remove(k3)\n",
    "                                        if (l == t[-1]):\n",
    "                                            if j == 0:\n",
    "                                                out2.write(\"multimulti=\"+str(k1)+str(k2)+str(k3)+\"\\n\")\n",
    "                                            # avg\n",
    "                                            cross_acc[i,j,k1,k2,k3,0,:] = np.mean(acc[i,j,k1,k2,k3,t,:], axis=0)\n",
    "                                            # std\n",
    "                                            # cross_acc[i,j,k1,k2,k3,1,:] = np.std(acc[i,j,k1,k2,k3,t,:], axis=0)\n",
    "                                            avgc[i,j,:] += cross_acc[i,j,k1,k2,k3,0,:]\n",
    "                                            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],\n",
    "                                                                                     cross_acc[i,j,k1,k2,k3,0,0],\n",
    "                                                                                     cross_acc[i,j,k1,k2,k3,0,1],\n",
    "                                                                                     cross_acc[i,j,k1,k2,k3,0,2],\n",
    "                                                                                     cross_acc[i,j,k1,k2,k3,0,3]))\n",
    "        out.write(\"multimulti=AVG\\n\")\n",
    "        out1.write(\"multimulti=AVG\\n\")\n",
    "        out2.write(\"multimulti=AVG\\n\")\n",
    "        avg /= comb(maxsurf,3)*maxsurf*1.\n",
    "        avgs /= comb(maxsurf,3)*3.\n",
    "        avgc /= comb(maxsurf,3)*1.\n",
    "        for j in range(len(subfeats)):\n",
    "            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avg[i,j,0],avg[i,j,1],avg[i,j,2],avg[i,j,3]))\n",
    "            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgs[i,j,0],avgs[i,j,1],avgs[i,j,2],avgs[i,j,3]))\n",
    "            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgc[i,j,0],avgc[i,j,1],avgc[i,j,2],avgc[i,j,3]))\n",
    "        out.close()\n",
    "        out1.close()\n",
    "        out2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ TRAINING with 4 surfaces each time, out of 6 surfaces in total ##############\n",
    "def filename4(i,j,k1,k2,k3,k4,l,retpath=0):\n",
    "    \"\"\"function for the filename of the selected combination for training per 4 surfaces\n",
    "    -> i  : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j  : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki : surface ids trained on\n",
    "    -> l  : surface id tested on\n",
    "    <- filename\n",
    "    \"\"\"\n",
    "    filepath = respath+'4/'\n",
    "    ensure_dir(filepath)\n",
    "    if retpath:\n",
    "        return filepath\n",
    "    else:\n",
    "        return filepath+'fs_'+str(i)+'_subfs_'+str(j)+'_tr1_'+str(k1)+'_tr2_'+str(k2)+'_tr3_' \\\n",
    "                                 +str(k3)+'_tr4_'+str(k4)+'_ts_'+str(l)+'.npz'\n",
    "\n",
    "def cross_fit4(i,j,k1,k2,k3,k4,kmax,l,data,labels,data2,labels2,pipe):\n",
    "    \"\"\"function for fitting model per 4 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki             : surface ids trained on\n",
    "    -> kmax           : maximum surfaces\n",
    "    -> l              : surface id tested on\n",
    "    -> data, labels   : training data and labels\n",
    "    -> data2, labels2 : testing data and labels\n",
    "    -> pipe           : the desired pipeline configuration\n",
    "    <- no output, saved model and confusion matrix in corresponding filename.npz\n",
    "    \"\"\"\n",
    "    fileid = filename4(i,j,k1,k2,k3,k4,l)\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k1,k2,k3,k4,l\n",
    "        if k1==l or k2==l or k3==l or k4==l: # perform K-fold      \n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+\"-\"+str(k4)+', cross-validating on '+str(l)+'...'\n",
    "            if l == k1: # copy if existent from the other sibling file\n",
    "                tmpcopyfileid1 = filepath+filename4(i,j,k1,k2,k3,k4,k2)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename4(i,j,k1,k2,k3,k4,k3)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename4(i,j,k1,k2,k3,k4,k4)+'.npz'\n",
    "            elif l == k2:   # same as above\n",
    "                tmpcopyfileid1 = filepath+filename4(i,j,k1,k2,k3,k4,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename4(i,j,k1,k2,k3,k4,k3)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename4(i,j,k1,k2,k3,k4,k4)+'.npz'\n",
    "            elif l == k3:   # same as above\n",
    "                tmpcopyfileid1 = filepath+filename4(i,j,k1,k2,k3,k4,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename4(i,j,k1,k2,k3,k4,k2)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename4(i,j,k1,k2,k3,k4,k4)+'.npz'\n",
    "            else:\n",
    "                tmpcopyfileid1 = filepath+filename4(i,j,k1,k2,k3,k4,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename4(i,j,k1,k2,k3,k4,k2)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename4(i,j,k1,k2,k3,k4,k3)+'.npz'\n",
    "            if not os.path.isfile(tmpcopyfileid1) and not os.path.isfile(tmpcopyfileid2) \\\n",
    "                                                  and not os.path.isfile(tmpcopyfileid3):\n",
    "                folds = cv.split(data, labels)\n",
    "                cm_all = np.zeros((2,2))\n",
    "                for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                    x_train, x_test = data[train_ind], data[test_ind]\n",
    "                    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                    model = pipe.fit(x_train,y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                    cm_all += cm/5.\n",
    "            else:\n",
    "                if os.path.isfile(tmpcopyfileid1):\n",
    "                    cm_all = np.load(tmpcopyfileid1)['cm']\n",
    "                    model = np.load(tmpcopyfileid1)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid2):\n",
    "                    cm_all = np.load(tmpcopyfileid2)['cm']\n",
    "                    model = np.load(tmpcopyfileid2)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid3):\n",
    "                    cm_all = np.load(tmpcopyfileid3)['cm']\n",
    "                    model = np.load(tmpcopyfileid3)['model'][0]\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            model = []\n",
    "            for m in range(kmax):\n",
    "                tmpcopyfileid = filepath+filename4(i,j,k1,k2,k3,k4,m)+'.npz'\n",
    "                if k1!=m and k2!=m and k3!=m and k4!=m and os.path.isfile(tmpcopyfileid):\n",
    "                    print 'Found precomputed model of '+str(k1)+str(k2)+str(k3)+str(k4)\\\n",
    "                                                       +', tested on '+str(m)+'. Testing on '+str(l)+'...'\n",
    "                    model = np.load(tmpcopyfileid)['model'][0]\n",
    "                    break\n",
    "            if model==[]: # model not found precomputed\n",
    "                print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+\"-\"+str(k4)+', testing on '+str(l)+'...'\n",
    "                model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps4(i,j,jmax,surf,surfla):\n",
    "    \"\"\"function for helping parallelization of computations per 4 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> jmax           : number of all subfeaturesets\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    \"\"\"\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k1 in range(surf.shape[0]): # for every training surface1\n",
    "        for k2 in range(surf.shape[0]): # for every training surface2\n",
    "            if k2 > k1:\n",
    "                for k3 in range(surf.shape[0]):\n",
    "                    if k3 > k2:\n",
    "                        for k4 in range(surf.shape[0]):\n",
    "                            if k4 > k3:\n",
    "                                for l in range(surf.shape[0]): # for every testing surface\n",
    "                                    tr_surf = np.concatenate((surf[k1],surf[k2],surf[k3]),axis=0)\n",
    "                                    tr_surfla = np.concatenate((surfla[:,k1],surfla[:,k2],surfla[:,k3]),axis=0)\n",
    "                                    ts_surf, ts_surfla = surf[l], surfla[:,l]\n",
    "                                    cross_fit4(i,j,k1,k2,k3,k4,surf.shape[0],l,\n",
    "                                               tr_surf,tr_surfla,ts_surf,ts_surfla,pipe)\n",
    "\n",
    "def train_4_surface(surf,surfla,n=-1):\n",
    "    \"\"\"Parallel training -on surface level- of all combinations on 4 surfaces\n",
    "    -> n              : number of cores to run in parallel, \n",
    "                        input of joblib's Parallel (n=-1 means all available cores)\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    *** Cross surface validation, TRAINING with 2 surfaces each time, out of 6 surfaces in total\n",
    "    total= 4 (featuresets) * [comb(6,4)*6] (surface combinations: trained on 4, tested on 1) * 1 (prefeatureset)\n",
    "         = 4*15*6*1 = 360 different runs-files.\n",
    "    Note that comb(n,r) = n!/(r!(n-r)!)\n",
    "    \"\"\"\n",
    "    print \"-------------------------- TRAINING all combinations per 4 surfaces ----------------------------------\"        \n",
    "    for i in range(len(prefeatid)-1):\n",
    "        _ = [Parallel(n_jobs=n)([delayed(init_steps4) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) \n",
    "                                 for j in range(surf.shape[0])])]\n",
    "        \n",
    "def bargraph_perf_gen4(maxsurf):\n",
    "    \"\"\"Perf file for bargraph generation using bargraph tool, for 4 surfaces\"\"\"\n",
    "    print \"---------------------------- Generating perf files for 4 surfaces ------------------------------------\"\n",
    "    prefeats = prefeatnames[prefeatid][:-1]\n",
    "    # prefeatures, subfeatures, trained, tested, (TP,TN,FN,FP)\n",
    "    acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,maxsurf,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all tested surfaces\n",
    "    avg = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # prefeatures, subfeatures, trained, cross_val_self_accuracy, (TP,TN,FN,FP)\n",
    "    self_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,1,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all self tested surfaces\n",
    "    avgs = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # features, subfeatures, trained, (tested avg, tested std), (TP,TN,FN,FP)\n",
    "    cross_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,2,4))\n",
    "     # features, subfeatures, (TP,TN,FN,FP) -> avg over all cross tested surfaces\n",
    "    avgc = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    initial_str = \"\"\"# clustered and stacked graph bogus data\n",
    "=stackcluster;TP;TN;FN;FP\n",
    "colors=med_blue,dark_green,yellow,red\n",
    "=nogridy\n",
    "=noupperright\n",
    "fontsz=5\n",
    "legendx=right\n",
    "legendy=center\n",
    "datascale=50\n",
    "yformat=%g%%\n",
    "xlabel=TrainedON-TestedON\n",
    "ylabel=Metrics\n",
    "=table\"\"\"\n",
    "    respath = filename4(_,_,_,_,_,_,_,1)\n",
    "    for i in range(len(prefeats)):\n",
    "        outname = respath+prefeats[i]\n",
    "        outfile = outname+'.perf'\n",
    "        outfile1 = outname+'_selfaccuracy.perf'\n",
    "        outfile2 = outname+'_crossaccuracy.perf'\n",
    "        out = open(outfile,'w+')\n",
    "        out.write(initial_str+\"\\n\")\n",
    "        out1 = open(outfile1,'w+')\n",
    "        out1.write(initial_str+\"\\n\")\n",
    "        out2 = open(outfile2,'w+')\n",
    "        out2.write(initial_str+\"\\n\")\n",
    "        for k1 in range(maxsurf):\n",
    "            for k2 in range(maxsurf):\n",
    "                if k2 > k1:\n",
    "                    for k3 in range(maxsurf):\n",
    "                        if k3 > k2:\n",
    "                            for k4 in range(maxsurf):\n",
    "                                if k4 > k3:\n",
    "                                    for l in range(maxsurf):\n",
    "                                        out.write(\"multimulti=\"+str(k1)+str(k2)+str(k3)+str(k4)+\"-\"+str(l)+\"\\n\")\n",
    "                                        for j in range(len(subfeats)):\n",
    "                                            fileid = filename4(i,j,k1,k2,k3,k4,l)\n",
    "                                            tmp = np.load(fileid)['cm']\n",
    "                                            acc[i,j,k1,k2,k3,k4,l,0] = round(tmp[1,1],2) # TP\n",
    "                                            acc[i,j,k1,k2,k3,k4,l,1] = round(tmp[0,0],2) # TN\n",
    "                                            acc[i,j,k1,k2,k3,k4,l,2] = 1-round(tmp[1,1],2) # FN\n",
    "                                            acc[i,j,k1,k2,k3,k4,l,3] = 1-round(tmp[0,0],2) # FP\n",
    "                                            avg[i,j,:] += acc[i,j,k1,k2,k3,k4,l,:]\n",
    "                                            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],\n",
    "                                                                                    acc[i,j,k1,k2,k3,k4,l,0],\n",
    "                                                                                    acc[i,j,k1,k2,k3,k4,l,1],\n",
    "                                                                                    acc[i,j,k1,k2,k3,k4,l,2],\n",
    "                                                                                    acc[i,j,k1,k2,k3,k4,l,3]))\n",
    "                                            if l == k1 or l == k2 or l == k3 or l == k4: # selc accuracy\n",
    "                                                if j == 0 and l == k4:\n",
    "                                                    out1.write(\"multimulti=\"+str(k1)+str(k2)+str(k3)\\\n",
    "                                                                            +str(k4)+\"-\"+str(l)+\"\\n\")\n",
    "                                                self_acc[i,j,k1,k2,k3,k4,0,:] = acc[i,j,k1,k2,k3,k4,l]\n",
    "                                                avgs[i,j,:] += self_acc[i,j,k1,k2,k3,k4,0,:]\n",
    "                                                if l == k4:\n",
    "                                                    out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" \\\n",
    "                                                               % (subfeats[j],\n",
    "                                                                  self_acc[i,j,k1,k2,k3,k4,0,0],\n",
    "                                                                  self_acc[i,j,k1,k2,k3,k4,0,1],\n",
    "                                                                  self_acc[i,j,k1,k2,k3,k4,0,2],\n",
    "                                                                  self_acc[i,j,k1,k2,k3,k4,0,3]))\n",
    "                                            if l != k1 and l != k2 and l != k3 and l!= k4:\n",
    "                                                t = range(maxsurf)\n",
    "                                                t.remove(k1)\n",
    "                                                t.remove(k2)\n",
    "                                                t.remove(k3)\n",
    "                                                t.remove(k4)\n",
    "                                                if (l == t[-1]):\n",
    "                                                    if j == 0:\n",
    "                                                        out2.write(\"multimulti=\"+str(k1)+str(k2)\\\n",
    "                                                                   +str(k3)+str(k4)+\"\\n\")\n",
    "                                                    cross_acc[i,j,k1,k2,k3,k4,0,:] = \\\n",
    "                                                        np.mean(acc[i,j,k1,k2,k3,k4,t,:], axis=0)\n",
    "                                                    avgc[i,j,:] += cross_acc[i,j,k1,k2,k3,k4,0,:]\n",
    "                                                    out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" \\\n",
    "                                                               % (subfeats[j],\n",
    "                                                                  cross_acc[i,j,k1,k2,k3,k4,0,0],\n",
    "                                                                  cross_acc[i,j,k1,k2,k3,k4,0,1],\n",
    "                                                                  cross_acc[i,j,k1,k2,k3,k4,0,2],\n",
    "                                                                  cross_acc[i,j,k1,k2,k3,k4,0,3]))\n",
    "        out.write(\"multimulti=AVG\\n\")\n",
    "        out1.write(\"multimulti=AVG\\n\")\n",
    "        out2.write(\"multimulti=AVG\\n\")\n",
    "        avg /= comb(maxsurf,4)*maxsurf*1.\n",
    "        avgs /= comb(maxsurf,4)*4.\n",
    "        avgc /= comb(maxsurf,4)*1.\n",
    "        for j in range(len(subfeats)):\n",
    "            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avg[i,j,0],avg[i,j,1],avg[i,j,2],avg[i,j,3]))\n",
    "            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgs[i,j,0],avgs[i,j,1],avgs[i,j,2],avgs[i,j,3]))\n",
    "            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgc[i,j,0],avgc[i,j,1],avgc[i,j,2],avgc[i,j,3]))\n",
    "        out.close()\n",
    "        out1.close()\n",
    "        out2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ TRAINING with 5 surfaces each time, out of 6 surfaces in total ##############\n",
    "def filename5(i,j,k1,k2,k3,k4,k5,l,retpath=0):\n",
    "    \"\"\"function for the filename of the selected combination for training per 5 surfaces\n",
    "    -> i  : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j  : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki : surface ids trained on\n",
    "    -> l  : surface id tested on\n",
    "    <- filename\n",
    "    \"\"\"\n",
    "    filepath = respath+'5/'\n",
    "    ensure_dir(filepath)\n",
    "    if retpath:\n",
    "        return filepath\n",
    "    else:\n",
    "        return filepath+'fs_'+str(i)+'_subfs_'+str(j)+'_tr1_'+str(k1)+'_tr2_'+str(k2)+'_tr3_' \\\n",
    "                                 +str(k3)+'_tr4_'+str(k4)+'_tr5_'+str(k5)+'_ts_'+str(l)+'.npz'\n",
    "\n",
    "def cross_fit5(i,j,k1,k2,k3,k4,k5,kmax,l,data,labels,data2,labels2,pipe):\n",
    "    \"\"\"function for fitting model per 5 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki             : surface ids trained on\n",
    "    -> kmax           : maximum surfaces\n",
    "    -> l              : surface id tested on\n",
    "    -> data, labels   : training data and labels\n",
    "    -> data2, labels2 : testing data and labels\n",
    "    -> pipe           : the desired pipeline configuration\n",
    "    <- no output, saved model and confusion matrix in corresponding filename.npz\n",
    "    \"\"\"\n",
    "    fileid = filename5(i,j,k1,k2,k3,k4,k5,l)\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k1,k2,k3,k4,k5,l\n",
    "        if k1==l or k2==l or k3==l or k4==l or k5==l: # perform K-fold      \n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+\"-\"+str(k4)+\"-\" \\\n",
    "                                           +str(k5)+', cross-validating on '+str(l)+'...'\n",
    "            if l == k1: # copy if existent from the other sibling file\n",
    "                tmpcopyfileid1 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k2)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k3)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k4)+'.npz'\n",
    "                tmpcopyfileid4 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k5)+'.npz'\n",
    "            elif l == k2:   # same as above\n",
    "                tmpcopyfileid1 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k3)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k4)+'.npz'\n",
    "                tmpcopyfileid4 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k5)+'.npz'\n",
    "            elif l == k3:   # same as above\n",
    "                tmpcopyfileid1 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k2)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k4)+'.npz'\n",
    "                tmpcopyfileid4 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k5)+'.npz'\n",
    "            elif l == k4:   # same as above\n",
    "                tmpcopyfileid1 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k2)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k3)+'.npz'\n",
    "                tmpcopyfileid4 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k5)+'.npz'\n",
    "            else:\n",
    "                tmpcopyfileid1 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k2)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k3)+'.npz'\n",
    "                tmpcopyfileid4 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k4)+'.npz'\n",
    "            if not os.path.isfile(tmpcopyfileid1) and not os.path.isfile(tmpcopyfileid2) \\\n",
    "               and not os.path.isfile(tmpcopyfileid3) and not os.path.isfile(tmpcopyfileid4):\n",
    "                folds = cv.split(data, labels)\n",
    "                cm_all = np.zeros((2,2))\n",
    "                for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                    x_train, x_test = data[train_ind], data[test_ind]\n",
    "                    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                    model = pipe.fit(x_train,y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                    cm_all += cm/5.\n",
    "            else:\n",
    "                if os.path.isfile(tmpcopyfileid1):\n",
    "                    cm_all = np.load(tmpcopyfileid1)['cm']\n",
    "                    model = np.load(tmpcopyfileid1)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid2):\n",
    "                    cm_all = np.load(tmpcopyfileid2)['cm']\n",
    "                    model = np.load(tmpcopyfileid2)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid3):\n",
    "                    cm_all = np.load(tmpcopyfileid3)['cm']\n",
    "                    model = np.load(tmpcopyfileid3)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid4):\n",
    "                    cm_all = np.load(tmpcopyfileid4)['cm']\n",
    "                    model = np.load(tmpcopyfileid4)['model'][0]\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            model = []\n",
    "            for m in range(kmax):\n",
    "                tmpcopyfileid = filepath+filename5(i,j,k1,k2,k3,k4,k5,m)+'.npz'\n",
    "                if k1!=m and k2!=m and k3!=m and k4!=m and k5!=m and os.path.isfile(tmpcopyfileid):\n",
    "                    print 'Found precomputed model of '+str(k1)+str(k2)+str(k3)+str(k4)+str(k5) \\\n",
    "                                                       +', tested on '+str(m)+'. Testing on '+str(l)+'...'\n",
    "                    model = np.load(tmpcopyfileid)['model'][0]\n",
    "                    break\n",
    "            if model==[]: # model not found precomputed\n",
    "                print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+\"-\"+str(k4)+\"-\" \\\n",
    "                                               +str(k5)+', testing on '+str(l)+'...'\n",
    "                model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps5(i,j,jmax,surf,surfla):\n",
    "    \"\"\"function for helping parallelization of computations per 5 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> jmax           : number of all subfeaturesets\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    \"\"\"\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k1 in range(surf.shape[0]): # for every training surface1\n",
    "        for k2 in range(surf.shape[0]): # for every training surface2\n",
    "            if k2 > k1:\n",
    "                for k3 in range(surf.shape[0]):\n",
    "                    if k3 > k2:\n",
    "                        for k4 in range(surf.shape[0]):\n",
    "                            if k4 > k3:\n",
    "                                for k5 in range(surf.shape[0]):\n",
    "                                    if k5 > k4:\n",
    "                                        for l in range(surf.shape[0]): # for every testing surface\n",
    "                                            tr_surf = np.concatenate((surf[k1],surf[k2],surf[k3]),axis=0)\n",
    "                                            tr_surfla = np.concatenate((surfla[:,k1],surfla[:,k2],\n",
    "                                                                        surfla[:,k3]),axis=0)\n",
    "                                            ts_surf, ts_surfla = surf[l], surfla[:,l]\n",
    "                                            cross_fit5(i,j,k1,k2,k3,k4,k5,surf.shape[0],l,\n",
    "                                                       tr_surf,tr_surfla,ts_surf,ts_surfla,pipe)\n",
    "\n",
    "def train_5_surface(surf,surfla,n=-1):\n",
    "    \"\"\"Parallel training -on surface level- of all combinations on 5 surfaces\n",
    "    -> n              : number of cores to run in parallel, \n",
    "                        input of joblib's Parallel (n=-1 means all available cores)\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    *** Cross surface validation, TRAINING with 5 surfaces each time, out of 6 surfaces in total\n",
    "    total= 4 (featuresets) * [comb(6,5)*6] (surface combinations: trained on 5, tested on 1) * 1 (prefeatureset)\n",
    "         = 4*6*6*1 = 144 different runs-files.\n",
    "    Note that comb(n,r) = n!/(r!(n-r)!)\n",
    "    \"\"\"\n",
    "    print \"-------------------------- TRAINING all combinations per 5 surfaces ----------------------------------\"        \n",
    "    for i in range(len(prefeatid)-1):\n",
    "        _ = [Parallel(n_jobs=n)([delayed(init_steps5) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) \n",
    "                                 for j in range(surf.shape[0])])]\n",
    "        \n",
    "def bargraph_perf_gen5(maxsurf):\n",
    "    \"\"\"Perf file for bargraph generation using bargraph tool, for 5 surfaces\"\"\"\n",
    "    print \"---------------------------- Generating perf files for 5 surfaces ------------------------------------\"\n",
    "    prefeats = prefeatnames[prefeatid][:-1]\n",
    "    # prefeatures, subfeatures, trained, tested, (TP,TN,FN,FP)\n",
    "    acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,maxsurf,maxsurf,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all tested surfaces\n",
    "    avg = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # prefeatures, subfeatures, trained, cross_val_self_accuracy, (TP,TN,FN,FP)\n",
    "    self_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,maxsurf,1,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all self tested surfaces\n",
    "    avgs = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # features, subfeatures, trained, (tested avg, tested std), (TP,TN,FN,FP)\n",
    "    cross_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,maxsurf,2,4))\n",
    "     # features, subfeatures, (TP,TN,FN,FP) -> avg over all cross tested surfaces\n",
    "    avgc = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    initial_str = \"\"\"# clustered and stacked graph bogus data\n",
    "=stackcluster;TP;TN;FN;FP\n",
    "colors=med_blue,dark_green,yellow,red\n",
    "=nogridy\n",
    "=noupperright\n",
    "fontsz=5\n",
    "legendx=right\n",
    "legendy=center\n",
    "datascale=50\n",
    "yformat=%g%%\n",
    "xlabel=TrainedON-TestedON\n",
    "ylabel=Metrics\n",
    "=table\"\"\"\n",
    "    respath = filename5(_,_,_,_,_,_,_,_,1)\n",
    "    for i in range(len(prefeats)):\n",
    "        outname = respath+prefeats[i]\n",
    "        outfile = outname+'.perf'\n",
    "        outfile1 = outname+'_selfaccuracy.perf'\n",
    "        outfile2 = outname+'_crossaccuracy.perf'\n",
    "        out = open(outfile,'w+')\n",
    "        out.write(initial_str+\"\\n\")\n",
    "        out1 = open(outfile1,'w+')\n",
    "        out1.write(initial_str+\"\\n\")\n",
    "        out2 = open(outfile2,'w+')\n",
    "        out2.write(initial_str+\"\\n\")\n",
    "        for k1 in range(maxsurf):\n",
    "            for k2 in range(maxsurf):\n",
    "                if k2 > k1:\n",
    "                    for k3 in range(maxsurf):\n",
    "                        if k3 > k2:\n",
    "                            for k4 in range(maxsurf):\n",
    "                                if k4 > k3:\n",
    "                                    for k5 in range(maxsurf):\n",
    "                                        if k5 > k4:\n",
    "                                            for l in range(maxsurf):\n",
    "                                                out.write(\"multimulti=\"+str(k1)+str(k2)+str(k3)+str(k4)\\\n",
    "                                                          +str(k5)+\"-\"+str(l)+\"\\n\")\n",
    "                                                for j in range(len(subfeats)):\n",
    "                                                    fileid = filename5(i,j,k1,k2,k3,k4,k5,l)\n",
    "                                                    tmp = np.load(fileid)['cm']\n",
    "                                                    acc[i,j,k1,k2,k3,k4,k5,l,0] = round(tmp[1,1],2) # TP\n",
    "                                                    acc[i,j,k1,k2,k3,k4,k5,l,1] = round(tmp[0,0],2) # TN\n",
    "                                                    acc[i,j,k1,k2,k3,k4,k5,l,2] = 1-round(tmp[1,1],2) # FN\n",
    "                                                    acc[i,j,k1,k2,k3,k4,k5,l,3] = 1-round(tmp[0,0],2) # FP\n",
    "                                                    avg[i,j,:] += acc[i,j,k1,k2,k3,k4,k5,l,:]\n",
    "                                                    out.write(\"%s %.2f %.2f %.2f %.2f\\n\" \\\n",
    "                                                              % (subfeats[j],\n",
    "                                                                 acc[i,j,k1,k2,k3,k4,k5,l,0],\n",
    "                                                                 acc[i,j,k1,k2,k3,k4,k5,l,1],\n",
    "                                                                 acc[i,j,k1,k2,k3,k4,k5,l,2],\n",
    "                                                                 acc[i,j,k1,k2,k3,k4,k5,l,3]))\n",
    "                                                    # selc accuracy\n",
    "                                                    if l == k1 or l == k2 or l == k3 or l == k4 or l == k5:\n",
    "                                                        if j == 0 and l == k5:\n",
    "                                                            out1.write(\"multimulti=\"+str(k1)+str(k2)\n",
    "                                                                       +str(k3)+str(k4)+str(k5)+\"-\"+str(l)+\"\\n\")\n",
    "                                                        self_acc[i,j,k1,k2,k3,k4,k5,0,:] = \\\n",
    "                                                            acc[i,j,k1,k2,k3,k4,k5,l]\n",
    "                                                        avgs[i,j,:] += self_acc[i,j,k1,k2,k3,k4,k5,0,:]\n",
    "                                                        if l == k5:\n",
    "                                                            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" \\\n",
    "                                                                       % (subfeats[j],\n",
    "                                                                          self_acc[i,j,k1,k2,k3,k4,k5,0,0],\n",
    "                                                                          self_acc[i,j,k1,k2,k3,k4,k5,0,1],\n",
    "                                                                          self_acc[i,j,k1,k2,k3,k4,k5,0,2],\n",
    "                                                                          self_acc[i,j,k1,k2,k3,k4,k5,0,3]))\n",
    "                                                    if l != k1 and l != k2 and l != k3 and l!= k4 and l!= k5:\n",
    "                                                        t = range(maxsurf)\n",
    "                                                        t.remove(k1)\n",
    "                                                        t.remove(k2)\n",
    "                                                        t.remove(k3)\n",
    "                                                        t.remove(k4)\n",
    "                                                        t.remove(k5)\n",
    "                                                        if (l == t[-1]):\n",
    "                                                            if j == 0:\n",
    "                                                                out2.write(\"multimulti=\"+str(k1)+str(k2)\\\n",
    "                                                                           +str(k3)+str(k4)+str(k5)+\"\\n\")\n",
    "                                                            cross_acc[i,j,k1,k2,k3,k4,k5,0,:] = \\\n",
    "                                                                np.mean(acc[i,j,k1,k2,k3,k4,k5,t,:], axis=0)\n",
    "                                                            avgc[i,j,:] += cross_acc[i,j,k1,k2,k3,k4,k5,0,:]\n",
    "                                                            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" \\\n",
    "                                                                       % (subfeats[j],\n",
    "                                                                          cross_acc[i,j,k1,k2,k3,k4,k5,0,0],\n",
    "                                                                          cross_acc[i,j,k1,k2,k3,k4,k5,0,1],\n",
    "                                                                          cross_acc[i,j,k1,k2,k3,k4,k5,0,2],\n",
    "                                                                          cross_acc[i,j,k1,k2,k3,k4,k5,0,3]))\n",
    "        out.write(\"multimulti=AVG\\n\")\n",
    "        out1.write(\"multimulti=AVG\\n\")\n",
    "        out2.write(\"multimulti=AVG\\n\")\n",
    "        avg /= comb(maxsurf,5)*maxsurf*1.\n",
    "        avgs /= comb(maxsurf,5)*5.\n",
    "        avgc /= comb(maxsurf,5)*1.\n",
    "        for j in range(len(subfeats)):\n",
    "            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avg[i,j,0],avg[i,j,1],avg[i,j,2],avg[i,j,3]))\n",
    "            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgs[i,j,0],avgs[i,j,1],avgs[i,j,2],avgs[i,j,3]))\n",
    "            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgc[i,j,0],avgc[i,j,1],avgc[i,j,2],avgc[i,j,3]))\n",
    "        out.close()\n",
    "        out1.close()\n",
    "        out2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bargraphs_from_perf(i,maxsurf=6):\n",
    "    \"\"\"Bargraph generation using bargraph tool, for i surfaces\"\"\"\n",
    "    print \"---------------------------- Generating bar graphs for \"+str(i+1)+\" surfaces ------------------------------------\"\n",
    "    resfold = respath+str(i+1)+'/'\n",
    "    allperf = glob.glob(resfold+\"*.perf\")\n",
    "    maxperf = len(allperf)\n",
    "    for k in range(len(allperf)):\n",
    "        j = allperf[k]\n",
    "        tmppdf = j[:-4]+\"pdf\"\n",
    "        tmppng = j[:-4]+\"png\"\n",
    "        with open(tmppdf, \"w\") as f1:\n",
    "            call([tool,\"-pdf\",j],stdout=f1)\n",
    "        with open(tmppng, \"w\") as f2:            \n",
    "            call([tool,\"-png\",\"-non-transparent\",j],stdout=f2)\n",
    "        img = mpimg.imread(tmppng)\n",
    "        if k!=0:\n",
    "            plt.subplot(maxsurf,maxperf-1,k+i*(maxperf-1))\n",
    "            plt.imshow(img)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "1 -> f1: (36,) (36,) (36, 4)\n",
      "2 -> f2: (36,) (36,) (36, 4)\n",
      "3 -> f: (72,) (72,) (72, 4)\n",
      "4 -> m1,m2: 36 36 1.0 1.0\n",
      "5 -> f=f+l: (72,) : [(345002, 4), (105001, 4), (210001, 4), (225002, 4), (130001, 4), (65001, 4), (195001, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (225002, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (75001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (130001, 4), (195001, 4), (65001, 4), (345002, 4), (105001, 4), (210001, 4), (225002, 4), (130001, 4), (65001, 4), (195001, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (225002, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (75001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (130001, 4), (195001, 4), (65001, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(72,) : [(345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 2.15881109238 seconds \n",
      "features:  (72,) , labels:  (72,)\n",
      "------------------------------------ AVG FEATURE COMPUTATION TIME ------------------------------------\n",
      "Avg feature computation time (millisec):  2.2910879453\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (72,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (9935, 3107) (9935,) (9935, 3107) (9935,) (9935, 3107) (9935,)\n",
      "Xsp,Ysp [0,1,2]:  (8826, 3107) (8826,) (8826, 3107) (8826,) (8826, 3107) (8826,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (1470, 6, 1)\n",
      "-------------------------- TRAINING all combinations per 1 surface -----------------------------------\n",
      "-------------------------- TRAINING all combinations per 2 surfaces ----------------------------------\n",
      "-------------------------- TRAINING all combinations per 3 surfaces ----------------------------------\n",
      "-------------------------- TRAINING all combinations per 4 surfaces ----------------------------------\n",
      "-------------------------- TRAINING all combinations per 5 surfaces ----------------------------------\n"
     ]
    }
   ],
   "source": [
    "############ TRAINING PROCEDURE ##############\n",
    "# necessary steps before training\n",
    "f,l,fd,member,m1,m2 = data_prep(datafile)                      # read input force and labels\n",
    "prefeat = compute_prefeat(f)                                   # compute corresponding prefeatures\n",
    "features, labels = feature_extraction(prefeat, member)         # feature extraction from prefeatures\n",
    "avg_feat_comp_time(prefeat)                                    # average feature extraction time\n",
    "new_labels = label_cleaning(prefeat,labels,member)             # trim labels, around change points\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2)   # compute data and labels, trimmed and untrimmed\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp)                      # compute per surface data and labels\n",
    "# training\n",
    "train_1_surface(surf,surfla)                                   # training of all combinations per 1 surface\n",
    "train_2_surface(surf,surfla)                                   # training of all combinations per 2 surfaces\n",
    "train_3_surface(surf,surfla)                                   # training of all combinations per 3 surfaces\n",
    "train_4_surface(surf,surfla)                                   # training of all combinations per 4 surfaces\n",
    "train_5_surface(surf,surfla)                                   # training of all combinations per 5 surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Generating perf files for 1 surface -------------------------------------\n",
      "---------------------------- Generating perf files for 2 surfaces ------------------------------------\n",
      "---------------------------- Generating perf files for 3 surfaces ------------------------------------\n",
      "---------------------------- Generating perf files for 4 surfaces ------------------------------------\n",
      "---------------------------- Generating perf files for 5 surfaces ------------------------------------\n",
      "---------------------------- Generating bar graphs for 1 surfaces ------------------------------------\n",
      "---------------------------- Generating bar graphs for 2 surfaces ------------------------------------\n",
      "---------------------------- Generating bar graphs for 3 surfaces ------------------------------------\n",
      "---------------------------- Generating bar graphs for 4 surfaces ------------------------------------\n",
      "---------------------------- Generating bar graphs for 5 surfaces ------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAAcRCAYAAACf9A6GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACAAIQ4AAAAAAEIcQAAAAAC+H+ghVs80ysoLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f10c3cc8910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############ OFFLINE TESTING PROCEDURE ##############\n",
    "# generate files with stats\n",
    "bargraph_perf_gen1(6)\n",
    "bargraph_perf_gen2(6)\n",
    "bargraph_perf_gen3(6)\n",
    "bargraph_perf_gen4(6)\n",
    "bargraph_perf_gen5(6)\n",
    "# use the bargraph tool to plot graphs from generated files\n",
    "# -left column cross-accuracy (trained on one, tested on all the others), \n",
    "# -right column self-accuracy (trained and tested on the same)\n",
    "# -each row i represents training only with i surfaces.\n",
    "# -each stack represents a training group, each bar represents a subfeatureset(AFFT,FREQ,TIME,BOTH)\n",
    "# -blue,green,yellow,red : TP,TN,FN,FP\n",
    "plt.figure(figsize=(20,40))\n",
    "for i in range(5):\n",
    "    make_bargraphs_from_perf(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "1 -> f1: (1, 1) (1, 1) (1, 1)\n",
      "2 -> f2: (1, 1) (1, 1) (1, 1)\n",
      "3 -> f: (2, 1) (2, 1) (2, 1)\n",
      "4 -> m1,m2: 1 1 1.0 1.0\n",
      "5 -> f=f+l: (2, 65000, 4) : [(65000, 4), (65000, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(2,) : [(65000, 2), (65000, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.676390171051 seconds \n",
      "features:  (2,) , labels:  (2,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (2,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (3199, 3107) (3199,) (3199, 3107) (3199,) (6398, 3107) (6398,)\n",
      "Xsp,Ysp [0,1,2]:  (2769, 3107) (2769,) (2769, 3107) (2769,) (5538, 3107) (5538,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (922, 6, 1)\n"
     ]
    }
   ],
   "source": [
    "############ ONLINE TESTING PROCEDURE ##############\n",
    "# same necessary steps as in training\n",
    "f,l,fd,member,m1,m2 = data_prep(validfile)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, validfeatfile, 'validfeat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,validXYfile,validXYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,validsurffile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3199,) (2769,) (2769,)\n",
      "(2650,) (2650,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZgAAALICAYAAADyhJW9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzAAAAAAADPkGE2YlSJmt+Z0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1028a41b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############ VISUALIZING ONLINE TESTING PROCEDURE ##############\n",
    "\n",
    "subfeats = ['AFFT','FREQ','TIME','BOTH']\n",
    "feats = ['fnorm','ftfn','fnormftfn']\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "\n",
    "fileid = filename1(0,3,0,5)\n",
    "fileidb = filename1(0,0,0,5)\n",
    "fileid5 = filename5(0,3,0,1,2,3,4,5)\n",
    "fileid5b = filename5(0,0,0,1,2,3,4,5)\n",
    "model = np.load(fileid)['model'][0]\n",
    "modelb = np.load(fileidb)['model'][0]\n",
    "model5 = np.load(fileid5)['model'][0]\n",
    "model5b = np.load(fileid5b)['model'][0]\n",
    "Yout = model.predict(X[0])\n",
    "Youtb = modelb.predict(Xsp[0][:,-window-2:-window/2-1])\n",
    "Yout5 = model5.predict(Xsp[0])\n",
    "Yout5b = model5b.predict(Xsp[0][:,-window-2:-window/2-1])\n",
    "print Yout.shape, Yout5.shape, Yout5b.shape\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('axes', linewidth=2)\n",
    "plt.rc('font', weight='bold')\n",
    "plt.rcParams['text.latex.preamble'] = [r'\\usepackage{sfmath} \\boldmath']\n",
    "offset = 2000-window\n",
    "endset = 2650\n",
    "skipf = 20\n",
    "skipy = 15\n",
    "ax = plt.figure(figsize=(20,10))\n",
    "tf = np.linalg.norm(f[0][offset+window::skipf,:3][:endset],axis=1)\n",
    "p1, = plt.plot(tf/max(tf),linewidth=5)\n",
    "ty = Yout[offset/skipf:][:endset]+0.02\n",
    "print tf.shape, ty.shape\n",
    "p = plt.scatter(range(len(tf))[::skipy],ty[::skipy],color='red',s=30)\n",
    "plt.hold\n",
    "plt.text(100, 0.15, r'\\textbf{Stable}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.text(1000, 0.85, r'\\textbf{Slip}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.annotate('', fontsize=10, xy=(100, 0.05), xytext=(100, 0.12),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.annotate('', xy=(1000, 0.98), xytext=(1000, 0.9),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.text(400, 0.55, r'\\textbf{P1}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=810,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(1000, 0.55, r'\\textbf{P2}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=1200,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(1250, 0.55, r'\\textbf{P3}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=1335,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(1385, 0.25, r'\\textbf{P4}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=1445,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(1650, 0.55, r'\\textbf{P1}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=1830,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(2000, 0.55, r'\\textbf{P2}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=2200,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(2250, 0.55, r'\\textbf{P3}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=2330,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(2385, 0.25, r'\\textbf{P4}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=2440,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(2540, 0.55, r'\\textbf{P1}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.xlabel(r't ($1e^{-2} sec$)',fontsize=35)\n",
    "plt.yticks([])\n",
    "plt.legend([p1,p],[r'$|\\textbf{f}|$',r'\\textbf{out1}'],loc=2, prop={'size': 35})\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.tight_layout()\n",
    "savefig(datapath+'validation.pdf', bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
