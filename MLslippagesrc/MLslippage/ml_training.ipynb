{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mainly Edited for private usage by:  Ioannis Agriomallos\n",
      "                                        Ioanna Mitsioni\n",
      "License: BSD 3 clause\n",
      "\n",
      "============= CURRENT CODE USAGE =============\n",
      "Current code trains MLP Classifiers, to classify force input samples as stable (0) or slip (1)\n",
      "---- Input\n",
      "-> Input samples originate from optoforce sensors and are 3D (fx,fy,fz) and come from 2 different datasets, \n",
      "   one training, containing several surfaces as well as slip-stable occurrences, \n",
      "   and one validation, containing 1 surface with slip-stable occurrences on a completely unseen task-setup.\n",
      "---- Input transformation\n",
      "-> Several pre-features can be taken from these inputs, but here |f| is kept.\n",
      "-> Several time and frequency domain features are extracted from pre-feature windows. \n",
      "  (implemented in 'featext.py') These windows have size w and are shifted by s on each sample\n",
      "-> Then a feature selection-ranking is performed using MutualVariableInformation\n",
      "-> Finally PCA is performed to keep a reduced set among the best selected features\n",
      "---- Training of ML Classifiers\n",
      "-> Several MLP Classifiers are trained for all combinations of selected featuresets-datasets\n",
      "---- Results\n",
      "-> Stats of classification results are kept inside each .npz along with the respective trained model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Mainly Edited for private usage by:  Ioannis Agriomallos\n",
    "                                        Ioanna Mitsioni\n",
    "License: BSD 3 clause\n",
    "\n",
    "============= CURRENT CODE USAGE =============\n",
    "Current code trains MLP Classifiers, to classify force input samples as stable (0) or slip (1)\n",
    "---- Input\n",
    "-> Input samples originate from optoforce sensors and are 3D (fx,fy,fz) and come from 2 different datasets, \n",
    "   one training, containing several surfaces as well as slip-stable occurrences, \n",
    "   and one validation, containing 1 surface with slip-stable occurrences on a completely unseen task-setup.\n",
    "---- Input transformation\n",
    "-> Several pre-features can be taken from these inputs, but here |f| is kept.\n",
    "-> Several time and frequency domain features are extracted from pre-feature windows. \n",
    "  (implemented in 'featext.py') These windows have size w and are shifted by s on each sample\n",
    "-> Then a feature selection-ranking is performed using MutualVariableInformation\n",
    "-> Finally PCA is performed to keep a reduced set among the best selected features\n",
    "---- Training of ML Classifiers\n",
    "-> Several MLP Classifiers are trained for all combinations of selected featuresets-datasets\n",
    "---- Results\n",
    "-> Stats of classification results are kept inside each .npz along with the respective trained model\n",
    "\"\"\"\n",
    "print(__doc__)\n",
    "import time\n",
    "start_time = time.time()\n",
    "from copy import deepcopy, copy\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import shutil\n",
    "import os, errno\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "from featext import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# %matplotlib qt\n",
    "# inline (suitable for ipython only, shown inside browser!) or qt (suitable in general, shown in external window!)\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import re\n",
    "import datetime\n",
    "import urllib\n",
    "import tarfile\n",
    "import zipfile\n",
    "import joblib\n",
    "from subprocess import call, check_output\n",
    "from joblib import Parallel, delayed, Memory\n",
    "from tempfile import mkdtemp\n",
    "import copy_reg\n",
    "import types\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "def _pickle_method(m):\n",
    "    \"\"\"Useful function for successful convertion from directories and lists to numpy arrays\"\"\"\n",
    "    if m.im_self is None:\n",
    "        return getattr, (m.im_class, m.im_func.func_name)\n",
    "    else:\n",
    "        return getattr, (m.im_self, m.im_func.func_name)\n",
    "copy_reg.pickle(types.MethodType, _pickle_method)\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    \"\"\"Useful function for creating directory only if not existent\"\"\"\n",
    "    try:\n",
    "        os.makedirs(directory)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "h = .2  # step size in the mesh\n",
    "\n",
    "######## TRAINING DEFAULTS\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ;\n",
    "decomp = PCA(n_components=20)\n",
    "names = [\"NearNb\", \"RBFSVM1\", \"MLP1\", \"RandFor\"]\n",
    "classifiers = [KNeighborsClassifier(5),\n",
    "               SVC(gamma='auto', C=1),\n",
    "               MLPClassifier(solver='lbfgs',alpha=1e-4,hidden_layer_sizes=(10,10),random_state=1,verbose=True),\n",
    "               RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)]\n",
    "\n",
    "download = 1            # Download pre-computed (1) data or compute them all anew (0)\n",
    "delete_big_features = 0 # Delete (1) or keep (0) computed big-in-size features, \n",
    "                        # helping mainly to avoid several computations when recomputing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ INITIALISATION PARAMETERS ############\n",
    "window, shift = 1024, 20\n",
    "samplesperdataset = 10000\n",
    "havelabel = 1\n",
    "returntime = 0\n",
    "featlabel = 0         # 0: all features, 1: temporal, 2: frequency, 3: FFT only\n",
    "magnFFT = 0           # 0: FFT in magnitude format, 1: FFT in real and imag format, \n",
    "featall = 0           # 0: all, 1: feat1 (phinyomark's), 2: feat2 (golz's)\n",
    "featparam = [havelabel,featlabel,magnFFT,featall,returntime]\n",
    "CV = 5                # cross validation checks\n",
    "numfeat = 10          # number of features to show\n",
    "nfeat = 1000          # number of features to keep\n",
    "###### Initialize necessary names and paths\n",
    "datapath = 'data/'\n",
    "ensure_dir(datapath)\n",
    "datafile = datapath+'dataset.npz'\n",
    "validfile = datapath+'validation.mat'\n",
    "featpath = datapath+'features/'+str(window)+'_'+str(shift)+'/'\n",
    "ensure_dir(featpath)\n",
    "allfeatpath = featpath+'AllFeatures/'\n",
    "ensure_dir(allfeatpath)\n",
    "prefeatname = 'prefeatures'+'_'+str(window)+'_'+str(shift)+'_'+str(samplesperdataset)\n",
    "prefeatfile = featpath+prefeatname+'.npz'\n",
    "featname = 'features'+'_'+str(window)+'_'+str(shift)+'_'+str(samplesperdataset)\n",
    "featfile = featpath+featname+'.npz'\n",
    "validfeatname = 'valid'+featname\n",
    "validfeatfile = featpath+validfeatname+'.npz'\n",
    "surffile = featpath+featname+'_2fing_6surf.npz'\n",
    "XYfile = featpath+featname+'_XY.npz'\n",
    "XYsplitfile = featpath+featname+'_XYsplit.npz'\n",
    "validsurffile = featpath+validfeatname+'_2fing_6surf.npz'\n",
    "validXYfile = featpath+validfeatname+'_XY.npz'\n",
    "validXYsplitfile = featpath+validfeatname+'_XYsplit.npz'\n",
    "respath = datapath+'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Feature Names ############\n",
    "\"\"\"features:                                                                       ||      if       \n",
    "   |--> time domain      :                                                         || samples = 1024\n",
    "   |----|---> phinyomark : 11+3{shist} --------------------------> = 14+0.0samples ||             14\n",
    "   |----|---> golz       : 10+samples{acrol} --------------------> = 10+1.0samples ||           1034\n",
    "   |--> frequency domain :                                                                          \n",
    "   |----|---> phinyomark : 3{arco}+4{mf}+2(samples/2+1){RF,IF} --> =  9+1.0samples ||           1033\n",
    "   |----|---> golz       : 2(samples/2+1){AF,PF} ----------------> =  2+1.0samples ||           1026\n",
    "   |----|----------------|-------alltogether---------------------> = 35+3.0samples || numfeat = 3107\n",
    "\"\"\"\n",
    "## Time Domain Phinyomark feats\n",
    "featnames = ['intsgnl', 'meanabs', 'meanabsslp', 'ssi', 'var', 'rms', 'rng', 'wavl', 'zerox', 'ssc', 'wamp', \n",
    "             'shist1', 'shist2', 'shist3']                                                   # 11+3{shist}\n",
    "## Frequency Domain Phinyomark feats\n",
    "featnames += ['arco1', 'arco2', 'arco3', 'mnf', 'mdf', 'mmnf', 'mmdf']                       # 3{arco}+4{mf}\n",
    "featnames += ['reFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{RF}\n",
    "featnames += ['imFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{IF}\n",
    "## Time Domain Golz feats\n",
    "featnames += ['meanv', 'stdr', 'mx', 'rngx', 'rngy', 'med', 'hjorth', 'sentr', 'se', 'ssk']  # 10\n",
    "featnames += ['acrol{:04d}'.format(i) for i in range(window)]                                # samples{acrol}\n",
    "## Frequency Domain Golz feats\n",
    "featnames += ['amFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{AF}\n",
    "featnames += ['phFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{PF}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessary  data/dataset.npz  already here!\n",
      "Necessary  data/validation.mat  already here!\n",
      "Necessary  data/features/1024_20/features_1024_20_10000.npz  already here!\n",
      "Necessary  data/features/1024_20/validfeatures_1024_20_10000.npz  already here!\n",
      "Desired trained models for 1 surface found!\n",
      "Desired trained models for 2 surface found!\n",
      "Desired trained models for 3 surface found!\n",
      "Desired trained models for 4 surface found!\n",
      "Desired trained models for 5 surface found!\n",
      "Downloaded 1.2 GB of content in total!\n"
     ]
    }
   ],
   "source": [
    "############ Download necessary files ############\n",
    "def convert_bytes(num):\n",
    "    \"\"\"this function will convert bytes to MB.... GB... etc\"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "def file_size(file_path):\n",
    "    \"\"\"this function will return the file size\"\"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        file_info = os.stat(file_path)\n",
    "        return file_info.st_size\n",
    "    \n",
    "def download_file(datafile, targetlink):\n",
    "    \"\"\"Function for checking if targetfile exists, else downloading it from targetlink to targetpath+targetfile\"\"\"\n",
    "    if not os.path.isfile(datafile):\n",
    "        print 'Necessary ', datafile, ' not here! Downloading...'\n",
    "        u = urllib.urlopen(targetlink)\n",
    "        data = u.read()\n",
    "        print 'Completed downloading ','{:.2f}'.format(len(data)*1./(1024**2)),'MB of ',datafile,'!'\n",
    "        u.close()\n",
    "        with open(datafile, \"wb\") as f :\n",
    "            f.write(data)\n",
    "        print 'Necessary ', datafile, ' completed saving!'\n",
    "    else:\n",
    "        print 'Necessary ', datafile, ' already here!'\n",
    "    return file_size(datafile)\n",
    "\n",
    "def extract_file(source,destination='.'):\n",
    "    \"\"\"Decompress source zip, tar or tgz file to destination folder\"\"\"\n",
    "    print \"Extracting compressed file...\"\n",
    "    if (source.endswith('tar.gz') or source.endswith('tgz')):\n",
    "        with tarfile.open(source, 'r:gz' ) as tgz_ref:\n",
    "            tgz_ref.extractall(destination)\n",
    "        print \"Done!\"\n",
    "    elif (source.endswith('tar')):\n",
    "        with tarfile.open(source, 'r:' ) as tar_ref:\n",
    "            tar_ref.extractall(destination)\n",
    "        print \"Done!\"\n",
    "    elif (source.endswith('zip')):\n",
    "        with zipfile.ZipFile(source, 'r') as zip_ref:\n",
    "            zip_ref.extractall(destination)\n",
    "        print \"Done!\"\n",
    "    else:\n",
    "        print \"Unsupported extension for decompressing. Supported extensions are .zip, .tgz, .tar.gz, .tar\"\n",
    "        \n",
    "####### Download necessary dataset\n",
    "total_size_of_downloads = 0\n",
    "datafile = datapath+'dataset.npz'\n",
    "validfile = datapath+'validation.mat'\n",
    "datalink = 'https://www.dropbox.com/s/j88wmtx1vvpik1m/dataset.npz?dl=1'\n",
    "validlink = 'https://www.dropbox.com/s/r8jl57lij28ljrw/validation.mat?dl=1'\n",
    "total_size_of_downloads += download_file(datafile, datalink)\n",
    "total_size_of_downloads += download_file(validfile, validlink)\n",
    "####### Download bargraph tool if not already downloaded (by Derek Bruening)\n",
    "toollink = 'https://github.com/derekbruening/bargraph/archive/rel_4_8.zip'\n",
    "toolfile = datapath+'bargraph.zip'\n",
    "toolpath = datapath+'bargraph-rel_4_8/'\n",
    "if not os.path.isdir(toolpath):\n",
    "    total_size_of_downloads += download_file(toolfile, toollink)\n",
    "    if os.path.isfile(toolfile):\n",
    "        extract_file(toolfile,datapath+'.')\n",
    "tool = './'+toolpath+'bargraph.pl'\n",
    "call(['chmod','+x',tool]) # make tool executable\n",
    "call(['rm',toolfile]) # delete zip file\n",
    "####### Download features and trained models, if not wanting to compute them and not already there\n",
    "if download==1:\n",
    "    featlink = 'https://www.dropbox.com/s/qvk9pcvlir06zse/features_1024_20_10000.npz?dl=1'\n",
    "    validfeatlink = 'https://www.dropbox.com/s/sghqwifo8rxwbcs/validfeatures_1024_20_10000.npz?dl=1'\n",
    "    total_size_of_downloads += download_file(featfile, featlink)\n",
    "    total_size_of_downloads += download_file(validfeatfile, validfeatlink)\n",
    "    reslink = {}\n",
    "    reslink[0] = 'https://www.dropbox.com/sh/mib7wk4sfv6eye3/AACUWSOgQjBD9i2sChtNisNKa?dl=1'\n",
    "    reslink[1] = 'https://www.dropbox.com/sh/y6js9ha585n4zam/AACARvB8krZnC3VPsOjWTaRra?dl=1'\n",
    "    reslink[2] = 'https://www.dropbox.com/sh/fc9jgi2cs7d0dzg/AADfw42xG0XtiUOYWo7cmmtUa?dl=1'\n",
    "    reslink[3] = 'https://www.dropbox.com/sh/mx6e7jcxzbcr5s4/AACkVMPatRd2UZfyUkxvP_tLa?dl=1'\n",
    "    reslink[4] = 'https://www.dropbox.com/sh/88itj3b4nwpe0f1/AACceO9FsZp5w55n7PKlVnWSa?dl=1'\n",
    "    for i in range(len(reslink)):\n",
    "        resfold = datapath+'results'+str(i+1)\n",
    "        if not os.path.isdir(resfold):\n",
    "            resfile = resfold+'.zip'\n",
    "            total_size_of_downloads += download_file(resfile, reslink[i]) # download\n",
    "            extract_file(resfile, resfold) # extract\n",
    "            call(['rm',resfile]) # delete zip\n",
    "        else:\n",
    "            print \"Desired trained models for \"+str(i+1)+\" surface found!\"\n",
    "print \"Downloaded \"+convert_bytes(total_size_of_downloads)+\" of content in total!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############ READ THE DATASET ############\n",
    "def data_prep(datafile,step=1,k=2):\n",
    "    \"\"\"Prepare dataset, from each of the k fingers for all n surfaces (see fd for details)\n",
    "    -> datafile : input file either in .npz or in .mat form\n",
    "    -> step     : increasing sampling step, decreases sampling frequency of input, which is 1KHz initially\n",
    "    -> k        : number of fingers logging data\n",
    "    ----- input format ----- either 'fi', 'li', 'fdi', with i in {1,...,k} for each finger\n",
    "                             or     'f', 'l', 'fd' for a finger\n",
    "                             corresponding to force, label and details respectively\n",
    "    <- f,l,fd   : output force, label and details for each experiment in the dataset\n",
    "    <- member   : how much each dataset is represented, \n",
    "                  to skip samples effectively and keep dimensions correct\n",
    "    <- m1, m2   : portion of data belonging to finger1 and finger2\n",
    "    \"\"\"\n",
    "    print \"---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\"\n",
    "    if datafile[-3:]=='mat':\n",
    "        inp = sio.loadmat(datafile,struct_as_record=True)\n",
    "    elif datafile[-3:]=='npz':\n",
    "        inp = np.load(datafile)\n",
    "    else:\n",
    "        print \"Unsupported input file format. Supported types: .npz .mat\"\n",
    "        return -1\n",
    "    if k==2:\n",
    "        f1, f2, l1, l2, fd1, fd2 = inp['f1'], inp['f2'], inp['l1'], inp['l2'], inp['fd1'], inp['fd2']\n",
    "        print 1, '-> f1:', f1.shape, l1.shape, fd1.shape\n",
    "        print 2, '-> f2:', f2.shape, l2.shape, fd2.shape\n",
    "        ####### MERGE THE DATASETS\n",
    "        f = np.concatenate((f1,f2),axis=0)\n",
    "        l = np.concatenate((l1,l2),axis=0)\n",
    "        fd = np.concatenate((fd2,fd2),axis=0)\n",
    "    elif k==1:\n",
    "        f, l, fd = inp['f'], inp['l'], inp['fd']\n",
    "    else:\n",
    "        print \"Unsupported number of fingers k. Should be k in {1,2}\"\n",
    "    print 3, '-> f:', f.shape, l.shape, fd.shape\n",
    "    # membership of each sample, representing its portion in the dataset \n",
    "    # (first half finger1 and second half finger2)\n",
    "    member = np.zeros(len(f))\n",
    "    m1,m2 = len(f)/2, len(f)/2\n",
    "    member[:m1] = np.ones(m1)*1./m1\n",
    "    member[-m2:] = np.ones(m2)*1./m2\n",
    "    print 4, '-> m1,m2:', m1, m2, sum(member[:m1]), sum(member[-m2:])\n",
    "    ####### MERGE f and l\n",
    "    while f.ndim>1:\n",
    "        f = f[:,0]\n",
    "        l = l[:,0]\n",
    "    for i in range(len(f)):\n",
    "        while l[i].ndim<2:\n",
    "            l[i] = l[i][:,np.newaxis]\n",
    "    f = np.array([np.concatenate((f[i],l[i]),axis=1) for i in range(len(f))])\n",
    "    print 5, '-> f=f+l:', f.shape, \":\", [fi.shape for fi in f]\n",
    "    ####### SUBSAMPLING\n",
    "    # step = 1 # NO SAMPLING\n",
    "    if step!=1:\n",
    "        f = np.array([fi[::step,:] for fi in f])\n",
    "        print 6, '-> fsampled:',f.shape, \":\", [fi.shape for fi in f]\n",
    "    return f,l,fd,member,m1,m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ PRE-FEATURES ############\n",
    "###### DEFINITION\n",
    "# featnum 0 : sf    = (fx^2+fy^2+fz^2)^0.5\n",
    "#         1 : ft    = (fx^2+fy^2)^0.5\n",
    "#         2 : fn    = |fz|\n",
    "#         3 : ft/fn = (fx^2+fy^2)^0.5/|fz|\n",
    "# input (nxm) -> keep (nx3) -> compute pre-feature and return (nx1)\n",
    "\n",
    "def sf(f):\n",
    "    \"\"\"Computation of norm (sf) of force (f)\"\"\"\n",
    "    return np.power(np.sum(np.power(f[:,:3],2),axis=1),0.5)\n",
    "def ft(f):\n",
    "    \"\"\"Computation of tangential (ft) of force (f)\"\"\"\n",
    "    return np.power(np.sum(np.power(f[:,:2],2),axis=1),0.5)\n",
    "def fn(f):\n",
    "    \"\"\"Computation of normal (fn) of force (f)\"\"\"\n",
    "    return np.abs(f[:,2])\n",
    "def ftn(f):\n",
    "    \"\"\"Computation of tangential (ft) to normal (fn) ratio of force (f), \n",
    "    corresponding to the friction cone boundary\n",
    "    \"\"\"\n",
    "    retft = ft(f)\n",
    "    retfn = fn(f)\n",
    "    retft[retfn<=1e-2] = 0\n",
    "    return np.divide(retft,retfn+np.finfo(float).eps)\n",
    "def lab(f):\n",
    "    \"\"\"Label embedded in input f\"\"\"\n",
    "    return np.abs(f[:,-1])\n",
    "###### COMPUTATION\n",
    "prefeatfn = np.array([sf,ft,fn,ftn,lab]) # convert to np.array to be easily indexed by a list\n",
    "prefeatnames = np.array(['fnorm','ft','fn','ftdivfn','label'])\n",
    "prefeatid = [0,4]     # only the prefeatures with corresponding ids will be computed\n",
    "def compute_prefeat(f):\n",
    "    \"\"\"Prefeature computation\n",
    "    -> f       : input force as an i by n by 4 matrix\n",
    "    <- prefeat : corresponding force profiles\n",
    "    \"\"\"\n",
    "    print \"--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\"\n",
    "    prefeat = [np.array([prfn(f[i]) for prfn in prefeatfn[prefeatid]]).transpose() for i in range(len(f))]\n",
    "    prefeat.append(prefeat[-1][:-1])\n",
    "    prefeat = np.array(prefeat)[:-1]\n",
    "    print prefeat.shape,\":\",[p.shape for p in prefeat]\n",
    "    return prefeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ AVG Computation time of ALL features in secs ############\n",
    "def avg_feat_comp_time(prefeat):\n",
    "    \"\"\"Average computation time for feature extraction\n",
    "    -> prefeat : desired prefeature input\n",
    "    \"\"\"\n",
    "    print \"------------------------------------ AVG FEATURE COMPUTATION TIME ------------------------------------\"\n",
    "    t1 = time.time()\n",
    "    m = int(ceil(0.2*len(prefeat)))\n",
    "    # avg over m*100 times\n",
    "    tmpfeat = [feat(prefeat[k][i:i+window,:2],*featparam) for k in range(m) for i in range(100)]\n",
    "    print 'Avg feature computation time (millisec): ', (time.time() - t1) / (100 * m) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ FEATURE COMPUTATION ############\n",
    "def tmpfeatfilename(p,name,mode='all'):\n",
    "    \"\"\"Filename for feature computation and intermittent saving\n",
    "    -> p    : prefeat id\n",
    "    -> name : desired prefix name for tmp filenames\n",
    "    -> mode : whether keeping whole feature matrix ('all') or sampling rows ('red') to reduce size\n",
    "    <- corresponding output filename\n",
    "    \"\"\"\n",
    "    if mode == 'all':\n",
    "        return allfeatpath+name+str(p)+'.pkl.z'\n",
    "    elif mode == 'red':\n",
    "        return allfeatpath+name+str(p)+'_red'+str(samplesperdataset)+'.pkl.z'\n",
    "    \n",
    "def feature_extraction(prefeat, member, featfile=featfile, name='feat_'):\n",
    "    \"\"\"Computation of all features in parallel or loading if already computed\n",
    "    -> prefeat          : computed prefeatures\n",
    "    -> member           : how much each dataset is represented, \n",
    "                          to skip samples effectively and keep dimensions correct\n",
    "    -> featfile         : desired final feature filename             \n",
    "    -> name             : desired per dataset feature temporary filenames\n",
    "    <- features, labels : computed features and corresponding labels\n",
    "    \"\"\"\n",
    "    print \"---------------------------------------- FEATURE EXTRACTION ------------------------------------------\"\n",
    "    if os.path.isfile(featfile):\n",
    "        start_time = time.time()\n",
    "        features = np.load(featfile)['features']\n",
    "        labels = np.load(featfile)['labels']\n",
    "        print(\"Features FOUND PRECOMPUTED! Feature Loading DONE in: %s seconds \" % (time.time() - start_time))\n",
    "        if delete_big_features:\n",
    "            for j in glob.glob(allfeatpath+\"*\"):\n",
    "                if 'red' not in j:\n",
    "                    call(['rm',j]) # delete big feature file, after reducing its size to desired\n",
    "    else:\n",
    "        start_time = time.time()\n",
    "        features = []\n",
    "        labels = []\n",
    "        for ixp in range(len(prefeat)):\n",
    "            p = prefeat[ixp]\n",
    "            now = time.time()\n",
    "            tmpfn = tmpfeatfilename(ixp,name)\n",
    "            tmpfnred = tmpfeatfilename(ixp,name,'red')\n",
    "            if not os.path.isfile(tmpfnred):\n",
    "                if not os.path.isfile(tmpfn):\n",
    "                    # Computation of all features in PARALLEL by ALL cores\n",
    "                    tmp = np.array([Parallel(n_jobs=-1)([delayed(feat) (p[k:k+window],*featparam) \n",
    "                                                         for k in range(0,len(p)-window,shift)])])\n",
    "                    with open(tmpfn,'wb') as fo:\n",
    "                        joblib.dump(tmp,fo)\n",
    "                    print 'sample:', ixp, ', time(sec):', '{:.2f}'.format(time.time()-now), tmpfn \\\n",
    "                                                        , ' computing... ', tmp.shape\n",
    "                else:\n",
    "                    with open(tmpfn,'rb') as fo:\n",
    "                        tmp = joblib.load(fo)\n",
    "                    print 'sample:', ixp, ', time(sec):', '{:.2f}'.format(time.time()-now), tmpfn \\\n",
    "                                                        , ' already here!', tmp.shape\n",
    "                # keep less from each feature vector but keep number of samples for each dataset almost equal\n",
    "                tmpskip = int(round(tmp.shape[1]/(member[ixp]*samplesperdataset)))\n",
    "                if tmpskip == 0: \n",
    "                    tmpskip = 1\n",
    "                # Save reduced size features\n",
    "                tmp = tmp[0,::tmpskip,:,:]\n",
    "                with open(tmpfnred,'wb') as fo:\n",
    "                    joblib.dump(tmp,fo)\n",
    "                print 'sample:',ixp, ', time(sec):', '{:.2f}'.format(time.time()-now), tmpfnred, tmp.shape\n",
    "                if delete_big_features:\n",
    "                    call(['rm',tmpfn]) # delete big feature file, after reducing its size to desired\n",
    "        for ixp in range(len(prefeat)):\n",
    "            if delete_big_features:\n",
    "                tmpfn = tmpfeatfilename(ixp,name)\n",
    "                call(['rm',tmpfn]) # delete big feature file if still here for some reason\n",
    "            tmpfnred = tmpfeatfilename(ixp,name,'red')\n",
    "            with open(tmpfnred,'rb') as fo:\n",
    "                tmp = joblib.load(fo)\n",
    "            print 'sample:', ixp, ', time(sec):', '{:.2f}'.format(time.time()-now), tmpfnred, 'already here!' \\\n",
    "                                                                                  , tmp.shape\n",
    "            features.append(tmp[:,:,:-1])\n",
    "            labels.append(tmp[:,0,-1])\n",
    "        print(\"Features NOT FOUND PRECOMPUTED! Feature Computation DONE in: %s sec \" % (time.time() - start_time))\n",
    "        features.append(tmp[:-1,:,:-1])\n",
    "        features = np.array(features)[:-1]\n",
    "        labels.append(tmp[:-1,0,-1])\n",
    "        labels = np.array(labels)[:-1]\n",
    "        print 'features: ',features.shape,[ftmp.shape for ftmp in features]\n",
    "        print 'labels: ', labels.shape,[l.shape for l in labels]\n",
    "        np.savez(featfile,features=features,labels=labels)\n",
    "    print 'features: ', features.shape, ', labels: ', labels.shape\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ LABEL TRIMMING ############\n",
    "def label_cleaning(prefeat,labels,member,history=500):\n",
    "    \"\"\"Keep the purely stable and slip parts of label, thus omitting some samples around sign change points\n",
    "    -> prefeat    : computed prefeatures\n",
    "    -> labels     : main structure, where the trimming will be performed around change points\n",
    "    -> member     : how much each dataset is represented, to skip samples effectively and keep dimensions correct\n",
    "    -> history    : how much samples to throw away around change points\n",
    "    <- new_labels : the trimmed labels\n",
    "    \"\"\"\n",
    "    print \"----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\"\n",
    "    lbl_approx = []\n",
    "    for i in range(len(prefeat)):\n",
    "        tmpd = np.abs(np.diff(prefeat[i][:,-1].astype(int),n=1,axis=0))\n",
    "        if np.sum(tmpd) > 0:\n",
    "            tmpind = np.array(range(len(tmpd)))[tmpd > 0]   # find the sign change points\n",
    "            tmpindrng = []\n",
    "            for j in range(len(tmpind)):\n",
    "                length = history                # keep/throw a portion of the signal's length around change points\n",
    "                tmprng = np.array(range(tmpind[j]-length,tmpind[j]+length))\n",
    "                tmprng = tmprng[tmprng>=0]      # make sure inside singal's x-range\n",
    "                tmprng = tmprng[tmprng<prefeat[i].shape[0]]\n",
    "                tmpindrng += tmprng.tolist()\n",
    "            tmpindrng = np.array(tmpindrng).flatten()\n",
    "            tmp_lbl = deepcopy(prefeat[i][:,-1])\n",
    "            tmp_lbl[tmpindrng] = -1\n",
    "            lbl_approx.append(tmp_lbl)\n",
    "        else:\n",
    "            lbl_approx.append(prefeat[i][:,-1])\n",
    "    new_labels = deepcopy(labels)\n",
    "    for ixp in range(len(lbl_approx)):\n",
    "        p = lbl_approx[ixp]\n",
    "        tmp = np.array([p[k+window] for k in range(0,len(p)-window,shift)])\n",
    "        tmpskip = int(round(tmp.shape[0]/(member[ixp]*samplesperdataset)))\n",
    "        if tmpskip == 0: \n",
    "            tmpskip = 1\n",
    "        # Sampling appropriately\n",
    "        tmp = tmp[::tmpskip]\n",
    "        if len(tmp) > len(labels[ixp]):\n",
    "            tmp = tmp[:-1]\n",
    "        new_labels[ixp] = tmp\n",
    "    print 'new_labels: ', new_labels.shape\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ GATHERING into complete arrays ready for FITTING ############\n",
    "def computeXY(features,labels,new_labels,m1,m2,XYfile=XYfile,XYsplitfile=XYsplitfile):\n",
    "    \"\"\"\n",
    "    -> features       : computed features as input data\n",
    "    -> labels         : corresponding labels\n",
    "    -> new_labels     : labels trimmed around change point\n",
    "    -> m1, m2         : portion of data belonging to finger1 and finger2\n",
    "    -> XY[split]file  : desired output filenames\n",
    "    <- X,Y,Yn,Xsp,Ysp : X corresponds to the data, Y the label, and *sp to the trimmed label's versions\n",
    "    \"\"\"\n",
    "    print \"----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\"\n",
    "    if os.path.isfile(XYfile) and os.path.isfile(XYsplitfile):\n",
    "        X = np.load(XYfile)['X']\n",
    "        Y = np.load(XYfile)['Y']\n",
    "        Yn = np.load(XYfile)['Yn']\n",
    "        Xsp = np.load(XYsplitfile)['X']\n",
    "        Ysp = np.load(XYsplitfile)['Y']\n",
    "        print(\"XY files FOUND PRECOMPUTED!\")\n",
    "    else:\n",
    "        # gathering features X,Xsp and labels Y,Ysp,Yn into one array each\n",
    "        ind,X,Xsp,Y,Ysp,Yn = {},{},{},{},{},{}\n",
    "        ind[2] = range(features.shape[0])                                      # indeces for both fingers\n",
    "        ind[0] = range(features.shape[0])[:m1]                                 # indeces for finger1\n",
    "        ind[1] = range(features.shape[0])[-m2:]                                # indeces for finger2\n",
    "        ind = np.array([i for _,i in ind.items()])                             # convert to array\n",
    "        for k in range(len(ind)):\n",
    "            X[k] = features[ind[k]]                                            # input feature matrix\n",
    "            Y[k] = labels[ind[k]]                                              # output label vector\n",
    "            Yn[k] = new_labels[ind[k]]                                         # output new_label vector\n",
    "            print 'Before -> X[',k,']: ',X[k].shape,', Y[',k,']: ',Y[k].shape,', Yn[',k,']: ',Yn[k].shape\n",
    "            X[k] = np.concatenate(X[k],axis=0)\n",
    "            Y[k] = np.concatenate(Y[k],axis=0)\n",
    "            Yn[k] = np.concatenate(Yn[k],axis=0)\n",
    "            print 'Gathered -> X[',k,']: ',X[k].shape,', Y[',k,']: ',Y[k].shape,', Yn[',k,']: ',Yn[k].shape\n",
    "            X[k] = np.array([X[k][:,:,i] for i in range(X[k].shape[2])])\n",
    "            tmp_sampling = int(round(X[k].shape[1]*1./samplesperdataset))\n",
    "            if tmp_sampling == 0:\n",
    "                tmp_sampling = 1\n",
    "            X[k] = X[k][0,::tmp_sampling,:]\n",
    "            Y[k] = Y[k][::tmp_sampling]\n",
    "            Yn[k] = Yn[k][::tmp_sampling]\n",
    "            print 'Gathered, sampled to max ', samplesperdataset, ' -> X[', k,']: ', X[k].shape, ', Y[', k \\\n",
    "                                             , ']: ', Y[k].shape, ', Yn[', k,']: ', Yn[k].shape\n",
    "            keepind = Yn[k]>=0\n",
    "            Xsp[k] = X[k][keepind,:]\n",
    "            Ysp[k] = Yn[k][keepind]\n",
    "            print 'Split -> Xsp[',k,']: ',Xsp[k].shape,', Ysp[',k,']: ',Ysp[k].shape\n",
    "        X = np.array([i for _,i in X.items()])\n",
    "        Xsp = np.array([i for _,i in Xsp.items()])\n",
    "        Y = np.array([i for _,i in Y.items()])\n",
    "        Ysp = np.array([i for _,i in Ysp.items()])\n",
    "        Yn = np.array([i for _,i in Yn.items()])\n",
    "        np.savez(XYfile,X=X,Y=Y,Yn=Yn)\n",
    "        np.savez(XYsplitfile, X=Xsp, Y=Ysp)\n",
    "    print 'X,Y [0,1,2]: ', X[0].shape, Y[0].shape, X[1].shape, Y[1].shape, X[2].shape, Y[2].shape\n",
    "    print 'Xsp,Ysp [0,1,2]: ', Xsp[0].shape, Ysp[0].shape, Xsp[1].shape, Ysp[1].shape, Xsp[2].shape, Ysp[2].shape\n",
    "    return X,Y,Yn,Xsp,Ysp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Prepare the indeces for each feature ############\n",
    "def get_feat_id(feat_ind, printit=0, sample_window=window): \n",
    "    \"\"\"Find the corresponding indeces of the desired features inside feature vector,\n",
    "    and link them with their names and level of abstraction\n",
    "    -> feat_ind        : range of indeces\n",
    "    -> printit         : print output indeces (1) or not (0)\n",
    "    -> sample_window   : parameter for accurate computation of feature indeces\n",
    "    <- full_path_id    : indeces of all features\n",
    "    <- norm_time_feats : indeces of time features\n",
    "    <- norm_freq_feats : indeces of frequency features\n",
    "    \"\"\"\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "    norm_time_phin = range(0,14)\n",
    "    norm_freq_phin = range(norm_time_phin[-1] + 1, norm_time_phin[-1] + 9 + sample_window + 1)\n",
    "    norm_time_golz = range(norm_freq_phin[-1] + 1, norm_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    norm_freq_golz = range(norm_time_golz[-1] + 1, norm_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    norm_time_feats = norm_time_phin + norm_time_golz\n",
    "    norm_freq_feats = norm_freq_phin + norm_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    norm_feats = norm_time_feats + norm_freq_feats\n",
    "\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "    disp = norm_feats[-1]+1\n",
    "    ftfn_time_phin = range(disp ,disp + 14)\n",
    "    ftfn_freq_phin = range(ftfn_time_phin[-1] + 1, ftfn_time_phin[-1] + 9 + sample_window + 1)\n",
    "    ftfn_time_golz = range(ftfn_freq_phin[-1] + 1, ftfn_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    ftfn_freq_golz = range(ftfn_time_golz[-1] + 1, ftfn_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    ftfn_time_feats = ftfn_time_phin + ftfn_time_golz\n",
    "    ftfn_freq_feats = ftfn_freq_phin + ftfn_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    ftfn_feats = ftfn_time_feats + ftfn_freq_feats\n",
    "\n",
    "    # create the final \"reference dictionary\"\n",
    "    # 3 np.arrays, id_list[0] = level 1 etc\n",
    "    id_list = [np.zeros((len(ftfn_feats + norm_feats),1)) for i in range(3)]\n",
    "    id_list[0][:norm_feats[-1]+1] = 0 # 0 signifies norm / 1 signifies ft/fn\n",
    "    id_list[0][norm_feats[-1]+1:] = 1\n",
    "\n",
    "    id_list[1][:norm_time_phin[-1]+1] = 0 # 0 signifies time / 1 signifies freq\n",
    "    id_list[1][norm_time_phin[-1]+1:norm_freq_phin[-1]+1] = 1\n",
    "    id_list[1][norm_freq_phin[-1]+1:norm_time_golz[-1]+1] = 0\n",
    "    id_list[1][norm_time_golz[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[1][norm_freq_golz[-1]+1:ftfn_time_phin[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_phin[-1]+1:ftfn_freq_phin[-1]+1] = 1\n",
    "    id_list[1][ftfn_freq_phin[-1]+1:ftfn_time_golz[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_golz[-1]+1:] = 1\n",
    "\n",
    "    id_list[2][:norm_freq_phin[-1]+1] = 0 #0 signifies phinyomark / 1 signifies golz\n",
    "    id_list[2][norm_freq_phin[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[2][norm_freq_golz[-1]+1:ftfn_freq_phin[-1]+1] = 0\n",
    "    id_list[2][ftfn_freq_phin[-1]+1:] = 1 \n",
    "    \n",
    "    full_path_id = [np.zeros((len(feat_ind),5)) for i in range(len(feat_ind))]\n",
    "   \n",
    "    for ind, val in enumerate(feat_ind):\n",
    "        full_path_id[ind] = [val, id_list[2][val], id_list[1][val], id_list[0][val]]\n",
    "        if (printit==1):\n",
    "            if(full_path_id[ind][1]==0):\n",
    "                lvl3 = 'Phin'\n",
    "            else:\n",
    "                lvl3 = 'Golz'\n",
    "            if(full_path_id[ind][2]==0):\n",
    "                lvl2 = 'Time'\n",
    "            else:\n",
    "                lvl2 = 'Freq'\n",
    "            if(full_path_id[ind][3]==0):\n",
    "                lvl1 = 'Norm'\n",
    "            else:\n",
    "                lvl1 = 'Ft/Fn'\n",
    "            print(feat_ind[ind],featnames[val%(norm_feats[-1]+1)],lvl3,lvl2,lvl1)\n",
    "    \n",
    "    return(full_path_id,norm_time_feats,norm_freq_feats)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Surface Splitting ############\n",
    "def surface_split(data_X, data_Y, n=6, k=2):\n",
    "    \"\"\"Split input data in k*n equal slices which represent n different surfaces sampled from k fingers.\n",
    "    Indexes 0:n:(k-1)*n, 1:n:(k-1)*n+1, 2:n:(k-1)*n+2, ... correspond to the same surface (finger1 upto fingerk)\n",
    "    Assuming k=2, namely 2 fingers case, unless stated differently\n",
    "    -> data_X, data_Y        : input data and labels, with the convention that data_X contains k*n almost \n",
    "                               equally sized data, where the n first are acquired from finger1 ... \n",
    "                               and the n last from fingerk. \n",
    "    -> n                     : number of different surfaces\n",
    "    -> k                     : number of fingers logging data\n",
    "    <- surfaces, surf_labels : corresponding output data and labels\n",
    "    \"\"\"\n",
    "    keep = data_X.shape[0]-np.mod(data_X.shape[0],k*n)\n",
    "    surfaces_pre = np.array(np.split(data_X[:keep,:],k*n))\n",
    "    surf_labels_pre = np.array(np.split(data_Y[:keep],k*n))\n",
    "    surfaces, surf_labels = {},{}\n",
    "    for i in range(n):\n",
    "        inds = range(i,k*n,n)\n",
    "        surfaces[inds[0]] = surfaces_pre[inds[0]]\n",
    "        surf_labels[inds[0]] = surf_labels_pre[inds[0]]\n",
    "        for tk in range(k-1):\n",
    "            surfaces[inds[0]] = np.concatenate((surfaces[inds[0]], surfaces_pre[inds[tk+1]]), axis = 0)\n",
    "            surf_labels[inds[0]] = np.concatenate((surf_labels[inds[0]], surf_labels_pre[inds[tk+1]]), axis = 0)\n",
    "    surfaces = np.array([i for _,i in surfaces.items()])\n",
    "    surf_labels = np.array([i for _,i in surf_labels.items()])\n",
    "    return surfaces, surf_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Featureset Splitting ############\n",
    "subfeats = ['AFFT','FREQ','TIME','BOTH']\n",
    "def feat_subsets(data,fs_ind,ofs=len(featnames)):\n",
    "    \"\"\"returns a splitting per featureset of input features\n",
    "    -> data                                : input data X\n",
    "    -> fs_ind                              : prefeature id\n",
    "    -> ofs                                 : number of features in total\n",
    "    <- X_amfft, X_freq_all, X_time, X_both : split featuresets amplitude of FFT, all time only,\n",
    "                                                               all frequency only and all features\n",
    "    \"\"\"\n",
    "    _,tf,ff = get_feat_id(range(ofs))\n",
    "    amfft_inds = []\n",
    "    temp1 = deepcopy(data)\n",
    "    \n",
    "    for i in range(len(featnames)):\n",
    "        if (featnames[i].startswith('amFFT')):\n",
    "            amfft_inds.append(i)\n",
    "\n",
    "    if (fs_ind == 2):\n",
    "        ff2 = [ff[i]+ofs for i in range(len(ff))]\n",
    "        tf2 = [tf[i]+ofs for i in range(len(tf))]\n",
    "        amfft2 = [amfft_inds[i]+ofs for i in range(len(amfft_inds))]\n",
    "        freqf = ff2 + ff\n",
    "        timef = tf2 + tf\n",
    "        amfft = amfft_inds + amfft2\n",
    "    else:\n",
    "        freqf = ff\n",
    "        timef = tf\n",
    "        amfft = amfft_inds\n",
    "\n",
    "    X_amfft = temp1[:,amfft]\n",
    "    X_time = np.delete(temp1,freqf,axis=1)\n",
    "    X_freq_all = np.delete(temp1,timef,axis=1)\n",
    "    X_both = data\n",
    "    return X_amfft, X_freq_all, X_time, X_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Prepare the dataset split for each surface ############\n",
    "def computeXY_persurf(Xsp, Ysp, surffile=surffile, n=6, k=2):\n",
    "    \"\"\"returns a split per surface data and label of inputs\n",
    "    -> Xsp, Ysp     : input data and labels, after having trimmed data around the label's change points\n",
    "    -> surffile     : desired output's filename for saving\n",
    "    <- surf, surfla : output data and label, split per surface\n",
    "    \"\"\"\n",
    "    print \"------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\"\n",
    "    if os.path.isfile(surffile):\n",
    "        surf = np.load(surffile)['surf']       # input array containing computed features for each surface\n",
    "        surfla = np.load(surffile)['surfla']   # corresponding label\n",
    "    else:\n",
    "        surf, surfla = [], []\n",
    "        for i in range(len(prefeatid)-1): # for each featureset (corresponding to each prefeature, here only |f|)\n",
    "            surf1, surfla1 = surface_split(Xsp[2], Ysp[2], n, k)\n",
    "            tmpsurf = deepcopy(surf1)\n",
    "            tmpsurfla = deepcopy(surfla1)\n",
    "            tmpsurfsubfeat = []\n",
    "            for j in range(tmpsurf.shape[0]+1): # for each surface\n",
    "                print i,j,surf1.shape\n",
    "                if j == tmpsurf.shape[0]:\n",
    "                    # ommit a sample for converting to array\n",
    "                    tmpsurfsubfeat.append(feat_subsets(tmpsurf[j-1,:-1,:],i))\n",
    "                else:\n",
    "                    # keep all subfeaturesets\n",
    "                    tmpsurfsubfeat.append(feat_subsets(tmpsurf[j],i))\n",
    "            surf.append(tmpsurfsubfeat)\n",
    "            surfla.append(surfla1)\n",
    "        # surf dims: (featuresets, surfaces, prefeaturesets) with each one enclosing (samples, features)\n",
    "        surf = np.array(surf).transpose()[:,:-1,:]\n",
    "        # surfla dims: (samples, surfaces, prefeaturesets)\n",
    "        surfla = np.array(surfla).transpose()\n",
    "        np.savez(surffile,surf=surf,surfla=surfla)\n",
    "    print surf.shape, surfla.shape\n",
    "    return surf, surfla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ PIPELINE OF TRANSFORMATIONS ############\n",
    "def make_pipe_clf(scaler,feature_selection,decomp,clf):\n",
    "    \"\"\"returns a pipeline of inputs: \n",
    "    -> scaler            : first normalize\n",
    "    -> feature_selection : then perform feature selection\n",
    "    -> decomp            : followed by PCA \n",
    "    -> clf               : and finally the desired classifier\n",
    "    <- pipeline          : output pipeline\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline([('scaler', scaler),\n",
    "                         ('feature_selection', feature_selection),\n",
    "                         ('decomp', decomp),         \n",
    "                         ('classifier', clf) ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comb(n,r):\n",
    "    \"\"\"Combinations of n objects by r, namely picking r among n possible.\n",
    "    comb(n,r) = n!/(r!(n-r)!)\n",
    "    \"\"\"\n",
    "    return math.factorial(n)/(math.factorial(r)*math.factorial(n-r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ TRAINING with 1 surface each time, out of 6 surfaces in total ##############\n",
    "def filename1(i,j,k,l,retpath=0):\n",
    "    \"\"\"function for the filename of the selected combination for training per 1 surface\n",
    "    -> i : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> k : surface id trained on\n",
    "    -> l : surface id tested on\n",
    "    <- filename\n",
    "    \"\"\"\n",
    "    filepath = respath+'1/'\n",
    "    ensure_dir(filepath)\n",
    "    if retpath:\n",
    "        return filepath\n",
    "    else:\n",
    "        return filepath+'fs_'+str(i)+'_subfs_'+str(j)+'_tr_'+str(k)+'_ts_'+str(l)+'.npz'\n",
    "\n",
    "def cross_fit1(i,j,k,kmax,l,data,labels,data2,labels2,pipe):\n",
    "    \"\"\"function for fitting model per 1 surface\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> k              : surface id trained on\n",
    "    -> kmax           : maximum surfaces\n",
    "    -> l              : surface id tested on\n",
    "    -> data, labels   : training data and labels\n",
    "    -> data2, labels2 : testing data and labels\n",
    "    -> pipe           : the desired pipeline configuration\n",
    "    <- no output, saved model and confusion matrix in corresponding filename.npz\n",
    "    \"\"\"\n",
    "    fileid = filename1(i,j,k,l)\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k,l\n",
    "        if k==l: # perform K-fold cross-validation       \n",
    "            folds = cv.split(data, labels)\n",
    "            cm_all = np.zeros((2,2))\n",
    "            for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                x_train, x_test = data[train_ind], data[test_ind]\n",
    "                y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                model = pipe.fit(x_train,y_train)\n",
    "                y_pred = model.predict(x_test)\n",
    "                cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                cm_all += cm/5.\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            # Check if model already existent, but not the cross-validated one (on the same surface)\n",
    "            model = []\n",
    "            for m in range(kmax):\n",
    "                tmpcopyfileid = filepath+filename1(i,j,k,m)+'.npz'\n",
    "                if k!=m and os.path.isfile(tmpcopyfileid):\n",
    "                    print 'Found precomputed model of '+str(k)+', tested on '+str(m)+'. Testing on '+str(l)+'...'\n",
    "                    model = np.load(tmpcopyfileid)['model'][0]\n",
    "                    break\n",
    "            if model==[]: # model not found precomputed\n",
    "                print 'Fitting on '+str(k)+', testing on '+str(l)+'...'\n",
    "                model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps1(i,j,jmax,surf,surfla):\n",
    "    \"\"\"function for helping parallelization of computations per 1 surface\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> jmax           : number of all subfeaturesets\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    \"\"\"\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k in range(surf.shape[0]): # for every training surface\n",
    "        for l in range(surf.shape[0]): # for every testing surface\n",
    "            cross_fit1(i,j,k,surf.shape[0],l,surf[k],surfla[:,k],surf[l],surfla[:,l],pipe)\n",
    "\n",
    "def train_1_surface(surf,surfla,n=-1):\n",
    "    \"\"\"Parallel training -on surface level- of all combinations on 1 surface\n",
    "    -> n              : number of cores to run in parallel, \n",
    "                        input of joblib's Parallel (n=-1 means all available cores)\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    *** Cross surface validation, TRAINING with 1 surface each time, out of 6 surfaces in total\n",
    "    total= 4 (featuresets) * [comb(6,1)*6] (surface combinations: trained on 1, tested on 1) * 1 (prefeatureset)\n",
    "         = 4*6*6*1 = 144 different runs-files.\n",
    "    Note that comb(n,r) = n!/(r!(n-r)!)\n",
    "    \"\"\"\n",
    "    print \"-------------------------- TRAINING all combinations per 1 surface -----------------------------------\"\n",
    "    for i in range(len(prefeatid)-1):\n",
    "        _ = [Parallel(n_jobs=n)([delayed(init_steps1) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) \n",
    "                                  for j in range(surf.shape[0])])]\n",
    "        \n",
    "def bargraph_perf_gen1(maxsurf):\n",
    "    \"\"\"Perf file for bargraph generation using bargraph tool, for 1 surface\"\"\"\n",
    "    print \"---------------------------- Generating perf files for 1 surface -------------------------------------\"\n",
    "    prefeats = prefeatnames[prefeatid][:-1]\n",
    "    # prefeatures, subfeatures, trained, tested, (TP,TN,FN,FP)\n",
    "    acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,4))\n",
    "    # prefeatures, subfeatures, trained, cross_val_self_accuracy, (TP,TN,FN,FP)\n",
    "    self_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,1,4))\n",
    "    # features, subfeatures, trained, (tested avg, tested std), (TP,TN,FN,FP)\n",
    "    cross_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,2,4))    \n",
    "    initial_str = \"\"\"# clustered and stacked graph data\n",
    "=stackcluster;TP;TN;FN;FP\n",
    "colors=med_blue,dark_green,yellow,red\n",
    "=nogridy\n",
    "=noupperright\n",
    "fontsz=5\n",
    "legendx=right\n",
    "legendy=center\n",
    "datascale=50\n",
    "yformat=%g%%\n",
    "xlabel=TrainedON-TestedON\n",
    "ylabel=Metrics\n",
    "=table\"\"\"\n",
    "    respath = filename1(_,_,_,_,1)\n",
    "    for i in range(len(prefeats)):\n",
    "        outname = respath+prefeats[i]\n",
    "        outfile = outname+'.perf'\n",
    "        outfile1 = outname+'_selfaccuracy.perf'\n",
    "        outfile2 = outname+'_crossaccuracy.perf'\n",
    "        out = open(outfile,'w+')\n",
    "        out.write(initial_str+\"\\n\")\n",
    "        out1 = open(outfile1,'w+')\n",
    "        out1.write(initial_str+\"\\n\")\n",
    "        out2 = open(outfile2,'w+')\n",
    "        out2.write(initial_str+\"\\n\")\n",
    "        for k in range(maxsurf):\n",
    "            for k2 in range(maxsurf):\n",
    "                out.write(\"multimulti=\"+str(k)+\"-\"+str(k2)+\"\\n\")\n",
    "                for j in range(len(subfeats)):\n",
    "                    fileid = filename1(i,j,k,k2)\n",
    "                    tmp = np.load(fileid)['cm']\n",
    "                    # print to outfile\n",
    "                    acc[i,j,k,k2,0] = round(tmp[1,1],2) # TP\n",
    "                    acc[i,j,k,k2,1] = round(tmp[0,0],2) # TN\n",
    "                    acc[i,j,k,k2,2] = 1-round(tmp[1,1],2) # FN\n",
    "                    acc[i,j,k,k2,3] = 1-round(tmp[0,0],2) # FP\n",
    "                    out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],acc[i,j,k,k2,0],acc[i,j,k,k2,1],\n",
    "                                                                        acc[i,j,k,k2,2],acc[i,j,k,k2,3]))\n",
    "                    # prepare and print to outfile1\n",
    "                    if k == k2:\n",
    "                        if j == 0:\n",
    "                            out1.write(\"multimulti=\"+str(k)+\"-\"+str(k2)+\"\\n\")\n",
    "                        self_acc[i,j,k,0,:] = acc[i,j,k,k2,:]\n",
    "                        out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],self_acc[i,j,k,0,0],\n",
    "                                                                 self_acc[i,j,k,0,1],self_acc[i,j,k,0,2],\n",
    "                                                                 self_acc[i,j,k,0,3]))\n",
    "                    # prepare and print to outfile2\n",
    "                    if k != k2:\n",
    "                        # all values of corresponding subfeatureset j have been filled to compute avg and std\n",
    "                        if (k < maxsurf-1 and k2 == maxsurf-1) or (k == maxsurf-1 and k2 == maxsurf-2):\n",
    "                            if j == 0:\n",
    "                                out2.write(\"multimulti=\"+str(k)+\"\\n\")\n",
    "                            t = range(maxsurf)\n",
    "                            t.remove(k)\n",
    "                            cross_acc[i,j,k,0,:] = np.mean(acc[i,j,k,t,:], axis=0) # avg\n",
    "                            # cross_acc[i,j,k,1,:] = np.std(acc[i,j,k,t,:], axis=0) # std\n",
    "                            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j], cross_acc[i,j,k,0,0],\n",
    "                                                                     cross_acc[i,j,k,0,1], cross_acc[i,j,k,0,2],\n",
    "                                                                     cross_acc[i,j,k,0,3]))\n",
    "        out.write(\"multimulti=AVG\\n\")\n",
    "        out1.write(\"multimulti=AVG\\n\")\n",
    "        out2.write(\"multimulti=AVG\\n\")\n",
    "        for j in range(4):\n",
    "            avgacc = np.mean(np.mean(acc[i,j,:,:,:], axis=0), axis=0)\n",
    "            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j], avgacc[0], avgacc[1], avgacc[2], avgacc[3]))\n",
    "            avgselfacc = np.mean(self_acc[i,j,:,0,:], axis=0)\n",
    "            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j], avgselfacc[0], avgselfacc[1],\n",
    "                                                                  avgselfacc[2], avgselfacc[3]))\n",
    "            avgcrossacc0 = np.mean(cross_acc[i,j,:,0,:], axis=0)\n",
    "            # avgcrossacc1 = np.std(cross_acc[i,j,:,0,:], axis=0)\n",
    "            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j], avgcrossacc0[0], avgcrossacc0[1],\n",
    "                                                                  avgcrossacc0[2], avgcrossacc0[3]))\n",
    "        out.close()\n",
    "        out1.close()\n",
    "        out2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ TRAINING with 2 surfaces each time, out of 6 surfaces in total ##############\n",
    "def filename2(i,j,k1,k2,l,retpath=0):\n",
    "    \"\"\"function for the filename of the selected combination for training per 2 surfaces\n",
    "    -> i  : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j  : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki : surface ids trained on\n",
    "    -> l  : surface id tested on\n",
    "    <- filename\n",
    "    \"\"\"\n",
    "    filepath = respath+'2/'\n",
    "    ensure_dir(filepath)\n",
    "    if retpath:\n",
    "        return filepath\n",
    "    else:\n",
    "        return filepath+'fs_'+str(i)+'_subfs_'+str(j)+'_tr1_'+str(k1)+'_tr2_'+str(k2)+'_ts_'+str(l)+'.npz'\n",
    "\n",
    "def cross_fit2(i,j,k1,k2,kmax,l,data,labels,data2,labels2,pipe):\n",
    "    \"\"\"function for fitting model per 2 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki             : surface ids trained on\n",
    "    -> kmax           : maximum surfaces\n",
    "    -> l              : surface id tested on\n",
    "    -> data, labels   : training data and labels\n",
    "    -> data2, labels2 : testing data and labels\n",
    "    -> pipe           : the desired pipeline configuration\n",
    "    <- no output, saved model and confusion matrix in corresponding filename.npz\n",
    "    \"\"\"\n",
    "    fileid = filename2(i,j,k1,k2,l)\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k1,k2,l\n",
    "        if k1==l or k2==l: # perform K-fold      \n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+', cross-validating on '+str(l)+'...'\n",
    "            if l == k1: # copy if existent from the other sibling file\n",
    "                tmpcopyfileid = filepath+filename2(i,j,k1,k2,k2)+'.npz'\n",
    "            else:   # same as above\n",
    "                tmpcopyfileid = filepath+filename2(i,j,k1,k2,k1)+'.npz'                \n",
    "            if not os.path.isfile(tmpcopyfileid):\n",
    "                folds = cv.split(data, labels)\n",
    "                cm_all = np.zeros((2,2))\n",
    "                for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                    x_train, x_test = data[train_ind], data[test_ind]\n",
    "                    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                    model = pipe.fit(x_train,y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                    cm_all += cm/5.\n",
    "            else:\n",
    "                cm_all = np.load(tmpcopyfileid)['cm']\n",
    "                model = np.load(tmpcopyfileid)['model'][0]\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            model = []\n",
    "            for m in range(kmax):\n",
    "                tmpcopyfileid = filepath+filename2(i,j,k1,k2,m)+'.npz'\n",
    "                if k1!=m and k2!=m and os.path.isfile(tmpcopyfileid):\n",
    "                    print 'Found precomputed model of '+str(k1)+str(k2)+', tested on '+str(m) \\\n",
    "                                                                       +'. Testing on '+str(l)+'...'\n",
    "                    model = np.load(tmpcopyfileid)['model'][0]\n",
    "                    break\n",
    "            if model==[]: # model not found precomputed\n",
    "                print 'Fitting on '+str(k1)+\"-\"+str(k2)+', testing on '+str(l)+'...'\n",
    "                model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps2(i,j,jmax,surf,surfla):\n",
    "    \"\"\"function for helping parallelization of computations per 2 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> jmax           : number of all subfeaturesets\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    \"\"\"\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k1 in range(surf.shape[0]): # for every training surface1\n",
    "        for k2 in range(surf.shape[0]): # for every training surface2\n",
    "            if k2 > k1:\n",
    "                for l in range(surf.shape[0]): # for every testing surface\n",
    "                    tr_surf = np.concatenate((surf[k1],surf[k2]),axis=0)\n",
    "                    tr_surfla = np.concatenate((surfla[:,k1],surfla[:,k2]),axis=0)\n",
    "                    ts_surf, ts_surfla = surf[l], surfla[:,l]\n",
    "                    cross_fit2(i,j,k1,k2,surf.shape[0],l,tr_surf,tr_surfla,ts_surf,ts_surfla,pipe)\n",
    "\n",
    "def train_2_surface(surf,surfla,n=-1):\n",
    "    \"\"\"Parallel training -on surface level- of all combinations on 2 surfaces\n",
    "    -> n              : number of cores to run in parallel, \n",
    "                        input of joblib's Parallel (n=-1 means all available cores)\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    *** Cross surface validation, TRAINING with 2 surfaces each time, out of 6 surfaces in total\n",
    "    total= 4 (featuresets) * [comb(6,2)*6] (surface combinations: trained on 2, tested on 1) * 1 (prefeatureset)\n",
    "         = 4*15*6*1 = 360 different runs-files.\n",
    "    Note that comb(n,r) = n!/(r!(n-r)!)\n",
    "    \"\"\"\n",
    "    print \"-------------------------- TRAINING all combinations per 2 surfaces ----------------------------------\"    \n",
    "    for i in range(len(prefeatid)-1):\n",
    "        _ = [Parallel(n_jobs=n)([delayed(init_steps2) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) \n",
    "                                 for j in range(surf.shape[0])])]\n",
    "\n",
    "def bargraph_perf_gen2(maxsurf):\n",
    "    \"\"\"Perf file for bargraph generation using bargraph tool, for 2 surfaces\"\"\"\n",
    "    print \"---------------------------- Generating perf files for 2 surfaces ------------------------------------\"\n",
    "    prefeats = prefeatnames[prefeatid][:-1]\n",
    "    # prefeatures, subfeatures, trained, tested, (TP,TN,FN,FP)\n",
    "    acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all tested surfaces\n",
    "    avg = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # prefeatures, subfeatures, trained, cross_val_self_accuracy, (TP,TN,FN,FP)\n",
    "    self_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,1,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all self tested surfaces\n",
    "    avgs = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # features, subfeatures, trained, (tested avg, tested std), (TP,TN,FN,FP)\n",
    "    cross_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,2,4))\n",
    "     # features, subfeatures, (TP,TN,FN,FP) -> avg over all cross tested surfaces\n",
    "    avgc = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    initial_str = \"\"\"# clustered and stacked graph bogus data\n",
    "=stackcluster;TP;TN;FN;FP\n",
    "colors=med_blue,dark_green,yellow,red\n",
    "=nogridy\n",
    "=noupperright\n",
    "fontsz=5\n",
    "legendx=right\n",
    "legendy=center\n",
    "datascale=50\n",
    "yformat=%g%%\n",
    "xlabel=TrainedON-TestedON\n",
    "ylabel=Metrics\n",
    "=table\"\"\"\n",
    "    respath = filename2(_,_,_,_,_,1)\n",
    "    for i in range(len(prefeats)):\n",
    "        outname = respath+prefeats[i]\n",
    "        outfile = outname+'.perf'\n",
    "        outfile1 = outname+'_selfaccuracy.perf'\n",
    "        outfile2 = outname+'_crossaccuracy.perf'\n",
    "        out = open(outfile,'w+')\n",
    "        out.write(initial_str+\"\\n\")\n",
    "        out1 = open(outfile1,'w+')\n",
    "        out1.write(initial_str+\"\\n\")\n",
    "        out2 = open(outfile2,'w+')\n",
    "        out2.write(initial_str+\"\\n\")\n",
    "        for k1 in range(maxsurf):\n",
    "            for k2 in range(maxsurf):\n",
    "                if k2 > k1:\n",
    "                    for l in range(maxsurf):\n",
    "                        out.write(\"multimulti=\"+str(k1)+str(k2)+\"-\"+str(l)+\"\\n\")\n",
    "                        for j in range(len(subfeats)):\n",
    "                            fileid = filename2(i,j,k1,k2,l)\n",
    "                            tmp = np.load(fileid)['cm']\n",
    "                            acc[i,j,k1,k2,l,0] = round(tmp[1,1],2) # TP\n",
    "                            acc[i,j,k1,k2,l,1] = round(tmp[0,0],2) # TN\n",
    "                            acc[i,j,k1,k2,l,2] = 1-round(tmp[1,1],2) # FN\n",
    "                            acc[i,j,k1,k2,l,3] = 1-round(tmp[0,0],2) # FP\n",
    "                            avg[i,j,:] += acc[i,j,k1,k2,l,:]\n",
    "                            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],acc[i,j,k1,k2,l,0],\n",
    "                                                                    acc[i,j,k1,k2,l,1],acc[i,j,k1,k2,l,2],\n",
    "                                                                    acc[i,j,k1,k2,l,3]))\n",
    "                            if l == k1 or l == k2: # selc accuracy\n",
    "                                if j == 0 and l == k2:\n",
    "                                    out1.write(\"multimulti=\"+str(k1)+str(k2)+\"-\"+str(l)+\"\\n\")\n",
    "                                self_acc[i,j,k1,k2,0,:] = acc[i,j,k1,k2,l]\n",
    "                                avgs[i,j,:] += self_acc[i,j,k1,k2,0,:]\n",
    "                                if l == k2:\n",
    "                                    out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],\n",
    "                                                                             self_acc[i,j,k1,k2,0,0],\n",
    "                                                                             self_acc[i,j,k1,k2,0,1],\n",
    "                                                                             self_acc[i,j,k1,k2,0,2],\n",
    "                                                                             self_acc[i,j,k1,k2,0,3]))\n",
    "                            if l != k1 and l != k2:\n",
    "                                t = range(maxsurf)\n",
    "                                t.remove(k1)\n",
    "                                t.remove(k2)\n",
    "                                if (l == t[-1]):\n",
    "                                    if j == 0:\n",
    "                                        out2.write(\"multimulti=\"+str(k1)+str(k2)+\"\\n\")\n",
    "                                    cross_acc[i,j,k1,k2,0,:] = np.mean(acc[i,j,k1,k2,t,:], axis=0) # avg\n",
    "                                    # cross_acc[i,j,k1,k2,1,:] = np.std(acc[i,j,k1,k2,t,:], axis=0) # std\n",
    "                                    avgc[i,j,:] += cross_acc[i,j,k1,k2,0,:]\n",
    "                                    out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],\n",
    "                                                                             cross_acc[i,j,k1,k2,0,0],\n",
    "                                                                             cross_acc[i,j,k1,k2,0,1],\n",
    "                                                                             cross_acc[i,j,k1,k2,0,2],\n",
    "                                                                             cross_acc[i,j,k1,k2,0,3]))\n",
    "        out.write(\"multimulti=AVG\\n\")\n",
    "        out1.write(\"multimulti=AVG\\n\")\n",
    "        out2.write(\"multimulti=AVG\\n\")\n",
    "        avg /= comb(maxsurf,2)*maxsurf*1.\n",
    "        avgs /= comb(maxsurf,2)*2.\n",
    "        avgc /= comb(maxsurf,2)*1.\n",
    "        for j in range(len(subfeats)):\n",
    "            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avg[i,j,0],avg[i,j,1],avg[i,j,2],avg[i,j,3]))\n",
    "            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgs[i,j,0],avgs[i,j,1],avgs[i,j,2],avgs[i,j,3]))\n",
    "            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgc[i,j,0],avgc[i,j,1],avgc[i,j,2],avgc[i,j,3]))\n",
    "        out.close()\n",
    "        out1.close()\n",
    "        out2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ TRAINING with 3 surfaces each time, out of 6 surfaces in total ##############\n",
    "def filename3(i,j,k1,k2,k3,l,retpath=0):\n",
    "    \"\"\"function for the filename of the selected combination for training per 3 surfaces\n",
    "    -> i  : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j  : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki : surface ids trained on\n",
    "    -> l  : surface id tested on\n",
    "    <- filename\n",
    "    \"\"\"\n",
    "    filepath = respath+'3/'\n",
    "    ensure_dir(filepath)\n",
    "    if retpath:\n",
    "        return filepath\n",
    "    else:\n",
    "        return filepath+'fs_'+str(i)+'_subfs_'+str(j)+'_tr1_'+str(k1)+'_tr2_'+str(k2)+'_tr3_'+str(k3)\\\n",
    "                                                                  +'_ts_'+str(l)+'.npz'\n",
    "\n",
    "def cross_fit3(i,j,k1,k2,k3,kmax,l,data,labels,data2,labels2,pipe):\n",
    "    \"\"\"function for fitting model per 3 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki             : surface ids trained on\n",
    "    -> kmax           : maximum surfaces\n",
    "    -> l              : surface id tested on\n",
    "    -> data, labels   : training data and labels\n",
    "    -> data2, labels2 : testing data and labels\n",
    "    -> pipe           : the desired pipeline configuration\n",
    "    <- no output, saved model and confusion matrix in corresponding filename.npz\n",
    "    \"\"\"\n",
    "    fileid = filename3(i,j,k1,k2,k3,l)\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k1,k2,k3,l\n",
    "        if k1==l or k2==l or k3==l: # perform K-fold      \n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+', cross-validating on '+str(l)+'...'\n",
    "            if l == k1: # copy if existent from the other sibling file\n",
    "                tmpcopyfileid1 = filepath+filename3(i,j,k1,k2,k3,k2)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename3(i,j,k1,k2,k3,k3)+'.npz'\n",
    "            elif l == k2:   # same as above\n",
    "                tmpcopyfileid1 = filepath+filename3(i,j,k1,k2,k3,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename3(i,j,k1,k2,k3,k3)+'.npz'\n",
    "            else:\n",
    "                tmpcopyfileid1 = filepath+filename3(i,j,k1,k2,k3,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename3(i,j,k1,k2,k3,k2)+'.npz'\n",
    "            if not os.path.isfile(tmpcopyfileid1) and not os.path.isfile(tmpcopyfileid2):\n",
    "                folds = cv.split(data, labels)\n",
    "                cm_all = np.zeros((2,2))\n",
    "                for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                    x_train, x_test = data[train_ind], data[test_ind]\n",
    "                    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                    model = pipe.fit(x_train,y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                    cm_all += cm/5.\n",
    "            else:\n",
    "                if os.path.isfile(tmpcopyfileid1):\n",
    "                    cm_all = np.load(tmpcopyfileid1)['cm']\n",
    "                    model = np.load(tmpcopyfileid1)['model'][0]\n",
    "                else:\n",
    "                    cm_all = np.load(tmpcopyfileid2)['cm']\n",
    "                    model = np.load(tmpcopyfileid2)['model'][0]\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            model = []\n",
    "            for m in range(kmax):\n",
    "                tmpcopyfileid = filepath+filename3(i,j,k1,k2,k3,m)+'.npz'\n",
    "                if k1!=m and k2!=m and k3!=m and os.path.isfile(tmpcopyfileid):\n",
    "                    print 'Found precomputed model of '+str(k1)+str(k2)+str(k3)+', tested on '+str(m) \\\n",
    "                                                                               +'. Testing on '+str(l)+'...'\n",
    "                    model = np.load(tmpcopyfileid)['model'][0]\n",
    "                    break\n",
    "            if model==[]: # model not found precomputed\n",
    "                print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+', testing on '+str(l)+'...'\n",
    "                model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps3(i,j,jmax,surf,surfla):\n",
    "    \"\"\"function for helping parallelization of computations per 3 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> jmax           : number of all subfeaturesets\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    \"\"\"\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k1 in range(surf.shape[0]): # for every training surface1\n",
    "        for k2 in range(surf.shape[0]): # for every training surface2\n",
    "            if k2 > k1:\n",
    "                for k3 in range(surf.shape[0]):\n",
    "                    if k3 > k2:\n",
    "                        for l in range(surf.shape[0]): # for every testing surface\n",
    "                            tr_surf = np.concatenate((surf[k1],surf[k2],surf[k3]),axis=0)\n",
    "                            tr_surfla = np.concatenate((surfla[:,k1],surfla[:,k2],surfla[:,k3]),axis=0)\n",
    "                            ts_surf, ts_surfla = surf[l], surfla[:,l]\n",
    "                            cross_fit3(i,j,k1,k2,k3,surf.shape[0],l,tr_surf,tr_surfla,ts_surf,ts_surfla,pipe)\n",
    "\n",
    "def train_3_surface(surf,surfla,n=-1):\n",
    "    \"\"\"Parallel training -on surface level- of all combinations on 3 surfaces\n",
    "    -> n              : number of cores to run in parallel, \n",
    "                        input of joblib's Parallel (n=-1 means all available cores)\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    *** Cross surface validation, TRAINING with 3 surfaces each time, out of 6 surfaces in total\n",
    "    total= 4 (featuresets) * [comb(6,3)*6] (surface combinations: trained on 3, tested on 1) * 1 (prefeatureset)\n",
    "         = 4*20*6*1 = 480 different runs-files.\n",
    "    Note that comb(n,r) = n!/(r!(n-r)!)\n",
    "    \"\"\"\n",
    "    print \"-------------------------- TRAINING all combinations per 3 surfaces ----------------------------------\"\n",
    "    for i in range(len(prefeatid)-1):\n",
    "        _ = [Parallel(n_jobs=n)([delayed(init_steps3) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) \n",
    "                                 for j in range(surf.shape[0])])]\n",
    "        \n",
    "def bargraph_perf_gen3(maxsurf):\n",
    "    \"\"\"Perf file for bargraph generation using bargraph tool, for 3 surfaces\"\"\"\n",
    "    print \"---------------------------- Generating perf files for 3 surfaces ------------------------------------\"\n",
    "    prefeats = prefeatnames[prefeatid][:-1]\n",
    "    # prefeatures, subfeatures, trained, tested, (TP,TN,FN,FP)\n",
    "    acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all tested surfaces\n",
    "    avg = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # prefeatures, subfeatures, trained, cross_val_self_accuracy, (TP,TN,FN,FP)\n",
    "    self_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,1,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all self tested surfaces\n",
    "    avgs = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # features, subfeatures, trained, (tested avg, tested std), (TP,TN,FN,FP)\n",
    "    cross_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,2,4))\n",
    "     # features, subfeatures, (TP,TN,FN,FP) -> avg over all cross tested surfaces\n",
    "    avgc = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    initial_str = \"\"\"# clustered and stacked graph bogus data\n",
    "=stackcluster;TP;TN;FN;FP\n",
    "colors=med_blue,dark_green,yellow,red\n",
    "=nogridy\n",
    "=noupperright\n",
    "fontsz=5\n",
    "legendx=right\n",
    "legendy=center\n",
    "datascale=50\n",
    "yformat=%g%%\n",
    "xlabel=TrainedON-TestedON\n",
    "ylabel=Metrics\n",
    "=table\"\"\"\n",
    "    respath = filename3(_,_,_,_,_,_,1)\n",
    "    for i in range(len(prefeats)):\n",
    "        outname = respath+prefeats[i]\n",
    "        outfile = outname+'.perf'\n",
    "        outfile1 = outname+'_selfaccuracy.perf'\n",
    "        outfile2 = outname+'_crossaccuracy.perf'\n",
    "        out = open(outfile,'w+')\n",
    "        out.write(initial_str+\"\\n\")\n",
    "        out1 = open(outfile1,'w+')\n",
    "        out1.write(initial_str+\"\\n\")\n",
    "        out2 = open(outfile2,'w+')\n",
    "        out2.write(initial_str+\"\\n\")\n",
    "        for k1 in range(maxsurf):\n",
    "            for k2 in range(maxsurf):\n",
    "                if k2 > k1:\n",
    "                    for k3 in range(maxsurf):\n",
    "                        if k3 > k2:\n",
    "                            for l in range(maxsurf):\n",
    "                                out.write(\"multimulti=\"+str(k1)+str(k2)+str(k3)+\"-\"+str(l)+\"\\n\")\n",
    "                                for j in range(len(subfeats)):\n",
    "                                    fileid = filename3(i,j,k1,k2,k3,l)\n",
    "                                    tmp = np.load(fileid)['cm']\n",
    "                                    acc[i,j,k1,k2,k3,l,0] = round(tmp[1,1],2) # TP\n",
    "                                    acc[i,j,k1,k2,k3,l,1] = round(tmp[0,0],2) # TN\n",
    "                                    acc[i,j,k1,k2,k3,l,2] = 1-round(tmp[1,1],2) # FN\n",
    "                                    acc[i,j,k1,k2,k3,l,3] = 1-round(tmp[0,0],2) # FP\n",
    "                                    avg[i,j,:] += acc[i,j,k1,k2,k3,l,:]\n",
    "                                    out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],acc[i,j,k1,k2,k3,l,0],\n",
    "                                                                            acc[i,j,k1,k2,k3,l,1],\n",
    "                                                                            acc[i,j,k1,k2,k3,l,2],\n",
    "                                                                            acc[i,j,k1,k2,k3,l,3]))\n",
    "                                    if l == k1 or l == k2 or l == k3: # selc accuracy\n",
    "                                        if j == 0 and l == k3:\n",
    "                                            out1.write(\"multimulti=\"+str(k1)+str(k2)+str(k3)+\"-\"+str(l)+\"\\n\")\n",
    "                                        self_acc[i,j,k1,k2,k3,0,:] = acc[i,j,k1,k2,k3,l]\n",
    "                                        avgs[i,j,:] += self_acc[i,j,k1,k2,k3,0,:]\n",
    "                                        if l == k3:\n",
    "                                            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],\n",
    "                                                                                     self_acc[i,j,k1,k2,k3,0,0],\n",
    "                                                                                     self_acc[i,j,k1,k2,k3,0,1],\n",
    "                                                                                     self_acc[i,j,k1,k2,k3,0,2],\n",
    "                                                                                     self_acc[i,j,k1,k2,k3,0,3]))\n",
    "                                    if l != k1 and l != k2 and l != k3:\n",
    "                                        t = range(maxsurf)\n",
    "                                        t.remove(k1)\n",
    "                                        t.remove(k2)\n",
    "                                        t.remove(k3)\n",
    "                                        if (l == t[-1]):\n",
    "                                            if j == 0:\n",
    "                                                out2.write(\"multimulti=\"+str(k1)+str(k2)+str(k3)+\"\\n\")\n",
    "                                            # avg\n",
    "                                            cross_acc[i,j,k1,k2,k3,0,:] = np.mean(acc[i,j,k1,k2,k3,t,:], axis=0)\n",
    "                                            # std\n",
    "                                            # cross_acc[i,j,k1,k2,k3,1,:] = np.std(acc[i,j,k1,k2,k3,t,:], axis=0)\n",
    "                                            avgc[i,j,:] += cross_acc[i,j,k1,k2,k3,0,:]\n",
    "                                            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],\n",
    "                                                                                     cross_acc[i,j,k1,k2,k3,0,0],\n",
    "                                                                                     cross_acc[i,j,k1,k2,k3,0,1],\n",
    "                                                                                     cross_acc[i,j,k1,k2,k3,0,2],\n",
    "                                                                                     cross_acc[i,j,k1,k2,k3,0,3]))\n",
    "        out.write(\"multimulti=AVG\\n\")\n",
    "        out1.write(\"multimulti=AVG\\n\")\n",
    "        out2.write(\"multimulti=AVG\\n\")\n",
    "        avg /= comb(maxsurf,3)*maxsurf*1.\n",
    "        avgs /= comb(maxsurf,3)*3.\n",
    "        avgc /= comb(maxsurf,3)*1.\n",
    "        for j in range(len(subfeats)):\n",
    "            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avg[i,j,0],avg[i,j,1],avg[i,j,2],avg[i,j,3]))\n",
    "            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgs[i,j,0],avgs[i,j,1],avgs[i,j,2],avgs[i,j,3]))\n",
    "            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgc[i,j,0],avgc[i,j,1],avgc[i,j,2],avgc[i,j,3]))\n",
    "        out.close()\n",
    "        out1.close()\n",
    "        out2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ TRAINING with 4 surfaces each time, out of 6 surfaces in total ##############\n",
    "def filename4(i,j,k1,k2,k3,k4,l,retpath=0):\n",
    "    \"\"\"function for the filename of the selected combination for training per 4 surfaces\n",
    "    -> i  : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j  : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki : surface ids trained on\n",
    "    -> l  : surface id tested on\n",
    "    <- filename\n",
    "    \"\"\"\n",
    "    filepath = respath+'4/'\n",
    "    ensure_dir(filepath)\n",
    "    if retpath:\n",
    "        return filepath\n",
    "    else:\n",
    "        return filepath+'fs_'+str(i)+'_subfs_'+str(j)+'_tr1_'+str(k1)+'_tr2_'+str(k2)+'_tr3_' \\\n",
    "                                 +str(k3)+'_tr4_'+str(k4)+'_ts_'+str(l)+'.npz'\n",
    "\n",
    "def cross_fit4(i,j,k1,k2,k3,k4,kmax,l,data,labels,data2,labels2,pipe):\n",
    "    \"\"\"function for fitting model per 4 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki             : surface ids trained on\n",
    "    -> kmax           : maximum surfaces\n",
    "    -> l              : surface id tested on\n",
    "    -> data, labels   : training data and labels\n",
    "    -> data2, labels2 : testing data and labels\n",
    "    -> pipe           : the desired pipeline configuration\n",
    "    <- no output, saved model and confusion matrix in corresponding filename.npz\n",
    "    \"\"\"\n",
    "    fileid = filename4(i,j,k1,k2,k3,k4,l)\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k1,k2,k3,k4,l\n",
    "        if k1==l or k2==l or k3==l or k4==l: # perform K-fold      \n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+\"-\"+str(k4)+', cross-validating on '+str(l)+'...'\n",
    "            if l == k1: # copy if existent from the other sibling file\n",
    "                tmpcopyfileid1 = filepath+filename4(i,j,k1,k2,k3,k4,k2)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename4(i,j,k1,k2,k3,k4,k3)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename4(i,j,k1,k2,k3,k4,k4)+'.npz'\n",
    "            elif l == k2:   # same as above\n",
    "                tmpcopyfileid1 = filepath+filename4(i,j,k1,k2,k3,k4,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename4(i,j,k1,k2,k3,k4,k3)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename4(i,j,k1,k2,k3,k4,k4)+'.npz'\n",
    "            elif l == k3:   # same as above\n",
    "                tmpcopyfileid1 = filepath+filename4(i,j,k1,k2,k3,k4,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename4(i,j,k1,k2,k3,k4,k2)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename4(i,j,k1,k2,k3,k4,k4)+'.npz'\n",
    "            else:\n",
    "                tmpcopyfileid1 = filepath+filename4(i,j,k1,k2,k3,k4,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename4(i,j,k1,k2,k3,k4,k2)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename4(i,j,k1,k2,k3,k4,k3)+'.npz'\n",
    "            if not os.path.isfile(tmpcopyfileid1) and not os.path.isfile(tmpcopyfileid2) \\\n",
    "                                                  and not os.path.isfile(tmpcopyfileid3):\n",
    "                folds = cv.split(data, labels)\n",
    "                cm_all = np.zeros((2,2))\n",
    "                for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                    x_train, x_test = data[train_ind], data[test_ind]\n",
    "                    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                    model = pipe.fit(x_train,y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                    cm_all += cm/5.\n",
    "            else:\n",
    "                if os.path.isfile(tmpcopyfileid1):\n",
    "                    cm_all = np.load(tmpcopyfileid1)['cm']\n",
    "                    model = np.load(tmpcopyfileid1)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid2):\n",
    "                    cm_all = np.load(tmpcopyfileid2)['cm']\n",
    "                    model = np.load(tmpcopyfileid2)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid3):\n",
    "                    cm_all = np.load(tmpcopyfileid3)['cm']\n",
    "                    model = np.load(tmpcopyfileid3)['model'][0]\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            model = []\n",
    "            for m in range(kmax):\n",
    "                tmpcopyfileid = filepath+filename4(i,j,k1,k2,k3,k4,m)+'.npz'\n",
    "                if k1!=m and k2!=m and k3!=m and k4!=m and os.path.isfile(tmpcopyfileid):\n",
    "                    print 'Found precomputed model of '+str(k1)+str(k2)+str(k3)+str(k4)\\\n",
    "                                                       +', tested on '+str(m)+'. Testing on '+str(l)+'...'\n",
    "                    model = np.load(tmpcopyfileid)['model'][0]\n",
    "                    break\n",
    "            if model==[]: # model not found precomputed\n",
    "                print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+\"-\"+str(k4)+', testing on '+str(l)+'...'\n",
    "                model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps4(i,j,jmax,surf,surfla):\n",
    "    \"\"\"function for helping parallelization of computations per 4 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> jmax           : number of all subfeaturesets\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    \"\"\"\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k1 in range(surf.shape[0]): # for every training surface1\n",
    "        for k2 in range(surf.shape[0]): # for every training surface2\n",
    "            if k2 > k1:\n",
    "                for k3 in range(surf.shape[0]):\n",
    "                    if k3 > k2:\n",
    "                        for k4 in range(surf.shape[0]):\n",
    "                            if k4 > k3:\n",
    "                                for l in range(surf.shape[0]): # for every testing surface\n",
    "                                    tr_surf = np.concatenate((surf[k1],surf[k2],surf[k3]),axis=0)\n",
    "                                    tr_surfla = np.concatenate((surfla[:,k1],surfla[:,k2],surfla[:,k3]),axis=0)\n",
    "                                    ts_surf, ts_surfla = surf[l], surfla[:,l]\n",
    "                                    cross_fit4(i,j,k1,k2,k3,k4,surf.shape[0],l,\n",
    "                                               tr_surf,tr_surfla,ts_surf,ts_surfla,pipe)\n",
    "\n",
    "def train_4_surface(surf,surfla,n=-1):\n",
    "    \"\"\"Parallel training -on surface level- of all combinations on 4 surfaces\n",
    "    -> n              : number of cores to run in parallel, \n",
    "                        input of joblib's Parallel (n=-1 means all available cores)\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    *** Cross surface validation, TRAINING with 2 surfaces each time, out of 6 surfaces in total\n",
    "    total= 4 (featuresets) * [comb(6,4)*6] (surface combinations: trained on 4, tested on 1) * 1 (prefeatureset)\n",
    "         = 4*15*6*1 = 360 different runs-files.\n",
    "    Note that comb(n,r) = n!/(r!(n-r)!)\n",
    "    \"\"\"\n",
    "    print \"-------------------------- TRAINING all combinations per 4 surfaces ----------------------------------\"        \n",
    "    for i in range(len(prefeatid)-1):\n",
    "        _ = [Parallel(n_jobs=n)([delayed(init_steps4) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) \n",
    "                                 for j in range(surf.shape[0])])]\n",
    "        \n",
    "def bargraph_perf_gen4(maxsurf):\n",
    "    \"\"\"Perf file for bargraph generation using bargraph tool, for 4 surfaces\"\"\"\n",
    "    print \"---------------------------- Generating perf files for 4 surfaces ------------------------------------\"\n",
    "    prefeats = prefeatnames[prefeatid][:-1]\n",
    "    # prefeatures, subfeatures, trained, tested, (TP,TN,FN,FP)\n",
    "    acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,maxsurf,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all tested surfaces\n",
    "    avg = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # prefeatures, subfeatures, trained, cross_val_self_accuracy, (TP,TN,FN,FP)\n",
    "    self_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,1,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all self tested surfaces\n",
    "    avgs = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # features, subfeatures, trained, (tested avg, tested std), (TP,TN,FN,FP)\n",
    "    cross_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,2,4))\n",
    "     # features, subfeatures, (TP,TN,FN,FP) -> avg over all cross tested surfaces\n",
    "    avgc = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    initial_str = \"\"\"# clustered and stacked graph bogus data\n",
    "=stackcluster;TP;TN;FN;FP\n",
    "colors=med_blue,dark_green,yellow,red\n",
    "=nogridy\n",
    "=noupperright\n",
    "fontsz=5\n",
    "legendx=right\n",
    "legendy=center\n",
    "datascale=50\n",
    "yformat=%g%%\n",
    "xlabel=TrainedON-TestedON\n",
    "ylabel=Metrics\n",
    "=table\"\"\"\n",
    "    respath = filename4(_,_,_,_,_,_,_,1)\n",
    "    for i in range(len(prefeats)):\n",
    "        outname = respath+prefeats[i]\n",
    "        outfile = outname+'.perf'\n",
    "        outfile1 = outname+'_selfaccuracy.perf'\n",
    "        outfile2 = outname+'_crossaccuracy.perf'\n",
    "        out = open(outfile,'w+')\n",
    "        out.write(initial_str+\"\\n\")\n",
    "        out1 = open(outfile1,'w+')\n",
    "        out1.write(initial_str+\"\\n\")\n",
    "        out2 = open(outfile2,'w+')\n",
    "        out2.write(initial_str+\"\\n\")\n",
    "        for k1 in range(maxsurf):\n",
    "            for k2 in range(maxsurf):\n",
    "                if k2 > k1:\n",
    "                    for k3 in range(maxsurf):\n",
    "                        if k3 > k2:\n",
    "                            for k4 in range(maxsurf):\n",
    "                                if k4 > k3:\n",
    "                                    for l in range(maxsurf):\n",
    "                                        out.write(\"multimulti=\"+str(k1)+str(k2)+str(k3)+str(k4)+\"-\"+str(l)+\"\\n\")\n",
    "                                        for j in range(len(subfeats)):\n",
    "                                            fileid = filename4(i,j,k1,k2,k3,k4,l)\n",
    "                                            tmp = np.load(fileid)['cm']\n",
    "                                            acc[i,j,k1,k2,k3,k4,l,0] = round(tmp[1,1],2) # TP\n",
    "                                            acc[i,j,k1,k2,k3,k4,l,1] = round(tmp[0,0],2) # TN\n",
    "                                            acc[i,j,k1,k2,k3,k4,l,2] = 1-round(tmp[1,1],2) # FN\n",
    "                                            acc[i,j,k1,k2,k3,k4,l,3] = 1-round(tmp[0,0],2) # FP\n",
    "                                            avg[i,j,:] += acc[i,j,k1,k2,k3,k4,l,:]\n",
    "                                            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],\n",
    "                                                                                    acc[i,j,k1,k2,k3,k4,l,0],\n",
    "                                                                                    acc[i,j,k1,k2,k3,k4,l,1],\n",
    "                                                                                    acc[i,j,k1,k2,k3,k4,l,2],\n",
    "                                                                                    acc[i,j,k1,k2,k3,k4,l,3]))\n",
    "                                            if l == k1 or l == k2 or l == k3 or l == k4: # selc accuracy\n",
    "                                                if j == 0 and l == k4:\n",
    "                                                    out1.write(\"multimulti=\"+str(k1)+str(k2)+str(k3)\\\n",
    "                                                                            +str(k4)+\"-\"+str(l)+\"\\n\")\n",
    "                                                self_acc[i,j,k1,k2,k3,k4,0,:] = acc[i,j,k1,k2,k3,k4,l]\n",
    "                                                avgs[i,j,:] += self_acc[i,j,k1,k2,k3,k4,0,:]\n",
    "                                                if l == k4:\n",
    "                                                    out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" \\\n",
    "                                                               % (subfeats[j],\n",
    "                                                                  self_acc[i,j,k1,k2,k3,k4,0,0],\n",
    "                                                                  self_acc[i,j,k1,k2,k3,k4,0,1],\n",
    "                                                                  self_acc[i,j,k1,k2,k3,k4,0,2],\n",
    "                                                                  self_acc[i,j,k1,k2,k3,k4,0,3]))\n",
    "                                            if l != k1 and l != k2 and l != k3 and l!= k4:\n",
    "                                                t = range(maxsurf)\n",
    "                                                t.remove(k1)\n",
    "                                                t.remove(k2)\n",
    "                                                t.remove(k3)\n",
    "                                                t.remove(k4)\n",
    "                                                if (l == t[-1]):\n",
    "                                                    if j == 0:\n",
    "                                                        out2.write(\"multimulti=\"+str(k1)+str(k2)\\\n",
    "                                                                   +str(k3)+str(k4)+\"\\n\")\n",
    "                                                    cross_acc[i,j,k1,k2,k3,k4,0,:] = \\\n",
    "                                                        np.mean(acc[i,j,k1,k2,k3,k4,t,:], axis=0)\n",
    "                                                    avgc[i,j,:] += cross_acc[i,j,k1,k2,k3,k4,0,:]\n",
    "                                                    out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" \\\n",
    "                                                               % (subfeats[j],\n",
    "                                                                  cross_acc[i,j,k1,k2,k3,k4,0,0],\n",
    "                                                                  cross_acc[i,j,k1,k2,k3,k4,0,1],\n",
    "                                                                  cross_acc[i,j,k1,k2,k3,k4,0,2],\n",
    "                                                                  cross_acc[i,j,k1,k2,k3,k4,0,3]))\n",
    "        out.write(\"multimulti=AVG\\n\")\n",
    "        out1.write(\"multimulti=AVG\\n\")\n",
    "        out2.write(\"multimulti=AVG\\n\")\n",
    "        avg /= comb(maxsurf,4)*maxsurf*1.\n",
    "        avgs /= comb(maxsurf,4)*4.\n",
    "        avgc /= comb(maxsurf,4)*1.\n",
    "        for j in range(len(subfeats)):\n",
    "            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avg[i,j,0],avg[i,j,1],avg[i,j,2],avg[i,j,3]))\n",
    "            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgs[i,j,0],avgs[i,j,1],avgs[i,j,2],avgs[i,j,3]))\n",
    "            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgc[i,j,0],avgc[i,j,1],avgc[i,j,2],avgc[i,j,3]))\n",
    "        out.close()\n",
    "        out1.close()\n",
    "        out2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ TRAINING with 5 surfaces each time, out of 6 surfaces in total ##############\n",
    "def filename5(i,j,k1,k2,k3,k4,k5,l,retpath=0):\n",
    "    \"\"\"function for the filename of the selected combination for training per 5 surfaces\n",
    "    -> i  : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j  : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki : surface ids trained on\n",
    "    -> l  : surface id tested on\n",
    "    <- filename\n",
    "    \"\"\"\n",
    "    filepath = respath+'5/'\n",
    "    ensure_dir(filepath)\n",
    "    if retpath:\n",
    "        return filepath\n",
    "    else:\n",
    "        return filepath+'fs_'+str(i)+'_subfs_'+str(j)+'_tr1_'+str(k1)+'_tr2_'+str(k2)+'_tr3_' \\\n",
    "                                 +str(k3)+'_tr4_'+str(k4)+'_tr5_'+str(k5)+'_ts_'+str(l)+'.npz'\n",
    "\n",
    "def cross_fit5(i,j,k1,k2,k3,k4,k5,kmax,l,data,labels,data2,labels2,pipe):\n",
    "    \"\"\"function for fitting model per 5 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> ki             : surface ids trained on\n",
    "    -> kmax           : maximum surfaces\n",
    "    -> l              : surface id tested on\n",
    "    -> data, labels   : training data and labels\n",
    "    -> data2, labels2 : testing data and labels\n",
    "    -> pipe           : the desired pipeline configuration\n",
    "    <- no output, saved model and confusion matrix in corresponding filename.npz\n",
    "    \"\"\"\n",
    "    fileid = filename5(i,j,k1,k2,k3,k4,k5,l)\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k1,k2,k3,k4,k5,l\n",
    "        if k1==l or k2==l or k3==l or k4==l or k5==l: # perform K-fold      \n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+\"-\"+str(k4)+\"-\" \\\n",
    "                                           +str(k5)+', cross-validating on '+str(l)+'...'\n",
    "            if l == k1: # copy if existent from the other sibling file\n",
    "                tmpcopyfileid1 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k2)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k3)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k4)+'.npz'\n",
    "                tmpcopyfileid4 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k5)+'.npz'\n",
    "            elif l == k2:   # same as above\n",
    "                tmpcopyfileid1 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k3)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k4)+'.npz'\n",
    "                tmpcopyfileid4 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k5)+'.npz'\n",
    "            elif l == k3:   # same as above\n",
    "                tmpcopyfileid1 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k2)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k4)+'.npz'\n",
    "                tmpcopyfileid4 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k5)+'.npz'\n",
    "            elif l == k4:   # same as above\n",
    "                tmpcopyfileid1 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k2)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k3)+'.npz'\n",
    "                tmpcopyfileid4 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k5)+'.npz'\n",
    "            else:\n",
    "                tmpcopyfileid1 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k1)+'.npz'\n",
    "                tmpcopyfileid2 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k2)+'.npz'\n",
    "                tmpcopyfileid3 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k3)+'.npz'\n",
    "                tmpcopyfileid4 = filepath+filename5(i,j,k1,k2,k3,k4,k5,k4)+'.npz'\n",
    "            if not os.path.isfile(tmpcopyfileid1) and not os.path.isfile(tmpcopyfileid2) \\\n",
    "               and not os.path.isfile(tmpcopyfileid3) and not os.path.isfile(tmpcopyfileid4):\n",
    "                folds = cv.split(data, labels)\n",
    "                cm_all = np.zeros((2,2))\n",
    "                for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                    x_train, x_test = data[train_ind], data[test_ind]\n",
    "                    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                    model = pipe.fit(x_train,y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                    cm_all += cm/5.\n",
    "            else:\n",
    "                if os.path.isfile(tmpcopyfileid1):\n",
    "                    cm_all = np.load(tmpcopyfileid1)['cm']\n",
    "                    model = np.load(tmpcopyfileid1)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid2):\n",
    "                    cm_all = np.load(tmpcopyfileid2)['cm']\n",
    "                    model = np.load(tmpcopyfileid2)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid3):\n",
    "                    cm_all = np.load(tmpcopyfileid3)['cm']\n",
    "                    model = np.load(tmpcopyfileid3)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid4):\n",
    "                    cm_all = np.load(tmpcopyfileid4)['cm']\n",
    "                    model = np.load(tmpcopyfileid4)['model'][0]\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            model = []\n",
    "            for m in range(kmax):\n",
    "                tmpcopyfileid = filepath+filename5(i,j,k1,k2,k3,k4,k5,m)+'.npz'\n",
    "                if k1!=m and k2!=m and k3!=m and k4!=m and k5!=m and os.path.isfile(tmpcopyfileid):\n",
    "                    print 'Found precomputed model of '+str(k1)+str(k2)+str(k3)+str(k4)+str(k5) \\\n",
    "                                                       +', tested on '+str(m)+'. Testing on '+str(l)+'...'\n",
    "                    model = np.load(tmpcopyfileid)['model'][0]\n",
    "                    break\n",
    "            if model==[]: # model not found precomputed\n",
    "                print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+\"-\"+str(k4)+\"-\" \\\n",
    "                                               +str(k5)+', testing on '+str(l)+'...'\n",
    "                model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps5(i,j,jmax,surf,surfla):\n",
    "    \"\"\"function for helping parallelization of computations per 5 surfaces\n",
    "    -> i              : prefeature id, among all computed prefeatures (0: |f|, ... see prefeatid)\n",
    "    -> j              : subfeatureset among all features (0: AFFT, 1: FREQ, 2: TIME, 3: ALL)\n",
    "    -> jmax           : number of all subfeaturesets\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    \"\"\"\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k1 in range(surf.shape[0]): # for every training surface1\n",
    "        for k2 in range(surf.shape[0]): # for every training surface2\n",
    "            if k2 > k1:\n",
    "                for k3 in range(surf.shape[0]):\n",
    "                    if k3 > k2:\n",
    "                        for k4 in range(surf.shape[0]):\n",
    "                            if k4 > k3:\n",
    "                                for k5 in range(surf.shape[0]):\n",
    "                                    if k5 > k4:\n",
    "                                        for l in range(surf.shape[0]): # for every testing surface\n",
    "                                            tr_surf = np.concatenate((surf[k1],surf[k2],surf[k3]),axis=0)\n",
    "                                            tr_surfla = np.concatenate((surfla[:,k1],surfla[:,k2],\n",
    "                                                                        surfla[:,k3]),axis=0)\n",
    "                                            ts_surf, ts_surfla = surf[l], surfla[:,l]\n",
    "                                            cross_fit5(i,j,k1,k2,k3,k4,k5,surf.shape[0],l,\n",
    "                                                       tr_surf,tr_surfla,ts_surf,ts_surfla,pipe)\n",
    "\n",
    "def train_5_surface(surf,surfla,n=-1):\n",
    "    \"\"\"Parallel training -on surface level- of all combinations on 5 surfaces\n",
    "    -> n              : number of cores to run in parallel, \n",
    "                        input of joblib's Parallel (n=-1 means all available cores)\n",
    "    -> surf, surfla   : surface data and labels\n",
    "    *** Cross surface validation, TRAINING with 5 surfaces each time, out of 6 surfaces in total\n",
    "    total= 4 (featuresets) * [comb(6,5)*6] (surface combinations: trained on 5, tested on 1) * 1 (prefeatureset)\n",
    "         = 4*6*6*1 = 144 different runs-files.\n",
    "    Note that comb(n,r) = n!/(r!(n-r)!)\n",
    "    \"\"\"\n",
    "    print \"-------------------------- TRAINING all combinations per 5 surfaces ----------------------------------\"        \n",
    "    for i in range(len(prefeatid)-1):\n",
    "        _ = [Parallel(n_jobs=n)([delayed(init_steps5) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) \n",
    "                                 for j in range(surf.shape[0])])]\n",
    "        \n",
    "def bargraph_perf_gen5(maxsurf):\n",
    "    \"\"\"Perf file for bargraph generation using bargraph tool, for 5 surfaces\"\"\"\n",
    "    print \"---------------------------- Generating perf files for 5 surfaces ------------------------------------\"\n",
    "    prefeats = prefeatnames[prefeatid][:-1]\n",
    "    # prefeatures, subfeatures, trained, tested, (TP,TN,FN,FP)\n",
    "    acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,maxsurf,maxsurf,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all tested surfaces\n",
    "    avg = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # prefeatures, subfeatures, trained, cross_val_self_accuracy, (TP,TN,FN,FP)\n",
    "    self_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,maxsurf,1,4))\n",
    "    # features, subfeatures, (TP,TN,FN,FP) -> avg over all self tested surfaces\n",
    "    avgs = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    # features, subfeatures, trained, (tested avg, tested std), (TP,TN,FN,FP)\n",
    "    cross_acc = np.zeros((len(prefeats),len(subfeats),maxsurf,maxsurf,maxsurf,maxsurf,maxsurf,2,4))\n",
    "     # features, subfeatures, (TP,TN,FN,FP) -> avg over all cross tested surfaces\n",
    "    avgc = np.zeros((len(prefeats),len(subfeats),4))\n",
    "    initial_str = \"\"\"# clustered and stacked graph bogus data\n",
    "=stackcluster;TP;TN;FN;FP\n",
    "colors=med_blue,dark_green,yellow,red\n",
    "=nogridy\n",
    "=noupperright\n",
    "fontsz=5\n",
    "legendx=right\n",
    "legendy=center\n",
    "datascale=50\n",
    "yformat=%g%%\n",
    "xlabel=TrainedON-TestedON\n",
    "ylabel=Metrics\n",
    "=table\"\"\"\n",
    "    respath = filename5(_,_,_,_,_,_,_,_,1)\n",
    "    for i in range(len(prefeats)):\n",
    "        outname = respath+prefeats[i]\n",
    "        outfile = outname+'.perf'\n",
    "        outfile1 = outname+'_selfaccuracy.perf'\n",
    "        outfile2 = outname+'_crossaccuracy.perf'\n",
    "        out = open(outfile,'w+')\n",
    "        out.write(initial_str+\"\\n\")\n",
    "        out1 = open(outfile1,'w+')\n",
    "        out1.write(initial_str+\"\\n\")\n",
    "        out2 = open(outfile2,'w+')\n",
    "        out2.write(initial_str+\"\\n\")\n",
    "        for k1 in range(maxsurf):\n",
    "            for k2 in range(maxsurf):\n",
    "                if k2 > k1:\n",
    "                    for k3 in range(maxsurf):\n",
    "                        if k3 > k2:\n",
    "                            for k4 in range(maxsurf):\n",
    "                                if k4 > k3:\n",
    "                                    for k5 in range(maxsurf):\n",
    "                                        if k5 > k4:\n",
    "                                            for l in range(maxsurf):\n",
    "                                                out.write(\"multimulti=\"+str(k1)+str(k2)+str(k3)+str(k4)\\\n",
    "                                                          +str(k5)+\"-\"+str(l)+\"\\n\")\n",
    "                                                for j in range(len(subfeats)):\n",
    "                                                    fileid = filename5(i,j,k1,k2,k3,k4,k5,l)\n",
    "                                                    tmp = np.load(fileid)['cm']\n",
    "                                                    acc[i,j,k1,k2,k3,k4,k5,l,0] = round(tmp[1,1],2) # TP\n",
    "                                                    acc[i,j,k1,k2,k3,k4,k5,l,1] = round(tmp[0,0],2) # TN\n",
    "                                                    acc[i,j,k1,k2,k3,k4,k5,l,2] = 1-round(tmp[1,1],2) # FN\n",
    "                                                    acc[i,j,k1,k2,k3,k4,k5,l,3] = 1-round(tmp[0,0],2) # FP\n",
    "                                                    avg[i,j,:] += acc[i,j,k1,k2,k3,k4,k5,l,:]\n",
    "                                                    out.write(\"%s %.2f %.2f %.2f %.2f\\n\" \\\n",
    "                                                              % (subfeats[j],\n",
    "                                                                 acc[i,j,k1,k2,k3,k4,k5,l,0],\n",
    "                                                                 acc[i,j,k1,k2,k3,k4,k5,l,1],\n",
    "                                                                 acc[i,j,k1,k2,k3,k4,k5,l,2],\n",
    "                                                                 acc[i,j,k1,k2,k3,k4,k5,l,3]))\n",
    "                                                    # selc accuracy\n",
    "                                                    if l == k1 or l == k2 or l == k3 or l == k4 or l == k5:\n",
    "                                                        if j == 0 and l == k5:\n",
    "                                                            out1.write(\"multimulti=\"+str(k1)+str(k2)\n",
    "                                                                       +str(k3)+str(k4)+str(k5)+\"-\"+str(l)+\"\\n\")\n",
    "                                                        self_acc[i,j,k1,k2,k3,k4,k5,0,:] = \\\n",
    "                                                            acc[i,j,k1,k2,k3,k4,k5,l]\n",
    "                                                        avgs[i,j,:] += self_acc[i,j,k1,k2,k3,k4,k5,0,:]\n",
    "                                                        if l == k5:\n",
    "                                                            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" \\\n",
    "                                                                       % (subfeats[j],\n",
    "                                                                          self_acc[i,j,k1,k2,k3,k4,k5,0,0],\n",
    "                                                                          self_acc[i,j,k1,k2,k3,k4,k5,0,1],\n",
    "                                                                          self_acc[i,j,k1,k2,k3,k4,k5,0,2],\n",
    "                                                                          self_acc[i,j,k1,k2,k3,k4,k5,0,3]))\n",
    "                                                    if l != k1 and l != k2 and l != k3 and l!= k4 and l!= k5:\n",
    "                                                        t = range(maxsurf)\n",
    "                                                        t.remove(k1)\n",
    "                                                        t.remove(k2)\n",
    "                                                        t.remove(k3)\n",
    "                                                        t.remove(k4)\n",
    "                                                        t.remove(k5)\n",
    "                                                        if (l == t[-1]):\n",
    "                                                            if j == 0:\n",
    "                                                                out2.write(\"multimulti=\"+str(k1)+str(k2)\\\n",
    "                                                                           +str(k3)+str(k4)+str(k5)+\"\\n\")\n",
    "                                                            cross_acc[i,j,k1,k2,k3,k4,k5,0,:] = \\\n",
    "                                                                np.mean(acc[i,j,k1,k2,k3,k4,k5,t,:], axis=0)\n",
    "                                                            avgc[i,j,:] += cross_acc[i,j,k1,k2,k3,k4,k5,0,:]\n",
    "                                                            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" \\\n",
    "                                                                       % (subfeats[j],\n",
    "                                                                          cross_acc[i,j,k1,k2,k3,k4,k5,0,0],\n",
    "                                                                          cross_acc[i,j,k1,k2,k3,k4,k5,0,1],\n",
    "                                                                          cross_acc[i,j,k1,k2,k3,k4,k5,0,2],\n",
    "                                                                          cross_acc[i,j,k1,k2,k3,k4,k5,0,3]))\n",
    "        out.write(\"multimulti=AVG\\n\")\n",
    "        out1.write(\"multimulti=AVG\\n\")\n",
    "        out2.write(\"multimulti=AVG\\n\")\n",
    "        avg /= comb(maxsurf,5)*maxsurf*1.\n",
    "        avgs /= comb(maxsurf,5)*5.\n",
    "        avgc /= comb(maxsurf,5)*1.\n",
    "        for j in range(len(subfeats)):\n",
    "            out.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avg[i,j,0],avg[i,j,1],avg[i,j,2],avg[i,j,3]))\n",
    "            out1.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgs[i,j,0],avgs[i,j,1],avgs[i,j,2],avgs[i,j,3]))\n",
    "            out2.write(\"%s %.2f %.2f %.2f %.2f\\n\" % (subfeats[j],avgc[i,j,0],avgc[i,j,1],avgc[i,j,2],avgc[i,j,3]))\n",
    "        out.close()\n",
    "        out1.close()\n",
    "        out2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bargraphs_from_perf(i,maxsurf=6):\n",
    "    \"\"\"Bargraph generation using bargraph tool, for i surfaces\"\"\"\n",
    "    print \"---------------------------- Generating bar graphs for \"+str(i+1)+\" surfaces ------------------------------------\"\n",
    "    resfold = respath+str(i+1)+'/'\n",
    "    allperf = glob.glob(resfold+\"*.perf\")\n",
    "    maxperf = len(allperf)\n",
    "    for k in range(len(allperf)):\n",
    "        j = allperf[k]\n",
    "        tmppdf = j[:-4]+\"pdf\"\n",
    "        tmppng = j[:-4]+\"png\"\n",
    "        with open(tmppdf, \"w\") as f1:\n",
    "            call([tool,\"-pdf\",j],stdout=f1)\n",
    "        with open(tmppng, \"w\") as f2:            \n",
    "            call([tool,\"-png\",\"-non-transparent\",j],stdout=f2)\n",
    "        img = mpimg.imread(tmppng)\n",
    "        if k!=0:\n",
    "            plt.subplot(maxsurf,maxperf-1,k+i*(maxperf-1))\n",
    "            plt.imshow(img)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "1 -> f1: (36,) (36,) (36, 4)\n",
      "2 -> f2: (36,) (36,) (36, 4)\n",
      "3 -> f: (72,) (72,) (72, 4)\n",
      "4 -> m1,m2: 36 36 1.0 1.0\n",
      "5 -> f=f+l: (72,) : [(345002, 4), (105001, 4), (210001, 4), (225002, 4), (130001, 4), (65001, 4), (195001, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (225002, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (75001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (130001, 4), (195001, 4), (65001, 4), (345002, 4), (105001, 4), (210001, 4), (225002, 4), (130001, 4), (65001, 4), (195001, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (225002, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (75001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (130001, 4), (195001, 4), (65001, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(72,) : [(345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 1.90207099915 seconds \n",
      "features:  (72,) , labels:  (72,)\n",
      "------------------------------------ AVG FEATURE COMPUTATION TIME ------------------------------------\n",
      "Avg feature computation time (millisec):  2.22414938609\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (72,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (9935, 3107) (9935,) (9935, 3107) (9935,) (9935, 3107) (9935,)\n",
      "Xsp,Ysp [0,1,2]:  (8826, 3107) (8826,) (8826, 3107) (8826,) (8826, 3107) (8826,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (1470, 6, 1)\n",
      "-------------------------- TRAINING all combinations per 1 surface -----------------------------------\n",
      "-------------------------- TRAINING all combinations per 2 surfaces ----------------------------------\n",
      "-------------------------- TRAINING all combinations per 3 surfaces ----------------------------------\n",
      "-------------------------- TRAINING all combinations per 4 surfaces ----------------------------------\n",
      "-------------------------- TRAINING all combinations per 5 surfaces ----------------------------------\n"
     ]
    }
   ],
   "source": [
    "############ TRAINING PROCEDURE ##############\n",
    "# necessary steps before training\n",
    "f,l,fd,member,m1,m2 = data_prep(datafile)                      # read input force and labels\n",
    "prefeat = compute_prefeat(f)                                   # compute corresponding prefeatures\n",
    "features, labels = feature_extraction(prefeat, member)         # feature extraction from prefeatures\n",
    "avg_feat_comp_time(prefeat)                                    # average feature extraction time\n",
    "new_labels = label_cleaning(prefeat,labels,member)             # trim labels, around change points\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2)   # compute data and labels, trimmed and untrimmed\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp)                      # compute per surface data and labels\n",
    "# training\n",
    "train_1_surface(surf,surfla)                                   # training of all combinations per 1 surface\n",
    "train_2_surface(surf,surfla)                                   # training of all combinations per 2 surfaces\n",
    "train_3_surface(surf,surfla)                                   # training of all combinations per 3 surfaces\n",
    "train_4_surface(surf,surfla)                                   # training of all combinations per 4 surfaces\n",
    "train_5_surface(surf,surfla)                                   # training of all combinations per 5 surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Generating perf files for 1 surface -------------------------------------\n",
      "---------------------------- Generating perf files for 2 surfaces ------------------------------------\n",
      "---------------------------- Generating perf files for 3 surfaces ------------------------------------\n",
      "---------------------------- Generating perf files for 4 surfaces ------------------------------------\n",
      "---------------------------- Generating perf files for 5 surfaces ------------------------------------\n",
      "---------------------------- Generating bar graphs for 1 surfaces ------------------------------------\n",
      "---------------------------- Generating bar graphs for 2 surfaces ------------------------------------\n",
      "---------------------------- Generating bar graphs for 3 surfaces ------------------------------------\n",
      "---------------------------- Generating bar graphs for 4 surfaces ------------------------------------\n",
      "---------------------------- Generating bar graphs for 5 surfaces ------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAAcRCAYAAACf9A6GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACAAIQ4AAAAAAEIcQAAAAAC+H+ghVs80ysoLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa715adcd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############ OFFLINE TESTING PROCEDURE ##############\n",
    "# generate files with stats\n",
    "bargraph_perf_gen1(6)\n",
    "bargraph_perf_gen2(6)\n",
    "bargraph_perf_gen3(6)\n",
    "bargraph_perf_gen4(6)\n",
    "bargraph_perf_gen5(6)\n",
    "# use the bargraph tool to plot graphs from generated files\n",
    "# -left column cross-accuracy (trained on one, tested on all the others), \n",
    "# -right column self-accuracy (trained and tested on the same)\n",
    "# -each row i represents training only with i surfaces.\n",
    "# -each stack represents a training group, each bar represents a subfeatureset(AFFT,FREQ,TIME,BOTH)\n",
    "# -blue,green,yellow,red : TP,TN,FN,FP\n",
    "plt.figure(figsize=(20,40))\n",
    "for i in range(5):\n",
    "    make_bargraphs_from_perf(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "1 -> f1: (1, 1) (1, 1) (1, 1)\n",
      "2 -> f2: (1, 1) (1, 1) (1, 1)\n",
      "3 -> f: (2, 1) (2, 1) (2, 1)\n",
      "4 -> m1,m2: 1 1 1.0 1.0\n",
      "5 -> f=f+l: (2, 65000, 4) : [(65000, 4), (65000, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(2,) : [(65000, 2), (65000, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 1.24508905411 seconds \n",
      "features:  (2,) , labels:  (2,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (2,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (3199, 3107) (3199,) (3199, 3107) (3199,) (6398, 3107) (6398,)\n",
      "Xsp,Ysp [0,1,2]:  (2769, 3107) (2769,) (2769, 3107) (2769,) (5538, 3107) (5538,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (922, 6, 1)\n"
     ]
    }
   ],
   "source": [
    "############ ONLINE TESTING PROCEDURE ##############\n",
    "# same necessary steps as in training\n",
    "f,l,fd,member,m1,m2 = data_prep(validfile)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, validfeatfile, 'validfeat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,validXYfile,validXYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,validsurffile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3199,) (2769,) (2769,)\n",
      "(2650,) (2650,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZgAAALICAYAAADyhJW9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBgAAAABgLQrMAAAAAACs5f8ypUpuzCgZnAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb6d8dee50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############ VISUALIZING ONLINE TESTING PROCEDURE ##############\n",
    "\n",
    "subfeats = ['AFFT','FREQ','TIME','BOTH']\n",
    "feats = ['fnorm','ftfn','fnormftfn']\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "\n",
    "fileid = filename1(0,3,0,5)\n",
    "fileidb = filename1(0,0,0,5)\n",
    "fileid5 = filename5(0,3,0,1,2,3,4,5)\n",
    "fileid5b = filename5(0,0,0,1,2,3,4,5)\n",
    "model = np.load(fileid)['model'][0]\n",
    "modelb = np.load(fileidb)['model'][0]\n",
    "model5 = np.load(fileid5)['model'][0]\n",
    "model5b = np.load(fileid5b)['model'][0]\n",
    "Yout = model.predict(X[0])\n",
    "Youtb = modelb.predict(Xsp[0][:,-window-2:-window/2-1])\n",
    "Yout5 = model5.predict(Xsp[0])\n",
    "Yout5b = model5b.predict(Xsp[0][:,-window-2:-window/2-1])\n",
    "print Yout.shape, Yout5.shape, Yout5b.shape\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('axes', linewidth=2)\n",
    "plt.rc('font', weight='bold')\n",
    "plt.rcParams['text.latex.preamble'] = [r'\\usepackage{sfmath} \\boldmath']\n",
    "offset = 2000-window\n",
    "endset = 2650\n",
    "skipf = 20\n",
    "skipy = 15\n",
    "ax = plt.figure(figsize=(20,10))\n",
    "tf = np.linalg.norm(f[0][offset+window::skipf,:3][:endset],axis=1)\n",
    "p1, = plt.plot(tf/max(tf),linewidth=5)\n",
    "ty = Yout[offset/skipf:][:endset]+0.02\n",
    "print tf.shape, ty.shape\n",
    "p = plt.scatter(range(len(tf))[::skipy],ty[::skipy],color='red',s=30)\n",
    "plt.hold\n",
    "plt.text(100, 0.15, r'\\textbf{Stable}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.text(1000, 0.85, r'\\textbf{Slip}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.annotate('', fontsize=10, xy=(100, 0.05), xytext=(100, 0.12),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.annotate('', xy=(1000, 0.98), xytext=(1000, 0.9),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.text(400, 0.55, r'\\textbf{P1}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=810,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(1000, 0.55, r'\\textbf{P2}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=1200,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(1250, 0.55, r'\\textbf{P3}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=1335,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(1385, 0.25, r'\\textbf{P4}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=1445,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(1650, 0.55, r'\\textbf{P1}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=1830,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(2000, 0.55, r'\\textbf{P2}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=2200,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(2250, 0.55, r'\\textbf{P3}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=2330,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(2385, 0.25, r'\\textbf{P4}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=2440,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(2540, 0.55, r'\\textbf{P1}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.xlabel(r't ($1e^{-2} sec$)',fontsize=35)\n",
    "# plt.yticks([])\n",
    "plt.legend([p1,p],[r'$|\\textbf{f}|$',r'\\textbf{out1}'],loc=2, prop={'size': 35})\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.tight_layout()\n",
    "savefig(datapath+'validation.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ PREDICTING ACCURACY FOR ATI SENSOR DATA ##############\n",
    "def testing_accuracy_simple(surf, surfla, ltest=6):\n",
    "    fileid = filename1(0,3,0,5)            #  all  features, 1 trained surface(surf 0)\n",
    "    fileidb = filename1(0,0,0,5)           # |FFT| features, 1 trained surface(surf 0)\n",
    "    fileid5 = filename5(0,3,0,1,2,3,4,5)   #  all  features, 5 trained surfaces(surf 0-4)\n",
    "    fileid5b = filename5(0,0,0,1,2,3,4,5)  # |FFT| features, 5 trained surfaces(surf 0-4)\n",
    "    model = np.load(fileid)['model'][0]\n",
    "    modelb = np.load(fileidb)['model'][0]\n",
    "    model5 = np.load(fileid5)['model'][0]\n",
    "    model5b = np.load(fileid5b)['model'][0]\n",
    "    for i in range(ltest):\n",
    "        Yout = model.predict(surf[3, i, 0])\n",
    "        Youtb = modelb.predict(surf[0, i, 0])\n",
    "        Yout5 = model5.predict(surf[3, i, 0])\n",
    "        Yout5b = model5b.predict(surf[0, i, 0])\n",
    "        #     print i, Yout.shape, Youtb.shape, Yout5.shape, Yout5b.shape\n",
    "        Ysc = model.score(surf[3, i ,0], surfla[:, i, 0])\n",
    "        Yscb = modelb.score(surf[0, i, 0], surfla[:, i, 0])\n",
    "        Ysc5 = model5.score(surf[3, i, 0], surfla[:, i, 0])\n",
    "        Ysc5b = model5b.score(surf[0, i ,0], surfla[:, i, 0])\n",
    "        print \"Accuracy for surface \", i, Ysc, Yscb, Ysc5, Ysc5b\n",
    "    Yscn = model.score(Xsp[2],Ysp[2])\n",
    "    Yscbn = modelb.score(Xsp[2][:,-window-2:-window/2-1],Ysp[2])\n",
    "    Ysc5n = model5.score(Xsp[2],Ysp[2])\n",
    "    Ysc5bn = model5b.score(Xsp[2][:,-window-2:-window/2-1],Ysp[2])\n",
    "    print \"Accuracy for dataset   \", Yscn, Yscbn, Ysc5n, Ysc5bn\n",
    "    \n",
    "# testing_accuracy_simple(surf, surfla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ PREDICTING ACCURACY FOR ATI SENSOR DATA DETAILED ##############\n",
    "def testing_accuracy(surf, surfla, trsurf=[1, 5], ltest=6, printit=True):\n",
    "    lsurf = len(trsurf)\n",
    "    lsubfs = surf.shape[0]\n",
    "    acc = np.zeros((lsurf,lsubfs,ltest,2))\n",
    "    for r in range(lsurf):  # for each number of surfaces used for training\n",
    "        for k in range(lsubfs):  # for each subfs\n",
    "            filenames = glob.glob(\"data/results\" + str(trsurf[r]) + \"/fs_\" + str(0) + \"_subfs_\" + str(k) + \"_*.npz\")\n",
    "            numf = len(filenames)\n",
    "            for i in range(ltest):  # for each testing surface\n",
    "                curracc = np.zeros(numf)\n",
    "                for n in range(numf):\n",
    "                    model = np.load(filenames[n])['model'][0]\n",
    "                    Ysc = model.score(surf[k, i ,0], surfla[:, i, 0])\n",
    "                    curracc[n] = Ysc\n",
    "#                     print \"Surf: \",trsurf[r],\"subfs: \",k,\"test_surf: \",i,\"model: \",n,\"Acc: \",Ysc\n",
    "                acc[r,k,i,0] = np.mean(curracc)\n",
    "                acc[r,k,i,1] = np.std(curracc)\n",
    "                if printit:\n",
    "                    print \"Surf: \",trsurf[r],\"subfs: \",k,\"test_surf: \",i,\"Acc_mean-std: \",acc[r,k,i,0], acc[r,k,i,1]\n",
    "            if printit:\n",
    "                print \"Surf: \",trsurf[r],\"subfs: \",k,\"Acc_mean-std: \",np.mean(acc[r,k,:,0]), np.mean(acc[r,k,:,1])\n",
    "    return acc\n",
    "\n",
    "# _ = testing_accuracy(surf, surfla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (6, 1) (6, 1) (6, 1)\n",
      "4 -> m1,m2: 3 3 1.0 1.0\n",
      "5 -> f=f+l: (6, 21000, 4) : [(21000, 4), (21000, 4), (21000, 4), (21000, 4), (21000, 4), (21000, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.173109054565 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (2997, 3107) (2997,) (2997, 3107) (2997,) (5994, 3107) (5994,)\n",
      "Xsp,Ysp [0,1,2]:  (2397, 3107) (2397,) (2397, 3107) (2397,) (4794, 3107) (4794,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (799, 6, 1)\n",
      "Accuracy for surface  0 0.858573216521 0.922403003755 0.546933667084 0.908635794743\n",
      "Accuracy for surface  1 0.728410513141 0.938673341677 0.53942428035 0.92365456821\n",
      "Accuracy for surface  2 0.660826032541 0.927409261577 0.504380475594 0.727158948686\n",
      "Accuracy for surface  3 0.787234042553 0.927409261577 0.548185231539 0.979974968711\n",
      "Accuracy for surface  4 0.82478097622 0.876095118899 0.599499374218 0.964956195244\n",
      "Accuracy for surface  5 0.853566958698 0.943679599499 0.613266583229 0.969962453066\n",
      "Accuracy for dataset    0.785565289946 0.922611597831 0.558614935336 0.91239048811\n",
      "Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.742942567098 0.187100927686\n",
      "Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.724864413851 0.16126480725\n",
      "Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.742664441663 0.171732419955\n",
      "Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.79251842581 0.132575315896\n",
      "Surf:  1 subfs:  0 test_surf:  4 Acc_mean-std:  0.728758169935 0.14949680311\n",
      "Surf:  1 subfs:  0 test_surf:  5 Acc_mean-std:  0.788346544291 0.156836329587\n",
      "Surf:  1 subfs:  0 Acc_mean-std:  0.753349093775 0.159834433914\n",
      "Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.641252955083 0.241246809464\n",
      "Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.641357252121 0.217057435593\n",
      "Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.607738840217 0.211866154422\n",
      "Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.622166597135 0.146506945118\n",
      "Surf:  1 subfs:  1 test_surf:  4 Acc_mean-std:  0.66444166319 0.171140418867\n",
      "Surf:  1 subfs:  1 test_surf:  5 Acc_mean-std:  0.609198998748 0.145359205\n",
      "Surf:  1 subfs:  1 Acc_mean-std:  0.631026051082 0.188862828077\n",
      "Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.588861076345 0.139811414533\n",
      "Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.559066889167 0.0908861501533\n",
      "Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.548880545126 0.0694855919466\n",
      "Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.59223334724 0.159909589848\n",
      "Surf:  1 subfs:  2 test_surf:  4 Acc_mean-std:  0.584202475316 0.131710967919\n",
      "Surf:  1 subfs:  2 test_surf:  5 Acc_mean-std:  0.596474760117 0.151687734599\n",
      "Surf:  1 subfs:  2 Acc_mean-std:  0.578286515552 0.1239152415\n",
      "Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.663607286886 0.110181559406\n",
      "Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.581734112085 0.139607830747\n",
      "Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.531393408427 0.16879691818\n",
      "Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.66138228341 0.0715890762604\n",
      "Surf:  1 subfs:  3 test_surf:  4 Acc_mean-std:  0.655298289529 0.112837393532\n",
      "Surf:  1 subfs:  3 test_surf:  5 Acc_mean-std:  0.648518982061 0.132276771736\n",
      "Surf:  1 subfs:  3 Acc_mean-std:  0.623655727066 0.12254825831\n",
      "Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.811570018078 0.171508592435\n",
      "Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.800618829092 0.153306519279\n",
      "Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.732721457377 0.130489039679\n",
      "Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.854297037964 0.151001761595\n",
      "Surf:  5 subfs:  0 test_surf:  4 Acc_mean-std:  0.839069670421 0.168320135898\n",
      "Surf:  5 subfs:  0 test_surf:  5 Acc_mean-std:  0.841329439577 0.151551344268\n",
      "Surf:  5 subfs:  0 Acc_mean-std:  0.813267742085 0.154362898859\n",
      "Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.467980809345 0.0340019541113\n",
      "Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.490856626338 0.0377339931308\n",
      "Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.47232651926 0.0285953154411\n",
      "Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.479557780559 0.0443413309612\n",
      "Surf:  5 subfs:  1 test_surf:  4 Acc_mean-std:  0.504693366708 0.0532281851711\n",
      "Surf:  5 subfs:  1 test_surf:  5 Acc_mean-std:  0.453622583785 0.0317768198424\n",
      "Surf:  5 subfs:  1 Acc_mean-std:  0.478172947666 0.0382795997763\n",
      "Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.509560561813 0.0200666043433\n",
      "Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.561083298568 0.0445403984575\n",
      "Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.567271589487 0.0505825580721\n",
      "Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.577214573773 0.0381377283737\n",
      "Surf:  5 subfs:  2 test_surf:  4 Acc_mean-std:  0.514497288277 0.0306773386584\n",
      "Surf:  5 subfs:  2 test_surf:  5 Acc_mean-std:  0.529342233347 0.0422668884676\n",
      "Surf:  5 subfs:  2 Acc_mean-std:  0.543161590877 0.0377119193954\n",
      "Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.620358781811 0.0819251739455\n",
      "Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.63934084272 0.0687636311441\n",
      "Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.606939229593 0.0534098151304\n",
      "Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.595988040606 0.0581867702458\n",
      "Surf:  5 subfs:  3 test_surf:  4 Acc_mean-std:  0.653907662356 0.0614460835532\n",
      "Surf:  5 subfs:  3 test_surf:  5 Acc_mean-std:  0.662494785148 0.080275933471\n",
      "Surf:  5 subfs:  3 Acc_mean-std:  0.629838223706 0.067334567915\n"
     ]
    }
   ],
   "source": [
    "############ NEW TESTING PROCEDURE WITH DATA FROM ATI F/T SENSOR ##############\n",
    "# same necessary steps as in testing before\n",
    "atifile = datapath+'ati_validation.mat'\n",
    "atifeatname = 'ati'+featname\n",
    "atifeatfile = featpath+atifeatname+'.npz'\n",
    "atisurffile = featpath+atifeatname+'_1fing_6surf.npz'\n",
    "atiXYfile = featpath+atifeatname+'_XY.npz'\n",
    "atiXYsplitfile = featpath+atifeatname+'_XYsplit.npz'\n",
    "f,l,fd,member,m1,m2 = data_prep(atifile,k=1)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, atifeatfile, 'atifeat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,atiXYfile,atiXYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,atisurffile,n=6, k=1)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA ROTATIONAL ##############\n",
    "testing_accuracy_simple(surf, surfla, ltest=6)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA DETAILED ##############\n",
    "_ = testing_accuracy(surf, surfla, ltest=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (4, 1) (4, 1) (4, 1)\n",
      "4 -> m1,m2: 2 2 1.0 1.0\n",
      "5 -> f=f+l: (4, 21500, 4) : [(21500, 4), (21500, 4), (21500, 4), (21500, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(4,) : [(21500, 2), (21500, 2), (21500, 2), (21500, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.118757963181 seconds \n",
      "features:  (4,) , labels:  (4,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (4,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (2048, 3107) (2048,) (2048, 3107) (2048,) (4096, 3107) (4096,)\n",
      "Xsp,Ysp [0,1,2]:  (1648, 3107) (1648,) (1648, 3107) (1648,) (3296, 3107) (3296,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "0 0 (4, 824, 3107)\n",
      "0 1 (4, 824, 3107)\n",
      "0 2 (4, 824, 3107)\n",
      "0 3 (4, 824, 3107)\n",
      "0 4 (4, 824, 3107)\n",
      "(4, 4, 1) (824, 4, 1)\n",
      "Accuracy for surface  0 0.756067961165 0.514563106796 0.559466019417 0.514563106796\n",
      "Accuracy for surface  1 0.680825242718 0.514563106796 0.555825242718 0.514563106796\n",
      "Accuracy for surface  2 0.739077669903 0.575242718447 0.502427184466 0.63713592233\n",
      "Accuracy for surface  3 0.54854368932 0.510922330097 0.523058252427 0.546116504854\n",
      "Accuracy for dataset    0.681128640777 0.528822815534 0.535194174757 0.553094660194\n",
      "Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.578276699029 0.126251673317\n",
      "Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.551611380798 0.0796126813904\n",
      "Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.617549892125 0.178064341417\n",
      "Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.541835221143 0.0593334263787\n",
      "Surf:  1 subfs:  0 Acc_mean-std:  0.572318298274 0.110815530626\n",
      "Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.589131607335 0.102267278167\n",
      "Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.603762135922 0.130985062331\n",
      "Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.597121089536 0.114640574993\n",
      "Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.522485167206 0.0290593979656\n",
      "Surf:  1 subfs:  1 Acc_mean-std:  0.578125 0.0942380783642\n",
      "Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.545678263215 0.124422686004\n",
      "Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.545374865156 0.122300916887\n",
      "Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.560443635383 0.113982529443\n",
      "Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.514091154261 0.0511929443634\n",
      "Surf:  1 subfs:  2 Acc_mean-std:  0.541396979504 0.102974769174\n",
      "Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.621696332255 0.105042003164\n",
      "Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.589873247033 0.0722135220717\n",
      "Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.603323894283 0.09326524205\n",
      "Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.533171521036 0.0417559213072\n",
      "Surf:  1 subfs:  3 Acc_mean-std:  0.587016248652 0.0780691721481\n",
      "Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.625539374326 0.123446003166\n",
      "Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.601065264293 0.109535471396\n",
      "Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.691781283711 0.122844699806\n",
      "Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.546082793959 0.0695836895758\n",
      "Surf:  5 subfs:  0 Acc_mean-std:  0.616117179072 0.106352465986\n",
      "Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.570354638619 0.0895834617122\n",
      "Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.521676105717 0.0423079526482\n",
      "Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.511023462783 0.0288004512111\n",
      "Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.516012675297 0.0227345188609\n",
      "Surf:  5 subfs:  1 Acc_mean-std:  0.529766720604 0.0458565961081\n",
      "Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.48931364617 0.0219135081687\n",
      "Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.487021305286 0.00937350828633\n",
      "Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.485706580367 0.00524418459618\n",
      "Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.485470604099 0.0080168875306\n",
      "Surf:  5 subfs:  2 Acc_mean-std:  0.486878033981 0.0111370221454\n",
      "Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.596986245955 0.0911974055303\n",
      "Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.605649946063 0.0649438452424\n",
      "Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.550667475728 0.0584832931622\n",
      "Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.530070118662 0.0338915064659\n",
      "Surf:  5 subfs:  3 Acc_mean-std:  0.570843446602 0.0621290126002\n"
     ]
    }
   ],
   "source": [
    "############ NEW TESTING PROCEDURE WITH DATA FROM ATI F/T SENSOR ROTATIONAL CASE ##############\n",
    "# same necessary steps as in testing before\n",
    "atirotfile = datapath+'ati_validation_rot.mat'\n",
    "atirotfeatname = 'ati_rot'+featname\n",
    "atirotfeatfile = featpath+atirotfeatname+'.npz'\n",
    "atirotsurffile = featpath+atirotfeatname+'_1fing_4surf.npz'\n",
    "atirotXYfile = featpath+atirotfeatname+'_XY.npz'\n",
    "atirotXYsplitfile = featpath+atirotfeatname+'_XYsplit.npz'\n",
    "f,l,fd,member,m1,m2 = data_prep(atirotfile,k=1)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, atirotfeatfile, 'atirotfeat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,atirotXYfile,atirotXYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,atirotsurffile,n=4, k=1)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA ROTATIONAL ##############\n",
    "testing_accuracy_simple(surf, surfla, ltest=4)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA DETAILED ##############\n",
    "_ = testing_accuracy(surf, surfla, ltest=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (6, 1) (6, 1) (6, 1)\n",
      "4 -> m1,m2: 3 3 1.0 1.0\n",
      "5 -> f=f+l: (6, 12500, 4) : [(12500, 4), (12500, 4), (12500, 4), (12500, 4), (12500, 4), (12500, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(12500, 2), (12500, 2), (12500, 2), (12500, 2), (12500, 2), (12500, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "sample: 0 , time(sec): 0.98 data/features/1024_20/AllFeatures/ati830feat_0.pkl.z  computing...  (1, 574, 3107, 2)\n",
      "sample: 0 , time(sec): 1.11 data/features/1024_20/AllFeatures/ati830feat_0_red10000.pkl.z (574, 3107, 2)\n",
      "sample: 1 , time(sec): 0.80 data/features/1024_20/AllFeatures/ati830feat_1.pkl.z  computing...  (1, 574, 3107, 2)\n",
      "sample: 1 , time(sec): 0.90 data/features/1024_20/AllFeatures/ati830feat_1_red10000.pkl.z (574, 3107, 2)\n",
      "sample: 2 , time(sec): 0.72 data/features/1024_20/AllFeatures/ati830feat_2.pkl.z  computing...  (1, 574, 3107, 2)\n",
      "sample: 2 , time(sec): 0.83 data/features/1024_20/AllFeatures/ati830feat_2_red10000.pkl.z (574, 3107, 2)\n",
      "sample: 3 , time(sec): 0.69 data/features/1024_20/AllFeatures/ati830feat_3.pkl.z  computing...  (1, 574, 3107, 2)\n",
      "sample: 3 , time(sec): 0.79 data/features/1024_20/AllFeatures/ati830feat_3_red10000.pkl.z (574, 3107, 2)\n",
      "sample: 4 , time(sec): 0.80 data/features/1024_20/AllFeatures/ati830feat_4.pkl.z  computing...  (1, 574, 3107, 2)\n",
      "sample: 4 , time(sec): 0.90 data/features/1024_20/AllFeatures/ati830feat_4_red10000.pkl.z (574, 3107, 2)\n",
      "sample: 5 , time(sec): 0.69 data/features/1024_20/AllFeatures/ati830feat_5.pkl.z  computing...  (1, 574, 3107, 2)\n",
      "sample: 5 , time(sec): 0.80 data/features/1024_20/AllFeatures/ati830feat_5_red10000.pkl.z (574, 3107, 2)\n",
      "sample: 0 , time(sec): 0.80 data/features/1024_20/AllFeatures/ati830feat_0_red10000.pkl.z already here! (574, 3107, 2)\n",
      "sample: 1 , time(sec): 0.81 data/features/1024_20/AllFeatures/ati830feat_1_red10000.pkl.z already here! (574, 3107, 2)\n",
      "sample: 2 , time(sec): 0.81 data/features/1024_20/AllFeatures/ati830feat_2_red10000.pkl.z already here! (574, 3107, 2)\n",
      "sample: 3 , time(sec): 0.82 data/features/1024_20/AllFeatures/ati830feat_3_red10000.pkl.z already here! (574, 3107, 2)\n",
      "sample: 4 , time(sec): 0.83 data/features/1024_20/AllFeatures/ati830feat_4_red10000.pkl.z already here! (574, 3107, 2)\n",
      "sample: 5 , time(sec): 0.83 data/features/1024_20/AllFeatures/ati830feat_5_red10000.pkl.z already here! (574, 3107, 2)\n",
      "Features NOT FOUND PRECOMPUTED! Feature Computation DONE in: 5.35794997215 sec \n",
      "features:  (6,) [(574, 3107, 1), (574, 3107, 1), (574, 3107, 1), (574, 3107, 1), (574, 3107, 1), (574, 3107, 1)]\n",
      "labels:  (6,) [(574,), (574,), (574,), (574,), (574,), (574,)]\n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "Before -> X[ 0 ]:  (3,) , Y[ 0 ]:  (3,) , Yn[ 0 ]:  (3,)\n",
      "Gathered -> X[ 0 ]:  (1722, 3107, 1) , Y[ 0 ]:  (1722,) , Yn[ 0 ]:  (1722,)\n",
      "Gathered, sampled to max  10000  -> X[ 0 ]:  (1722, 3107) , Y[ 0 ]:  (1722,) , Yn[ 0 ]:  (1722,)\n",
      "Split -> Xsp[ 0 ]:  (1422, 3107) , Ysp[ 0 ]:  (1422,)\n",
      "Before -> X[ 1 ]:  (3,) , Y[ 1 ]:  (3,) , Yn[ 1 ]:  (3,)\n",
      "Gathered -> X[ 1 ]:  (1722, 3107, 1) , Y[ 1 ]:  (1722,) , Yn[ 1 ]:  (1722,)\n",
      "Gathered, sampled to max  10000  -> X[ 1 ]:  (1722, 3107) , Y[ 1 ]:  (1722,) , Yn[ 1 ]:  (1722,)\n",
      "Split -> Xsp[ 1 ]:  (1422, 3107) , Ysp[ 1 ]:  (1422,)\n",
      "Before -> X[ 2 ]:  (6,) , Y[ 2 ]:  (6,) , Yn[ 2 ]:  (6,)\n",
      "Gathered -> X[ 2 ]:  (3444, 3107, 1) , Y[ 2 ]:  (3444,) , Yn[ 2 ]:  (3444,)\n",
      "Gathered, sampled to max  10000  -> X[ 2 ]:  (3444, 3107) , Y[ 2 ]:  (3444,) , Yn[ 2 ]:  (3444,)\n",
      "Split -> Xsp[ 2 ]:  (2844, 3107) , Ysp[ 2 ]:  (2844,)\n",
      "X,Y [0,1,2]:  (1722, 3107) (1722,) (1722, 3107) (1722,) (3444, 3107) (3444,)\n",
      "Xsp,Ysp [0,1,2]:  (1422, 3107) (1422,) (1422, 3107) (1422,) (2844, 3107) (2844,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "0 0 (6, 474, 3107)\n",
      "0 1 (6, 474, 3107)\n",
      "0 2 (6, 474, 3107)\n",
      "0 3 (6, 474, 3107)\n",
      "0 4 (6, 474, 3107)\n",
      "0 5 (6, 474, 3107)\n",
      "0 6 (6, 474, 3107)\n",
      "(4, 6, 1) (474, 6, 1)\n",
      "Accuracy for surface  0 0.87552742616 0.405063291139 0.556962025316 0.959915611814\n",
      "Accuracy for surface  1 0.928270042194 0.424050632911 0.679324894515 0.978902953586\n",
      "Accuracy for surface  2 0.725738396624 0.462025316456 0.542194092827 0.96835443038\n",
      "Accuracy for surface  3 0.822784810127 0.782700421941 0.550632911392 0.911392405063\n",
      "Accuracy for surface  4 0.900843881857 0.601265822785 0.677215189873 0.947257383966\n",
      "Accuracy for surface  5 0.827004219409 0.784810126582 0.605485232068 0.985232067511\n",
      "Accuracy for dataset    0.846694796062 0.576652601969 0.601969057665 0.958509142053\n",
      "Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.656000937647 0.222181573556\n",
      "Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.682899671824 0.23438082164\n",
      "Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.68723628692 0.218337938842\n",
      "Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.773968588842 0.153476201729\n",
      "Surf:  1 subfs:  0 test_surf:  4 Acc_mean-std:  0.773792780122 0.197230814133\n",
      "Surf:  1 subfs:  0 test_surf:  5 Acc_mean-std:  0.759552273793 0.173230380556\n",
      "Surf:  1 subfs:  0 Acc_mean-std:  0.722241756524 0.199806288409\n",
      "Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.677918424754 0.219306139881\n",
      "Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.699601500234 0.221553185234\n",
      "Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.786040787623 0.171485793837\n",
      "Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.746659634318 0.122899601047\n",
      "Surf:  1 subfs:  1 test_surf:  4 Acc_mean-std:  0.764826535396 0.157500662258\n",
      "Surf:  1 subfs:  1 test_surf:  5 Acc_mean-std:  0.725328176278 0.147429481448\n",
      "Surf:  1 subfs:  1 Acc_mean-std:  0.7333958431 0.173362477284\n",
      "Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.574191279887 0.218753810569\n",
      "Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.587962962963 0.235022958994\n",
      "Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.542604313174 0.185159099491\n",
      "Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.606364275668 0.184623181746\n",
      "Surf:  1 subfs:  2 test_surf:  4 Acc_mean-std:  0.643811533052 0.204414969444\n",
      "Surf:  1 subfs:  2 test_surf:  5 Acc_mean-std:  0.642756680731 0.186351272361\n",
      "Surf:  1 subfs:  2 Acc_mean-std:  0.599615174246 0.202387548767\n",
      "Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.594467885607 0.184879976016\n",
      "Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.637775433662 0.185687848163\n",
      "Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.546354899203 0.106027073109\n",
      "Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.660337552743 0.161228003376\n",
      "Surf:  1 subfs:  3 test_surf:  4 Acc_mean-std:  0.676511954993 0.145719023462\n",
      "Surf:  1 subfs:  3 test_surf:  5 Acc_mean-std:  0.604137365213 0.150210338982\n",
      "Surf:  1 subfs:  3 Acc_mean-std:  0.61993084857 0.155625377185\n",
      "Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.856364275668 0.18051121276\n",
      "Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.858415377403 0.182461182889\n",
      "Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.771624472574 0.215095269254\n",
      "Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.762189404594 0.122247236607\n",
      "Surf:  5 subfs:  0 test_surf:  4 Acc_mean-std:  0.725562587904 0.210948413639\n",
      "Surf:  5 subfs:  0 test_surf:  5 Acc_mean-std:  0.798699015471 0.167173571307\n",
      "Surf:  5 subfs:  0 Acc_mean-std:  0.795475855602 0.179739481076\n",
      "Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.45270745429 0.133387154619\n",
      "Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.473452883263 0.129717173264\n",
      "Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.643518518519 0.176539610208\n",
      "Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.672937177684 0.077458833923\n",
      "Surf:  5 subfs:  1 test_surf:  4 Acc_mean-std:  0.724624941397 0.0941776790117\n",
      "Surf:  5 subfs:  1 test_surf:  5 Acc_mean-std:  0.601910454759 0.0942988147058\n",
      "Surf:  5 subfs:  1 Acc_mean-std:  0.594858571652 0.117596544288\n",
      "Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.423816221285 0.0110943830907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.426336146273 0.0260024603688\n",
      "Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.424050632911 0.0107228907749\n",
      "Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.62464838256 0.0532752639794\n",
      "Surf:  5 subfs:  2 test_surf:  4 Acc_mean-std:  0.616912798875 0.11808209406\n",
      "Surf:  5 subfs:  2 test_surf:  5 Acc_mean-std:  0.554383497421 0.0407272915478\n",
      "Surf:  5 subfs:  2 Acc_mean-std:  0.511691279887 0.0433173973036\n",
      "Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.588607594937 0.109887060279\n",
      "Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.700363338022 0.102237251107\n",
      "Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.555028129395 0.0499603098318\n",
      "Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.623183309892 0.0676427842612\n",
      "Surf:  5 subfs:  3 test_surf:  4 Acc_mean-std:  0.689932020628 0.0595106386029\n",
      "Surf:  5 subfs:  3 test_surf:  5 Acc_mean-std:  0.62962962963 0.0442352193001\n",
      "Surf:  5 subfs:  3 Acc_mean-std:  0.631124003751 0.0722455438971\n"
     ]
    }
   ],
   "source": [
    "############ NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE ##############\n",
    "# same necessary steps as in testing before\n",
    "ati830file = datapath+'ati_new_830Hz_validation.mat'\n",
    "ati830featname = 'ati_830'+featname\n",
    "ati830featfile = featpath+ati830featname+'.npz'\n",
    "ati830surffile = featpath+ati830featname+'_1fing_6surf.npz'\n",
    "ati830XYfile = featpath+ati830featname+'_XY.npz'\n",
    "ati830XYsplitfile = featpath+ati830featname+'_XYsplit.npz'\n",
    "f,l,fd,member,m1,m2 = data_prep(ati830file,k=1)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, ati830featfile, 'ati830feat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,ati830XYfile,ati830XYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,ati830surffile,n=6, k=1)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA ROTATIONAL ##############\n",
    "testing_accuracy_simple(surf, surfla, ltest=6)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA DETAILED ##############\n",
    "_ = testing_accuracy(surf, surfla, ltest=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (6, 1) (6, 1) (6, 1)\n",
      "4 -> m1,m2: 3 3 1.0 1.0\n",
      "5 -> f=f+l: (6,) : [(21500, 4), (21500, 4), (21500, 4), (21500, 4), (21500, 4), (21499, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21500, 2), (21500, 2), (21500, 2), (21500, 2), (21500, 2), (21499, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "sample: 0 , time(sec): 1.12 data/features/1024_20/AllFeatures/ati830rotfeat_0.pkl.z  computing...  (1, 1024, 3107, 2)\n",
      "sample: 0 , time(sec): 1.31 data/features/1024_20/AllFeatures/ati830rotfeat_0_red10000.pkl.z (1024, 3107, 2)\n",
      "sample: 1 , time(sec): 1.08 data/features/1024_20/AllFeatures/ati830rotfeat_1.pkl.z  computing...  (1, 1024, 3107, 2)\n",
      "sample: 1 , time(sec): 1.27 data/features/1024_20/AllFeatures/ati830rotfeat_1_red10000.pkl.z (1024, 3107, 2)\n",
      "sample: 2 , time(sec): 0.98 data/features/1024_20/AllFeatures/ati830rotfeat_2.pkl.z  computing...  (1, 1024, 3107, 2)\n",
      "sample: 2 , time(sec): 1.16 data/features/1024_20/AllFeatures/ati830rotfeat_2_red10000.pkl.z (1024, 3107, 2)\n",
      "sample: 3 , time(sec): 1.13 data/features/1024_20/AllFeatures/ati830rotfeat_3.pkl.z  computing...  (1, 1024, 3107, 2)\n",
      "sample: 3 , time(sec): 1.32 data/features/1024_20/AllFeatures/ati830rotfeat_3_red10000.pkl.z (1024, 3107, 2)\n",
      "sample: 4 , time(sec): 0.98 data/features/1024_20/AllFeatures/ati830rotfeat_4.pkl.z  computing...  (1, 1024, 3107, 2)\n",
      "sample: 4 , time(sec): 1.17 data/features/1024_20/AllFeatures/ati830rotfeat_4_red10000.pkl.z (1024, 3107, 2)\n",
      "sample: 5 , time(sec): 1.10 data/features/1024_20/AllFeatures/ati830rotfeat_5.pkl.z  computing...  (1, 1024, 3107, 2)\n",
      "sample: 5 , time(sec): 1.28 data/features/1024_20/AllFeatures/ati830rotfeat_5_red10000.pkl.z (1024, 3107, 2)\n",
      "sample: 0 , time(sec): 1.29 data/features/1024_20/AllFeatures/ati830rotfeat_0_red10000.pkl.z already here! (1024, 3107, 2)\n",
      "sample: 1 , time(sec): 1.30 data/features/1024_20/AllFeatures/ati830rotfeat_1_red10000.pkl.z already here! (1024, 3107, 2)\n",
      "sample: 2 , time(sec): 1.31 data/features/1024_20/AllFeatures/ati830rotfeat_2_red10000.pkl.z already here! (1024, 3107, 2)\n",
      "sample: 3 , time(sec): 1.32 data/features/1024_20/AllFeatures/ati830rotfeat_3_red10000.pkl.z already here! (1024, 3107, 2)\n",
      "sample: 4 , time(sec): 1.33 data/features/1024_20/AllFeatures/ati830rotfeat_4_red10000.pkl.z already here! (1024, 3107, 2)\n",
      "sample: 5 , time(sec): 1.36 data/features/1024_20/AllFeatures/ati830rotfeat_5_red10000.pkl.z already here! (1024, 3107, 2)\n",
      "Features NOT FOUND PRECOMPUTED! Feature Computation DONE in: 7.58360981941 sec \n",
      "features:  (6,) [(1024, 3107, 1), (1024, 3107, 1), (1024, 3107, 1), (1024, 3107, 1), (1024, 3107, 1), (1024, 3107, 1)]\n",
      "labels:  (6,) [(1024,), (1024,), (1024,), (1024,), (1024,), (1024,)]\n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "Before -> X[ 0 ]:  (3,) , Y[ 0 ]:  (3,) , Yn[ 0 ]:  (3,)\n",
      "Gathered -> X[ 0 ]:  (3072, 3107, 1) , Y[ 0 ]:  (3072,) , Yn[ 0 ]:  (3072,)\n",
      "Gathered, sampled to max  10000  -> X[ 0 ]:  (3072, 3107) , Y[ 0 ]:  (3072,) , Yn[ 0 ]:  (3072,)\n",
      "Split -> Xsp[ 0 ]:  (2472, 3107) , Ysp[ 0 ]:  (2472,)\n",
      "Before -> X[ 1 ]:  (3,) , Y[ 1 ]:  (3,) , Yn[ 1 ]:  (3,)\n",
      "Gathered -> X[ 1 ]:  (3072, 3107, 1) , Y[ 1 ]:  (3072,) , Yn[ 1 ]:  (3072,)\n",
      "Gathered, sampled to max  10000  -> X[ 1 ]:  (3072, 3107) , Y[ 1 ]:  (3072,) , Yn[ 1 ]:  (3072,)\n",
      "Split -> Xsp[ 1 ]:  (2472, 3107) , Ysp[ 1 ]:  (2472,)\n",
      "Before -> X[ 2 ]:  (6,) , Y[ 2 ]:  (6,) , Yn[ 2 ]:  (6,)\n",
      "Gathered -> X[ 2 ]:  (6144, 3107, 1) , Y[ 2 ]:  (6144,) , Yn[ 2 ]:  (6144,)\n",
      "Gathered, sampled to max  10000  -> X[ 2 ]:  (6144, 3107) , Y[ 2 ]:  (6144,) , Yn[ 2 ]:  (6144,)\n",
      "Split -> Xsp[ 2 ]:  (4944, 3107) , Ysp[ 2 ]:  (4944,)\n",
      "X,Y [0,1,2]:  (3072, 3107) (3072,) (3072, 3107) (3072,) (6144, 3107) (6144,)\n",
      "Xsp,Ysp [0,1,2]:  (2472, 3107) (2472,) (2472, 3107) (2472,) (4944, 3107) (4944,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "0 0 (6, 824, 3107)\n",
      "0 1 (6, 824, 3107)\n",
      "0 2 (6, 824, 3107)\n",
      "0 3 (6, 824, 3107)\n",
      "0 4 (6, 824, 3107)\n",
      "0 5 (6, 824, 3107)\n",
      "0 6 (6, 824, 3107)\n",
      "(4, 6, 1) (824, 6, 1)\n",
      "Accuracy for surface  0 0.81432038835 0.408980582524 0.779126213592 0.719660194175\n",
      "Accuracy for surface  1 0.82645631068 0.292475728155 0.712378640777 0.796116504854\n",
      "Accuracy for surface  2 0.794902912621 0.305825242718 0.691747572816 0.904126213592\n",
      "Accuracy for surface  3 0.714805825243 0.705097087379 0.745145631068 0.824029126214\n",
      "Accuracy for surface  4 0.86286407767 0.712378640777 0.853155339806 0.905339805825\n",
      "Accuracy for surface  5 0.839805825243 0.684466019417 0.796116504854 0.683252427184\n",
      "Accuracy for dataset    0.808859223301 0.518203883495 0.762944983819 0.805420711974\n",
      "Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.567286947141 0.0954398731441\n",
      "Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.559937971953 0.153880293582\n",
      "Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.572512135922 0.15293011123\n",
      "Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.643507281553 0.100586053035\n",
      "Surf:  1 subfs:  0 test_surf:  4 Acc_mean-std:  0.688915857605 0.136384467293\n",
      "Surf:  1 subfs:  0 test_surf:  5 Acc_mean-std:  0.602784519957 0.0748839946865\n",
      "Surf:  1 subfs:  0 Acc_mean-std:  0.605824119022 0.119017465495\n",
      "Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.650283171521 0.0830128727704\n",
      "Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.633090614887 0.142838597154\n",
      "Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.712075242718 0.119207727263\n",
      "Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.646743527508 0.0513518081212\n",
      "Surf:  1 subfs:  1 test_surf:  4 Acc_mean-std:  0.770833333333 0.0707156883823\n",
      "Surf:  1 subfs:  1 test_surf:  5 Acc_mean-std:  0.760012135922 0.110800215791\n",
      "Surf:  1 subfs:  1 Acc_mean-std:  0.695506337648 0.0963211515805\n",
      "Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.555724110032 0.103577399391\n",
      "Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.562162891046 0.150085843063\n",
      "Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.608919902913 0.160917930587\n",
      "Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.567927454153 0.0838425887203\n",
      "Surf:  1 subfs:  2 test_surf:  4 Acc_mean-std:  0.701388888889 0.126552497173\n",
      "Surf:  1 subfs:  2 test_surf:  5 Acc_mean-std:  0.582389428263 0.140699601378\n",
      "Surf:  1 subfs:  2 Acc_mean-std:  0.596418779216 0.127612643385\n",
      "Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.629449838188 0.122715919859\n",
      "Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.65442961165 0.1291832608\n",
      "Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.632584951456 0.124927443241\n",
      "Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.688376483279 0.0900887838313\n",
      "Surf:  1 subfs:  3 test_surf:  4 Acc_mean-std:  0.787048274002 0.0756702228925\n",
      "Surf:  1 subfs:  3 test_surf:  5 Acc_mean-std:  0.758124325782 0.114782638445\n",
      "Surf:  1 subfs:  3 Acc_mean-std:  0.69166891406 0.109561378178\n",
      "Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.774339266451 0.142319223771\n",
      "Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.798139158576 0.150124514988\n",
      "Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.759978425027 0.14864760347\n",
      "Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.774844929881 0.0935317099505\n",
      "Surf:  5 subfs:  0 test_surf:  4 Acc_mean-std:  0.852009169364 0.105877352053\n",
      "Surf:  5 subfs:  0 test_surf:  5 Acc_mean-std:  0.729200377562 0.138884940894\n",
      "Surf:  5 subfs:  0 Acc_mean-std:  0.781418554477 0.129897557521\n",
      "Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.500606796117 0.104440445194\n",
      "Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.50515776699 0.105350701105\n",
      "Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.62870819849 0.109305653526\n",
      "Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.758562567422 0.0642535325315\n",
      "Surf:  5 subfs:  1 test_surf:  4 Acc_mean-std:  0.820658036677 0.0836924696341\n",
      "Surf:  5 subfs:  1 test_surf:  5 Acc_mean-std:  0.781283710895 0.106124425814\n",
      "Surf:  5 subfs:  1 Acc_mean-std:  0.665829512765 0.0955278713008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.476537216828 0.0406135570767\n",
      "Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.4491302589 0.0342078227352\n",
      "Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.52754180151 0.0753925389724\n",
      "Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.671352481122 0.0531691144206\n",
      "Surf:  5 subfs:  2 test_surf:  4 Acc_mean-std:  0.77100188781 0.0388695102314\n",
      "Surf:  5 subfs:  2 test_surf:  5 Acc_mean-std:  0.544936623517 0.0882876121346\n",
      "Surf:  5 subfs:  2 Acc_mean-std:  0.573416711615 0.0550900259285\n",
      "Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.724042610572 0.0906935364375\n",
      "Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.705805016181 0.0827422990618\n",
      "Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.689522653722 0.0501540636306\n",
      "Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.742347626753 0.0250038280937\n",
      "Surf:  5 subfs:  3 test_surf:  4 Acc_mean-std:  0.84752562028 0.044055935847\n",
      "Surf:  5 subfs:  3 test_surf:  5 Acc_mean-std:  0.790891316073 0.0543810451245\n",
      "Surf:  5 subfs:  3 Acc_mean-std:  0.75002247393 0.0578384513658\n"
     ]
    }
   ],
   "source": [
    "############ NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE ##############\n",
    "# same necessary steps as in testing before\n",
    "ati830rotfile = datapath+'ati_new_830Hz_validation_rot.mat'\n",
    "ati830rotfeatname = 'ati_830_rot'+featname\n",
    "ati830rotfeatfile = featpath+ati830rotfeatname+'.npz'\n",
    "ati830rotsurffile = featpath+ati830rotfeatname+'_1fing_6surf.npz'\n",
    "ati830rotXYfile = featpath+ati830rotfeatname+'_XY.npz'\n",
    "ati830rotXYsplitfile = featpath+ati830rotfeatname+'_XYsplit.npz'\n",
    "f,l,fd,member,m1,m2 = data_prep(ati830rotfile,k=1)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, ati830rotfeatfile, 'ati830rotfeat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,ati830rotXYfile,ati830rotXYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,ati830rotsurffile,n=6, k=1)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA ROTATIONAL ##############\n",
    "testing_accuracy_simple(surf, surfla, ltest=6)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA DETAILED ##############\n",
    "_ = testing_accuracy(surf, surfla, ltest=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (6, 1) (6, 1) (6, 1)\n",
      "4 -> m1,m2: 3 3 1.0 1.0\n",
      "5 -> f=f+l: (6, 12500, 4) : [(12500, 4), (12500, 4), (12500, 4), (12500, 4), (12500, 4), (12500, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(12500, 2), (12500, 2), (12500, 2), (12500, 2), (12500, 2), (12500, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.0977799892426 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (1722, 3107) (1722,) (1722, 3107) (1722,) (3444, 3107) (3444,)\n",
      "Xsp,Ysp [0,1,2]:  (1422, 3107) (1422,) (1422, 3107) (1422,) (2844, 3107) (2844,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (474, 6, 1)\n",
      "Accuracy for surface  0 0.877637130802 0.957805907173 0.580168776371 0.835443037975\n",
      "Accuracy for surface  1 0.913502109705 0.936708860759 0.683544303797 0.898734177215\n",
      "Accuracy for surface  2 0.831223628692 0.898734177215 0.518987341772 0.959915611814\n",
      "Accuracy for surface  3 0.732067510549 0.824894514768 0.535864978903 0.770042194093\n",
      "Accuracy for surface  4 0.84388185654 0.972573839662 0.584388185654 0.951476793249\n",
      "Accuracy for surface  5 0.869198312236 0.799578059072 0.563291139241 0.959915611814\n",
      "Accuracy for dataset    0.844585091421 0.898382559775 0.57770745429 0.895921237693\n"
     ]
    }
   ],
   "source": [
    "############ NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE ##############\n",
    "# same necessary steps as in testing before\n",
    "ati1500file = datapath+'ati_new_1500Hz_validation.mat'\n",
    "ati1500featname = 'ati_1500'+featname\n",
    "ati1500featfile = featpath+ati1500featname+'.npz'\n",
    "ati1500surffile = featpath+ati1500featname+'_1fing_6surf.npz'\n",
    "ati1500XYfile = featpath+ati1500featname+'_XY.npz'\n",
    "ati1500XYsplitfile = featpath+ati1500featname+'_XYsplit.npz'\n",
    "f,l,fd,member,m1,m2 = data_prep(ati1500file,k=1)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, ati1500featfile, 'ati1500feat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,ati1500XYfile,ati1500XYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,ati1500surffile,n=6, k=1)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA ROTATIONAL ##############\n",
    "testing_accuracy_simple(surf, surfla, ltest=6)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA DETAILED ##############\n",
    "# _ = testing_accuracy(surf, surfla, ltest=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (6, 1) (6, 1) (6, 1)\n",
      "4 -> m1,m2: 3 3 1.0 1.0\n",
      "5 -> f=f+l: (6,) : [(21500, 4), (21500, 4), (21500, 4), (21500, 4), (21500, 4), (21499, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21500, 2), (21500, 2), (21500, 2), (21500, 2), (21500, 2), (21499, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.191049098969 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (3072, 3107) (3072,) (3072, 3107) (3072,) (6144, 3107) (6144,)\n",
      "Xsp,Ysp [0,1,2]:  (2472, 3107) (2472,) (2472, 3107) (2472,) (4944, 3107) (4944,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (824, 6, 1)\n",
      "Accuracy for surface  0 0.837378640777 0.683252427184 0.788834951456 0.809466019417\n",
      "Accuracy for surface  1 0.888349514563 0.718446601942 0.700242718447 0.73786407767\n",
      "Accuracy for surface  2 0.925970873786 0.635922330097 0.706310679612 0.813106796117\n",
      "Accuracy for surface  3 0.791262135922 0.739077669903 0.703883495146 0.741504854369\n",
      "Accuracy for surface  4 0.839805825243 0.650485436893 0.758495145631 0.906553398058\n",
      "Accuracy for surface  5 0.813106796117 0.593446601942 0.746359223301 0.763349514563\n",
      "Accuracy for dataset    0.849312297735 0.670105177994 0.734021035599 0.795307443366\n"
     ]
    }
   ],
   "source": [
    "############ NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE ##############\n",
    "# same necessary steps as in testing before\n",
    "ati1500rotfile = datapath+'ati_new_1500Hz_validation_rot.mat'\n",
    "ati1500rotfeatname = 'ati_1500_rot'+featname\n",
    "ati1500rotfeatfile = featpath+ati1500rotfeatname+'.npz'\n",
    "ati1500rotsurffile = featpath+ati1500rotfeatname+'_1fing_6surf.npz'\n",
    "ati1500rotXYfile = featpath+ati1500rotfeatname+'_XY.npz'\n",
    "ati1500rotXYsplitfile = featpath+ati1500rotfeatname+'_XYsplit.npz'\n",
    "f,l,fd,member,m1,m2 = data_prep(ati1500rotfile,k=1)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, ati1500rotfeatfile, 'ati1500rotfeat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,ati1500rotXYfile,ati1500rotXYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,ati1500rotsurffile,n=6, k=1)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA ROTATIONAL ##############\n",
    "testing_accuracy_simple(surf, surfla, ltest=6)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA DETAILED ##############\n",
    "# _ = testing_accuracy(surf, surfla, ltest=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (6, 1) (6, 1) (6, 1)\n",
      "4 -> m1,m2: 3 3 1.0 1.0\n",
      "5 -> f=f+l: (6, 16499, 4) : [(16499, 4), (16499, 4), (16499, 4), (16499, 4), (16499, 4), (16499, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(16499, 2), (16499, 2), (16499, 2), (16499, 2), (16499, 2), (16499, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.145493984222 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (2322, 3107) (2322,) (2322, 3107) (2322,) (4644, 3107) (4644,)\n",
      "Xsp,Ysp [0,1,2]:  (1872, 3107) (1872,) (1872, 3107) (1872,) (3744, 3107) (3744,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (624, 6, 1)\n",
      "Accuracy for surface  0 0.799679487179 0.908653846154 0.761217948718 0.767628205128\n",
      "Accuracy for surface  1 0.735576923077 0.75 0.608974358974 0.668269230769\n",
      "Accuracy for surface  2 0.74358974359 0.831730769231 0.596153846154 0.761217948718\n",
      "Accuracy for surface  3 0.716346153846 0.783653846154 0.644230769231 0.794871794872\n",
      "Accuracy for surface  4 0.891025641026 0.926282051282 0.649038461538 0.879807692308\n",
      "Accuracy for surface  5 0.817307692308 0.738782051282 0.703525641026 0.940705128205\n",
      "Accuracy for dataset    0.783920940171 0.823183760684 0.660523504274 0.802083333333\n"
     ]
    }
   ],
   "source": [
    "############ NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE WITH VERTICAL SLIDE Fd=3N ##############\n",
    "# same necessary steps as in testing before\n",
    "atifd3Nfile = datapath+'ati_new_fd3N_validation.mat'\n",
    "atifd3Nfeatname = 'ati_fd3N'+featname\n",
    "atifd3Nfeatfile = featpath+atifd3Nfeatname+'.npz'\n",
    "atifd3Nsurffile = featpath+atifd3Nfeatname+'_1fing_6surf.npz'\n",
    "atifd3NXYfile = featpath+atifd3Nfeatname+'_XY.npz'\n",
    "atifd3NXYsplitfile = featpath+atifd3Nfeatname+'_XYsplit.npz'\n",
    "f,l,fd,member,m1,m2 = data_prep(atifd3Nfile,k=1)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, atifd3Nfeatfile, 'atifd3Nfeat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,atifd3NXYfile,atifd3NXYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,atifd3Nsurffile,n=6, k=1)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA ROTATIONAL ##############\n",
    "testing_accuracy_simple(surf, surfla, ltest=6)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA DETAILED ##############\n",
    "# _ = testing_accuracy(surf, surfla, ltest=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (6, 1) (6, 1) (6, 1)\n",
      "4 -> m1,m2: 3 3 1.0 1.0\n",
      "5 -> f=f+l: (6,) : [(21500, 4), (21500, 4), (21500, 4), (21500, 4), (21500, 4), (21499, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21500, 2), (21500, 2), (21500, 2), (21500, 2), (21500, 2), (21499, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.173919916153 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (3072, 3107) (3072,) (3072, 3107) (3072,) (6144, 3107) (6144,)\n",
      "Xsp,Ysp [0,1,2]:  (2472, 3107) (2472,) (2472, 3107) (2472,) (4944, 3107) (4944,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (824, 6, 1)\n",
      "Accuracy for surface  0 0.85072815534 0.842233009709 0.606796116505 0.76213592233\n",
      "Accuracy for surface  1 0.779126213592 0.945388349515 0.549757281553 0.904126213592\n",
      "Accuracy for surface  2 0.729368932039 0.668689320388 0.60072815534 0.678398058252\n",
      "Accuracy for surface  3 0.768203883495 0.870145631068 0.586165048544 0.708737864078\n",
      "Accuracy for surface  4 0.785194174757 0.85072815534 0.604368932039 0.770631067961\n",
      "Accuracy for surface  5 0.854368932039 0.68567961165 0.68932038835 0.690533980583\n",
      "Accuracy for dataset    0.794498381877 0.810477346278 0.606189320388 0.752427184466\n"
     ]
    }
   ],
   "source": [
    "############ NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE WITH VERTICAL SLIDE Fd=3N ##############\n",
    "# same necessary steps as in testing before\n",
    "atifd3Nrotfile = datapath+'ati_new_fd3N_validation_rot.mat'\n",
    "atifd3Nrotfeatname = 'ati_fd3Nrot'+featname\n",
    "atifd3Nrotfeatfile = featpath+atifd3Nrotfeatname+'.npz'\n",
    "atifd3Nrotsurffile = featpath+atifd3Nrotfeatname+'_1fing_6surf.npz'\n",
    "atifd3NrotXYfile = featpath+atifd3Nrotfeatname+'_XY.npz'\n",
    "atifd3NrotXYsplitfile = featpath+atifd3Nrotfeatname+'_XYsplit.npz'\n",
    "f,l,fd,member,m1,m2 = data_prep(atifd3Nrotfile,k=1)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, atifd3Nrotfeatfile, 'atifd3Nrotfeat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,atifd3NrotXYfile,atifd3NrotXYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,atifd3Nrotsurffile,n=6, k=1)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA ROTATIONAL ##############\n",
    "testing_accuracy_simple(surf, surfla, ltest=6)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA DETAILED ##############\n",
    "# _ = testing_accuracy(surf, surfla, ltest=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (6, 1) (6, 1) (6, 1)\n",
      "4 -> m1,m2: 3 3 1.0 1.0\n",
      "5 -> f=f+l: (6, 16499, 4) : [(16499, 4), (16499, 4), (16499, 4), (16499, 4), (16499, 4), (16499, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(16499, 2), (16499, 2), (16499, 2), (16499, 2), (16499, 2), (16499, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.76664686203 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (2322, 3107) (2322,) (2322, 3107) (2322,) (4644, 3107) (4644,)\n",
      "Xsp,Ysp [0,1,2]:  (1872, 3107) (1872,) (1872, 3107) (1872,) (3744, 3107) (3744,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (624, 6, 1)\n",
      "Accuracy for surface  0 0.740384615385 0.767628205128 0.655448717949 0.786858974359\n",
      "Accuracy for surface  1 0.729166666667 0.671474358974 0.623397435897 0.863782051282\n",
      "Accuracy for surface  2 0.75 0.703525641026 0.666666666667 0.793269230769\n",
      "Accuracy for surface  3 0.701923076923 0.732371794872 0.605769230769 0.711538461538\n",
      "Accuracy for surface  4 0.698717948718 0.559294871795 0.612179487179 0.636217948718\n",
      "Accuracy for surface  5 0.583333333333 0.535256410256 0.613782051282 0.762820512821\n",
      "Accuracy for dataset    0.700587606838 0.661591880342 0.629540598291 0.759081196581\n"
     ]
    }
   ],
   "source": [
    "########## NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE WITH VERTICAL SLIDE Fd=1.5N kp=1 ###########\n",
    "# same necessary steps as in testing before\n",
    "atifd1c5Nkp1file = datapath+'ati_new_fd1.5N_kp1_validation.mat'\n",
    "atifd1c5Nkp1featname = 'ati_fd1c5Nkp1'+featname\n",
    "atifd1c5Nkp1featfile = featpath+atifd1c5Nkp1featname+'.npz'\n",
    "atifd1c5Nkp1surffile = featpath+atifd1c5Nkp1featname+'_1fing_6surf.npz'\n",
    "atifd1c5Nkp1XYfile = featpath+atifd1c5Nkp1featname+'_XY.npz'\n",
    "atifd1c5Nkp1XYsplitfile = featpath+atifd1c5Nkp1featname+'_XYsplit.npz'\n",
    "f,l,fd,member,m1,m2 = data_prep(atifd1c5Nkp1file,k=1)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, atifd1c5Nkp1featfile, 'atifd1c5Nkp1feat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,atifd1c5Nkp1XYfile,atifd1c5Nkp1XYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,atifd1c5Nkp1surffile,n=6, k=1)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA ROTATIONAL ##############\n",
    "testing_accuracy_simple(surf, surfla, ltest=6)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA DETAILED ##############\n",
    "# _ = testing_accuracy(surf, surfla, ltest=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (6, 1) (6, 1) (6, 1)\n",
      "4 -> m1,m2: 3 3 1.0 1.0\n",
      "5 -> f=f+l: (6,) : [(21500, 4), (21500, 4), (21500, 4), (21500, 4), (21500, 4), (21499, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21500, 2), (21500, 2), (21500, 2), (21500, 2), (21500, 2), (21499, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.176841974258 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (3072, 3107) (3072,) (3072, 3107) (3072,) (6144, 3107) (6144,)\n",
      "Xsp,Ysp [0,1,2]:  (2472, 3107) (2472,) (2472, 3107) (2472,) (4944, 3107) (4944,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (824, 6, 1)\n",
      "Accuracy for surface  0 0.871359223301 0.688106796117 0.618932038835 0.955097087379\n",
      "Accuracy for surface  1 0.900485436893 0.567961165049 0.635922330097 0.93567961165\n",
      "Accuracy for surface  2 0.775485436893 0.581310679612 0.508495145631 0.752427184466\n",
      "Accuracy for surface  3 0.808252427184 0.739077669903 0.553398058252 0.873786407767\n",
      "Accuracy for surface  4 0.753640776699 0.719660194175 0.510922330097 0.561893203883\n",
      "Accuracy for surface  5 0.808252427184 0.553398058252 0.481796116505 0.531553398058\n",
      "Accuracy for dataset    0.819579288026 0.641585760518 0.551577669903 0.768406148867\n"
     ]
    }
   ],
   "source": [
    "########## NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE WITH VERTICAL SLIDE Fd=1.5N kp=1###########\n",
    "# same necessary steps as in testing before\n",
    "atifd1c5Nkp1rotfile = datapath+'ati_new_fd1.5N_kp1_validation_rot.mat'\n",
    "atifd1c5Nkp1rotfeatname = 'ati_fd1c5Nkp1rot'+featname\n",
    "atifd1c5Nkp1rotfeatfile = featpath+atifd1c5Nkp1rotfeatname+'.npz'\n",
    "atifd1c5Nkp1rotsurffile = featpath+atifd1c5Nkp1rotfeatname+'_1fing_6surf.npz'\n",
    "atifd1c5Nkp1rotXYfile = featpath+atifd1c5Nkp1rotfeatname+'_XY.npz'\n",
    "atifd1c5Nkp1rotXYsplitfile = featpath+atifd1c5Nkp1rotfeatname+'_XYsplit.npz'\n",
    "f,l,fd,member,m1,m2 = data_prep(atifd1c5Nkp1rotfile,k=1)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, atifd1c5Nkp1rotfeatfile, 'atifd1c5Nkp1rotfeat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,atifd1c5Nkp1rotXYfile,atifd1c5Nkp1rotXYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,atifd1c5Nkp1rotsurffile,n=6, k=1)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA ROTATIONAL ##############\n",
    "testing_accuracy_simple(surf, surfla, ltest=6)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA DETAILED ##############\n",
    "# _ = testing_accuracy(surf, surfla, ltest=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (6, 1) (6, 1) (6, 1)\n",
      "4 -> m1,m2: 3 3 1.0 1.0\n",
      "5 -> f=f+l: (6, 16499, 4) : [(16499, 4), (16499, 4), (16499, 4), (16499, 4), (16499, 4), (16499, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(16499, 2), (16499, 2), (16499, 2), (16499, 2), (16499, 2), (16499, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.133768081665 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (2322, 3107) (2322,) (2322, 3107) (2322,) (4644, 3107) (4644,)\n",
      "Xsp,Ysp [0,1,2]:  (1872, 3107) (1872,) (1872, 3107) (1872,) (3744, 3107) (3744,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (624, 6, 1)\n",
      "Accuracy for surface  0 0.775641025641 0.75641025641 0.621794871795 0.913461538462\n",
      "Accuracy for surface  1 0.764423076923 0.639423076923 0.647435897436 0.966346153846\n",
      "Accuracy for surface  2 0.822115384615 0.700320512821 0.629807692308 0.929487179487\n",
      "Accuracy for surface  3 0.713141025641 0.706730769231 0.669871794872 0.871794871795\n",
      "Accuracy for surface  4 0.642628205128 0.511217948718 0.608974358974 0.842948717949\n",
      "Accuracy for surface  5 0.846153846154 0.490384615385 0.69391025641 0.458333333333\n",
      "Accuracy for dataset    0.760683760684 0.634081196581 0.645299145299 0.830395299145\n",
      "Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.816728988604 0.11889083638\n",
      "Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.773459757835 0.14640219697\n",
      "Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.76655982906 0.108971085714\n",
      "Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.78770477208 0.128453333295\n",
      "Surf:  1 subfs:  0 test_surf:  4 Acc_mean-std:  0.656339031339 0.128973195878\n",
      "Surf:  1 subfs:  0 test_surf:  5 Acc_mean-std:  0.661013176638 0.170086881933\n",
      "Surf:  1 subfs:  0 Acc_mean-std:  0.743634259259 0.133629588362\n",
      "Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.658386752137 0.108387857892\n",
      "Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.690527065527 0.0681385868441\n",
      "Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.698450854701 0.0863093972965\n",
      "Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.654246794872 0.120711352555\n",
      "Surf:  1 subfs:  1 test_surf:  4 Acc_mean-std:  0.643295940171 0.090816188156\n",
      "Surf:  1 subfs:  1 test_surf:  5 Acc_mean-std:  0.663105413105 0.143413376631\n",
      "Surf:  1 subfs:  1 Acc_mean-std:  0.668002136752 0.102962793229\n",
      "Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.688123219373 0.123794707388\n",
      "Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.695824430199 0.123948787819\n",
      "Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.738559472934 0.15147276031\n",
      "Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.66359508547 0.102436301224\n",
      "Surf:  1 subfs:  2 test_surf:  4 Acc_mean-std:  0.652421652422 0.0753023044475\n",
      "Surf:  1 subfs:  2 test_surf:  5 Acc_mean-std:  0.655582264957 0.0923329569026\n",
      "Surf:  1 subfs:  2 Acc_mean-std:  0.682351020893 0.111547969682\n",
      "Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.652644230769 0.0885716744086\n",
      "Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.656873219373 0.0872271793661\n",
      "Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.733529202279 0.097342201896\n",
      "Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.635594729345 0.076363929057\n",
      "Surf:  1 subfs:  3 test_surf:  4 Acc_mean-std:  0.640001780627 0.0382721640265\n",
      "Surf:  1 subfs:  3 test_surf:  5 Acc_mean-std:  0.695913461538 0.100387829075\n",
      "Surf:  1 subfs:  3 Acc_mean-std:  0.669092770655 0.0813608296381\n",
      "Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.814592236467 0.117819539336\n",
      "Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.778445512821 0.0988084525368\n",
      "Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.833021723647 0.0586547455148\n",
      "Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.778757122507 0.0919338572507\n",
      "Surf:  5 subfs:  0 test_surf:  4 Acc_mean-std:  0.743189102564 0.0896929985288\n",
      "Surf:  5 subfs:  0 test_surf:  5 Acc_mean-std:  0.655760327635 0.121805894456\n",
      "Surf:  5 subfs:  0 Acc_mean-std:  0.767294337607 0.0964525812705\n",
      "Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.66448539886 0.0404189287086\n",
      "Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.677573005698 0.0441292658165\n",
      "Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.661858974359 0.0549603948112\n",
      "Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.703614672365 0.044445189933\n",
      "Surf:  5 subfs:  1 test_surf:  4 Acc_mean-std:  0.586894586895 0.01534854839\n",
      "Surf:  5 subfs:  1 test_surf:  5 Acc_mean-std:  0.601540242165 0.0570646261606\n",
      "Surf:  5 subfs:  1 Acc_mean-std:  0.64932781339 0.0427278256366\n",
      "Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.625756766382 0.0351743373241\n",
      "Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.64979522792 0.0443222963459\n",
      "Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.740651709402 0.0316199159353\n",
      "Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.659143518519 0.024100168438\n",
      "Surf:  5 subfs:  2 test_surf:  4 Acc_mean-std:  0.602430555556 0.00214923570238\n",
      "Surf:  5 subfs:  2 test_surf:  5 Acc_mean-std:  0.601228632479 0.00158014951472\n",
      "Surf:  5 subfs:  2 Acc_mean-std:  0.646501068376 0.0231576838767\n",
      "Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.66359508547 0.0463765902919\n",
      "Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.679175569801 0.041071416972\n",
      "Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.677528490028 0.0471284515003\n",
      "Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.712918447293 0.0252800015193\n",
      "Surf:  5 subfs:  3 test_surf:  4 Acc_mean-std:  0.625 0.0157924631401\n",
      "Surf:  5 subfs:  3 test_surf:  5 Acc_mean-std:  0.707888176638 0.0476261079793\n",
      "Surf:  5 subfs:  3 Acc_mean-std:  0.677684294872 0.0372125052338\n"
     ]
    }
   ],
   "source": [
    "########## NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE WITH VERTICAL SLIDE Fd=1.5N kp=2 ###########\n",
    "# same necessary steps as in testing before\n",
    "atifd1c5Nkp2file = datapath+'ati_new_fd1.5N_kp2_validation.mat'\n",
    "atifd1c5Nkp2featname = 'ati_fd1c5Nkp2'+featname\n",
    "atifd1c5Nkp2featfile = featpath+atifd1c5Nkp2featname+'.npz'\n",
    "atifd1c5Nkp2surffile = featpath+atifd1c5Nkp2featname+'_1fing_6surf.npz'\n",
    "atifd1c5Nkp2XYfile = featpath+atifd1c5Nkp2featname+'_XY.npz'\n",
    "atifd1c5Nkp2XYsplitfile = featpath+atifd1c5Nkp2featname+'_XYsplit.npz'\n",
    "f,l,fd,member,m1,m2 = data_prep(atifd1c5Nkp2file,k=1)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, atifd1c5Nkp2featfile, 'atifd1c5Nkp2feat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,atifd1c5Nkp2XYfile,atifd1c5Nkp2XYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,atifd1c5Nkp2surffile,n=6, k=1)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA ROTATIONAL ##############\n",
    "testing_accuracy_simple(surf, surfla, ltest=6)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA DETAILED ##############\n",
    "_ = testing_accuracy(surf, surfla, ltest=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (6, 1) (6, 1) (6, 1)\n",
      "4 -> m1,m2: 3 3 1.0 1.0\n",
      "5 -> f=f+l: (6,) : [(21500, 4), (21500, 4), (21500, 4), (21500, 4), (21500, 4), (21499, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21500, 2), (21500, 2), (21500, 2), (21500, 2), (21500, 2), (21499, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.187205076218 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (3072, 3107) (3072,) (3072, 3107) (3072,) (6144, 3107) (6144,)\n",
      "Xsp,Ysp [0,1,2]:  (2472, 3107) (2472,) (2472, 3107) (2472,) (4944, 3107) (4944,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (824, 6, 1)\n",
      "Accuracy for surface  0 0.743932038835 0.739077669903 0.509708737864 0.898058252427\n",
      "Accuracy for surface  1 0.756067961165 0.688106796117 0.571601941748 0.894417475728\n",
      "Accuracy for surface  2 0.700242718447 0.791262135922 0.515776699029 0.832524271845\n",
      "Accuracy for surface  3 0.779126213592 0.461165048544 0.598300970874 0.927184466019\n",
      "Accuracy for surface  4 0.684466019417 0.481796116505 0.547330097087 0.557038834951\n",
      "Accuracy for surface  5 0.628640776699 0.260922330097 0.578883495146 0.514563106796\n",
      "Accuracy for dataset    0.715412621359 0.570388349515 0.553600323625 0.770631067961\n",
      "Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.681196062567 0.132834253126\n",
      "Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.653249730313 0.144650886928\n",
      "Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.697141316073 0.143339932165\n",
      "Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.632618662352 0.172989902527\n",
      "Surf:  1 subfs:  0 test_surf:  4 Acc_mean-std:  0.564084412082 0.144581919445\n",
      "Surf:  1 subfs:  0 test_surf:  5 Acc_mean-std:  0.504550970874 0.142675067331\n",
      "Surf:  1 subfs:  0 Acc_mean-std:  0.622140192377 0.14684532692\n",
      "Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.705535329018 0.0934427285136\n",
      "Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.713491100324 0.0950347569476\n",
      "Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.590614886731 0.0817582555086\n",
      "Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.71409789644 0.0962236453615\n",
      "Surf:  1 subfs:  1 test_surf:  4 Acc_mean-std:  0.615796925566 0.164493456435\n",
      "Surf:  1 subfs:  1 test_surf:  5 Acc_mean-std:  0.650755124056 0.133015008597\n",
      "Surf:  1 subfs:  1 Acc_mean-std:  0.665048543689 0.110661308561\n",
      "Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.587446062567 0.14754727079\n",
      "Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.59186218986 0.121893651832\n",
      "Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.581243257821 0.112902836531\n",
      "Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.568837648328 0.12214404105\n",
      "Surf:  1 subfs:  2 test_surf:  4 Acc_mean-std:  0.535059331176 0.0720250931445\n",
      "Surf:  1 subfs:  2 test_surf:  5 Acc_mean-std:  0.538565264293 0.0873112450176\n",
      "Surf:  1 subfs:  2 Acc_mean-std:  0.567168959008 0.110637356394\n",
      "Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.612830366775 0.109514133244\n",
      "Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.626483279396 0.101856275133\n",
      "Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.581108414239 0.103515022715\n",
      "Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.654598166127 0.121792738979\n",
      "Surf:  1 subfs:  3 test_surf:  4 Acc_mean-std:  0.555791531823 0.090703553923\n",
      "Surf:  1 subfs:  3 test_surf:  5 Acc_mean-std:  0.530137540453 0.0625732700671\n",
      "Surf:  1 subfs:  3 Acc_mean-std:  0.593491549802 0.0983258323435\n",
      "Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.747842502697 0.132310656342\n",
      "Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.723874056095 0.143037084866\n",
      "Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.673948220065 0.110321994119\n",
      "Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.776193365696 0.15999213313\n",
      "Surf:  5 subfs:  0 test_surf:  4 Acc_mean-std:  0.667138619202 0.156490304448\n",
      "Surf:  5 subfs:  0 test_surf:  5 Acc_mean-std:  0.553398058252 0.0606236257365\n",
      "Surf:  5 subfs:  0 Acc_mean-std:  0.690399137001 0.127129299774\n",
      "Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.628809331176 0.0786524460342\n",
      "Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.663801240561 0.0781260236845\n",
      "Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.556971413161 0.0635550786965\n",
      "Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.705703883495 0.0747213839651\n",
      "Surf:  5 subfs:  1 test_surf:  4 Acc_mean-std:  0.543689320388 0.0558538163824\n",
      "Surf:  5 subfs:  1 test_surf:  5 Acc_mean-std:  0.541700377562 0.0843139280978\n",
      "Surf:  5 subfs:  1 Acc_mean-std:  0.606779261057 0.0725371128101\n",
      "Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.53546386192 0.0707443841699\n",
      "Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.543925296656 0.0565300556398\n",
      "Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.617010517799 0.0368160483437\n",
      "Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.577939590076 0.0592109973652\n",
      "Surf:  5 subfs:  2 test_surf:  4 Acc_mean-std:  0.48931364617 0.0189068241099\n",
      "Surf:  5 subfs:  2 test_surf:  5 Acc_mean-std:  0.486785329018 0.00797745386071\n",
      "Surf:  5 subfs:  2 Acc_mean-std:  0.54173970694 0.0416976272482\n",
      "Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.581782632147 0.0573387746154\n",
      "Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.618830906149 0.0381755461958\n",
      "Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.549892125135 0.043427065737\n",
      "Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.634506472492 0.0612496819265\n",
      "Surf:  5 subfs:  3 test_surf:  4 Acc_mean-std:  0.603795846818 0.0663001615896\n",
      "Surf:  5 subfs:  3 test_surf:  5 Acc_mean-std:  0.611245954693 0.0476308110815\n",
      "Surf:  5 subfs:  3 Acc_mean-std:  0.600008989572 0.0523536735243\n"
     ]
    }
   ],
   "source": [
    "########## NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE WITH VERTICAL SLIDE Fd=1.5N kp=2###########\n",
    "# same necessary steps as in testing before\n",
    "atifd1c5Nkp2rotfile = datapath+'ati_new_fd1.5N_kp2_validation_rot.mat'\n",
    "atifd1c5Nkp2rotfeatname = 'ati_fd1c5Nkp2rot'+featname\n",
    "atifd1c5Nkp2rotfeatfile = featpath+atifd1c5Nkp2rotfeatname+'.npz'\n",
    "atifd1c5Nkp2rotsurffile = featpath+atifd1c5Nkp2rotfeatname+'_1fing_6surf.npz'\n",
    "atifd1c5Nkp2rotXYfile = featpath+atifd1c5Nkp2rotfeatname+'_XY.npz'\n",
    "atifd1c5Nkp2rotXYsplitfile = featpath+atifd1c5Nkp2rotfeatname+'_XYsplit.npz'\n",
    "f,l,fd,member,m1,m2 = data_prep(atifd1c5Nkp2rotfile,k=1)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, atifd1c5Nkp2rotfeatfile, 'atifd1c5Nkp2rotfeat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,atifd1c5Nkp2rotXYfile,atifd1c5Nkp2rotXYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,atifd1c5Nkp2rotsurffile,n=6, k=1)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA ROTATIONAL ##############\n",
    "testing_accuracy_simple(surf, surfla, ltest=6)\n",
    "############ PREDICTING SCORE FOR ATI SENSOR DATA DETAILED ##############\n",
    "_ = testing_accuracy(surf, surfla, ltest=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (6, 1) (6, 1) (6, 1)\n",
      "4 -> m1,m2: 3 3 1.0 1.0\n",
      "5 -> f=f+l: (6, 21000, 4) : [(21000, 4), (21000, 4), (21000, 4), (21000, 4), (21000, 4), (21000, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.490967988968 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (2997, 3107) (2997,) (2997, 3107) (2997,) (5994, 3107) (5994,)\n",
      "Xsp,Ysp [0,1,2]:  (2397, 3107) (2397,) (2397, 3107) (2397,) (4794, 3107) (4794,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (799, 6, 1)\n",
      "0 ===========================================================================================\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.482875823975 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (2997, 3107) (2997,) (2997, 3107) (2997,) (5994, 3107) (5994,)\n",
      "Xsp,Ysp [0,1,2]:  (2397, 3107) (2397,) (2397, 3107) (2397,) (4794, 3107) (4794,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (799, 6, 1)\n",
      "1 ===========================================================================================\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.61487698555 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (2997, 3107) (2997,) (2997, 3107) (2997,) (5994, 3107) (5994,)\n",
      "Xsp,Ysp [0,1,2]:  (2397, 3107) (2397,) (2397, 3107) (2397,) (4794, 3107) (4794,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (799, 6, 1)\n",
      "2 ===========================================================================================\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.542134046555 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (2997, 3107) (2997,) (2997, 3107) (2997,) (5994, 3107) (5994,)\n",
      "Xsp,Ysp [0,1,2]:  (2397, 3107) (2397,) (2397, 3107) (2397,) (4794, 3107) (4794,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (799, 6, 1)\n",
      "3 ===========================================================================================\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.54497385025 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (2997, 3107) (2997,) (2997, 3107) (2997,) (5994, 3107) (5994,)\n",
      "Xsp,Ysp [0,1,2]:  (2397, 3107) (2397,) (2397, 3107) (2397,) (4794, 3107) (4794,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (799, 6, 1)\n",
      "4 ===========================================================================================\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.598809957504 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (2997, 3107) (2997,) (2997, 3107) (2997,) (5994, 3107) (5994,)\n",
      "Xsp,Ysp [0,1,2]:  (2397, 3107) (2397,) (2397, 3107) (2397,) (4794, 3107) (4794,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (799, 6, 1)\n",
      "5 ===========================================================================================\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.597034931183 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (2997, 3107) (2997,) (2997, 3107) (2997,) (5994, 3107) (5994,)\n",
      "Xsp,Ysp [0,1,2]:  (2397, 3107) (2397,) (2397, 3107) (2397,) (4794, 3107) (4794,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (799, 6, 1)\n",
      "6 ===========================================================================================\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 0.565989017487 seconds \n",
      "features:  (6,) , labels:  (6,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (6,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "Before -> X[ 0 ]:  (3,) , Y[ 0 ]:  (3,) , Yn[ 0 ]:  (3,)\n",
      "Gathered -> X[ 0 ]:  (2997, 3107, 1) , Y[ 0 ]:  (2997,) , Yn[ 0 ]:  (2997,)\n",
      "Gathered, sampled to max  10000  -> X[ 0 ]:  (2997, 3107) , Y[ 0 ]:  (2997,) , Yn[ 0 ]:  (2997,)\n",
      "Split -> Xsp[ 0 ]:  (2397, 3107) , Ysp[ 0 ]:  (2397,)\n",
      "Before -> X[ 1 ]:  (3,) , Y[ 1 ]:  (3,) , Yn[ 1 ]:  (3,)\n",
      "Gathered -> X[ 1 ]:  (2997, 3107, 1) , Y[ 1 ]:  (2997,) , Yn[ 1 ]:  (2997,)\n",
      "Gathered, sampled to max  10000  -> X[ 1 ]:  (2997, 3107) , Y[ 1 ]:  (2997,) , Yn[ 1 ]:  (2997,)\n",
      "Split -> Xsp[ 1 ]:  (2397, 3107) , Ysp[ 1 ]:  (2397,)\n",
      "Before -> X[ 2 ]:  (6,) , Y[ 2 ]:  (6,) , Yn[ 2 ]:  (6,)\n",
      "Gathered -> X[ 2 ]:  (5994, 3107, 1) , Y[ 2 ]:  (5994,) , Yn[ 2 ]:  (5994,)\n",
      "Gathered, sampled to max  10000  -> X[ 2 ]:  (5994, 3107) , Y[ 2 ]:  (5994,) , Yn[ 2 ]:  (5994,)\n",
      "Split -> Xsp[ 2 ]:  (4794, 3107) , Ysp[ 2 ]:  (4794,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X,Y [0,1,2]:  (2997, 3107) (2997,) (2997, 3107) (2997,) (5994, 3107) (5994,)\n",
      "Xsp,Ysp [0,1,2]:  (2397, 3107) (2397,) (2397, 3107) (2397,) (4794, 3107) (4794,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "0 0 (6, 799, 3107)\n",
      "0 1 (6, 799, 3107)\n",
      "0 2 (6, 799, 3107)\n",
      "0 3 (6, 799, 3107)\n",
      "0 4 (6, 799, 3107)\n",
      "0 5 (6, 799, 3107)\n",
      "0 6 (6, 799, 3107)\n",
      "(4, 6, 1) (799, 6, 1)\n",
      "7 ===========================================================================================\n",
      "Saving Scaled Acc file of shape:  (8, 2, 4, 6, 2)\n"
     ]
    }
   ],
   "source": [
    "############ NEW TESTING PROCEDURE WITH DATA FROM ATI F/T SENSOR BUT SCALED ##############\n",
    "# same necessary steps as in testing before\n",
    "# c = np.array(range(5, 150, 25))/100.\n",
    "# c[-2] = 1\n",
    "c = np.array([0.05, 0.3, 0.55, 0.8, 1., 1.3, 2.0, 5.0])\n",
    "f,l,fd,member,m1,m2 = data_prep(atifile,k=1)\n",
    "\n",
    "def test_dataset_scaled(c, f, l, member, m1, m2):\n",
    "    atifeatname = 'ati_'+str(c)+'_'+featname\n",
    "    atifeatfile = featpath+atifeatname+'.npz'\n",
    "    atisurffile = featpath+atifeatname+'_1fing_6surf.npz'\n",
    "    atiXYfile = featpath+atifeatname+'_XY.npz'\n",
    "    atiXYsplitfile = featpath+atifeatname+'_XYsplit.npz'\n",
    "    f[:,:,:-1] = c*f[:,:,:-1]\n",
    "    prefeat = compute_prefeat(f)\n",
    "    features, labels = feature_extraction(prefeat, member, atifeatfile, 'atifeat_'+str(c)+'_')\n",
    "    new_labels = label_cleaning(prefeat,labels,member)\n",
    "    X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,atiXYfile,atiXYsplitfile)\n",
    "    surf, surfla = computeXY_persurf(Xsp,Ysp,atisurffile,n=6, k=1)\n",
    "    return testing_accuracy(surf, surfla, printit=False)\n",
    "\n",
    "scaleaccfile = featpath+'newer_scaled_acc.npz'\n",
    "if os.path.isfile(scaleaccfile):\n",
    "    scaled_acc = np.load(scaleaccfile)['scaled_acc']\n",
    "    print \"Loaded Scaled Acc file of shape: \", scaled_acc.shape\n",
    "else:\n",
    "    scaled_acc = {}\n",
    "    for t in range(len(c)):\n",
    "        scaled_acc[t] = test_dataset_scaled(c[t], f, l, member, m1, m2)\n",
    "        print t, '==========================================================================================='\n",
    "    scaled_acc = np.array([i for _,i in scaled_acc.items()])\n",
    "    print \"Saving Scaled Acc file of shape: \", scaled_acc.shape\n",
    "    np.savez(scaleaccfile,scaled_acc=scaled_acc)\n",
    "# scaled_acc = [Parallel(n_jobs=1)([delayed(test_dataset_scaled) (t, f, l, member, m1, m2) for t in c])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below we see the result of scaling. \n",
    "## At c<=0.5 or c>=2.0 we get better results for the combined features, irrespectively of number of training surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.05 Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.696912807676 0.20089862115\n",
      "C:  0.05 Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.707412042831 0.200803000487\n",
      "C:  0.05 Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.731956612432 0.224358710851\n",
      "C:  0.05 Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.702544847726 0.179309632219\n",
      "C:  0.05 Surf:  1 subfs:  0 test_surf:  4 Acc_mean-std:  0.767973856209 0.184876795997\n",
      "C:  0.05 Surf:  1 subfs:  0 test_surf:  5 Acc_mean-std:  0.759039076624 0.204367587853\n",
      "C:  0.05 Surf:  1 subfs:  0 Acc_mean-std:  0.727639873916 0.199102391426\n",
      "C:  0.05 Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.840251703518 0.109425101306\n",
      "C:  0.05 Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.897858434154 0.0931564785074\n",
      "C:  0.05 Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.896919760812 0.0899096862243\n",
      "C:  0.05 Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.796794604367 0.132773087883\n",
      "C:  0.05 Surf:  1 subfs:  1 test_surf:  4 Acc_mean-std:  0.899631483799 0.0836614745843\n",
      "C:  0.05 Surf:  1 subfs:  1 test_surf:  5 Acc_mean-std:  0.882005284383 0.0832547072408\n",
      "C:  0.05 Surf:  1 subfs:  1 Acc_mean-std:  0.868910211839 0.0986967559577\n",
      "C:  0.05 Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.567758308997 0.108542765842\n",
      "C:  0.05 Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.569044639132 0.123929811555\n",
      "C:  0.05 Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.554929773328 0.0865151456506\n",
      "C:  0.05 Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.579717702684 0.12861607585\n",
      "C:  0.05 Surf:  1 subfs:  2 test_surf:  4 Acc_mean-std:  0.565011820331 0.0804153534881\n",
      "C:  0.05 Surf:  1 subfs:  2 test_surf:  5 Acc_mean-std:  0.589730218328 0.123059834021\n",
      "C:  0.05 Surf:  1 subfs:  2 Acc_mean-std:  0.571032077133 0.108513164401\n",
      "C:  0.05 Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.930920595188 0.0356138200374\n",
      "C:  0.05 Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.917222917536 0.0482011694441\n",
      "C:  0.05 Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.894555694618 0.0847145588427\n",
      "C:  0.05 Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.921777221527 0.0890335132895\n",
      "C:  0.05 Surf:  1 subfs:  3 test_surf:  4 Acc_mean-std:  0.920629954109 0.0724313456076\n",
      "C:  0.05 Surf:  1 subfs:  3 test_surf:  5 Acc_mean-std:  0.926540119594 0.058504461538\n",
      "C:  0.05 Surf:  1 subfs:  3 Acc_mean-std:  0.918607750429 0.0647498114599\n",
      "C:  0.05 Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.680190515923 0.123530139521\n",
      "C:  0.05 Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.745132804895 0.143097406968\n",
      "C:  0.05 Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.730983173411 0.155125271446\n",
      "C:  0.05 Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.79046725073 0.155456860547\n",
      "C:  0.05 Surf:  5 subfs:  0 test_surf:  4 Acc_mean-std:  0.83041301627 0.117409191238\n",
      "C:  0.05 Surf:  5 subfs:  0 test_surf:  5 Acc_mean-std:  0.814420803783 0.1286227713\n",
      "C:  0.05 Surf:  5 subfs:  0 Acc_mean-std:  0.765267927502 0.13720694017\n",
      "C:  0.05 Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.816506744542 0.103165019683\n",
      "C:  0.05 Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.888471700737 0.100016358015\n",
      "C:  0.05 Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.896815463774 0.0774282802798\n",
      "C:  0.05 Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.809240717564 0.095578149301\n",
      "C:  0.05 Surf:  5 subfs:  1 test_surf:  4 Acc_mean-std:  0.902482269504 0.0724139224196\n",
      "C:  0.05 Surf:  5 subfs:  1 test_surf:  5 Acc_mean-std:  0.902864691976 0.0541752812285\n",
      "C:  0.05 Surf:  5 subfs:  1 Acc_mean-std:  0.869396931349 0.0837961684878\n",
      "C:  0.05 Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.568766513698 0.0918162051611\n",
      "C:  0.05 Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.612571269643 0.101384637057\n",
      "C:  0.05 Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.600194687804 0.104802880314\n",
      "C:  0.05 Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.538311778612 0.0712786302421\n",
      "C:  0.05 Surf:  5 subfs:  2 test_surf:  4 Acc_mean-std:  0.618377138089 0.0829907594268\n",
      "C:  0.05 Surf:  5 subfs:  2 test_surf:  5 Acc_mean-std:  0.682276456682 0.0906067707279\n",
      "C:  0.05 Surf:  5 subfs:  2 Acc_mean-std:  0.603416307421 0.0904799804881\n",
      "C:  0.05 Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.954352663051 0.0217368361337\n",
      "C:  0.05 Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.966798776248 0.0148629276566\n",
      "C:  0.05 Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.969406202197 0.0157745798103\n",
      "C:  0.05 Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.936378806842 0.0405901775374\n",
      "C:  0.05 Surf:  5 subfs:  3 test_surf:  4 Acc_mean-std:  0.970518703935 0.0126966621727\n",
      "C:  0.05 Surf:  5 subfs:  3 test_surf:  5 Acc_mean-std:  0.970483938256 0.0116416239779\n",
      "C:  0.05 Surf:  5 subfs:  3 Acc_mean-std:  0.961323181755 0.0195504678815\n",
      "C:  0.3 Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.556702822973 0.0942068764815\n",
      "C:  0.3 Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.582811848144 0.0919533224884\n",
      "C:  0.3 Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.602558753998 0.118332403922\n",
      "C:  0.3 Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.5758239466 0.126776256599\n",
      "C:  0.3 Surf:  1 subfs:  0 test_surf:  4 Acc_mean-std:  0.606382978723 0.157143347183\n",
      "C:  0.3 Surf:  1 subfs:  0 test_surf:  5 Acc_mean-std:  0.59581421221 0.130784308484\n",
      "C:  0.3 Surf:  1 subfs:  0 Acc_mean-std:  0.586682427108 0.11986608586\n",
      "C:  0.3 Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.750104297038 0.133744431388\n",
      "C:  0.3 Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.827214573773 0.147077002473\n",
      "C:  0.3 Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.827075511055 0.14757629157\n",
      "C:  0.3 Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.676122931442 0.159409582975\n",
      "C:  0.3 Surf:  1 subfs:  1 test_surf:  4 Acc_mean-std:  0.800514532054 0.115483632815\n",
      "C:  0.3 Surf:  1 subfs:  1 test_surf:  5 Acc_mean-std:  0.801383674037 0.120726718549\n",
      "C:  0.3 Surf:  1 subfs:  1 Acc_mean-std:  0.780402586567 0.137336276628\n",
      "C:  0.3 Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.502016409401 0.0202771849132\n",
      "C:  0.3 Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.51484494507 0.0288254866361\n",
      "C:  0.3 Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.522841051314 0.0412166006376\n",
      "C:  0.3 Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.512515644556 0.0442460439207\n",
      "C:  0.3 Surf:  1 subfs:  2 test_surf:  4 Acc_mean-std:  0.488701154221 0.0286791990595\n",
      "C:  0.3 Surf:  1 subfs:  2 test_surf:  5 Acc_mean-std:  0.5122722848 0.0273645209133\n",
      "C:  0.3 Surf:  1 subfs:  2 Acc_mean-std:  0.508865248227 0.0317681726801\n",
      "C:  0.3 Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.823633708803 0.140314639217\n",
      "C:  0.3 Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.838930607704 0.125833179262\n",
      "C:  0.3 Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.834584897789 0.139801144042\n",
      "C:  0.3 Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.789180920595 0.150210749072\n",
      "C:  0.3 Surf:  1 subfs:  3 test_surf:  4 Acc_mean-std:  0.820470031984 0.117975559135\n",
      "C:  0.3 Surf:  1 subfs:  3 test_surf:  5 Acc_mean-std:  0.81761924628 0.128196838552\n",
      "C:  0.3 Surf:  1 subfs:  3 Acc_mean-std:  0.820736568859 0.133722018214\n",
      "C:  0.3 Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.511368377138 0.0432302100992\n",
      "C:  0.3 Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.54199694062 0.0824904226614\n",
      "C:  0.3 Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.533166458073 0.0812441123057\n",
      "C:  0.3 Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.519746905855 0.0636643411623\n",
      "C:  0.3 Surf:  5 subfs:  0 test_surf:  4 Acc_mean-std:  0.606591572799 0.0944214857604\n",
      "C:  0.3 Surf:  5 subfs:  0 test_surf:  5 Acc_mean-std:  0.588513419552 0.0953661049592\n",
      "C:  0.3 Surf:  5 subfs:  0 Acc_mean-std:  0.550230612339 0.0767361128247\n",
      "C:  0.3 Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.723751912112 0.103820191158\n",
      "C:  0.3 Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.799575858712 0.123404210461\n",
      "C:  0.3 Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.825580586845 0.132886428261\n",
      "C:  0.3 Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.683041301627 0.0929783963845\n",
      "C:  0.3 Surf:  5 subfs:  1 test_surf:  4 Acc_mean-std:  0.771728549576 0.105977401307\n",
      "C:  0.3 Surf:  5 subfs:  1 test_surf:  5 Acc_mean-std:  0.78587818106 0.108375162056\n",
      "C:  0.3 Surf:  5 subfs:  1 Acc_mean-std:  0.764926064989 0.111240298271\n",
      "C:  0.3 Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.50305937978 0.0128041576882\n",
      "C:  0.3 Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.504901960784 0.00657898572712\n",
      "C:  0.3 Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.501321095814 0.00536248629806\n",
      "C:  0.3 Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.493394520929 0.0158342308316\n",
      "C:  0.3 Surf:  5 subfs:  2 test_surf:  4 Acc_mean-std:  0.494611319705 0.0187498563914\n",
      "C:  0.3 Surf:  5 subfs:  2 test_surf:  5 Acc_mean-std:  0.501286330135 0.0205176129875\n",
      "C:  0.3 Surf:  5 subfs:  2 Acc_mean-std:  0.499762434525 0.0133078883206\n",
      "C:  0.3 Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.543596161869 0.131706306148\n",
      "C:  0.3 Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.655124461132 0.11497013831\n",
      "C:  0.3 Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.674210819079 0.10662802744\n",
      "C:  0.3 Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.485954665554 0.141932477207\n",
      "C:  0.3 Surf:  5 subfs:  3 test_surf:  4 Acc_mean-std:  0.565359477124 0.120590330277\n",
      "C:  0.3 Surf:  5 subfs:  3 test_surf:  5 Acc_mean-std:  0.539076623557 0.129517138846\n",
      "C:  0.3 Surf:  5 subfs:  3 Acc_mean-std:  0.577220368053 0.124224069705\n",
      "C:  0.55 Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.502225003477 0.00690324192975\n",
      "C:  0.55 Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.515818384091 0.0310786311985\n",
      "C:  0.55 Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.514462522598 0.0366935234873\n",
      "C:  0.55 Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.510916423307 0.0285402301002\n",
      "C:  0.55 Surf:  1 subfs:  0 test_surf:  4 Acc_mean-std:  0.541857877903 0.0656100125506\n",
      "C:  0.55 Surf:  1 subfs:  0 test_surf:  5 Acc_mean-std:  0.536052009456 0.0794449478708\n",
      "C:  0.55 Surf:  1 subfs:  0 Acc_mean-std:  0.520222036805 0.0413784311895\n",
      "C:  0.55 Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.726081212627 0.137330378562\n",
      "C:  0.55 Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.804616882214 0.154140938636\n",
      "C:  0.55 Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.812752051175 0.153915087284\n",
      "C:  0.55 Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.659504936726 0.160015435947\n",
      "C:  0.55 Surf:  1 subfs:  1 test_surf:  4 Acc_mean-std:  0.75305937978 0.137429407552\n",
      "C:  0.55 Surf:  1 subfs:  1 test_surf:  5 Acc_mean-std:  0.757857043527 0.148667292844\n",
      "C:  0.55 Surf:  1 subfs:  1 Acc_mean-std:  0.752311917675 0.148583090138\n",
      "C:  0.55 Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.446599916562 0.068927954722\n",
      "C:  0.55 Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.460749548046 0.0443919881274\n",
      "C:  0.55 Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.485919899875 0.0202527016552\n",
      "C:  0.55 Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.436761229314 0.0794283327612\n",
      "C:  0.55 Surf:  1 subfs:  2 test_surf:  4 Acc_mean-std:  0.444965929634 0.0621613748938\n",
      "C:  0.55 Surf:  1 subfs:  2 test_surf:  5 Acc_mean-std:  0.453518286747 0.050758403767\n",
      "C:  0.55 Surf:  1 subfs:  2 Acc_mean-std:  0.454752468363 0.0543201259877\n",
      "C:  0.55 Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.733312473926 0.173716008029\n",
      "C:  0.55 Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.739083576693 0.158957852265\n",
      "C:  0.55 Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.748400778751 0.163069740955\n",
      "C:  0.55 Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.694444444444 0.19106287148\n",
      "C:  0.55 Surf:  1 subfs:  3 test_surf:  4 Acc_mean-std:  0.717111667362 0.154491900074\n",
      "C:  0.55 Surf:  1 subfs:  3 test_surf:  5 Acc_mean-std:  0.716972604645 0.160432889978\n",
      "C:  0.55 Surf:  1 subfs:  3 Acc_mean-std:  0.72488759097 0.166955210464\n",
      "C:  0.55 Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.499548046169 0.00102838266289\n",
      "C:  0.55 Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.50664024475 0.02565930887\n",
      "C:  0.55 Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.50462383535 0.023220220782\n",
      "C:  0.55 Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.504032818801 0.0275606553656\n",
      "C:  0.55 Surf:  5 subfs:  0 test_surf:  4 Acc_mean-std:  0.528646919761 0.0418388737408\n",
      "C:  0.55 Surf:  5 subfs:  0 test_surf:  5 Acc_mean-std:  0.505840634126 0.0323186212846\n",
      "C:  0.55 Surf:  5 subfs:  0 Acc_mean-std:  0.50822208316 0.025271010451\n",
      "C:  0.55 Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.711827284105 0.103314679032\n",
      "C:  0.55 Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.780698094841 0.125284703824\n",
      "C:  0.55 Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.814664163538 0.130628990211\n",
      "C:  0.55 Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.664545960228 0.088401808158\n",
      "C:  0.55 Surf:  5 subfs:  1 test_surf:  4 Acc_mean-std:  0.738388263107 0.115403053082\n",
      "C:  0.55 Surf:  5 subfs:  1 test_surf:  5 Acc_mean-std:  0.753511333611 0.110437491104\n",
      "C:  0.55 Surf:  5 subfs:  1 Acc_mean-std:  0.743939183238 0.112245120902\n",
      "C:  0.55 Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.478271450424 0.0324525093503\n",
      "C:  0.55 Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.48153942428 0.028785037743\n",
      "C:  0.55 Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.489048811014 0.0203320381291\n",
      "C:  0.55 Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.459324155194 0.0510582737931\n",
      "C:  0.55 Surf:  5 subfs:  2 test_surf:  4 Acc_mean-std:  0.47437769434 0.0338623249071\n",
      "C:  0.55 Surf:  5 subfs:  2 test_surf:  5 Acc_mean-std:  0.469719093311 0.0398745670915\n",
      "C:  0.55 Surf:  5 subfs:  2 Acc_mean-std:  0.475380104761 0.034394125169\n",
      "C:  0.55 Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.317584480601 0.145456158078\n",
      "C:  0.55 Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.360902517035 0.148205511926\n",
      "C:  0.55 Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.397684605757 0.133965597022\n",
      "C:  0.55 Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.27562230566 0.157450840811\n",
      "C:  0.55 Surf:  5 subfs:  3 test_surf:  4 Acc_mean-std:  0.318314559866 0.147132330871\n",
      "C:  0.55 Surf:  5 subfs:  3 test_surf:  5 Acc_mean-std:  0.303608677514 0.159812299419\n",
      "C:  0.55 Surf:  5 subfs:  3 Acc_mean-std:  0.328952857739 0.148670456355\n",
      "C:  0.8 Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.499791405924 0.000884989713625\n",
      "C:  0.8 Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.504901960784 0.0146740409832\n",
      "C:  0.8 Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.50152968989 0.00517389936651\n",
      "C:  0.8 Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.499617577527 0.000495334683937\n",
      "C:  0.8 Surf:  1 subfs:  0 test_surf:  4 Acc_mean-std:  0.529168404951 0.0515382053941\n",
      "C:  0.8 Surf:  1 subfs:  0 test_surf:  5 Acc_mean-std:  0.521033235989 0.0531410097283\n",
      "C:  0.8 Surf:  1 subfs:  0 Acc_mean-std:  0.509340379178 0.0209845799783\n",
      "C:  0.8 Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.720970657767 0.137427864071\n",
      "C:  0.8 Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.800410235016 0.153551733044\n",
      "C:  0.8 Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.809310248922 0.153364785956\n",
      "C:  0.8 Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.656202197191 0.157755555392\n",
      "C:  0.8 Surf:  1 subfs:  1 test_surf:  4 Acc_mean-std:  0.742977332777 0.144480922381\n",
      "C:  0.8 Surf:  1 subfs:  1 test_surf:  5 Acc_mean-std:  0.745306633292 0.158667163039\n",
      "C:  0.8 Surf:  1 subfs:  1 Acc_mean-std:  0.745862884161 0.150874670647\n",
      "C:  0.8 Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.422229175358 0.0819937399148\n",
      "C:  0.8 Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.445556946183 0.0607778851947\n",
      "C:  0.8 Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.464191350299 0.0410869735179\n",
      "C:  0.8 Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.418648310388 0.0924175341294\n",
      "C:  0.8 Surf:  1 subfs:  2 test_surf:  4 Acc_mean-std:  0.425601446252 0.0768135863869\n",
      "C:  0.8 Surf:  1 subfs:  2 test_surf:  5 Acc_mean-std:  0.425879571687 0.0753649045986\n",
      "C:  0.8 Surf:  1 subfs:  2 Acc_mean-std:  0.433684466694 0.0714091039571\n",
      "C:  0.8 Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.685753024614 0.191287790771\n",
      "C:  0.8 Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.708628841608 0.18057280118\n",
      "C:  0.8 Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.709776109025 0.17882822023\n",
      "C:  0.8 Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.663085801697 0.206221133511\n",
      "C:  0.8 Surf:  1 subfs:  3 test_surf:  4 Acc_mean-std:  0.690724516757 0.172920532853\n",
      "C:  0.8 Surf:  1 subfs:  3 test_surf:  5 Acc_mean-std:  0.673828396607 0.187964509047\n",
      "C:  0.8 Surf:  1 subfs:  3 Acc_mean-std:  0.688632781718 0.186299164599\n",
      "C:  0.8 Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.499374217772 1.11022302463e-16\n",
      "C:  0.8 Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.503928521763 0.0194745841817\n",
      "C:  0.8 Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.499860937283 0.00267582831385\n",
      "C:  0.8 Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.502155472118 0.0164541226063\n",
      "C:  0.8 Surf:  5 subfs:  0 test_surf:  4 Acc_mean-std:  0.508448060075 0.0267332250382\n",
      "C:  0.8 Surf:  5 subfs:  0 test_surf:  5 Acc_mean-std:  0.503719927687 0.0257095665724\n",
      "C:  0.8 Surf:  5 subfs:  0 Acc_mean-std:  0.502914522783 0.0151745544521\n",
      "C:  0.8 Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.706612432207 0.103032118822\n",
      "C:  0.8 Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.776839104436 0.125327660473\n",
      "C:  0.8 Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.810596579057 0.12971935449\n",
      "C:  0.8 Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.658566263385 0.0859715464276\n",
      "C:  0.8 Surf:  5 subfs:  1 test_surf:  4 Acc_mean-std:  0.73258239466 0.115986559645\n",
      "C:  0.8 Surf:  5 subfs:  1 test_surf:  5 Acc_mean-std:  0.742455847587 0.108968040339\n",
      "C:  0.8 Surf:  5 subfs:  1 Acc_mean-std:  0.737942103555 0.111500880033\n",
      "C:  0.8 Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.456334306772 0.0592475315713\n",
      "C:  0.8 Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.468328466138 0.0426592168594\n",
      "C:  0.8 Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.479279655124 0.0253627485016\n",
      "C:  0.8 Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.445556946183 0.0648153856416\n",
      "C:  0.8 Surf:  5 subfs:  2 test_surf:  4 Acc_mean-std:  0.463009317202 0.0445092488968\n",
      "C:  0.8 Surf:  5 subfs:  2 test_surf:  5 Acc_mean-std:  0.452544847726 0.0610652699914\n",
      "C:  0.8 Surf:  5 subfs:  2 Acc_mean-std:  0.460842256524 0.0496099002437\n",
      "C:  0.8 Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.244402725629 0.143836653053\n",
      "C:  0.8 Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.301835627868 0.148781397128\n",
      "C:  0.8 Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.31713252677 0.122365373464\n",
      "C:  0.8 Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.232547628981 0.15819899573\n",
      "C:  0.8 Surf:  5 subfs:  3 test_surf:  4 Acc_mean-std:  0.269155889306 0.149679569673\n",
      "C:  0.8 Surf:  5 subfs:  3 test_surf:  5 Acc_mean-std:  0.23769294952 0.15643091991\n",
      "C:  0.8 Surf:  5 subfs:  3 Acc_mean-std:  0.267127891346 0.14654881816\n",
      "C:  1.0 Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.499791405924 0.000884989713625\n",
      "C:  1.0 Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.504901960784 0.0146740409832\n",
      "C:  1.0 Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.50152968989 0.00517389936651\n",
      "C:  1.0 Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.499617577527 0.000495334683937\n",
      "C:  1.0 Surf:  1 subfs:  0 test_surf:  4 Acc_mean-std:  0.529168404951 0.0515382053941\n",
      "C:  1.0 Surf:  1 subfs:  0 test_surf:  5 Acc_mean-std:  0.521033235989 0.0531410097283\n",
      "C:  1.0 Surf:  1 subfs:  0 Acc_mean-std:  0.509340379178 0.0209845799783\n",
      "C:  1.0 Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.720970657767 0.137427864071\n",
      "C:  1.0 Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.800410235016 0.153551733044\n",
      "C:  1.0 Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.809310248922 0.153364785956\n",
      "C:  1.0 Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.656202197191 0.157755555392\n",
      "C:  1.0 Surf:  1 subfs:  1 test_surf:  4 Acc_mean-std:  0.742977332777 0.144480922381\n",
      "C:  1.0 Surf:  1 subfs:  1 test_surf:  5 Acc_mean-std:  0.745306633292 0.158667163039\n",
      "C:  1.0 Surf:  1 subfs:  1 Acc_mean-std:  0.745862884161 0.150874670647\n",
      "C:  1.0 Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.422229175358 0.0819937399148\n",
      "C:  1.0 Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.445556946183 0.0607778851947\n",
      "C:  1.0 Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.464191350299 0.0410869735179\n",
      "C:  1.0 Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.418648310388 0.0924175341294\n",
      "C:  1.0 Surf:  1 subfs:  2 test_surf:  4 Acc_mean-std:  0.425601446252 0.0768135863869\n",
      "C:  1.0 Surf:  1 subfs:  2 test_surf:  5 Acc_mean-std:  0.425879571687 0.0753649045986\n",
      "C:  1.0 Surf:  1 subfs:  2 Acc_mean-std:  0.433684466694 0.0714091039571\n",
      "C:  1.0 Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.685753024614 0.191287790771\n",
      "C:  1.0 Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.708628841608 0.18057280118\n",
      "C:  1.0 Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.709776109025 0.17882822023\n",
      "C:  1.0 Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.663085801697 0.206221133511\n",
      "C:  1.0 Surf:  1 subfs:  3 test_surf:  4 Acc_mean-std:  0.690724516757 0.172920532853\n",
      "C:  1.0 Surf:  1 subfs:  3 test_surf:  5 Acc_mean-std:  0.673828396607 0.187964509047\n",
      "C:  1.0 Surf:  1 subfs:  3 Acc_mean-std:  0.688632781718 0.186299164599\n",
      "C:  1.0 Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.499374217772 1.11022302463e-16\n",
      "C:  1.0 Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.503928521763 0.0194745841817\n",
      "C:  1.0 Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.499860937283 0.00267582831385\n",
      "C:  1.0 Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.502155472118 0.0164541226063\n",
      "C:  1.0 Surf:  5 subfs:  0 test_surf:  4 Acc_mean-std:  0.508448060075 0.0267332250382\n",
      "C:  1.0 Surf:  5 subfs:  0 test_surf:  5 Acc_mean-std:  0.503719927687 0.0257095665724\n",
      "C:  1.0 Surf:  5 subfs:  0 Acc_mean-std:  0.502914522783 0.0151745544521\n",
      "C:  1.0 Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.706612432207 0.103032118822\n",
      "C:  1.0 Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.776839104436 0.125327660473\n",
      "C:  1.0 Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.810596579057 0.12971935449\n",
      "C:  1.0 Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.658566263385 0.0859715464276\n",
      "C:  1.0 Surf:  5 subfs:  1 test_surf:  4 Acc_mean-std:  0.73258239466 0.115986559645\n",
      "C:  1.0 Surf:  5 subfs:  1 test_surf:  5 Acc_mean-std:  0.742455847587 0.108968040339\n",
      "C:  1.0 Surf:  5 subfs:  1 Acc_mean-std:  0.737942103555 0.111500880033\n",
      "C:  1.0 Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.456334306772 0.0592475315713\n",
      "C:  1.0 Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.468328466138 0.0426592168594\n",
      "C:  1.0 Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.479279655124 0.0253627485016\n",
      "C:  1.0 Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.445556946183 0.0648153856416\n",
      "C:  1.0 Surf:  5 subfs:  2 test_surf:  4 Acc_mean-std:  0.463009317202 0.0445092488968\n",
      "C:  1.0 Surf:  5 subfs:  2 test_surf:  5 Acc_mean-std:  0.452544847726 0.0610652699914\n",
      "C:  1.0 Surf:  5 subfs:  2 Acc_mean-std:  0.460842256524 0.0496099002437\n",
      "C:  1.0 Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.244402725629 0.143836653053\n",
      "C:  1.0 Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.301835627868 0.148781397128\n",
      "C:  1.0 Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.31713252677 0.122365373464\n",
      "C:  1.0 Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.232547628981 0.15819899573\n",
      "C:  1.0 Surf:  5 subfs:  3 test_surf:  4 Acc_mean-std:  0.269155889306 0.149679569673\n",
      "C:  1.0 Surf:  5 subfs:  3 test_surf:  5 Acc_mean-std:  0.23769294952 0.15643091991\n",
      "C:  1.0 Surf:  5 subfs:  3 Acc_mean-std:  0.267127891346 0.14654881816\n",
      "C:  1.3 Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.502746488666 0.00820079561739\n",
      "C:  1.3 Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.519364483382 0.0358192972169\n",
      "C:  1.3 Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.51640940064 0.0414449477447\n",
      "C:  1.3 Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.514045334446 0.0363308501585\n",
      "C:  1.3 Surf:  1 subfs:  0 test_surf:  4 Acc_mean-std:  0.543665693228 0.0684273004865\n",
      "C:  1.3 Surf:  1 subfs:  0 test_surf:  5 Acc_mean-std:  0.540502016409 0.0842803462964\n",
      "C:  1.3 Surf:  1 subfs:  0 Acc_mean-std:  0.522788902795 0.0457505895867\n",
      "C:  1.3 Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.727749965234 0.137426135879\n",
      "C:  1.3 Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.805486024197 0.154255107593\n",
      "C:  1.3 Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.813551661799 0.153856899391\n",
      "C:  1.3 Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.659887359199 0.16015879095\n",
      "C:  1.3 Surf:  1 subfs:  1 test_surf:  4 Acc_mean-std:  0.754693366708 0.136193243081\n",
      "C:  1.3 Surf:  1 subfs:  1 test_surf:  5 Acc_mean-std:  0.761055486024 0.146907811166\n",
      "C:  1.3 Surf:  1 subfs:  1 Acc_mean-std:  0.753737310527 0.14813299801\n",
      "C:  1.3 Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.454178834654 0.0601675702168\n",
      "C:  1.3 Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.465095257961 0.0357533870083\n",
      "C:  1.3 Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.487936309275 0.0176607940035\n",
      "C:  1.3 Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.432276456682 0.0785113729447\n",
      "C:  1.3 Surf:  1 subfs:  2 test_surf:  4 Acc_mean-std:  0.447538589904 0.0644298275929\n",
      "C:  1.3 Surf:  1 subfs:  2 test_surf:  5 Acc_mean-std:  0.45800305938 0.0475255356\n",
      "C:  1.3 Surf:  1 subfs:  2 Acc_mean-std:  0.45750475131 0.0506747478944\n",
      "C:  1.3 Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.741656236963 0.169900707169\n",
      "C:  1.3 Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.746141009595 0.1527294714\n",
      "C:  1.3 Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.758934779586 0.159027307414\n",
      "C:  1.3 Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.692879988875 0.189814254382\n",
      "C:  1.3 Surf:  1 subfs:  3 test_surf:  4 Acc_mean-std:  0.735537477402 0.155198427699\n",
      "C:  1.3 Surf:  1 subfs:  3 test_surf:  5 Acc_mean-std:  0.723821443471 0.159099174646\n",
      "C:  1.3 Surf:  1 subfs:  3 Acc_mean-std:  0.733161822649 0.164294890452\n",
      "C:  1.3 Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.499721874565 0.0016846115199\n",
      "C:  1.3 Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.507961340565 0.0269193912424\n",
      "C:  1.3 Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.50563204005 0.0281316006132\n",
      "C:  1.3 Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.50410235016 0.0279720084307\n",
      "C:  1.3 Surf:  5 subfs:  0 test_surf:  4 Acc_mean-std:  0.535078570435 0.0428319236259\n",
      "C:  1.3 Surf:  5 subfs:  0 test_surf:  5 Acc_mean-std:  0.506605479071 0.0333308414823\n",
      "C:  1.3 Surf:  5 subfs:  0 Acc_mean-std:  0.509850275808 0.0268117294857\n",
      "C:  1.3 Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.712244472257 0.103464501562\n",
      "C:  1.3 Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.781219580031 0.125198094671\n",
      "C:  1.3 Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.815116117369 0.13072130276\n",
      "C:  1.3 Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.664893617021 0.0886440767568\n",
      "C:  1.3 Surf:  5 subfs:  1 test_surf:  4 Acc_mean-std:  0.739535530524 0.115355646361\n",
      "C:  1.3 Surf:  5 subfs:  1 test_surf:  5 Acc_mean-std:  0.754658601029 0.110305638485\n",
      "C:  1.3 Surf:  5 subfs:  1 Acc_mean-std:  0.744611319705 0.112281543432\n",
      "C:  1.3 Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.482130440829 0.028466956832\n",
      "C:  1.3 Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.484459741343 0.0242586480303\n",
      "C:  1.3 Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.489535530524 0.0181684189469\n",
      "C:  1.3 Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.456090947017 0.0518668865692\n",
      "C:  1.3 Surf:  5 subfs:  2 test_surf:  4 Acc_mean-std:  0.475976915589 0.0317019344706\n",
      "C:  1.3 Surf:  5 subfs:  2 test_surf:  5 Acc_mean-std:  0.472535113336 0.0379439956881\n",
      "C:  1.3 Surf:  5 subfs:  2 Acc_mean-std:  0.476788114773 0.0320678067562\n",
      "C:  1.3 Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.336497010152 0.146200536634\n",
      "C:  1.3 Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.37755527743 0.141420322453\n",
      "C:  1.3 Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.418613544709 0.133029875921\n",
      "C:  1.3 Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.276004728132 0.154488801975\n",
      "C:  1.3 Surf:  5 subfs:  3 test_surf:  4 Acc_mean-std:  0.342754832429 0.145861755738\n",
      "C:  1.3 Surf:  5 subfs:  3 test_surf:  5 Acc_mean-std:  0.309796968433 0.158783938755\n",
      "C:  1.3 Surf:  5 subfs:  3 Acc_mean-std:  0.343537060214 0.146630871913\n",
      "C:  2.0 Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.574920038938 0.106102090908\n",
      "C:  2.0 Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.600159922125 0.102617043602\n",
      "C:  2.0 Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.622409956891 0.142111768188\n",
      "C:  2.0 Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.594006396885 0.150832204896\n",
      "C:  2.0 Surf:  1 subfs:  0 test_surf:  4 Acc_mean-std:  0.625225976916 0.166864164328\n",
      "C:  2.0 Surf:  1 subfs:  0 test_surf:  5 Acc_mean-std:  0.607425949103 0.138177477199\n",
      "C:  2.0 Surf:  1 subfs:  0 Acc_mean-std:  0.604024706809 0.13445079152\n",
      "C:  2.0 Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.75872618551 0.130522269236\n",
      "C:  2.0 Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.832707551106 0.141935968596\n",
      "C:  2.0 Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.831247392574 0.143238227215\n",
      "C:  2.0 Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.682693644834 0.156854835552\n",
      "C:  2.0 Surf:  1 subfs:  1 test_surf:  4 Acc_mean-std:  0.813099707968 0.111560199364\n",
      "C:  2.0 Surf:  1 subfs:  1 test_surf:  5 Acc_mean-std:  0.808510638298 0.117991622107\n",
      "C:  2.0 Surf:  1 subfs:  1 Acc_mean-std:  0.787830853382 0.133683853678\n",
      "C:  2.0 Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.51331525518 0.0193760268905\n",
      "C:  2.0 Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.518842998192 0.0377335607117\n",
      "C:  2.0 Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.527847309136 0.0500298660682\n",
      "C:  2.0 Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.511125017383 0.0525303317287\n",
      "C:  2.0 Surf:  1 subfs:  2 test_surf:  4 Acc_mean-std:  0.506605479071 0.0167917871229\n",
      "C:  2.0 Surf:  1 subfs:  2 test_surf:  5 Acc_mean-std:  0.525448477263 0.0368751613895\n",
      "C:  2.0 Surf:  1 subfs:  2 Acc_mean-std:  0.517197422704 0.0355561223186\n",
      "C:  2.0 Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.846370463079 0.124142876448\n",
      "C:  2.0 Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.850438047559 0.112477090198\n",
      "C:  2.0 Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.848804060631 0.136405476533\n",
      "C:  2.0 Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.793109442359 0.141197950767\n",
      "C:  2.0 Surf:  1 subfs:  3 test_surf:  4 Acc_mean-std:  0.848560700876 0.106870218474\n",
      "C:  2.0 Surf:  1 subfs:  3 test_surf:  5 Acc_mean-std:  0.840460297594 0.120365283881\n",
      "C:  2.0 Surf:  1 subfs:  3 Acc_mean-std:  0.837957168683 0.123576482717\n",
      "C:  2.0 Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.519885968572 0.0570452572605\n",
      "C:  2.0 Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.560666110416 0.0994179962952\n",
      "C:  2.0 Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.552809066889 0.0959391345825\n",
      "C:  2.0 Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.537685996384 0.0782915996947\n",
      "C:  2.0 Surf:  5 subfs:  0 test_surf:  4 Acc_mean-std:  0.616569322765 0.104012190405\n",
      "C:  2.0 Surf:  5 subfs:  0 test_surf:  5 Acc_mean-std:  0.616047837575 0.112444826782\n",
      "C:  2.0 Surf:  5 subfs:  0 Acc_mean-std:  0.567277383767 0.0911918341701\n",
      "C:  2.0 Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.728688638576 0.104156397087\n",
      "C:  2.0 Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.807815324711 0.121657546076\n",
      "C:  2.0 Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.82992629676 0.132048379649\n",
      "C:  2.0 Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.689785843415 0.0939614569026\n",
      "C:  2.0 Surf:  5 subfs:  1 test_surf:  4 Acc_mean-std:  0.784383256849 0.101503090971\n",
      "C:  2.0 Surf:  5 subfs:  1 test_surf:  5 Acc_mean-std:  0.797211792518 0.105491485826\n",
      "C:  2.0 Surf:  5 subfs:  1 Acc_mean-std:  0.772968525472 0.109803059419\n",
      "C:  2.0 Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.507300792657 0.00870114877539\n",
      "C:  2.0 Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.504450006953 0.0075552788379\n",
      "C:  2.0 Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.502259769156 0.00539786854428\n",
      "C:  2.0 Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.488840216938 0.0218265070465\n",
      "C:  2.0 Surf:  5 subfs:  2 test_surf:  4 Acc_mean-std:  0.50152968989 0.0100195146199\n",
      "C:  2.0 Surf:  5 subfs:  2 test_surf:  5 Acc_mean-std:  0.507231261299 0.0188142400396\n",
      "C:  2.0 Surf:  5 subfs:  2 Acc_mean-std:  0.501935289482 0.0120524263106\n",
      "C:  2.0 Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.620880267 0.120652290328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  2.0 Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.685926853011 0.0979490546837\n",
      "C:  2.0 Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.750625782228 0.0933939647075\n",
      "C:  2.0 Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.488388263107 0.137526031899\n",
      "C:  2.0 Surf:  5 subfs:  3 test_surf:  4 Acc_mean-std:  0.651543596162 0.109184752856\n",
      "C:  2.0 Surf:  5 subfs:  3 test_surf:  5 Acc_mean-std:  0.610033375052 0.124933877682\n",
      "C:  2.0 Surf:  5 subfs:  3 Acc_mean-std:  0.634566356093 0.113939995359\n",
      "C:  5.0 Surf:  1 subfs:  0 test_surf:  0 Acc_mean-std:  0.718050340704 0.210765009088\n",
      "C:  5.0 Surf:  1 subfs:  0 test_surf:  1 Acc_mean-std:  0.75152968989 0.181457540755\n",
      "C:  5.0 Surf:  1 subfs:  0 test_surf:  2 Acc_mean-std:  0.739465999166 0.204902779402\n",
      "C:  5.0 Surf:  1 subfs:  0 test_surf:  3 Acc_mean-std:  0.779481296065 0.187949587138\n",
      "C:  5.0 Surf:  1 subfs:  0 test_surf:  4 Acc_mean-std:  0.809727437074 0.157225281544\n",
      "C:  5.0 Surf:  1 subfs:  0 test_surf:  5 Acc_mean-std:  0.816854401335 0.176342327772\n",
      "C:  5.0 Surf:  1 subfs:  0 Acc_mean-std:  0.769184860706 0.18644042095\n",
      "C:  5.0 Surf:  1 subfs:  1 test_surf:  0 Acc_mean-std:  0.884125990822 0.0877183973814\n",
      "C:  5.0 Surf:  1 subfs:  1 test_surf:  1 Acc_mean-std:  0.911451814768 0.0871750431503\n",
      "C:  5.0 Surf:  1 subfs:  1 test_surf:  2 Acc_mean-std:  0.913572521207 0.0822368457681\n",
      "C:  5.0 Surf:  1 subfs:  1 test_surf:  3 Acc_mean-std:  0.864831038798 0.117075736351\n",
      "C:  5.0 Surf:  1 subfs:  1 test_surf:  4 Acc_mean-std:  0.933562786817 0.0671604091395\n",
      "C:  5.0 Surf:  1 subfs:  1 test_surf:  5 Acc_mean-std:  0.91955221805 0.0646753399247\n",
      "C:  5.0 Surf:  1 subfs:  1 Acc_mean-std:  0.904516061744 0.0843402952859\n",
      "C:  5.0 Surf:  1 subfs:  2 test_surf:  0 Acc_mean-std:  0.620880267 0.128918353444\n",
      "C:  5.0 Surf:  1 subfs:  2 test_surf:  1 Acc_mean-std:  0.654602975942 0.140558200429\n",
      "C:  5.0 Surf:  1 subfs:  2 test_surf:  2 Acc_mean-std:  0.634369350577 0.136868284936\n",
      "C:  5.0 Surf:  1 subfs:  2 test_surf:  3 Acc_mean-std:  0.61166736198 0.140626016859\n",
      "C:  5.0 Surf:  1 subfs:  2 test_surf:  4 Acc_mean-std:  0.663746349604 0.100239383459\n",
      "C:  5.0 Surf:  1 subfs:  2 test_surf:  5 Acc_mean-std:  0.693575302461 0.119713192409\n",
      "C:  5.0 Surf:  1 subfs:  2 Acc_mean-std:  0.646473601261 0.127820571923\n",
      "C:  5.0 Surf:  1 subfs:  3 test_surf:  0 Acc_mean-std:  0.93085106383 0.0429180727121\n",
      "C:  5.0 Surf:  1 subfs:  3 test_surf:  1 Acc_mean-std:  0.895285773884 0.066017965421\n",
      "C:  5.0 Surf:  1 subfs:  3 test_surf:  2 Acc_mean-std:  0.852384925601 0.124235922408\n",
      "C:  5.0 Surf:  1 subfs:  3 test_surf:  3 Acc_mean-std:  0.916701432346 0.0929564315019\n",
      "C:  5.0 Surf:  1 subfs:  3 test_surf:  4 Acc_mean-std:  0.911973299958 0.0704257591549\n",
      "C:  5.0 Surf:  1 subfs:  3 test_surf:  5 Acc_mean-std:  0.916736198025 0.0522656058191\n",
      "C:  5.0 Surf:  1 subfs:  3 Acc_mean-std:  0.903988782274 0.0748032928361\n",
      "C:  5.0 Surf:  5 subfs:  0 test_surf:  0 Acc_mean-std:  0.767104714226 0.132153977968\n",
      "C:  5.0 Surf:  5 subfs:  0 test_surf:  1 Acc_mean-std:  0.813064942289 0.154750419375\n",
      "C:  5.0 Surf:  5 subfs:  0 test_surf:  2 Acc_mean-std:  0.796898901405 0.171792542088\n",
      "C:  5.0 Surf:  5 subfs:  0 test_surf:  3 Acc_mean-std:  0.887637324433 0.127323784161\n",
      "C:  5.0 Surf:  5 subfs:  0 test_surf:  4 Acc_mean-std:  0.908253372271 0.0614392379666\n",
      "C:  5.0 Surf:  5 subfs:  0 test_surf:  5 Acc_mean-std:  0.914128772076 0.0806055001888\n",
      "C:  5.0 Surf:  5 subfs:  0 Acc_mean-std:  0.84784800445 0.121344243625\n",
      "C:  5.0 Surf:  5 subfs:  1 test_surf:  0 Acc_mean-std:  0.899666249479 0.0704174178904\n",
      "C:  5.0 Surf:  5 subfs:  1 test_surf:  1 Acc_mean-std:  0.946252259769 0.0240940956486\n",
      "C:  5.0 Surf:  5 subfs:  1 test_surf:  2 Acc_mean-std:  0.952405785009 0.0161858414573\n",
      "C:  5.0 Surf:  5 subfs:  1 test_surf:  3 Acc_mean-std:  0.905054929773 0.0590429227919\n",
      "C:  5.0 Surf:  5 subfs:  1 test_surf:  4 Acc_mean-std:  0.957724933945 0.0123233422466\n",
      "C:  5.0 Surf:  5 subfs:  1 test_surf:  5 Acc_mean-std:  0.945869837297 0.0159171768771\n",
      "C:  5.0 Surf:  5 subfs:  1 Acc_mean-std:  0.934495665879 0.0329967994853\n",
      "C:  5.0 Surf:  5 subfs:  2 test_surf:  0 Acc_mean-std:  0.866325963009 0.0562251542808\n",
      "C:  5.0 Surf:  5 subfs:  2 test_surf:  1 Acc_mean-std:  0.91086079822 0.0313559446301\n",
      "C:  5.0 Surf:  5 subfs:  2 test_surf:  2 Acc_mean-std:  0.910130718954 0.0354754926851\n",
      "C:  5.0 Surf:  5 subfs:  2 test_surf:  3 Acc_mean-std:  0.794152412738 0.0699928624536\n",
      "C:  5.0 Surf:  5 subfs:  2 test_surf:  4 Acc_mean-std:  0.878320122375 0.0393509405529\n",
      "C:  5.0 Surf:  5 subfs:  2 test_surf:  5 Acc_mean-std:  0.898379919344 0.0263849977016\n",
      "C:  5.0 Surf:  5 subfs:  2 Acc_mean-std:  0.876361655773 0.0431308987173\n",
      "C:  5.0 Surf:  5 subfs:  3 test_surf:  0 Acc_mean-std:  0.97489917953 0.0102908759797\n",
      "C:  5.0 Surf:  5 subfs:  3 test_surf:  1 Acc_mean-std:  0.967980809345 0.0142620240823\n",
      "C:  5.0 Surf:  5 subfs:  3 test_surf:  2 Acc_mean-std:  0.975316367682 0.00868418555833\n",
      "C:  5.0 Surf:  5 subfs:  3 test_surf:  3 Acc_mean-std:  0.977715199555 0.0116245847598\n",
      "C:  5.0 Surf:  5 subfs:  3 test_surf:  4 Acc_mean-std:  0.970970657767 0.00814756521839\n",
      "C:  5.0 Surf:  5 subfs:  3 test_surf:  5 Acc_mean-std:  0.978653872897 0.00535030137761\n",
      "C:  5.0 Surf:  5 subfs:  3 Acc_mean-std:  0.974256014463 0.00972658949601\n"
     ]
    }
   ],
   "source": [
    "############ NEW TESTING PROCEDURE WITH DATA FROM ATI F/T SENSOR BUT SCALED PRINTOUTS ##############\n",
    "trsurf=[1, 5]\n",
    "for a in range(scaled_acc.shape[0]): # for each c\n",
    "    for r in range(scaled_acc.shape[1]):  # for each number of surfaces used for training\n",
    "        for k in range(scaled_acc.shape[2]):  # for each subfs\n",
    "            for i in range(scaled_acc.shape[3]):  # for each testing surface\n",
    "                print \"C: \",c[a],\"Surf: \",trsurf[r],\"subfs: \",k,\"test_surf: \",i,\"Acc_mean-std: \",scaled_acc[a,r,k,i,0], scaled_acc[a,r,k,i,1]\n",
    "            print \"C: \",c[a],\"Surf: \",trsurf[r],\"subfs: \",k,\"Acc_mean-std: \",np.mean(scaled_acc[a,r,k,:,0]), np.mean(scaled_acc[a,r,k,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the training forces and compare them with testing ones (2.86 1.35 2.12 1.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "1 -> f1: (36,) (36,) (36, 4)\n",
      "2 -> f2: (36,) (36,) (36, 4)\n",
      "3 -> f: (72,) (72,) (72, 4)\n",
      "4 -> m1,m2: 36 36 1.0 1.0\n",
      "5 -> f=f+l: (72,) : [(345002, 4), (105001, 4), (210001, 4), (225002, 4), (130001, 4), (65001, 4), (195001, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (225002, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (75001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (130001, 4), (195001, 4), (65001, 4), (345002, 4), (105001, 4), (210001, 4), (225002, 4), (130001, 4), (65001, 4), (195001, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (225002, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (75001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (130001, 4), (195001, 4), (65001, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(72,) : [(345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2)]\n",
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "1 -> f1: (1, 1) (1, 1) (1, 1)\n",
      "2 -> f2: (1, 1) (1, 1) (1, 1)\n",
      "3 -> f: (2, 1) (2, 1) (2, 1)\n",
      "4 -> m1,m2: 1 1 1.0 1.0\n",
      "5 -> f=f+l: (2, 65000, 4) : [(65000, 4), (65000, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(2,) : [(65000, 2), (65000, 2)]\n",
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (6, 1) (6, 1) (6, 1)\n",
      "4 -> m1,m2: 3 3 1.0 1.0\n",
      "5 -> f=f+l: (6, 21000, 4) : [(21000, 4), (21000, 4), (21000, 4), (21000, 4), (21000, 4), (21000, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(6,) : [(21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2), (21000, 2)]\n",
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "3 -> f: (4, 1) (4, 1) (4, 1)\n",
      "4 -> m1,m2: 2 2 1.0 1.0\n",
      "5 -> f=f+l: (4, 21500, 4) : [(21500, 4), (21500, 4), (21500, 4), (21500, 4)]\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(4,) : [(21500, 2), (21500, 2), (21500, 2), (21500, 2)]\n",
      "(72,) (2,) (6,) (4,)\n",
      "2.86251014916 1.34931022067 2.12259710319 1.68059995482\n"
     ]
    }
   ],
   "source": [
    "f,_,_,_,_,_ = data_prep(datafile)                        # read training input force\n",
    "pf = compute_prefeat(f)                                  # compute corresponding prefeatures\n",
    "fv,_,_,_,_,_ = data_prep(validfile)                      # read validation input force\n",
    "pfv = compute_prefeat(fv)                                # compute corresponding prefeatures\n",
    "fa,_,_,_,_,_ = data_prep(atifile,k=1)                    # read validation input force\n",
    "pfa = compute_prefeat(fa)                                # compute corresponding prefeatures\n",
    "fa2,_,_,_,_,_ = data_prep(atirotfile,k=1)                    # read validation input force\n",
    "pfa2 = compute_prefeat(fa2)                                # compute corresponding prefeatures\n",
    "print pf.shape, pfv.shape, pfa.shape, pfa2.shape\n",
    "mf, mfv, mfa, mfa2 = 0, 0, 0, 0\n",
    "for p in range(len(pf)):\n",
    "    mf += np.mean(pf[p][:,0])\n",
    "for p in range(len(pfv)):\n",
    "    mfv += np.mean(pfv[p][:,0])\n",
    "for p in range(len(pfa)):\n",
    "    mfa += np.mean(pfa[p][:,0])\n",
    "for p in range(len(pfa2)):\n",
    "    mfa2 += np.mean(pfa2[p][:,0])\n",
    "mf /= len(pf)\n",
    "mfv /= len(pfv)\n",
    "mfa /= len(pfa)\n",
    "mfa2 /= len(pfa2)\n",
    "print mf, mfv, mfa, mfa2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
