{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC, OneClassSVM\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, ParameterGrid\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D #, axes3d\n",
    "\n",
    "import pywt\n",
    "from scipy.stats import kstat,moment,kstatvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def k_order_feats(data,order):\n",
    "    ind = np.arange(0,data.shape[1]*(len(order)+2),(len(order)+2))\n",
    "#     print(ind)\n",
    "    k_order_feats_ = np.zeros((1,data.shape[1]*(len(order)+2)))\n",
    "    for i in range(data.shape[1]): # for each prefeature\n",
    "        kstat_feats = np.zeros((1,len(order)))\n",
    "        kstatvar_feats = np.zeros((1,2))\n",
    "        for j in range(len(order)): # for each order\n",
    "            kstat_feats[:,j] = kstat(data[:,i],order[j])\n",
    "            kstatvar_feats[:,0],kstatvar_feats[:,1] = kstatvar(data[:,i],1), kstatvar(data[:,i],2)\n",
    "            kstats_feats = np.concatenate((kstat_feats, kstatvar_feats), axis = 1)\n",
    "        k_order_feats_[:,ind[i]:ind[i]+6] = kstats_feats\n",
    "#         print(range(ind[i], ind[i]+6,1))\n",
    "    return k_order_feats_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# output will be calculated by a simple majority vote.\n",
    "# ONLY THE LAST LABEL WILL BE KEPT \n",
    "def nodes_pred(X_test, nodes):\n",
    "    Y_pred = [nodes[i].predict(X_test) for i in range(len(nodes))]\n",
    "    Y_vote = np.zeros(X_test.shape[0])\n",
    "    for i in range(X_test.shape[0]): # for every point in X_test \n",
    "        votes = np.zeros(2)\n",
    "        for j in range(len(Y_pred)): # for every node \n",
    "            if (Y_pred[j][i]==1.):\n",
    "                votes[1]+=1\n",
    "            else:\n",
    "                votes[0]+=1\n",
    "            Y_vote[i] = np.argmax(votes)\n",
    "    return Y_vote[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((49,), ':', [(2478, 4), (2478, 4), (2476, 4), (2464, 4), (1264, 4), (3889, 4), (2092, 4), (2019, 4), (3896, 4), (6116, 4), (6073, 4), (2447, 4), (2440, 4), (2440, 4), (2440, 4), (2440, 4), (2440, 4), (2440, 4), (2440, 4), (2440, 4), (2440, 4), (2440, 4), (2440, 4), (2440, 4), (2440, 4), (2440, 4), (2440, 4), (2440, 4), (39998, 4), (39974, 4), (39984, 4), (39832, 4), (39926, 4), (39876, 4), (23980, 4), (20980, 4), (20480, 4), (20480, 4), (23480, 4), (23980, 4), (23980, 4), (23980, 4), (23980, 4), (23980, 4), (23980, 4), (26980, 4), (27480, 4), (27480, 4), (27480, 4)])\n"
     ]
    }
   ],
   "source": [
    "datapath = 'tmp/features/1024_1/'\n",
    "clfpath = 'tmp/'\n",
    "forcesfile_sc = datapath + 'newprefeaturesfxyz_trans_1024_1_10_20000.npz'\n",
    "newprefeat_sc = np.load(forcesfile_sc, encoding = 'latin1')['newprefeatf']\n",
    "print (newprefeat_sc.shape,\":\",[fi.shape for fi in newprefeat_sc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "[(3898, 163), (3895, 163), (3896, 163), (3881, 163), (3891, 163), (3886, 163), (2296, 163), (1996, 163), (1946, 163), (1946, 163), (2246, 163), (2296, 163), (2296, 163), (2296, 163), (2296, 163), (2296, 163), (2296, 163), (2596, 163), (2646, 163), (2646, 163), (2646, 163)]\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "from_d = 28\n",
    "window, shift = 1024,10\n",
    "order = [1,2,3,4]\n",
    "datasets = range(from_d,len(newprefeat_sc))\n",
    "total_scales = np.arange(1,10)\n",
    "features = []\n",
    "cwtdatafile = datapath + 'cwt_162_features_dataset.npz'\n",
    "\n",
    "if not os.path.isfile(cwtdatafile):    \n",
    "    for d in datasets:\n",
    "        print(d)\n",
    "        rows,cols = newprefeat_sc[d].shape[0], newprefeat_sc[d][:,:3].shape[1]*len(total_scales)\n",
    "        coef_tot = np.zeros((rows,cols))\n",
    "        direction_ind = np.arange(0, cols,len(total_scales))\n",
    "        for i in range(newprefeat_sc[d][:,:3].shape[1]): #for each direction\n",
    "            coefs, freq = pywt.cwt(newprefeat_sc[d][:,i],total_scales,'gaus1')\n",
    "            coef_tot[:,direction_ind[i]:direction_ind[i]+len(total_scales)] = np.transpose(coefs)\n",
    "        range1 = range(0,coef_tot.shape[0]-window,shift)\n",
    "        X_final = np.ones((1,162))\n",
    "        y_final = []\n",
    "        for k in range1:\n",
    "            data = coef_tot[k:k+window,:]\n",
    "            label = newprefeat_sc[d][k+window-1,3]\n",
    "            stat_feats = k_order_feats(data,order)\n",
    "            X_final = np.append(X_final,stat_feats,axis = 0)\n",
    "            y_final.append(label)\n",
    "        X_final = X_final[1:,:]\n",
    "        label_final = np.array(y_final)\n",
    "        label_final = label_final[:,np.newaxis]\n",
    "        data_final = np.concatenate((X_final,label_final),axis = 1)\n",
    "        features.append(data_final)\n",
    "    np.savez(cwtdatafile, cwt_datasets=features)\n",
    "else:\n",
    "    features = np.load(cwtdatafile)['cwt_datasets']\n",
    "    \n",
    "print(len(features))\n",
    "print([features[i].shape for i in range(len(features))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "CPU times: user 152 ms, sys: 0 ns, total: 152 ms\n",
      "Wall time: 149 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the different nodes\n",
    "# from_d = 0 if you're gonna be using it as a finished structure\n",
    "# features = deepcopy(cwt_data)\n",
    "cols = features[0].shape[1]-1\n",
    "from_d = 0\n",
    "from_r = [int(np.ceil(0.1*features[i].shape[0])) for i in range(from_d,len(features))]\n",
    "to_r = [int(np.ceil(0.9*features[i].shape[0])) for i in range(from_d,len(features))]\n",
    "\n",
    "X_train = [features[i+from_d][from_r[i]:to_r[i],:cols] for i in range(len(from_r))]\n",
    "Y_train = [features[i+from_d][from_r[i]:to_r[i],cols] for i in range(len(from_r))]\n",
    "\n",
    "# clf = [SVC(kernel = 'rbf', C = 100) for i in range(len(X_train))]\n",
    "print len(X_train)\n",
    "clf = [KNeighborsClassifier(n_neighbors=7) for i in range(len(X_train))]\n",
    "nodes = [clf[i].fit(X_train[i],Y_train[i]) for i in range(len(X_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clfdatafile = clfpath + 'cwt_162_classifiers.npz'\n",
    "if not os.path.isfile(clfdatafile):\n",
    "    np.savez(clfdatafile, nodes = nodes)\n",
    "else:\n",
    "    nodes = np.load(clfdatafile)['nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch no:30 out of 30                          \n",
      " Average error for 31 batches = 0.064516\n"
     ]
    }
   ],
   "source": [
    "# --------- Example\n",
    "# simulating the online procedure with input of size 1024\n",
    "X_test = features[0][:,:cols]\n",
    "Y_test = features[0][:,cols]\n",
    "wind = 128\n",
    "test_batches = np.arange(0,X_test.shape[0],wind)\n",
    "x_batch = [X_test[batch:batch+wind,:] for batch in test_batches]\n",
    "y_batch = [Y_test[batch:batch+wind] for batch in test_batches]\n",
    "average_score = np.zeros(len(test_batches))\n",
    "\n",
    "for batch_id,batch in enumerate(test_batches):\n",
    "    Y_vot = nodes_pred(X_test = x_batch[batch_id],nodes = nodes)\n",
    "    average_score[batch_id] = np.abs(Y_vot-y_batch[batch_id][-1]) \n",
    "#     print('Batch no:%d out of %d ' %(batch_id,len(test_batches)-1), end = ' ')\n",
    "    print '\\r Batch no:%d out of %d ' %(batch_id,len(test_batches)-1),\n",
    "print('\\n Average error for %d batches = %f' %(len(test_batches),np.mean(average_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pipelined nodes, using StandardScaler\n",
    "# %%time\n",
    "\n",
    "# features = deepcopy(cwt_data)\n",
    "cols = features[0].shape[1]-1\n",
    "from_d = 0\n",
    "from_r = [int(np.ceil(0.1*features[i].shape[0])) for i in range(from_d,len(features))]\n",
    "to_r = [int(np.ceil(0.9*features[i].shape[0])) for i in range(from_d,len(features))]\n",
    "\n",
    "X_train = [features[i+from_d][from_r[i]:to_r[i],:cols] for i in range(len(from_r))]\n",
    "Y_train = [features[i+from_d][from_r[i]:to_r[i],cols] for i in range(len(from_r))]\n",
    " \n",
    "# clf = [SVC(kernel = 'rbf', C = 100) for i in range(len(X_train))]\n",
    "clf = [KNeighborsClassifier(n_neighbors=7) for i in range(len(X_train))]\n",
    "sca = [StandardScaler() for i in range(len(X_train))]\n",
    "pipe = [Pipeline([('scaler', sca[i]), ('clf', clf[i])]) for i in range(len(X_train))]\n",
    "piped_nodes = [clf[i].fit(X_train[i],Y_train[i]) for i in range(len(X_train))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pipedatafile = clfpath + 'cwt_162_piped_classifiers.npz'\n",
    "if not os.path.isfile(pipedatafile):\n",
    "    np.savez(pipedatafile, nodes = piped_nodes)\n",
    "else:\n",
    "    nodes = np.load(pipedatafile)['nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch no:30 out of 30                          \n",
      " Average error for 31 batches = 0.064516\n"
     ]
    }
   ],
   "source": [
    "# --------- Example\n",
    "# simulating the online procedure with input of size 1024\n",
    "X_test = features[0][:,:cols]\n",
    "Y_test = features[0][:,cols]\n",
    "wind = 128\n",
    "test_batches = np.arange(0,X_test.shape[0],wind)\n",
    "x_batch = [X_test[batch:batch+wind,:] for batch in test_batches]\n",
    "y_batch = [Y_test[batch:batch+wind] for batch in test_batches]\n",
    "average_score = np.zeros(len(test_batches))\n",
    "\n",
    "for batch_id,batch in enumerate(test_batches):\n",
    "    Y_vot = nodes_pred(X_test = x_batch[batch_id],nodes = nodes)\n",
    "    average_score[batch_id] = np.abs(Y_vot-y_batch[batch_id][-1]) \n",
    "#     print('Batch no:%d out of %d ' %(batch_id,len(test_batches)-1), end = ' ')\n",
    "    print '\\r Batch no:%d out of %d ' %(batch_id,len(test_batches)-1),\n",
    "print('\\n Average error for %d batches = %f' %(len(test_batches),np.mean(average_score)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
