{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mainly Edited for private usage by:  Ioannis Agriomallos\n",
      "                                        Ioanna Mitsioni\n",
      "License: BSD 3 clause\n",
      "\n",
      "============= CURRENT CODE USAGE =============\n",
      "Current code trains MLP Classifiers, to classify force input samples as stable (0) or slip (1)\n",
      "---- Input\n",
      "-> Input samples originate from optoforce sensors and are 3D (fx,fy,fz) and come from 2 different datasets, \n",
      "   one training, containing several surfaces as well as slip-stable occurrences, \n",
      "   and one validation, containing 1 surface with slip-stable occurrences on a completely unseen task-setup.\n",
      "---- Input transformation\n",
      "-> Several pre-features can be taken from these inputs, but here |f| is kept.\n",
      "-> Several time and frequency domain features are extracted from pre-feature windows. \n",
      "  (implemented in 'featext.py') These windows have size w and are shifted by s on each sample\n",
      "-> Then a feature selection-ranking is performed using MutualVariableInformation\n",
      "-> Finally PCA is performed to keep a reduced set among the best selected features\n",
      "---- Training of ML Classifiers\n",
      "-> Several MLP Classifiers are trained for all combinations of selected featuresets-datasets\n",
      "---- Results\n",
      "-> Stats of classification results are kept inside each .npz along with the respective trained model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Mainly Edited for private usage by:  Ioannis Agriomallos\n",
    "                                        Ioanna Mitsioni\n",
    "License: BSD 3 clause\n",
    "\n",
    "============= CURRENT CODE USAGE =============\n",
    "Current code trains MLP Classifiers, to classify force input samples as stable (0) or slip (1)\n",
    "---- Input\n",
    "-> Input samples originate from optoforce sensors and are 3D (fx,fy,fz) and come from 2 different datasets, \n",
    "   one training, containing several surfaces as well as slip-stable occurrences, \n",
    "   and one validation, containing 1 surface with slip-stable occurrences on a completely unseen task-setup.\n",
    "---- Input transformation\n",
    "-> Several pre-features can be taken from these inputs, but here |f| is kept.\n",
    "-> Several time and frequency domain features are extracted from pre-feature windows. \n",
    "  (implemented in 'featext.py') These windows have size w and are shifted by s on each sample\n",
    "-> Then a feature selection-ranking is performed using MutualVariableInformation\n",
    "-> Finally PCA is performed to keep a reduced set among the best selected features\n",
    "---- Training of ML Classifiers\n",
    "-> Several MLP Classifiers are trained for all combinations of selected featuresets-datasets\n",
    "---- Results\n",
    "-> Stats of classification results are kept inside each .npz along with the respective trained model\n",
    "\"\"\"\n",
    "print(__doc__)\n",
    "import time\n",
    "start_time = time.time()\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from ml_training import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# %matplotlib qt\n",
    "# inline (suitable for ipython only, shown inside browser!) or qt (suitable in general, shown in external window!)\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class struct:\n",
    "    def __init__(self):\n",
    "        ####### TRAINING DEFAULTS\n",
    "        self.cv = KFold(n_splits=5,random_state=42)\n",
    "        self.scaler = StandardScaler() ;\n",
    "        self.decomp = PCA(n_components=20)\n",
    "        self.names = [\"NearNb\", \"RBFSVM1\", \"MLP1\", \"RandFor\"]\n",
    "        self.classifiers = [KNeighborsClassifier(5),\n",
    "                       SVC(gamma='auto', C=1),\n",
    "                       MLPClassifier(solver='lbfgs',alpha=1e-4,hidden_layer_sizes=(10,10),random_state=1,verbose=True),\n",
    "                       RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)]\n",
    "\n",
    "        self.download = 0            # Download pre-computed (1) data or compute them all anew (0)\n",
    "        self.delete_big_features = 1 # Delete (1) or keep (0) computed big-in-size features,\n",
    "                                  # helping mainly to avoid several computations when recomputing features\n",
    "\n",
    "        ############ INITIALISATION PARAMETERS ############\n",
    "        self.window, self.shift = 1024, 20\n",
    "        self.samplesperdataset = 10000\n",
    "        self.havelabel = 1\n",
    "        self.returntime = 0\n",
    "        self.featlabel = 0         # 0: all features, 1: temporal, 2: frequency, 3: FFT only\n",
    "        self.magnFFT = 0           # 0: FFT in magnitude format, 1: FFT in real and imag format,\n",
    "        self.featall = 0           # 0: all, 1: feat1 (phinyomark's), 2: feat2 (golz's)\n",
    "        self.CV = 5                # cross validation checks\n",
    "        self.numfeat = 10          # number of features to show\n",
    "        self.nfeat = 1000          # number of features to keep\n",
    "        ###### Initialize necessary names and paths\n",
    "        self.datapath = 'data/'\n",
    "        self.datafile = self.datapath+'dataset.npz'\n",
    "        self.validfile = self.datapath+'validation.mat'\n",
    "        self.featpath = self.datapath+'features/'+str(self.window)+'_'+str(self.shift)+'/'\n",
    "        self.allfeatpath = self.featpath+'AllFeatures/'\n",
    "        self.prefeatname = 'prefeatures_scaled'+'_'+str(self.window)+'_'+str(self.shift)+'_'+str(self.samplesperdataset)\n",
    "        self.prefeatfile = self.featpath+self.prefeatname+'.npz'\n",
    "        self.featname = 'features_scaled'+'_'+str(self.window)+'_'+str(self.shift)+'_'+str(self.samplesperdataset)\n",
    "        self.featfile = self.featpath+self.featname+'.npz'\n",
    "        self.validfeatname = 'valid'+self.featname\n",
    "        self.validfeatfile = self.featpath+self.validfeatname+'.npz'\n",
    "        self.surffile = self.featpath+self.featname+'_2fing_6surf.npz'\n",
    "        self.XYfile = self.featpath+self.featname+'_XY.npz'\n",
    "        self.XYsplitfile = self.featpath+self.featname+'_XYsplit.npz'\n",
    "        self.validsurffile = self.featpath+self.validfeatname+'_2fing_6surf.npz'\n",
    "        self.validXYfile = self.featpath+self.validfeatname+'_XY.npz'\n",
    "        self.validXYsplitfile = self.featpath+self.validfeatname+'_XYsplit.npz'\n",
    "        self.respath = self.datapath+'scaled_results'\n",
    "        self.toolfile = self.datapath+'bargraph.zip'\n",
    "        self.toolpath = self.datapath+'bargraph-rel_4_8/'\n",
    "        self.tool = './'+self.toolpath+'bargraph.pl'\n",
    "######### INITIALIZE OBJECT-STRUCT WITH PARAMETERS AND PASS THEM TO ML MODULE ########\n",
    "c = struct()\n",
    "m = ml(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessary  data/dataset.npz  already here!\n",
      "Necessary  data/validation.mat  already here!\n",
      "Downloaded 575.7 MB of content in total!\n"
     ]
    }
   ],
   "source": [
    "######### DOWNLOAD NECESSARY FILES ###########\n",
    "download_required_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- LOADING DATA and COMPUTING NECESSARY STRUCTS ----------------------------\n",
      "1 -> f1: (36,) (36,) (36, 4)\n",
      "2 -> f2: (36,) (36,) (36, 4)\n",
      "3 -> f: (72,) (72,) (72, 4)\n",
      "4 -> m1,m2: 36 36 1.0 1.0\n",
      "5 -> f=f+l: (72,) : [(345002, 4), (105001, 4), (210001, 4), (225002, 4), (130001, 4), (65001, 4), (195001, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (225002, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (75001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (130001, 4), (195001, 4), (65001, 4), (345002, 4), (105001, 4), (210001, 4), (225002, 4), (130001, 4), (65001, 4), (195001, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (225002, 4), (65001, 4), (130001, 4), (195001, 4), (65001, 4), (130001, 4), (75001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (195001, 4), (130001, 4), (65001, 4), (65001, 4), (130001, 4), (195001, 4), (130001, 4), (195001, 4), (65001, 4)]\n",
      "6 -> scaled f:  (432,) (432,)\n",
      "--------------------------------------- COMPUTING PREFEATURES ----------------------------------------\n",
      "(432,) : [(345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2), (345002, 2), (105001, 2), (210001, 2), (225002, 2), (130001, 2), (65001, 2), (195001, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (225002, 2), (65001, 2), (130001, 2), (195001, 2), (65001, 2), (130001, 2), (75001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (195001, 2), (130001, 2), (65001, 2), (65001, 2), (130001, 2), (195001, 2), (130001, 2), (195001, 2), (65001, 2)]\n",
      "---------------------------------------- FEATURE EXTRACTION ------------------------------------------\n",
      "Features FOUND PRECOMPUTED! Feature Loading DONE in: 2.27001905441 seconds \n",
      "features:  (432,) , labels:  (432,)\n",
      "----------- KEEPING LABEL's PURE (STABLE, SLIP) PHASE PARTS (TRIMMING AROUND CHANGE POINTS)-----------\n",
      "new_labels:  (432,)\n",
      "----------------------------- COMPUTING X,Y for CLASSIFIERS' INPUT -----------------------------------\n",
      "XY files FOUND PRECOMPUTED!\n",
      "X,Y [0,1,2]:  (10152, 3107) (10152,) (10152, 3107) (10152,) (10152, 3107) (10152,)\n",
      "Xsp,Ysp [0,1,2]:  (9096, 3107) (9096,) (9096, 3107) (9096,) (9060, 3107) (9060,)\n",
      "------------------------ COMPUTING X,Y per surface CLASSIFIERS' INPUT --------------------------------\n",
      "(4, 6, 1) (1510, 6, 1)\n",
      "-------------------------- TRAINING all combinations per 1 surface -----------------------------------\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 2 0 0\n",
      "0 3 0 0\n",
      "0 0 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "0 0 0 2\n",
      "Found precomputed model of 0, tested on 1. Testing on 2...\n",
      "0 0 0 3\n",
      "Found precomputed model of 0, tested on 1. Testing on 3...\n",
      "0 0 0 4\n",
      "Found precomputed model of 0, tested on 1. Testing on 4...\n",
      "0 0 0 5\n",
      "Found precomputed model of 0, tested on 1. Testing on 5...\n",
      "0 0 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "0 2 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "0 0 1 1\n",
      "0 2 0 2\n",
      "Found precomputed model of 0, tested on 1. Testing on 2...\n",
      "0 2 0 3\n",
      "Found precomputed model of 0, tested on 1. Testing on 3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 0 4\n",
      "Found precomputed model of 0, tested on 1. Testing on 4...\n",
      "0 2 0 5\n",
      "Found precomputed model of 0, tested on 1. Testing on 5...\n",
      "0 2 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "0 2 1 1\n",
      "0 0 1 2\n",
      "Found precomputed model of 1, tested on 0. Testing on 2...\n",
      "0 0 1 3\n",
      "Found precomputed model of 1, tested on 0. Testing on 3...\n",
      "0 0 1 4\n",
      "Found precomputed model of 1, tested on 0. Testing on 4...\n",
      "0 0 1 5\n",
      "Found precomputed model of 1, tested on 0. Testing on 5...\n",
      "0 0 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "0 0 2 1\n",
      "Found precomputed model of 2, tested on 0. Testing on 1...\n",
      "0 0 2 2\n",
      "0 1 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "0 0 2 3\n",
      "Found precomputed model of 2, tested on 0. Testing on 3...\n",
      "0 0 2 4\n",
      "Found precomputed model of 2, tested on 0. Testing on 4...\n",
      "0 0 2 5\n",
      "Found precomputed model of 2, tested on 0. Testing on 5...\n",
      "0 0 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "0 0 3 1\n",
      "Found precomputed model of 3, tested on 0. Testing on 1...\n",
      "0 0 3 2\n",
      "Found precomputed model of 3, tested on 0. Testing on 2...\n",
      "0 0 3 3\n",
      "0 1 0 2\n",
      "Found precomputed model of 0, tested on 1. Testing on 2...\n",
      "0 1 0 3\n",
      "Found precomputed model of 0, tested on 1. Testing on 3...\n",
      "0 1 0 4\n",
      "Found precomputed model of 0, tested on 1. Testing on 4...\n",
      "0 1 0 5\n",
      "Found precomputed model of 0, tested on 1. Testing on 5...\n",
      "0 1 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "0 2 1 2\n",
      "Found precomputed model of 1, tested on 0. Testing on 2...\n",
      "0 2 1 3\n",
      "Found precomputed model of 1, tested on 0. Testing on 3...\n",
      "0 2 1 4\n",
      "Found precomputed model of 1, tested on 0. Testing on 4...\n",
      "0 2 1 5\n",
      "Found precomputed model of 1, tested on 0. Testing on 5...\n",
      "0 2 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "0 2 2 1\n",
      "Found precomputed model of 2, tested on 0. Testing on 1...\n",
      "0 2 2 2\n",
      "0 0 3 4\n",
      "Found precomputed model of 3, tested on 0. Testing on 4...\n",
      "0 0 3 5\n",
      "Found precomputed model of 3, tested on 0. Testing on 5...\n",
      "0 0 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "0 1 1 1\n",
      "0 3 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "0 0 4 1\n",
      "Found precomputed model of 4, tested on 0. Testing on 1...\n",
      "0 0 4 2\n",
      "Found precomputed model of 4, tested on 0. Testing on 2...\n",
      "0 0 4 3\n",
      "Found precomputed model of 4, tested on 0. Testing on 3...\n",
      "0 0 4 4\n",
      "0 0 4 5\n",
      "Found precomputed model of 4, tested on 0. Testing on 5...\n",
      "0 0 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "0 3 0 2\n",
      "Found precomputed model of 0, tested on 1. Testing on 2...\n",
      "0 3 0 3\n",
      "Found precomputed model of 0, tested on 1. Testing on 3...\n",
      "0 3 0 4\n",
      "Found precomputed model of 0, tested on 1. Testing on 4...\n",
      "0 3 0 5\n",
      "Found precomputed model of 0, tested on 1. Testing on 5...\n",
      "0 3 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "0 0 5 1\n",
      "Found precomputed model of 5, tested on 0. Testing on 1...\n",
      "0 0 5 2\n",
      "Found precomputed model of 5, tested on 0. Testing on 2...\n",
      "0 0 5 3\n",
      "Found precomputed model of 5, tested on 0. Testing on 3...\n",
      "0 0 5 4\n",
      "Found precomputed model of 5, tested on 0. Testing on 4...\n",
      "0 0 5 5\n",
      "0 2 2 3\n",
      "Found precomputed model of 2, tested on 0. Testing on 3...\n",
      "0 2 2 4\n",
      "Found precomputed model of 2, tested on 0. Testing on 4...\n",
      "0 2 2 5\n",
      "Found precomputed model of 2, tested on 0. Testing on 5...\n",
      "0 2 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "0 2 3 1\n",
      "Found precomputed model of 3, tested on 0. Testing on 1...\n",
      "0 2 3 2\n",
      "Found precomputed model of 3, tested on 0. Testing on 2...\n",
      "0 2 3 3\n",
      "0 3 1 1\n",
      "0 1 1 2\n",
      "Found precomputed model of 1, tested on 0. Testing on 2...\n",
      "0 1 1 3\n",
      "Found precomputed model of 1, tested on 0. Testing on 3...\n",
      "0 1 1 4\n",
      "Found precomputed model of 1, tested on 0. Testing on 4...\n",
      "0 1 1 5\n",
      "Found precomputed model of 1, tested on 0. Testing on 5...\n",
      "0 1 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "0 2 3 4\n",
      "Found precomputed model of 3, tested on 0. Testing on 4...\n",
      "0 2 3 5\n",
      "Found precomputed model of 3, tested on 0. Testing on 5...\n",
      "0 2 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "0 2 4 1\n",
      "Found precomputed model of 4, tested on 0. Testing on 1...\n",
      "0 2 4 2\n",
      "Found precomputed model of 4, tested on 0. Testing on 2...\n",
      "0 2 4 3\n",
      "Found precomputed model of 4, tested on 0. Testing on 3...\n",
      "0 2 4 4\n",
      "0 1 2 1\n",
      "Found precomputed model of 2, tested on 0. Testing on 1...\n",
      "0 1 2 2\n",
      "0 2 4 5\n",
      "Found precomputed model of 4, tested on 0. Testing on 5...\n",
      "0 2 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "0 2 5 1\n",
      "Found precomputed model of 5, tested on 0. Testing on 1...\n",
      "0 2 5 2\n",
      "Found precomputed model of 5, tested on 0. Testing on 2...\n",
      "0 2 5 3\n",
      "Found precomputed model of 5, tested on 0. Testing on 3...\n",
      "0 2 5 4\n",
      "Found precomputed model of 5, tested on 0. Testing on 4...\n",
      "0 2 5 5\n",
      "0 3 1 2\n",
      "Found precomputed model of 1, tested on 0. Testing on 2...\n",
      "0 3 1 3\n",
      "Found precomputed model of 1, tested on 0. Testing on 3...\n",
      "0 3 1 4\n",
      "Found precomputed model of 1, tested on 0. Testing on 4...\n",
      "0 3 1 5\n",
      "Found precomputed model of 1, tested on 0. Testing on 5...\n",
      "0 3 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "0 1 2 3\n",
      "Found precomputed model of 2, tested on 0. Testing on 3...\n",
      "0 1 2 4\n",
      "Found precomputed model of 2, tested on 0. Testing on 4...\n",
      "0 1 2 5\n",
      "Found precomputed model of 2, tested on 0. Testing on 5...\n",
      "0 1 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "0 1 3 1\n",
      "Found precomputed model of 3, tested on 0. Testing on 1...\n",
      "0 1 3 2\n",
      "Found precomputed model of 3, tested on 0. Testing on 2...\n",
      "0 1 3 3\n",
      "0 3 2 1\n",
      "Found precomputed model of 2, tested on 0. Testing on 1...\n",
      "0 3 2 2\n",
      "0 1 3 4\n",
      "Found precomputed model of 3, tested on 0. Testing on 4...\n",
      "0 1 3 5\n",
      "Found precomputed model of 3, tested on 0. Testing on 5...\n",
      "0 1 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "0 1 4 1\n",
      "Found precomputed model of 4, tested on 0. Testing on 1...\n",
      "0 1 4 2\n",
      "Found precomputed model of 4, tested on 0. Testing on 2...\n",
      "0 1 4 3\n",
      "Found precomputed model of 4, tested on 0. Testing on 3...\n",
      "0 1 4 4\n",
      "0 3 2 3\n",
      "Found precomputed model of 2, tested on 0. Testing on 3...\n",
      "0 3 2 4\n",
      "Found precomputed model of 2, tested on 0. Testing on 4...\n",
      "0 3 2 5\n",
      "Found precomputed model of 2, tested on 0. Testing on 5...\n",
      "0 3 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "0 3 3 1\n",
      "Found precomputed model of 3, tested on 0. Testing on 1...\n",
      "0 3 3 2\n",
      "Found precomputed model of 3, tested on 0. Testing on 2...\n",
      "0 3 3 3\n"
     ]
    }
   ],
   "source": [
    "############ TRAINING PROCEDURE ##############\n",
    "# necessary steps before training\n",
    "f,l,fd,member,m1,m2 = data_prep(c.datafile)                      # read input force and labels\n",
    "### BEGIN SCALING \n",
    "tf = deepcopy(f)\n",
    "scales = [0.1, 0.5, 1.0, 2.0, 5.0, 20.0]\n",
    "for sc in scales:\n",
    "    for i in range(len(f)):\n",
    "        tf[i][:,:-1] = sc * deepcopy(f[i][:,:-1])\n",
    "#     print tf.shape\n",
    "    tf = np.concatenate((deepcopy(f),tf),axis=0)\n",
    "#     print tf.shape, f.shape, np.max(tf[0][:,:-1]), np.max(f[0][:,:-1])\n",
    "tf = tf[len(f):]\n",
    "tm = np.ones(len(f)*len(scales))*member[0]/(len(scales)*1.)\n",
    "m1, m2 = len(scales)*m1, len(scales)*m2\n",
    "print '6 -> scaled f: ', tf.shape, tm.shape\n",
    "# for i in range(len(tf)/len(f)):\n",
    "#     print i,np.max(tf[i*len(f)][:,:-1])\n",
    "### FINISH SCALING\n",
    "prefeat = compute_prefeat(tf)                                    # compute corresponding prefeatures\n",
    "features, labels = feature_extraction(prefeat, tm, c.featfile,\n",
    "                                      c.featname+'_')            # feature extraction from prefeatures\n",
    "# avg_feat_comp_time(prefeat)                                      # average feature extraction time\n",
    "new_labels = label_cleaning(prefeat,labels,tm)                   # trim labels, around change points\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,\n",
    "                           c.XYfile,c.XYsplitfile)               # compute data and labels, trimmed and untrimmed\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,c.surffile)             # compute per surface data and labels\n",
    "# training and offline testing\n",
    "train_1_surface(surf,surfla)                                     # training of all combinations per 1 surface\n",
    "train_2_surface(surf,surfla)                                     # training of all combinations per 2 surfaces\n",
    "train_3_surface(surf,surfla)                                     # training of all combinations per 3 surfaces\n",
    "train_4_surface(surf,surfla)                                     # training of all combinations per 4 surfaces\n",
    "train_5_surface(surf,surfla)                                     # training of all combinations per 5 surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ RESULT REPORTING ##############\n",
    "# generate files with stats\n",
    "bargraph_perf_gen1(6)\n",
    "bargraph_perf_gen2(6)\n",
    "bargraph_perf_gen3(6)\n",
    "bargraph_perf_gen4(6)\n",
    "bargraph_perf_gen5(6)\n",
    "# use the bargraph tool to plot graphs from generated files\n",
    "# -left column cross-accuracy (trained on one, tested on all the others), \n",
    "# -right column self-accuracy (trained and tested on the same)\n",
    "# -each row i represents training only with i surfaces.\n",
    "# -each stack represents a training group, each bar represents a subfeatureset(AFFT,FREQ,TIME,BOTH)\n",
    "# -blue,green,yellow,red : TP,TN,FN,FP\n",
    "plt.figure(figsize=(20,40))\n",
    "for i in range(5):\n",
    "    make_bargraphs_from_perf(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ ONLINE TESTING PROCEDURE ##############\n",
    "# same necessary steps as in training for data preparation\n",
    "f,l,fd,member,m1,m2 = data_prep(c.validfile)\n",
    "prefeat = compute_prefeat(f)\n",
    "features, labels = feature_extraction(prefeat, member, c.validfeatfile, 'validfeat_')\n",
    "new_labels = label_cleaning(prefeat,labels,member)\n",
    "X,Y,Yn,Xsp,Ysp = computeXY(features,labels,new_labels,m1,m2,c.validXYfile,c.validXYsplitfile)\n",
    "surf, surfla = computeXY_persurf(Xsp,Ysp,c.validsurffile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ VISUALIZING ONLINE TESTING PROCEDURE ##############\n",
    "window=c.window\n",
    "subfeats = ['AFFT','FREQ','TIME','BOTH']\n",
    "feats = ['fnorm','ftfn','fnormftfn']\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "\n",
    "fileid = filename1(0,3,0,5)\n",
    "fileidb = filename1(0,0,0,5)\n",
    "fileid5 = filename5(0,3,0,1,2,3,4,5)\n",
    "fileid5b = filename5(0,0,0,1,2,3,4,5)\n",
    "model = np.load(fileid)['model'][0]\n",
    "modelb = np.load(fileidb)['model'][0]\n",
    "model5 = np.load(fileid5)['model'][0]\n",
    "model5b = np.load(fileid5b)['model'][0]\n",
    "Yout = model.predict(X[0])\n",
    "Youtb = modelb.predict(Xsp[0][:,-window-2:-window/2-1])\n",
    "Yout5 = model5.predict(Xsp[0])\n",
    "Yout5b = model5b.predict(Xsp[0][:,-window-2:-window/2-1])\n",
    "print Yout.shape, Yout5.shape, Yout5b.shape\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('axes', linewidth=2)\n",
    "plt.rc('font', weight='bold')\n",
    "plt.rcParams['text.latex.preamble'] = [r'\\usepackage{sfmath} \\boldmath']\n",
    "offset = 2000-window\n",
    "endset = 2650\n",
    "skipf = 20\n",
    "skipy = 15\n",
    "ax = plt.figure(figsize=(20,10))\n",
    "tf = np.linalg.norm(f[0][offset+window::skipf,:3][:endset],axis=1)\n",
    "p1, = plt.plot(tf/max(tf),linewidth=5)\n",
    "ty = Yout[offset/skipf:][:endset]+0.02\n",
    "print tf.shape, ty.shape\n",
    "p = plt.scatter(range(len(tf))[::skipy],ty[::skipy],color='red',s=30)\n",
    "plt.hold\n",
    "plt.text(100, 0.15, r'\\textbf{Stable}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.text(1000, 0.85, r'\\textbf{Slip}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.annotate('', fontsize=10, xy=(100, 0.05), xytext=(100, 0.12),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.annotate('', xy=(1000, 0.98), xytext=(1000, 0.9),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.text(400, 0.55, r'\\textbf{P1}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=810,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(1000, 0.55, r'\\textbf{P2}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=1200,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(1250, 0.55, r'\\textbf{P3}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=1335,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(1385, 0.25, r'\\textbf{P4}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=1445,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(1650, 0.55, r'\\textbf{P1}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=1830,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(2000, 0.55, r'\\textbf{P2}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=2200,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(2250, 0.55, r'\\textbf{P3}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=2330,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(2385, 0.25, r'\\textbf{P4}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.axvline(x=2440,linestyle='dashed',color='black',linewidth=5)\n",
    "plt.text(2540, 0.55, r'\\textbf{P1}', ha=\"center\", va=\"center\", rotation=0,\n",
    "            size=25)\n",
    "plt.xlabel(r't ($1e^{-2} sec$)',fontsize=35)\n",
    "# plt.yticks([])\n",
    "plt.legend([p1,p],[r'$|\\textbf{f}|$',r'\\textbf{out1}'],loc=2, prop={'size': 35})\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.tight_layout()\n",
    "savefig(c.datapath+'validation.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE\n",
    "prediction('ati_new_fd1.0N_kp3.5_152Hz_validation.mat')\n",
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE\n",
    "prediction('ati_new_fd1.0N_kp3.5_152Hz_validation_rot.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE\n",
    "prediction('ati_new_fd1.5N_kp3_152Hz_validation.mat')\n",
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE\n",
    "prediction('ati_new_fd1.5N_kp3_152Hz_validation_rot.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE\n",
    "prediction('ati_new_fd1.0N_kp3.5_326Hz_validation.mat')\n",
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE\n",
    "prediction('ati_new_fd1.0N_kp3.5_326Hz_validation_rot.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE\n",
    "prediction('ati_new_fd1.5N_kp3_326Hz_validation.mat')\n",
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE\n",
    "prediction('ati_new_fd1.5N_kp3_326Hz_validation_rot.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE\n",
    "prediction('ati_new_fd1.0N_kp3.5_836Hz_validation.mat')\n",
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE\n",
    "prediction('ati_new_fd1.0N_kp3.5_836Hz_validation_rot.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE\n",
    "prediction('ati_new_fd1.5N_kp3.5_836Hz_validation.mat')\n",
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE\n",
    "prediction('ati_new_fd1.5N_kp3.5_836Hz_validation_rot.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE\n",
    "prediction('ati_new_fd1N_kp3_nofilt_validation.mat')\n",
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE\n",
    "prediction('ati_new_fd1N_kp3_nofilt_validation_rot.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE\n",
    "prediction('ati_new_fd1.5N_kp3_nofilt_validation.mat')\n",
    "####### NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE\n",
    "prediction('ati_new_fd1.5N_kp3_nofilt_validation_rot.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Version of one of the above on the following ranges (0.1, 0.5, 1.0, 2.0, 5.0, 20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sc in [0.1, 0.5, 1.0, 2.0, 5.0, 20.0]:\n",
    "    print \"-------- SCALING = \",sc,\"--------\"\n",
    "    ####### NEWER TESTING DATA FROM ATI F/T SENSOR TRANSLATIONAL CASE\n",
    "    prediction('ati_new_fd1.5N_kp3_152Hz_validation.mat',scale=sc)\n",
    "    ####### NEWER TESTING DATA FROM ATI F/T SENSOR ROTATIONAL CASE\n",
    "    prediction('ati_new_fd1.5N_kp3_152Hz_validation_rot.mat',scale=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the training forces and compare them with testing ones (2.86 1.35 2.12 1.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "printit = False\n",
    "f,_,_,_,_,_ = data_prep(c.datafile,printit=printit)                        # read training input force\n",
    "pf = compute_prefeat(f,printit=printit)                                  # compute corresponding prefeatures\n",
    "fv,_,_,_,_,_ = data_prep(c.validfile,printit=printit)                      # read validation input force\n",
    "pfv = compute_prefeat(fv,printit=printit)                                # compute corresponding prefeatures\n",
    "\n",
    "atifiles = ['ati_new_fd1.0N_kp3.5_152Hz_validation.mat',\n",
    "            'ati_new_fd1.0N_kp3.5_152Hz_validation_rot.mat',\n",
    "            'ati_new_fd1.5N_kp3_152Hz_validation.mat',\n",
    "            'ati_new_fd1.5N_kp3_152Hz_validation_rot.mat',\n",
    "            'ati_new_fd1.0N_kp3.5_326Hz_validation.mat',\n",
    "            'ati_new_fd1.0N_kp3.5_326Hz_validation_rot.mat',\n",
    "            'ati_new_fd1.5N_kp3_326Hz_validation.mat',\n",
    "            'ati_new_fd1.5N_kp3_326Hz_validation_rot.mat',\n",
    "            'ati_new_fd1.0N_kp3.5_836Hz_validation.mat',\n",
    "            'ati_new_fd1.0N_kp3.5_836Hz_validation_rot.mat',\n",
    "            'ati_new_fd1.5N_kp3.5_836Hz_validation.mat',\n",
    "            'ati_new_fd1.5N_kp3.5_836Hz_validation_rot.mat',\n",
    "            'ati_new_fd1N_kp3_nofilt_validation.mat',\n",
    "            'ati_new_fd1N_kp3_nofilt_validation_rot.mat',\n",
    "            'ati_new_fd1.5N_kp3_nofilt_validation.mat',\n",
    "            'ati_new_fd1.5N_kp3_nofilt_validation_rot.mat']\n",
    "atiftr = []\n",
    "atifrt = []\n",
    "for filen in atifiles:\n",
    "    tf,_,_,_,_,_ = data_prep(c.datapath+filen,k=1,printit=printit)\n",
    "    ptf = compute_prefeat(tf,printit=printit)\n",
    "    if filen[-7:-4] == 'rot':\n",
    "        atifrt.append(ptf)\n",
    "    else:\n",
    "        atiftr.append(ptf)\n",
    "atiftr = np.array(atiftr).flatten()\n",
    "atifrt = np.array(atifrt).flatten()\n",
    "\n",
    "plist = [pf, pfv, atiftr, atifrt]\n",
    "pname = ['train', 'valid','atitran','atirot']\n",
    "print pf.shape, pfv.shape, atiftr.shape, atifrt.shape\n",
    "mf, mfst, mfsl = np.zeros((4,4)), np.zeros((4,4)), np.zeros((4,4))\n",
    "print 'datasetname: [all/stable/slip:[0:mean, 1:max, 2:min, 3:std]]'\n",
    "for ind in range(len(plist)):\n",
    "    pt = plist[ind]\n",
    "    # 0:mean, 1:max, 2:min, 3:std\n",
    "    for p in range(len(pt)):\n",
    "        mf[ind,0] += np.mean(pt[p][:,0])\n",
    "        mf[ind,1] += np.max(pt[p][:,0])\n",
    "        mf[ind,2] += np.min(pt[p][:,0])\n",
    "        mf[ind,3] += np.std(pt[p][:,0])\n",
    "        stind = pt[p][:,1]==0\n",
    "        slind = pt[p][:,1]==1\n",
    "        mfst[ind,0] += np.mean(pt[p][stind,0])\n",
    "        mfst[ind,1] += np.max(pt[p][stind,0])\n",
    "        mfst[ind,2] += np.min(pt[p][stind,0])\n",
    "        mfst[ind,3] += np.std(pt[p][stind,0])\n",
    "        mfsl[ind,0] += np.mean(pt[p][slind,0])\n",
    "        mfsl[ind,1] += np.max(pt[p][slind,0])\n",
    "        mfsl[ind,2] += np.min(pt[p][slind,0])\n",
    "        mfsl[ind,3] += np.std(pt[p][slind,0])\n",
    "    mf[ind,0] /= len(plist[ind])\n",
    "    mf[ind,1] /= len(plist[ind])\n",
    "    mf[ind,2] /= len(plist[ind])\n",
    "    mf[ind,3] /= len(plist[ind])\n",
    "    mfst[ind,0] /= len(plist[ind])\n",
    "    mfst[ind,1] /= len(plist[ind])\n",
    "    mfst[ind,2] /= len(plist[ind])\n",
    "    mfst[ind,3] /= len(plist[ind])\n",
    "    mfsl[ind,0] /= len(plist[ind])\n",
    "    mfsl[ind,1] /= len(plist[ind])\n",
    "    mfsl[ind,2] /= len(plist[ind])\n",
    "    mfsl[ind,3] /= len(plist[ind])\n",
    "    print pname[ind], mf[ind], mfst[ind], mfsl[ind]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
