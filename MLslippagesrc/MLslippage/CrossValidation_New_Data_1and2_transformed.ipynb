{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "import time\n",
    "start_time = time.time()\n",
    "from copy import deepcopy, copy\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import shutil\n",
    "import os\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "# from featext2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "#matplotlib qt\n",
    "# inline (suitable for ipython only, shown inside browser!) or qt (suitable in general, shown in external window!)\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mpl_toolkits.mplot3d import Axes3D #, axes3d\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, ParameterGrid, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.decomposition import PCA, KernelPCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LassoCV, RandomizedLasso\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2, f_classif, mutual_info_classif, SelectFdr\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import datetime\n",
    "import urllib\n",
    "import tarfile\n",
    "import joblib\n",
    "from joblib import Parallel, delayed, Memory\n",
    "from tempfile import mkdtemp\n",
    "import copy_reg\n",
    "import types\n",
    "import itertools\n",
    "from itertools import compress\n",
    "from collections import Counter\n",
    "\n",
    "#import multiprocessing\n",
    "def _pickle_method(m):\n",
    "    if m.im_self is None:\n",
    "        return getattr, (m.im_class, m.im_func.func_name)\n",
    "    else:\n",
    "        return getattr, (m.im_self, m.im_func.func_name)\n",
    "copy_reg.pickle(types.MethodType, _pickle_method)\n",
    "\n",
    "h = .2  # step size in the mesh\n",
    "names = [\"NearNb\", \"RBFSVM1\", \"NaiveBayes\", \"MLP1\", \"Log.Regr\", \"RandFor\", \"AdaBoost\", \"EnsembleMLP\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    SVC(gamma='auto', C=1),\n",
    "    MLPClassifier(solver='lbfgs',alpha=1e-4,hidden_layer_sizes=(10,10),random_state=1,verbose=True),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "parameters_clf = [{'n_neighbors':range(3,10)},\n",
    "              {'kernel':['rbf'], 'C':[0.01,0.1,1,10,100,1000]},\n",
    "              {'solver':['lbfgs'], 'alpha':[1e-5,1e-2], 'hidden_layer_sizes':[(10,10),(50,50),(100,100)]},\n",
    "              {'max_depth':[4,7,10,20],'n_estimators':[5,10,20],'max_features':[20,35,50]},\n",
    "              {'solver':['lbfgs'], 'alpha':[1e-5], 'hidden_layer_sizes':[(len(names)-1,len(names)-1),(len(names)-1,2)]}\n",
    "             ]\n",
    "makepipe_parameters_clf = [{'classifier__'+key:p[key] for key in p} for p in parameters_clf]\n",
    "makepipe_parameters_clf += [{'feature_selection__k': (750,500,100), 'feature_selection__score_func': [mutual_info_classif]},\n",
    "                            {'decomp__n_components': (100,50)}]\n",
    "metric = ['accuracy','f1']\n",
    "dataset = 0 # all datasets (0), dataset 1-2 (1), dataset 3 (2), dataset4 (3)\n",
    "download = 1 # Download pre-computed (1) data or compute them anew (0)\n",
    "window = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pipe_clf(scaler,feature_selection,decomp,clf):\n",
    "    order = 1\n",
    "# order = 1 : first perform feature selection and then apply PCA\n",
    "# order = 0 : first apply PCA and then reduce the transformed features\n",
    "    if order:\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                    ('feature_selection', feature_selection),\n",
    "                    ('decomp', decomp),         \n",
    "                    ('classifier', clf) ])\n",
    "#     else:\n",
    "#         pipeline = Pipeline([('scaler', scaler),\n",
    "#                     ('decomp', decomp ),                 \n",
    "#                     ('feature_selection', feature_selection),        \n",
    "#                     ('classifier', clf) ])\n",
    "    return pipeline\n",
    "###########################################################################################\n",
    "def make_pipe(scaler,feature_selection,decomp,order):\n",
    "    if order:\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                    ('feature_selection', feature_selection),\n",
    "                    ('decomp', decomp),         \n",
    "                     ])\n",
    "    else:\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                    ('decomp', decomp ),                 \n",
    "                    ('feature_selection', feature_selection),        \n",
    "                     ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feat_id(feat_ind, printit = 0): \n",
    "    sample_window = 1024\n",
    "    ##  features:                                                                                  ||      if         ##\n",
    "##  |----------> time domain      :                                                            || samples = 1024  ##\n",
    "##  |------------|---> phinyomark : 11+3{shist} -----------------------------> = 14+0.0samples ||             14  ##\n",
    "##  |------------|---> golz       : 10+samples{acrol} -----------------------> = 10+1.0samples ||           1034  ##\n",
    "##  |----------> frequency domain :                                                                               ##\n",
    "##  |------------|---> phinyomark : 3{arco}+4{mf}+3(samples/2+1){RF,IF} -----> =  9+1.0samples ||           1033  ##\n",
    "##  |------------|---> golz       : 2(samples/2+1){AF,PF} -------------------> =  2+1.0samples ||           1027  ##\n",
    "##  |------------|--------|-------alltogether--------------------------------> = 35+3.0samples || numfeat = 3108  ##\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "    norm_time_phin = range(0,14)\n",
    "    norm_freq_phin = range(norm_time_phin[-1] + 1, norm_time_phin[-1] + 9 + sample_window + 1)\n",
    "    norm_time_golz = range(norm_freq_phin[-1] + 1, norm_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    norm_freq_golz = range(norm_time_golz[-1] + 1, norm_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    norm_time_feats = norm_time_phin + norm_time_golz\n",
    "    norm_freq_feats = norm_freq_phin + norm_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    norm_feats = norm_time_feats + norm_freq_feats\n",
    "#     print(norm_time_phin,norm_time_golz)\n",
    "\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "#     np.arange(norm_feats[-1]+1,norm_feats[-1]+1+len(norm_feats))\n",
    "    disp = norm_feats[-1]+1\n",
    "    ftfn_time_phin = range(disp ,disp + 14)\n",
    "    ftfn_freq_phin = range(ftfn_time_phin[-1] + 1, ftfn_time_phin[-1] + 9 + sample_window + 1)\n",
    "    ftfn_time_golz = range(ftfn_freq_phin[-1] + 1, ftfn_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    ftfn_freq_golz = range(ftfn_time_golz[-1] + 1, ftfn_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    ftfn_time_feats = ftfn_time_phin + ftfn_time_golz\n",
    "    ftfn_freq_feats = ftfn_freq_phin + ftfn_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    ftfn_feats = ftfn_time_feats + ftfn_freq_feats\n",
    "\n",
    "    # create the final \"reference dictionary\"\n",
    "    id_list = [np.zeros((len(ftfn_feats + norm_feats),1)) for i in range(3)] #3 np.arrays, id_list[0] = level 1 etc\n",
    "    id_list[0][:norm_feats[-1]+1] = 0 # 0 signifies norm / 1 signifies ft/fn\n",
    "    id_list[0][norm_feats[-1]+1:] = 1\n",
    "\n",
    "    id_list[1][:norm_time_phin[-1]+1] = 0 #0 signifies time / 1 signifies freq\n",
    "    id_list[1][norm_time_phin[-1]+1:norm_freq_phin[-1]+1] = 1\n",
    "    id_list[1][norm_freq_phin[-1]+1:norm_time_golz[-1]+1] = 0\n",
    "    id_list[1][norm_time_golz[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[1][norm_freq_golz[-1]+1:ftfn_time_phin[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_phin[-1]+1:ftfn_freq_phin[-1]+1] = 1\n",
    "    id_list[1][ftfn_freq_phin[-1]+1:ftfn_time_golz[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_golz[-1]+1:] = 1\n",
    "\n",
    "    id_list[2][:norm_freq_phin[-1]+1] = 0 #0 signifies phinyomark / 1 signifies golz\n",
    "    id_list[2][norm_freq_phin[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[2][norm_freq_golz[-1]+1:ftfn_freq_phin[-1]+1] = 0\n",
    "    id_list[2][ftfn_freq_phin[-1]+1:] = 1 \n",
    "    \n",
    "    full_path_id = [np.zeros((len(feat_ind),5)) for i in range(len(feat_ind))]\n",
    "   \n",
    "    for ind, val in enumerate(feat_ind):\n",
    "\n",
    "        full_path_id[ind] = [val, id_list[2][val], id_list[1][val], id_list[0][val]]\n",
    "\n",
    "        if (printit==1):\n",
    "            if(full_path_id[ind][1]==0):\n",
    "                lvl3 = 'Phin'\n",
    "            else:\n",
    "                lvl3 = 'Golz'\n",
    "            if(full_path_id[ind][2]==0):\n",
    "                lvl2 = 'Time'\n",
    "            else:\n",
    "                lvl2 = 'Freq'\n",
    "            if(full_path_id[ind][3]==0):\n",
    "                lvl1 = 'Norm'\n",
    "            else:\n",
    "                lvl1 = 'Ft/Fn'\n",
    "            print(feat_ind[ind],featnames[val%(norm_feats[-1]+1)],lvl3,lvl2,lvl1)\n",
    "    \n",
    "    return(full_path_id,norm_time_feats,norm_freq_feats)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feat_occ(feat_masks):\n",
    "    #get the number of occurences for each feature after SelectKbest\n",
    "#     print(\"If it ain't working, just make sure you're adding the lists instead of concatenating them,\")\n",
    "#     print(\"if the input isn't a single list you'll get the unhashable error\")\n",
    "    feat_occ = Counter(feat_masks)\n",
    "    return feat_occ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################## Feature Names ###########################################################\n",
    "####################################################################################################################\n",
    "##  features:                                                                                  ||      if         ##\n",
    "##  |----------> time domain      :                                                            || samples = 1024  ##\n",
    "##  |------------|---> phinyomark : 11+3{shist} -----------------------------> = 14+0.0samples ||             14  ##\n",
    "##  |------------|---> golz       : 10+samples{acrol} -----------------------> = 10+1.0samples ||           1034  ##\n",
    "##  |----------> frequency domain :                                                                               ##\n",
    "##  |------------|---> phinyomark : 3{arco}+4{mf}+3(samples/2+1){RF,IF} -----> =  9+1.0samples ||           1033  ##\n",
    "##  |------------|---> golz       : 2(samples/2+1){AF,PF} -------------------> =  2+1.0samples ||           1027  ##\n",
    "##  |------------|--------|-------alltogether--------------------------------> = 35+3.0samples || numfeat = 3108  ##\n",
    "####################################################################################################################\n",
    "## Time Domain Phinyomark feats\n",
    "featnames = ['intsgnl', 'meanabs', 'meanabsslp', 'ssi', 'var', 'rms', 'rng', 'wavl', 'zerox', 'ssc', 'wamp', \n",
    "             'shist1', 'shist2', 'shist3']                                                   # 11+3{shist}\n",
    "## Frequency Domain Phinyomark feats\n",
    "featnames += ['arco1', 'arco2', 'arco3', 'mnf', 'mdf', 'mmnf', 'mmdf']                       # 3{arco}+4{mf}\n",
    "featnames += ['reFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{RF}\n",
    "featnames += ['imFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{IF}\n",
    "## Time Domain Golz feats\n",
    "featnames += ['meanv', 'stdr', 'mx', 'rngx', 'rngy', 'med', 'hjorth', 'sentr', 'se', 'ssk']  # 10\n",
    "featnames += ['acrol{:04d}'.format(i) for i in range(window)]                                # samples{acrol}\n",
    "## Frequency Domain Golz feats\n",
    "featnames += ['amFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{AF}\n",
    "featnames += ['phFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{PF}\n",
    "# featnames += ['ffaf']                                                                        # 1{ffaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temps = range(len(featnames))\n",
    "_,tf,ff = get_feat_id(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 3107) (9000,)\n",
      "(9000, 3107) (9000,)\n",
      "(9000, 6214) (9000,)\n"
     ]
    }
   ],
   "source": [
    "# datasets = np.load('newfeatures_newdata_NOsample_1024_20_10_10000_XYsplit.npz')\n",
    "# X = datasets['Xsp']\n",
    "# Y = datasets['Ysp']\n",
    "\n",
    "# ================ 21/07\n",
    "# filename = 'tmp/features/1024_20/newfeatures_testdata_NOsample_trans_1024_20_10_10000_XYsplit.npz'\n",
    "# filename1 = 'tmp/features/1024_20/newfeatures_newdata2_NOsample_trans_1024_20_10_10000_XYsplit.npz'\n",
    "# Xsp = np.load(filename)['Xsp'][0:2,:]\n",
    "# Ysp = np.load(filename)['Ysp'][0:2]\n",
    "# Xsp1 = np.load(filename1)['Xsp'][2,:]\n",
    "# Ysp1 = np.load(filename1)['Ysp'][2]\n",
    "# ================ 27/07\n",
    "filename = 'tmp/features/1024_20/newfeatures_newdata1and2_NOsample_transtart_1024_20_10_10000_XYsplit.npz'\n",
    "Xsp = np.load(filename)['Xsp'][2,:]\n",
    "Ysp = np.load(filename)['Ysp'][2][:-1]\n",
    "for i in range(len(Xsp)):\n",
    "    Xsp[i] = Xsp[i][:-1,:]\n",
    "    print Xsp[i].shape, Ysp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for j in range(Xsp1.shape[0]):\n",
    "#     Xsp1[j] = Xsp1[j][:8730,:]\n",
    "# Ysp1 = Ysp1[:8730]\n",
    "# print([ Xsp[i][j].shape for i in range(len(Xsp)) for j in range(len(Xsp[i]))])\n",
    "# print([ Xsp[i].shape for i in range(len(Xsp))])\n",
    "# print([ Xsp1[j].shape for j in range(len(Xsp1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================== 21/07 \n",
    "# X_new = {}\n",
    "# for i in range(Xsp.shape[1]):\n",
    "#     X_new[i] = np.concatenate((Xsp[0][i][::2,:],Xsp[1][i][::2,:]),axis=0)\n",
    "# X_new = [i for _,i in X_new.items()]\n",
    "# #X_new = np.array(X_new)\n",
    "# #print X_new.shape\n",
    "# for i in range(len(X_new)):\n",
    "#     print X_new[i].shape\n",
    "# Y_new = np.concatenate((Ysp[0][::2],Ysp[1][::2]),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newfile='2_fingers_6_surfaces.npz'\n",
    "# np.savez(newfile,X_new=X_new,Y_new=Y_new,Xsp1=Xsp1[2],Ysp1=Ysp1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def surface_split(data_X, data_Y):\n",
    "#     surfaces_pre = np.split(data_X,6)\n",
    "#     surf_labels_pre = np.split(data_Y,6)\n",
    "#     surfaces = [np.empty_like(surfaces_pre[i]) for i in range(3)]\n",
    "#     surf_labels = [np.empty_like(surf_labels_pre[i]) for i in range(3)]\n",
    "\n",
    "#     for i in range(3):\n",
    "#         inds = range(i,6,3)\n",
    "#         surfaces[inds[0]] = np.concatenate((surfaces_pre[inds[0]], surfaces_pre[inds[1]]), axis = 0)\n",
    "#         surf_labels[inds[0]] = np.concatenate((surf_labels_pre[inds[0]], surf_labels_pre[inds[1]]), axis = 0)\n",
    "#     return surfaces, surf_labels\n",
    "\n",
    "def surface_split(data_X, data_Y):\n",
    "    surfaces_pre = np.split(data_X,12)\n",
    "    surf_labels_pre = np.split(data_Y,12)\n",
    "    surfaces = [np.empty_like(surfaces_pre[i]) for i in range(6)]\n",
    "    surf_labels = [np.empty_like(surf_labels_pre[i]) for i in range(6)]\n",
    "\n",
    "    for i in range(6):\n",
    "        inds = range(i,12,6)\n",
    "        surfaces[inds[0]] = np.concatenate((surfaces_pre[inds[0]], surfaces_pre[inds[1]]), axis = 0)\n",
    "        surf_labels[inds[0]] = np.concatenate((surf_labels_pre[inds[0]], surf_labels_pre[inds[1]]), axis = 0)\n",
    "    return surfaces, surf_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#====== 25/07\n",
    "def feat_subsets(data,fs_ind):\n",
    "#     data = X_new[fs_ind]\n",
    "    _,tf,ff = get_feat_id(range(len(featnames)))\n",
    "    ofs = 3107\n",
    "    amfft_inds = []\n",
    "    temp1 = deepcopy(data)\n",
    "    \n",
    "    for i in range(len(featnames)):\n",
    "        if (featnames[i].startswith('amFFT')):\n",
    "            amfft_inds.append(i)\n",
    "\n",
    "    if (fs_ind == 2):\n",
    "        ff2 = [ff[i]+ofs for i in range(len(ff))]\n",
    "        tf2 = [tf[i]+ofs for i in range(len(tf))]\n",
    "        amfft2 = [amfft_inds[i]+ofs for i in range(len(amfft_inds))]\n",
    "        freqf = ff2 + ff\n",
    "        timef = tf2 + tf\n",
    "        amfft = amfft_inds + amfft2\n",
    "    else:\n",
    "        freqf = ff\n",
    "        timef = tf\n",
    "        amfft = amfft_inds\n",
    "\n",
    "    X_amfft = temp1[:,amfft]\n",
    "    X_time = np.delete(temp1,freqf,axis=1)\n",
    "    X_freq_all = np.delete(temp1,timef,axis=1)\n",
    "    X_both = data\n",
    "    return X_amfft, X_freq_all, X_time, X_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 6\n",
      "0 1 6\n",
      "0 2 6\n",
      "0 3 6\n",
      "0 4 6\n",
      "0 5 6\n",
      "0 6 6\n",
      "1 0 6\n",
      "1 1 6\n",
      "1 2 6\n",
      "1 3 6\n",
      "1 4 6\n",
      "1 5 6\n",
      "1 6 6\n",
      "2 0 6\n",
      "2 1 6\n",
      "2 2 6\n",
      "2 3 6\n",
      "2 4 6\n",
      "2 5 6\n",
      "2 6 6\n",
      "(4, 6, 3) (1500, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "# =================== 21/07\n",
    "# surf1, surflab1 = surface_split(Xsp1[2][2], Ysp1[2]) \n",
    "# surf, surfla = [], []\n",
    "# for i in range(Xsp1.shape[0]): # for each featureset\n",
    "#     surf1, surfla1 = surface_split(X_new[i], Y_new)\n",
    "#     surf2, surfla2 = surface_split(Xsp1[i], Ysp1)\n",
    "#     tmpsurf = surf1 + surf2\n",
    "#     tmpsurfla = surfla1 + surfla2\n",
    "#     tmpsurfsubfeat = []\n",
    "#     for j in range(len(tmpsurf)): # for each surface\n",
    "#         tmpsurfsubfeat.append(feat_subsets(tmpsurf[j],i)) # keep all subfeaturesets\n",
    "# #     surf.append(surf1 + surf2)\n",
    "#     surf.append(tmpsurfsubfeat)\n",
    "#     surfla.append(surfla1 + surfla2)\n",
    "# surf = np.array(surf).transpose() # array dims: (subfeaturesets, surfaces, featuresets)\n",
    "# surfla = np.array(surfla).transpose()\n",
    "# print surf.shape, surfla.shape\n",
    "\n",
    "# =================== 27/07\n",
    "surf, surfla = [], []\n",
    "for i in range(Xsp.shape[0]): # for each featureset\n",
    "    surf1, surfla1 = surface_split(Xsp[i], Ysp)\n",
    "    tmpsurf = surf1\n",
    "    tmpsurfla = surfla1\n",
    "    tmpsurfsubfeat = []\n",
    "    for j in range(len(tmpsurf)+1): # for each surface\n",
    "        print i,j,len(surf1)\n",
    "        if j == len(tmpsurf):\n",
    "            tmpsurfsubfeat.append(feat_subsets(tmpsurf[j-1][:-1,:],i)) # keep all subfeaturesets\n",
    "        else:\n",
    "            tmpsurfsubfeat.append(feat_subsets(tmpsurf[j],i)) # keep all subfeaturesets\n",
    "#     surf.append(surf1 + surf2)\n",
    "    surf.append(tmpsurfsubfeat)\n",
    "    surfla.append(surfla1)\n",
    "# surf[-1][-1] = surf[-1][-1][:-1,:]\n",
    "# surfla[-1][-1] = surfla[-1][-1][:-1]\n",
    "surf = np.array(surf).transpose()[:,:-1,:] # array dims: (subfeaturesets, surfaces, featuresets)\n",
    "surfla = np.array(surfla).transpose()\n",
    "print surf.shape, surfla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surffile = '2_fingers_6_surfaces_transtart.npz'\n",
    "np.savez(surffile,surf=surf,surfla=surfla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 3) (1500, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "surf = np.load(surffile)['surf']\n",
    "surfla = np.load(surffile)['surfla']\n",
    "print surf.shape, surfla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 6214) (1500,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f263556d190>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f261e78db50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print surf[-1,-1,-1].shape, surfla[:,-1,-1].shape\n",
    "plt.plot(surf[-1,-1,-1][:,0]/np.max(surf[-1,-1,-1][:,0],axis=0))\n",
    "plt.hold\n",
    "plt.plot(surfla[:,-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "[[ 0.9171943   0.0828057 ]\n",
      " [ 0.08659248  0.91340752]]\n",
      "0 0 0 1\n",
      "[[ 0.96688742  0.03311258]\n",
      " [ 0.53313253  0.46686747]]\n",
      "0 0 0 2\n",
      "[[ 0.96907216  0.03092784]\n",
      " [ 0.33981337  0.66018663]]\n",
      "0 0 0 3\n",
      "[[ 0.80550344  0.19449656]\n",
      " [ 0.1395881   0.8604119 ]]\n",
      "0 0 0 4\n",
      "[[ 0.90955414  0.09044586]\n",
      " [ 0.46865672  0.53134328]]\n",
      "0 0 0 5\n",
      "[[ 0.80509554  0.19490446]\n",
      " [ 0.1380597   0.8619403 ]]\n",
      "0 0 1 0\n",
      "[[ 0.7414665   0.2585335 ]\n",
      " [ 0.00955414  0.99044586]]\n",
      "0 0 1 1\n",
      "[[ 0.89573954  0.10426046]\n",
      " [ 0.10922867  0.89077133]]\n",
      "0 0 1 2\n",
      "[[ 0.85438144  0.14561856]\n",
      " [ 0.04898911  0.95101089]]\n",
      "0 0 1 3\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'tmpresults2/fs_0_subfs_0_tr_1_fs_3.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-a823318bce8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mfileid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tmpresults2/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jagrio/.local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'tmpresults2/fs_0_subfs_0_tr_1_fs_3.npz'"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        for k in range(6):\n",
    "            for k2 in range(6):\n",
    "                fileid = 'tmpresults2/'+filename(i,j,k,k2)+'.npz'\n",
    "                print i,j,k,k2\n",
    "                print np.load(fileid)['cm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "[[ 0.9171943   0.0828057 ]\n",
      " [ 0.08659248  0.91340752]]\n",
      "0 0 0 1\n",
      "[[ 0.96688742  0.03311258]\n",
      " [ 0.53313253  0.46686747]]\n",
      "0 0 0 2\n",
      "[[ 0.96907216  0.03092784]\n",
      " [ 0.33981337  0.66018663]]\n",
      "0 0 0 3\n",
      "[[ 0.80550344  0.19449656]\n",
      " [ 0.1395881   0.8604119 ]]\n",
      "0 0 0 4\n",
      "[[ 0.90955414  0.09044586]\n",
      " [ 0.46865672  0.53134328]]\n",
      "0 0 0 5\n",
      "[[ 0.80509554  0.19490446]\n",
      " [ 0.1380597   0.8619403 ]]\n",
      "0 0 1 0\n",
      "[[ 0.7414665   0.2585335 ]\n",
      " [ 0.00955414  0.99044586]]\n",
      "0 0 1 1\n",
      "[[ 0.89573954  0.10426046]\n",
      " [ 0.10922867  0.89077133]]\n",
      "0 0 1 2\n",
      "[[ 0.85438144  0.14561856]\n",
      " [ 0.04898911  0.95101089]]\n",
      "0 0 1 3\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'tmpresults2/fs_0_subfs_0_tr_1_fs_3.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-a823318bce8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mfileid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tmpresults2/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jagrio/.local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'tmpresults2/fs_0_subfs_0_tr_1_fs_3.npz'"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        for k in range(6):\n",
    "            for k2 in range(6):\n",
    "                fileid = 'tmpresults2/'+filename(i,j,k,k2)+'.npz'\n",
    "                print i,j,k,k2\n",
    "                print np.load(fileid)['cm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "print surf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0 0 0\n",
      "2 1 0 0\n",
      "2 2 0 0\n",
      "2 3 0 0\n",
      "2 0 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "2 0 0 2\n",
      "Fitting on 0, testing on 2...\n",
      "2 0 0 3\n",
      "Fitting on 0, testing on 3...\n",
      "2 0 0 4\n",
      "Fitting on 0, testing on 4...\n",
      "2 2 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "2 0 0 5\n",
      "Fitting on 0, testing on 5...\n",
      "2 0 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "2 2 0 2\n",
      "Fitting on 0, testing on 2...\n",
      "2 0 1 1\n",
      "2 2 0 3\n",
      "Fitting on 0, testing on 3...\n",
      "2 2 0 4\n",
      "Fitting on 0, testing on 4...\n",
      "2 0 1 2\n",
      "Fitting on 1, testing on 2...\n",
      "2 0 1 3\n",
      "Fitting on 1, testing on 3...\n",
      "2 1 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "2 2 0 5\n",
      "Fitting on 0, testing on 5...\n",
      "2 0 1 4\n",
      "Fitting on 1, testing on 4...\n",
      "2 0 1 5\n",
      "Fitting on 1, testing on 5...\n",
      "2 2 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "2 0 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "2 0 2 1\n",
      "Fitting on 2, testing on 1...\n",
      "2 1 0 2\n",
      "Fitting on 0, testing on 2...\n",
      "2 2 1 1\n",
      "2 0 2 2\n",
      "2 1 0 3\n",
      "Fitting on 0, testing on 3...\n",
      "2 3 0 1\n",
      "Fitting on 0, testing on 1...\n",
      "2 0 2 3\n",
      "Fitting on 2, testing on 3...\n",
      "2 0 2 4\n",
      "Fitting on 2, testing on 4...\n",
      "2 0 2 5\n",
      "Fitting on 2, testing on 5...\n",
      "2 1 0 4\n",
      "Fitting on 0, testing on 4...\n",
      "2 0 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "2 2 1 2\n",
      "Fitting on 1, testing on 2...\n",
      "2 0 3 1\n",
      "Fitting on 3, testing on 1...\n",
      "2 0 3 2\n",
      "Fitting on 3, testing on 2...\n",
      "2 3 0 2\n",
      "Fitting on 0, testing on 2...\n",
      "2 2 1 3\n",
      "Fitting on 1, testing on 3...\n",
      "2 0 3 3\n",
      "2 1 0 5\n",
      "Fitting on 0, testing on 5...\n",
      "2 2 1 4\n",
      "Fitting on 1, testing on 4...\n",
      "2 2 1 5\n",
      "Fitting on 1, testing on 5...\n",
      "2 0 3 4\n",
      "Fitting on 3, testing on 4...\n",
      "2 1 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "2 3 0 3\n",
      "Fitting on 0, testing on 3...\n",
      "2 2 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "2 0 3 5\n",
      "Fitting on 3, testing on 5...\n",
      "2 0 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "2 2 2 1\n",
      "Fitting on 2, testing on 1...\n",
      "2 0 4 1\n",
      "Fitting on 4, testing on 1...\n",
      "2 0 4 2\n",
      "Fitting on 4, testing on 2...\n",
      "2 1 1 1\n",
      "2 0 4 3\n",
      "Fitting on 4, testing on 3...\n",
      "2 2 2 2\n",
      "2 0 4 4\n",
      "2 3 0 4\n",
      "Fitting on 0, testing on 4...\n",
      "2 0 4 5\n",
      "Fitting on 4, testing on 5...\n",
      "2 0 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "2 3 0 5\n",
      "Fitting on 0, testing on 5...\n",
      "2 0 5 1\n",
      "Fitting on 5, testing on 1...\n",
      "2 2 2 3\n",
      "Fitting on 2, testing on 3...\n",
      "2 0 5 2\n",
      "Fitting on 5, testing on 2...\n",
      "2 0 5 3\n",
      "Fitting on 5, testing on 3...\n",
      "2 2 2 4\n",
      "Fitting on 2, testing on 4...\n",
      "2 0 5 4\n",
      "Fitting on 5, testing on 4...\n",
      "2 0 5 5\n",
      "2 2 2 5\n",
      "Fitting on 2, testing on 5...\n",
      "2 3 1 0\n",
      "Fitting on 1, testing on 0...\n",
      "2 2 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "2 1 1 2\n",
      "Fitting on 1, testing on 2...\n",
      "2 2 3 1\n",
      "Fitting on 3, testing on 1...\n",
      "2 2 3 2\n",
      "Fitting on 3, testing on 2...\n",
      "2 3 1 1\n",
      "2 1 1 3\n",
      "Fitting on 1, testing on 3...\n",
      "2 2 3 3\n",
      "2 1 1 4\n",
      "Fitting on 1, testing on 4...\n",
      "2 1 1 5\n",
      "Fitting on 1, testing on 5...\n",
      "2 2 3 4\n",
      "Fitting on 3, testing on 4...\n",
      "2 2 3 5\n",
      "Fitting on 3, testing on 5...\n",
      "2 1 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "2 2 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "2 2 4 1\n",
      "Fitting on 4, testing on 1...\n",
      "2 1 2 1\n",
      "Fitting on 2, testing on 1...\n",
      "2 2 4 2\n",
      "Fitting on 4, testing on 2...\n",
      "2 2 4 3\n",
      "Fitting on 4, testing on 3...\n",
      "2 1 2 2\n",
      "2 2 4 4\n",
      "2 3 1 2\n",
      "Fitting on 1, testing on 2...\n",
      "2 2 4 5\n",
      "Fitting on 4, testing on 5...\n",
      "2 3 1 3\n",
      "Fitting on 1, testing on 3...\n",
      "2 2 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "2 2 5 1\n",
      "Fitting on 5, testing on 1...\n",
      "2 2 5 2\n",
      "Fitting on 5, testing on 2...\n",
      "2 3 1 4\n",
      "Fitting on 1, testing on 4...\n",
      "2 1 2 3\n",
      "Fitting on 2, testing on 3...\n",
      "2 2 5 3\n",
      "Fitting on 5, testing on 3...\n",
      "2 2 5 4\n",
      "Fitting on 5, testing on 4...\n",
      "2 1 2 4\n",
      "Fitting on 2, testing on 4...\n",
      "2 2 5 5\n",
      "2 3 1 5\n",
      "Fitting on 1, testing on 5...\n",
      "2 1 2 5\n",
      "Fitting on 2, testing on 5...\n",
      "2 3 2 0\n",
      "Fitting on 2, testing on 0...\n",
      "2 1 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "2 1 3 1\n",
      "Fitting on 3, testing on 1...\n",
      "2 3 2 1\n",
      "Fitting on 2, testing on 1...\n",
      "2 1 3 2\n",
      "Fitting on 3, testing on 2...\n",
      "2 3 2 2\n",
      "2 1 3 3\n",
      "2 1 3 4\n",
      "Fitting on 3, testing on 4...\n",
      "2 1 3 5\n",
      "Fitting on 3, testing on 5...\n",
      "2 3 2 3\n",
      "Fitting on 2, testing on 3...\n",
      "2 1 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "2 1 4 1\n",
      "Fitting on 4, testing on 1...\n",
      "2 3 2 4\n",
      "Fitting on 2, testing on 4...\n",
      "2 1 4 2\n",
      "Fitting on 4, testing on 2...\n",
      "2 3 2 5\n",
      "Fitting on 2, testing on 5...\n",
      "2 1 4 3\n",
      "Fitting on 4, testing on 3...\n",
      "2 1 4 4\n",
      "2 3 3 0\n",
      "Fitting on 3, testing on 0...\n",
      "2 3 3 1\n",
      "Fitting on 3, testing on 1...\n",
      "2 3 3 2\n",
      "Fitting on 3, testing on 2...\n",
      "2 1 4 5\n",
      "Fitting on 4, testing on 5...\n",
      "2 3 3 3\n",
      "2 1 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "2 1 5 1\n",
      "Fitting on 5, testing on 1...\n",
      "2 1 5 2\n",
      "Fitting on 5, testing on 2...\n",
      "2 1 5 3\n",
      "Fitting on 5, testing on 3...\n",
      "2 1 5 4\n",
      "Fitting on 5, testing on 4...\n",
      "2 1 5 5\n",
      "2 3 3 4\n",
      "Fitting on 3, testing on 4...\n",
      "2 3 3 5\n",
      "Fitting on 3, testing on 5...\n",
      "2 3 4 0\n",
      "Fitting on 4, testing on 0...\n",
      "2 3 4 1\n",
      "Fitting on 4, testing on 1...\n",
      "2 3 4 2\n",
      "Fitting on 4, testing on 2...\n",
      "2 3 4 3\n",
      "Fitting on 4, testing on 3...\n",
      "2 3 4 4\n",
      "2 3 4 5\n",
      "Fitting on 4, testing on 5...\n",
      "2 3 5 0\n",
      "Fitting on 5, testing on 0...\n",
      "2 3 5 1\n",
      "Fitting on 5, testing on 1...\n",
      "2 3 5 2\n",
      "Fitting on 5, testing on 2...\n",
      "2 3 5 3\n",
      "Fitting on 5, testing on 3...\n",
      "2 3 5 4\n",
      "Fitting on 5, testing on 4...\n",
      "2 3 5 5\n"
     ]
    }
   ],
   "source": [
    "# Cross surface validation for 1 out of 6 surfaces\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ;\n",
    "decomp = PCA(n_components=20)\n",
    "def filename(i,j,k,l):\n",
    "    return 'fs_'+str(i)+'_subfs_'+str(j)+'_tr_'+str(k)+'_ts_'+str(l)\n",
    "\n",
    "def cross_fit(i,j,k,l,data,labels,data2,labels2,pipe):\n",
    "    fileid = 'tmpresults1_transtart/'+filename(i,j,k,l)+'.npz'\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k,l\n",
    "        if k==l: # perform K-fold                  \n",
    "#             data = surf[j][k][i][::100,:]\n",
    "#             labels = surfla[k][i][::100]\n",
    "            folds = cv.split(data, labels)\n",
    "            cm_all = np.zeros((2,2))\n",
    "            for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                x_train, x_test = data[train_ind], data[test_ind]\n",
    "                y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                model = pipe.fit(x_train,y_train)\n",
    "                y_pred = model.predict(x_test)\n",
    "                cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                cm_all += cm/5.\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "#             tr_data = surf[j][k][i]\n",
    "#             tr_labels = surfla[k][i]\n",
    "#             ts_data = surf[j][l][i]\n",
    "#             ts_labels = surfla[l][i]\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            print 'Fitting on '+str(k)+', testing on '+str(l)+'...'\n",
    "            model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps(i,j,jmax,surf,surfla):\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k in range(surf.shape[0]): # for every training surface\n",
    "        for l in range(surf.shape[0]): # for every testing surface\n",
    "#             cross_fit(i,j,k,l,surf[k][::100,:],surfla[k][::100],surf[l][::100,:],surfla[l][::100],pipe)\n",
    "            cross_fit(i,j,k,l,surf[k],surfla[:,k],surf[l],surfla[:,l],pipe)\n",
    "\n",
    "# for i in range(surf.shape[2]): # for every featureset\n",
    "for i in [2]:#range(1): # for every featureset\n",
    "#     for j in range(surf.shape[0]): # for every subfeatureset\n",
    "#         if j==surf.shape[0]-1:\n",
    "#             featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "#         else:\n",
    "#             featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "#         pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "#         init_steps(i,j,surf[j][:][i],surfla[:][i])\n",
    "    # for every subfeatureset\n",
    "    [Parallel(n_jobs=-1)([delayed(init_steps) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) for j in range(surf.shape[0])])]\n",
    "#         for k in range(surf.shape[1]): # for every training surface\n",
    "#             for l in range(surf.shape[1]): # for every testing surface\n",
    "#                 cross_fit(i,j,k,l,surf,surfla,pipe)\n",
    "#             [Parallel(n_jobs=-1)([delayed(cross_fit) (i,j,k,l,surf,surfla,pipe) for l in range(surf.shape[1])])]\n",
    "            \n",
    "            \n",
    "\n",
    "# for i in range(surf.shape[2]): # for every featureset\n",
    "#     for j in range(surf.shape[0]): # for every subfeatureset\n",
    "#         if j==surf.shape[0]-1:\n",
    "#             featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "#         else:\n",
    "#             featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "#         pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "#         for k in range(surf.shape[1]): # for every training surface\n",
    "# #             for l in range(surf.shape[1]): # for every testing surface\n",
    "# #                 cross_fit(i,j,k,l,surf,surfla,pipe)\n",
    "# #             [Parallel(n_jobs=-1)([delayed(cross_fit) (i,j,k,l,surf,surfla,pipe) for l in range(surf.shape[1])])]\n",
    "#             [Parallel(n_jobs=-1)([delayed(cross_fit) (i,j,k,l,surf[j][k][i][::100,:],surfla[k][i][::100],surf[j][l][i][::100,:],surfla[l][i][::100],pipe) for l in range(surf.shape[1])])]\n",
    "    \n",
    "#     print(temp_surf[3].shape, i)\n",
    "#     X_amfft, X_freq_all, X_time, X_both = feat_subsets(surf[:,i],i)\n",
    "#     for j in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 1 0\n",
      "Fitting on 0-1, cross-validating on 0...\n",
      "0 1 0 1 0\n",
      "Fitting on 0-1, cross-validating on 0...\n",
      "Fitting on 0-1, cross-validating on 0...\n",
      "0 2 0 1 0\n",
      "0 3 0 1 0\n",
      "Fitting on 0-1, cross-validating on 0...\n",
      "0 0 0 1 1\n",
      "Fitting on 0-1, cross-validating on 1...\n",
      "0 0 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "0 0 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "0 0 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "0 0 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "0 2 0 1 1\n",
      "Fitting on 0-1, cross-validating on 1...\n",
      "0 2 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "0 0 0 2 0\n",
      "Fitting on 0-2, cross-validating on 0...\n",
      "0 2 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "0 2 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "0 0 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "0 0 0 2 2\n",
      "Fitting on 0-2, cross-validating on 2...\n",
      "0 0 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "0 2 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "0 0 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "0 0 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "0 1 0 1 1\n",
      "Fitting on 0-1, cross-validating on 1...\n",
      "0 1 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "0 2 0 2 0\n",
      "Fitting on 0-2, cross-validating on 0...\n",
      "0 0 0 3 0\n",
      "Fitting on 0-3, cross-validating on 0...\n",
      "0 1 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "0 0 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "0 0 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "0 0 0 3 3\n",
      "Fitting on 0-3, cross-validating on 3...\n",
      "0 0 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "0 1 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "0 0 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "0 3 0 1 1\n",
      "Fitting on 0-1, cross-validating on 1...\n",
      "0 3 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n",
      "0 2 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "0 0 0 4 0\n",
      "Fitting on 0-4, cross-validating on 0...\n",
      "0 2 0 2 2\n",
      "Fitting on 0-2, cross-validating on 2...\n",
      "0 2 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "0 1 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "0 2 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "0 0 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "0 3 0 1 3\n",
      "Fitting on 0-1, testing on 3...\n",
      "0 0 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "0 2 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "0 0 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "0 1 0 2 0\n",
      "Fitting on 0-2, cross-validating on 0...\n",
      "0 0 0 4 4\n",
      "Fitting on 0-4, cross-validating on 4...\n",
      "0 0 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "0 2 0 3 0\n",
      "Fitting on 0-3, cross-validating on 0...\n",
      "0 0 0 5 0\n",
      "Fitting on 0-5, cross-validating on 0...\n",
      "0 3 0 1 4\n",
      "Fitting on 0-1, testing on 4...\n",
      "0 0 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "0 0 0 5 2\n",
      "Fitting on 0-5, testing on 2...\n",
      "0 0 0 5 3\n",
      "Fitting on 0-5, testing on 3...\n",
      "0 2 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "0 0 0 5 4\n",
      "Fitting on 0-5, testing on 4...\n",
      "0 3 0 1 5\n",
      "Fitting on 0-1, testing on 5...\n",
      "0 0 0 5 5\n",
      "Fitting on 0-5, cross-validating on 5...\n",
      "0 0 1 2 0\n",
      "Fitting on 1-2, testing on 0...\n",
      "0 2 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "0 0 1 2 1\n",
      "Fitting on 1-2, cross-validating on 1...\n",
      "0 2 0 3 3\n",
      "Fitting on 0-3, cross-validating on 3...\n",
      "0 2 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "0 2 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "0 0 1 2 2\n",
      "Fitting on 1-2, cross-validating on 2...\n",
      "0 0 1 2 3\n",
      "Fitting on 1-2, testing on 3...\n",
      "0 3 0 2 0\n",
      "Fitting on 0-2, cross-validating on 0...\n",
      "0 1 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "0 0 1 2 4\n",
      "Fitting on 1-2, testing on 4...\n",
      "0 2 0 4 0\n",
      "Fitting on 0-4, cross-validating on 0...\n",
      "0 0 1 2 5\n",
      "Fitting on 1-2, testing on 5...\n",
      "0 0 1 3 0\n",
      "Fitting on 1-3, testing on 0...\n",
      "0 0 1 3 1\n",
      "Fitting on 1-3, cross-validating on 1...\n",
      "0 1 0 2 2\n",
      "Fitting on 0-2, cross-validating on 2...\n",
      "0 1 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "0 1 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "0 0 1 3 2\n",
      "Fitting on 1-3, testing on 2...\n",
      "0 0 1 3 3\n",
      "Fitting on 1-3, cross-validating on 3...\n",
      "0 0 1 3 4\n",
      "Fitting on 1-3, testing on 4...\n",
      "0 2 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "0 0 1 3 5\n",
      "Fitting on 1-3, testing on 5...\n",
      "0 0 1 4 0\n",
      "Fitting on 1-4, testing on 0...\n",
      "0 2 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "0 1 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "0 0 1 4 1\n",
      "Fitting on 1-4, cross-validating on 1...\n",
      "0 2 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "0 2 0 4 4\n",
      "Fitting on 0-4, cross-validating on 4...\n",
      "0 2 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "0 1 0 3 0\n",
      "Fitting on 0-3, cross-validating on 0...\n",
      "0 0 1 4 2\n",
      "Fitting on 1-4, testing on 2...\n",
      "0 2 0 5 0\n",
      "Fitting on 0-5, cross-validating on 0...\n",
      "0 0 1 4 3\n",
      "Fitting on 1-4, testing on 3...\n",
      "0 0 1 4 4\n",
      "Fitting on 1-4, cross-validating on 4...\n",
      "0 0 1 4 5\n",
      "Fitting on 1-4, testing on 5...\n",
      "0 0 1 5 0\n",
      "Fitting on 1-5, testing on 0...\n",
      "0 0 1 5 1\n",
      "Fitting on 1-5, cross-validating on 1...\n",
      "0 3 0 2 1\n",
      "Fitting on 0-2, testing on 1...\n",
      "0 0 1 5 2\n",
      "Fitting on 1-5, testing on 2...\n",
      "0 2 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "0 0 1 5 3\n",
      "Fitting on 1-5, testing on 3...\n",
      "0 0 1 5 4\n",
      "Fitting on 1-5, testing on 4...\n",
      "0 2 0 5 2\n",
      "Fitting on 0-5, testing on 2...\n",
      "0 0 1 5 5\n",
      "Fitting on 1-5, cross-validating on 5...\n",
      "0 0 2 3 0\n",
      "Fitting on 2-3, testing on 0...\n",
      "0 3 0 2 2\n",
      "Fitting on 0-2, cross-validating on 2...\n",
      "0 3 0 2 3\n",
      "Fitting on 0-2, testing on 3...\n",
      "0 0 2 3 1\n",
      "Fitting on 2-3, testing on 1...\n",
      "0 2 0 5 3\n",
      "Fitting on 0-5, testing on 3...\n",
      "0 0 2 3 2\n",
      "Fitting on 2-3, cross-validating on 2...\n",
      "0 2 0 5 4\n",
      "Fitting on 0-5, testing on 4...\n",
      "0 1 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "0 2 0 5 5\n",
      "Fitting on 0-5, cross-validating on 5...\n",
      "0 2 1 2 0\n",
      "Fitting on 1-2, testing on 0...\n",
      "0 0 2 3 3\n",
      "Fitting on 2-3, cross-validating on 3...\n",
      "0 0 2 3 4\n",
      "Fitting on 2-3, testing on 4...\n",
      "0 3 0 2 4\n",
      "Fitting on 0-2, testing on 4...\n",
      "0 0 2 3 5\n",
      "Fitting on 2-3, testing on 5...\n",
      "0 2 1 2 1\n",
      "Fitting on 1-2, cross-validating on 1...\n",
      "0 1 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "0 0 2 4 0\n",
      "Fitting on 2-4, testing on 0...\n",
      "0 0 2 4 1\n",
      "Fitting on 2-4, testing on 1...\n",
      "0 0 2 4 2\n",
      "Fitting on 2-4, cross-validating on 2...\n",
      "0 1 0 3 3\n",
      "Fitting on 0-3, cross-validating on 3...\n",
      "0 1 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "0 3 0 2 5\n",
      "Fitting on 0-2, testing on 5...\n",
      "0 0 2 4 3\n",
      "Fitting on 2-4, testing on 3...\n",
      "0 1 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "0 2 1 2 2\n",
      "Fitting on 1-2, cross-validating on 2...\n",
      "0 2 1 2 3\n",
      "Fitting on 1-2, testing on 3...\n",
      "0 0 2 4 4\n",
      "Fitting on 2-4, cross-validating on 4...\n",
      "0 0 2 4 5\n",
      "Fitting on 2-4, testing on 5...\n",
      "0 0 2 5 0\n",
      "Fitting on 2-5, testing on 0...\n",
      "0 2 1 2 4\n",
      "Fitting on 1-2, testing on 4...\n",
      "0 0 2 5 1\n",
      "Fitting on 2-5, testing on 1...\n",
      "0 3 0 3 0\n",
      "Fitting on 0-3, cross-validating on 0...\n",
      "0 0 2 5 2\n",
      "Fitting on 2-5, cross-validating on 2...\n",
      "0 1 0 4 0\n",
      "Fitting on 0-4, cross-validating on 0...\n",
      "0 2 1 2 5\n",
      "Fitting on 1-2, testing on 5...\n",
      "0 2 1 3 0\n",
      "Fitting on 1-3, testing on 0...\n",
      "0 0 2 5 3\n",
      "Fitting on 2-5, testing on 3...\n",
      "0 2 1 3 1\n",
      "Fitting on 1-3, cross-validating on 1...\n",
      "0 0 2 5 4\n",
      "Fitting on 2-5, testing on 4...\n",
      "0 0 2 5 5\n",
      "Fitting on 2-5, cross-validating on 5...\n",
      "0 0 3 4 0\n",
      "Fitting on 3-4, testing on 0...\n",
      "0 0 3 4 1\n",
      "Fitting on 3-4, testing on 1...\n",
      "0 0 3 4 2\n",
      "Fitting on 3-4, testing on 2...\n",
      "0 0 3 4 3\n",
      "Fitting on 3-4, cross-validating on 3...\n",
      "0 2 1 3 2\n",
      "Fitting on 1-3, testing on 2...\n",
      "0 0 3 4 4\n",
      "Fitting on 3-4, cross-validating on 4...\n",
      "0 0 3 4 5\n",
      "Fitting on 3-4, testing on 5...\n",
      "0 2 1 3 3\n",
      "Fitting on 1-3, cross-validating on 3...\n",
      "0 2 1 3 4\n",
      "Fitting on 1-3, testing on 4...\n",
      "0 0 3 5 0\n",
      "Fitting on 3-5, testing on 0...\n",
      "0 0 3 5 1\n",
      "Fitting on 3-5, testing on 1...\n",
      "0 1 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "0 2 1 3 5\n",
      "Fitting on 1-3, testing on 5...\n",
      "0 0 3 5 2\n",
      "Fitting on 3-5, testing on 2...\n",
      "0 0 3 5 3\n",
      "Fitting on 3-5, cross-validating on 3...\n",
      "0 2 1 4 0\n",
      "Fitting on 1-4, testing on 0...\n",
      "0 1 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "0 2 1 4 1\n",
      "Fitting on 1-4, cross-validating on 1...\n",
      "0 0 3 5 4\n",
      "Fitting on 3-5, testing on 4...\n",
      "0 3 0 3 1\n",
      "Fitting on 0-3, testing on 1...\n",
      "0 0 3 5 5\n",
      "Fitting on 3-5, cross-validating on 5...\n",
      "0 0 4 5 0\n",
      "Fitting on 4-5, testing on 0...\n",
      "0 1 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "0 0 4 5 1\n",
      "Fitting on 4-5, testing on 1...\n",
      "0 0 4 5 2\n",
      "Fitting on 4-5, testing on 2...\n",
      "0 0 4 5 3\n",
      "Fitting on 4-5, testing on 3...\n",
      "0 0 4 5 4\n",
      "Fitting on 4-5, cross-validating on 4...\n",
      "0 1 0 4 4\n",
      "Fitting on 0-4, cross-validating on 4...\n",
      "0 1 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "0 3 0 3 2\n",
      "Fitting on 0-3, testing on 2...\n",
      "0 2 1 4 2\n",
      "Fitting on 1-4, testing on 2...\n",
      "0 2 1 4 3\n",
      "Fitting on 1-4, testing on 3...\n",
      "0 1 0 5 0\n",
      "Fitting on 0-5, cross-validating on 0...\n",
      "0 0 4 5 5\n",
      "Fitting on 4-5, cross-validating on 5...\n",
      "0 2 1 4 4\n",
      "Fitting on 1-4, cross-validating on 4...\n",
      "0 2 1 4 5\n",
      "Fitting on 1-4, testing on 5...\n",
      "0 3 0 3 3\n",
      "Fitting on 0-3, cross-validating on 3...\n",
      "0 3 0 3 4\n",
      "Fitting on 0-3, testing on 4...\n",
      "0 2 1 5 0\n",
      "Fitting on 1-5, testing on 0...\n",
      "0 2 1 5 1\n",
      "Fitting on 1-5, cross-validating on 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 0 3 5\n",
      "Fitting on 0-3, testing on 5...\n",
      "0 2 1 5 2\n",
      "Fitting on 1-5, testing on 2...\n",
      "0 3 0 4 0\n",
      "Fitting on 0-4, cross-validating on 0...\n",
      "0 2 1 5 3\n",
      "Fitting on 1-5, testing on 3...\n",
      "0 1 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "0 2 1 5 4\n",
      "Fitting on 1-5, testing on 4...\n",
      "0 2 1 5 5\n",
      "Fitting on 1-5, cross-validating on 5...\n",
      "0 2 2 3 0\n",
      "Fitting on 2-3, testing on 0...\n",
      "0 1 0 5 2\n",
      "Fitting on 0-5, testing on 2...\n",
      "0 2 2 3 1\n",
      "Fitting on 2-3, testing on 1...\n",
      "0 2 2 3 2\n",
      "Fitting on 2-3, cross-validating on 2...\n",
      "0 1 0 5 3\n",
      "Fitting on 0-5, testing on 3...\n",
      "0 1 0 5 4\n",
      "Fitting on 0-5, testing on 4...\n",
      "0 2 2 3 3\n",
      "Fitting on 2-3, cross-validating on 3...\n",
      "0 2 2 3 4\n",
      "Fitting on 2-3, testing on 4...\n",
      "0 1 0 5 5\n",
      "Fitting on 0-5, cross-validating on 5...\n",
      "0 1 1 2 0\n",
      "Fitting on 1-2, testing on 0...\n",
      "0 2 2 3 5\n",
      "Fitting on 2-3, testing on 5...\n",
      "0 1 1 2 1\n",
      "Fitting on 1-2, cross-validating on 1...\n",
      "0 2 2 4 0\n",
      "Fitting on 2-4, testing on 0...\n",
      "0 2 2 4 1\n",
      "Fitting on 2-4, testing on 1...\n",
      "0 3 0 4 1\n",
      "Fitting on 0-4, testing on 1...\n",
      "0 2 2 4 2\n",
      "Fitting on 2-4, cross-validating on 2...\n",
      "0 3 0 4 2\n",
      "Fitting on 0-4, testing on 2...\n",
      "0 2 2 4 3\n",
      "Fitting on 2-4, testing on 3...\n",
      "0 2 2 4 4\n",
      "Fitting on 2-4, cross-validating on 4...\n",
      "0 2 2 4 5\n",
      "Fitting on 2-4, testing on 5...\n",
      "0 3 0 4 3\n",
      "Fitting on 0-4, testing on 3...\n",
      "0 1 1 2 2\n",
      "Fitting on 1-2, cross-validating on 2...\n",
      "0 1 1 2 3\n",
      "Fitting on 1-2, testing on 3...\n",
      "0 2 2 5 0\n",
      "Fitting on 2-5, testing on 0...\n",
      "0 2 2 5 1\n",
      "Fitting on 2-5, testing on 1...\n",
      "0 1 1 2 4\n",
      "Fitting on 1-2, testing on 4...\n",
      "0 2 2 5 2\n",
      "Fitting on 2-5, cross-validating on 2...\n",
      "0 3 0 4 4\n",
      "Fitting on 0-4, cross-validating on 4...\n",
      "0 3 0 4 5\n",
      "Fitting on 0-4, testing on 5...\n",
      "0 1 1 2 5\n",
      "Fitting on 1-2, testing on 5...\n",
      "0 3 0 5 0\n",
      "Fitting on 0-5, cross-validating on 0...\n",
      "0 1 1 3 0\n",
      "Fitting on 1-3, testing on 0...\n",
      "0 2 2 5 3\n",
      "Fitting on 2-5, testing on 3...\n",
      "0 2 2 5 4\n",
      "Fitting on 2-5, testing on 4...\n",
      "0 1 1 3 1\n",
      "Fitting on 1-3, cross-validating on 1...\n",
      "0 2 2 5 5\n",
      "Fitting on 2-5, cross-validating on 5...\n",
      "0 2 3 4 0\n",
      "Fitting on 3-4, testing on 0...\n",
      "0 2 3 4 1\n",
      "Fitting on 3-4, testing on 1...\n",
      "0 2 3 4 2\n",
      "Fitting on 3-4, testing on 2...\n",
      "0 2 3 4 3\n",
      "Fitting on 3-4, cross-validating on 3...\n",
      "0 2 3 4 4\n",
      "Fitting on 3-4, cross-validating on 4...\n",
      "0 2 3 4 5\n",
      "Fitting on 3-4, testing on 5...\n",
      "0 1 1 3 2\n",
      "Fitting on 1-3, testing on 2...\n",
      "0 2 3 5 0\n",
      "Fitting on 3-5, testing on 0...\n",
      "0 3 0 5 1\n",
      "Fitting on 0-5, testing on 1...\n",
      "0 2 3 5 1\n",
      "Fitting on 3-5, testing on 1...\n",
      "0 1 1 3 3\n",
      "Fitting on 1-3, cross-validating on 3...\n",
      "0 1 1 3 4\n",
      "Fitting on 1-3, testing on 4...\n",
      "0 2 3 5 2\n",
      "Fitting on 3-5, testing on 2...\n",
      "0 2 3 5 3\n",
      "Fitting on 3-5, cross-validating on 3...\n",
      "0 1 1 3 5\n",
      "Fitting on 1-3, testing on 5...\n",
      "0 3 0 5 2\n",
      "Fitting on 0-5, testing on 2...\n",
      "0 1 1 4 0\n",
      "Fitting on 1-4, testing on 0...\n",
      "0 3 0 5 3\n",
      "Fitting on 0-5, testing on 3...\n",
      "0 2 3 5 4\n",
      "Fitting on 3-5, testing on 4...\n",
      "0 1 1 4 1\n",
      "Fitting on 1-4, cross-validating on 1...\n",
      "0 2 3 5 5\n",
      "Fitting on 3-5, cross-validating on 5...\n",
      "0 2 4 5 0\n",
      "Fitting on 4-5, testing on 0...\n",
      "0 2 4 5 1\n",
      "Fitting on 4-5, testing on 1...\n",
      "0 3 0 5 4\n",
      "Fitting on 0-5, testing on 4...\n",
      "0 2 4 5 2\n",
      "Fitting on 4-5, testing on 2...\n",
      "0 2 4 5 3\n",
      "Fitting on 4-5, testing on 3...\n",
      "0 2 4 5 4\n",
      "Fitting on 4-5, cross-validating on 4...\n",
      "0 3 0 5 5\n",
      "Fitting on 0-5, cross-validating on 5...\n",
      "0 3 1 2 0\n",
      "Fitting on 1-2, testing on 0...\n",
      "0 3 1 2 1\n",
      "Fitting on 1-2, cross-validating on 1...\n",
      "0 1 1 4 2\n",
      "Fitting on 1-4, testing on 2...\n",
      "0 2 4 5 5\n",
      "Fitting on 4-5, cross-validating on 5...\n",
      "0 1 1 4 3\n",
      "Fitting on 1-4, testing on 3...\n",
      "0 1 1 4 4\n",
      "Fitting on 1-4, cross-validating on 4...\n",
      "0 1 1 4 5\n",
      "Fitting on 1-4, testing on 5...\n",
      "0 1 1 5 0\n",
      "Fitting on 1-5, testing on 0...\n",
      "0 1 1 5 1\n",
      "Fitting on 1-5, cross-validating on 1...\n",
      "0 3 1 2 2\n",
      "Fitting on 1-2, cross-validating on 2...\n",
      "0 3 1 2 3\n",
      "Fitting on 1-2, testing on 3...\n",
      "0 3 1 2 4\n",
      "Fitting on 1-2, testing on 4...\n",
      "0 1 1 5 2\n",
      "Fitting on 1-5, testing on 2...\n",
      "0 3 1 2 5\n",
      "Fitting on 1-2, testing on 5...\n",
      "0 1 1 5 3\n",
      "Fitting on 1-5, testing on 3...\n",
      "0 1 1 5 4\n",
      "Fitting on 1-5, testing on 4...\n",
      "0 3 1 3 0\n",
      "Fitting on 1-3, testing on 0...\n",
      "0 1 1 5 5\n",
      "Fitting on 1-5, cross-validating on 5...\n",
      "0 1 2 3 0\n",
      "Fitting on 2-3, testing on 0...\n",
      "0 3 1 3 1\n",
      "Fitting on 1-3, cross-validating on 1...\n",
      "0 1 2 3 1\n",
      "Fitting on 2-3, testing on 1...\n",
      "0 1 2 3 2\n",
      "Fitting on 2-3, cross-validating on 2...\n",
      "0 1 2 3 3\n",
      "Fitting on 2-3, cross-validating on 3...\n",
      "0 1 2 3 4\n",
      "Fitting on 2-3, testing on 4...\n",
      "0 3 1 3 2\n",
      "Fitting on 1-3, testing on 2...\n",
      "0 1 2 3 5\n",
      "Fitting on 2-3, testing on 5...\n",
      "0 1 2 4 0\n",
      "Fitting on 2-4, testing on 0...\n",
      "0 3 1 3 3\n",
      "Fitting on 1-3, cross-validating on 3...\n",
      "0 3 1 3 4\n",
      "Fitting on 1-3, testing on 4...\n",
      "0 1 2 4 1\n",
      "Fitting on 2-4, testing on 1...\n",
      "0 3 1 3 5\n",
      "Fitting on 1-3, testing on 5...\n",
      "0 1 2 4 2\n",
      "Fitting on 2-4, cross-validating on 2...\n",
      "0 3 1 4 0\n",
      "Fitting on 1-4, testing on 0...\n",
      "0 3 1 4 1\n",
      "Fitting on 1-4, cross-validating on 1...\n",
      "0 1 2 4 3\n",
      "Fitting on 2-4, testing on 3...\n",
      "0 1 2 4 4\n",
      "Fitting on 2-4, cross-validating on 4...\n",
      "0 1 2 4 5\n",
      "Fitting on 2-4, testing on 5...\n",
      "0 1 2 5 0\n",
      "Fitting on 2-5, testing on 0...\n",
      "0 1 2 5 1\n",
      "Fitting on 2-5, testing on 1...\n",
      "0 1 2 5 2\n",
      "Fitting on 2-5, cross-validating on 2...\n",
      "0 3 1 4 2\n",
      "Fitting on 1-4, testing on 2...\n",
      "0 3 1 4 3\n",
      "Fitting on 1-4, testing on 3...\n",
      "0 3 1 4 4\n",
      "Fitting on 1-4, cross-validating on 4...\n",
      "0 3 1 4 5\n",
      "Fitting on 1-4, testing on 5...\n",
      "0 1 2 5 3\n",
      "Fitting on 2-5, testing on 3...\n",
      "0 1 2 5 4\n",
      "Fitting on 2-5, testing on 4...\n",
      "0 3 1 5 0\n",
      "Fitting on 1-5, testing on 0...\n",
      "0 1 2 5 5\n",
      "Fitting on 2-5, cross-validating on 5...\n",
      "0 1 3 4 0\n",
      "Fitting on 3-4, testing on 0...\n",
      "0 3 1 5 1\n",
      "Fitting on 1-5, cross-validating on 1...\n",
      "0 1 3 4 1\n",
      "Fitting on 3-4, testing on 1...\n",
      "0 1 3 4 2\n",
      "Fitting on 3-4, testing on 2...\n",
      "0 1 3 4 3\n",
      "Fitting on 3-4, cross-validating on 3...\n",
      "0 3 1 5 2\n",
      "Fitting on 1-5, testing on 2...\n",
      "0 1 3 4 4\n",
      "Fitting on 3-4, cross-validating on 4...\n",
      "0 1 3 4 5\n",
      "Fitting on 3-4, testing on 5...\n",
      "0 1 3 5 0\n",
      "Fitting on 3-5, testing on 0...\n",
      "0 3 1 5 3\n",
      "Fitting on 1-5, testing on 3...\n",
      "0 1 3 5 1\n",
      "Fitting on 3-5, testing on 1...\n",
      "0 3 1 5 4\n",
      "Fitting on 1-5, testing on 4...\n",
      "0 1 3 5 2\n",
      "Fitting on 3-5, testing on 2...\n",
      "0 1 3 5 3\n",
      "Fitting on 3-5, cross-validating on 3...\n",
      "0 3 1 5 5\n",
      "Fitting on 1-5, cross-validating on 5...\n",
      "0 3 2 3 0\n",
      "Fitting on 2-3, testing on 0...\n",
      "0 3 2 3 1\n",
      "Fitting on 2-3, testing on 1...\n",
      "0 3 2 3 2\n",
      "Fitting on 2-3, cross-validating on 2...\n",
      "0 1 3 5 4\n",
      "Fitting on 3-5, testing on 4...\n",
      "0 1 3 5 5\n",
      "Fitting on 3-5, cross-validating on 5...\n",
      "0 1 4 5 0\n",
      "Fitting on 4-5, testing on 0...\n",
      "0 1 4 5 1\n",
      "Fitting on 4-5, testing on 1...\n",
      "0 1 4 5 2\n",
      "Fitting on 4-5, testing on 2...\n",
      "0 1 4 5 3\n",
      "Fitting on 4-5, testing on 3...\n",
      "0 1 4 5 4\n",
      "Fitting on 4-5, cross-validating on 4...\n",
      "0 3 2 3 3\n",
      "Fitting on 2-3, cross-validating on 3...\n",
      "0 3 2 3 4\n",
      "Fitting on 2-3, testing on 4...\n",
      "0 3 2 3 5\n",
      "Fitting on 2-3, testing on 5...\n",
      "0 3 2 4 0\n",
      "Fitting on 2-4, testing on 0...\n",
      "0 1 4 5 5\n",
      "Fitting on 4-5, cross-validating on 5...\n",
      "0 3 2 4 1\n",
      "Fitting on 2-4, testing on 1...\n",
      "0 3 2 4 2\n",
      "Fitting on 2-4, cross-validating on 2...\n",
      "0 3 2 4 3\n",
      "Fitting on 2-4, testing on 3...\n",
      "0 3 2 4 4\n",
      "Fitting on 2-4, cross-validating on 4...\n",
      "0 3 2 4 5\n",
      "Fitting on 2-4, testing on 5...\n",
      "0 3 2 5 0\n",
      "Fitting on 2-5, testing on 0...\n",
      "0 3 2 5 1\n",
      "Fitting on 2-5, testing on 1...\n",
      "0 3 2 5 2\n",
      "Fitting on 2-5, cross-validating on 2...\n",
      "0 3 2 5 3\n",
      "Fitting on 2-5, testing on 3...\n",
      "0 3 2 5 4\n",
      "Fitting on 2-5, testing on 4...\n",
      "0 3 2 5 5\n",
      "Fitting on 2-5, cross-validating on 5...\n",
      "0 3 3 4 0\n",
      "Fitting on 3-4, testing on 0...\n",
      "0 3 3 4 1\n",
      "Fitting on 3-4, testing on 1...\n",
      "0 3 3 4 2\n",
      "Fitting on 3-4, testing on 2...\n",
      "0 3 3 4 3\n",
      "Fitting on 3-4, cross-validating on 3...\n",
      "0 3 3 4 4\n",
      "Fitting on 3-4, cross-validating on 4...\n",
      "0 3 3 4 5\n",
      "Fitting on 3-4, testing on 5...\n",
      "0 3 3 5 0\n",
      "Fitting on 3-5, testing on 0...\n",
      "0 3 3 5 1\n",
      "Fitting on 3-5, testing on 1...\n",
      "0 3 3 5 2\n",
      "Fitting on 3-5, testing on 2...\n",
      "0 3 3 5 3\n",
      "Fitting on 3-5, cross-validating on 3...\n",
      "0 3 3 5 4\n",
      "Fitting on 3-5, testing on 4...\n",
      "0 3 3 5 5\n",
      "Fitting on 3-5, cross-validating on 5...\n",
      "0 3 4 5 0\n",
      "Fitting on 4-5, testing on 0...\n",
      "0 3 4 5 1\n",
      "Fitting on 4-5, testing on 1...\n",
      "0 3 4 5 2\n",
      "Fitting on 4-5, testing on 2...\n",
      "0 3 4 5 3\n",
      "Fitting on 4-5, testing on 3...\n",
      "0 3 4 5 4\n",
      "Fitting on 4-5, cross-validating on 4...\n",
      "0 3 4 5 5\n",
      "Fitting on 4-5, cross-validating on 5...\n",
      "1 0 0 1 0\n",
      "Fitting on 0-1, cross-validating on 0...\n",
      "1 1 0 1 0\n",
      "Fitting on 0-1, cross-validating on 0...\n",
      "1 2 0 1 0\n",
      "Fitting on 0-1, cross-validating on 0...\n",
      "1 3 0 1 0\n",
      "Fitting on 0-1, cross-validating on 0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 0 1 1\n",
      "Fitting on 0-1, cross-validating on 1...\n",
      "1 0 0 1 2\n",
      "Fitting on 0-1, testing on 2...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6944e7ae36f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#         init_steps(i,j,surf[j][:][i],surfla[:][i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# for every subfeatureset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_steps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurfla\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;31m#         for k in range(surf.shape[1]): # for every training surface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m#             for l in range(surf.shape[1]): # for every testing surface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jagrio/.local/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jagrio/.local/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Cross surface validation for 2 out of 6 surfaces\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ;\n",
    "decomp = PCA(n_components=20)\n",
    "def filename(i,j,k1,k2,l):\n",
    "    return 'fs_'+str(i)+'_subfs_'+str(j)+'_tr1_'+str(k1)+'_tr2_'+str(k2)+'_ts_'+str(l)\n",
    "\n",
    "def cross_fit(i,j,k1,k2,l,data,labels,data2,labels2,pipe):\n",
    "    fileid = 'tmpresults2_transtart/'+filename(i,j,k1,k2,l)+'.npz'\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k1,k2,l\n",
    "        if k1==l or k2==l: # perform K-fold      \n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+', cross-validating on '+str(l)+'...'\n",
    "            if l == k1: # copy if existent from the other sibling file\n",
    "                tmpcopyfileid = 'tmpresults2_transtart/'+filename(i,j,k1,k2,k2)+'.npz'\n",
    "            else:   # same as above\n",
    "                tmpcopyfileid = 'tmpresults2_transtart/'+filename(i,j,k1,k2,k1)+'.npz'                \n",
    "            if not os.path.isfile(tmpcopyfileid):\n",
    "                folds = cv.split(data, labels)\n",
    "                cm_all = np.zeros((2,2))\n",
    "                for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                    x_train, x_test = data[train_ind], data[test_ind]\n",
    "                    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                    model = pipe.fit(x_train,y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                    cm_all += cm/5.\n",
    "            else:\n",
    "                cm_all = np.load(tmpcopyfileid)['cm']\n",
    "                model = np.load(tmpcopyfileid)['model'][0]\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+', testing on '+str(l)+'...'\n",
    "            model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps(i,j,jmax,surf,surfla):\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k1 in range(surf.shape[0]): # for every training surface1\n",
    "        for k2 in range(surf.shape[0]): # for every training surface2\n",
    "            if k2 > k1:\n",
    "                for l in range(surf.shape[0]): # for every testing surface\n",
    "#                     if l != k1 and l != k2:\n",
    "        #             cross_fit(i,j,k,l,surf[k][::100,:],surfla[k][::100],surf[l][::100,:],surfla[l][::100],pipe)\n",
    "                    tr_surf, tr_surfla = np.concatenate((surf[k1],surf[k2]),axis=0), np.concatenate((surfla[:,k1],surfla[:,k2]),axis=0)\n",
    "                    ts_surf, ts_surfla = surf[l], surfla[:,l]\n",
    "        #                 print tr_surf.shape, tr_surfla.shape\n",
    "                    cross_fit(i,j,k1,k2,l,tr_surf,tr_surfla,ts_surf,ts_surfla,pipe)\n",
    "\n",
    "for i in range(surf.shape[2]): # for every featureset\n",
    "#     for j in range(surf.shape[0]): # for every subfeatureset\n",
    "#         if j==surf.shape[0]-1:\n",
    "#             featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "#         else:\n",
    "#             featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "#         pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "#         init_steps(i,j,surf[j][:][i],surfla[:][i])\n",
    "    # for every subfeatureset\n",
    "    [Parallel(n_jobs=-1)([delayed(init_steps) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) for j in range(surf.shape[0])])]\n",
    "#         for k in range(surf.shape[1]): # for every training surface\n",
    "#             for l in range(surf.shape[1]): # for every testing surface\n",
    "#                 cross_fit(i,j,k,l,surf,surfla,pipe)\n",
    "#             [Parallel(n_jobs=-1)([delayed(cross_fit) (i,j,k,l,surf,surfla,pipe) for l in range(surf.shape[1])])]\n",
    "            \n",
    "            \n",
    "\n",
    "# for i in range(surf.shape[2]): # for every featureset\n",
    "#     for j in range(surf.shape[0]): # for every subfeatureset\n",
    "#         if j==surf.shape[0]-1:\n",
    "#             featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "#         else:\n",
    "#             featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "#         pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "#         for k in range(surf.shape[1]): # for every training surface\n",
    "# #             for l in range(surf.shape[1]): # for every testing surface\n",
    "# #                 cross_fit(i,j,k,l,surf,surfla,pipe)\n",
    "# #             [Parallel(n_jobs=-1)([delayed(cross_fit) (i,j,k,l,surf,surfla,pipe) for l in range(surf.shape[1])])]\n",
    "#             [Parallel(n_jobs=-1)([delayed(cross_fit) (i,j,k,l,surf[j][k][i][::100,:],surfla[k][i][::100],surf[j][l][i][::100,:],surfla[l][i][::100],pipe) for l in range(surf.shape[1])])]\n",
    "    \n",
    "#     print(temp_surf[3].shape, i)\n",
    "#     X_amfft, X_freq_all, X_time, X_both = feat_subsets(surf[:,i],i)\n",
    "#     for j in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 1 2 0\n",
      "Fitting on 0-1-2, cross-validating on 0...\n",
      "0 1 0 1 2 0\n",
      "Fitting on 0-1-2, cross-validating on 0...\n",
      "Fitting on 0-1-2, cross-validating on 0...\n",
      "0 2 0 1 2 0\n",
      "0 3 0 1 2 0\n",
      "Fitting on 0-1-2, cross-validating on 0...\n",
      "0 0 0 1 2 1\n",
      "Fitting on 0-1-2, cross-validating on 1...\n",
      "0 0 0 1 2 2\n",
      "Fitting on 0-1-2, cross-validating on 2...\n",
      "0 0 0 1 2 3\n",
      "Fitting on 0-1-2, testing on 3...\n",
      "0 0 0 1 2 4\n",
      "Fitting on 0-1-2, testing on 4...\n",
      "0 0 0 1 2 5\n",
      "Fitting on 0-1-2, testing on 5...\n",
      "0 0 0 1 3 0\n",
      "Fitting on 0-1-3, cross-validating on 0...\n",
      "0 2 0 1 2 1\n",
      "Fitting on 0-1-2, cross-validating on 1...\n",
      "0 2 0 1 2 2\n",
      "Fitting on 0-1-2, cross-validating on 2...\n",
      "0 2 0 1 2 3\n",
      "Fitting on 0-1-2, testing on 3...\n",
      "0 2 0 1 2 4\n",
      "Fitting on 0-1-2, testing on 4...\n",
      "0 0 0 1 3 1\n",
      "Fitting on 0-1-3, cross-validating on 1...\n",
      "0 0 0 1 3 2\n",
      "Fitting on 0-1-3, testing on 2...\n",
      "0 2 0 1 2 5\n",
      "Fitting on 0-1-2, testing on 5...\n",
      "0 0 0 1 3 3\n",
      "Fitting on 0-1-3, cross-validating on 3...\n",
      "0 0 0 1 3 4\n",
      "Fitting on 0-1-3, testing on 4...\n",
      "0 0 0 1 3 5\n",
      "Fitting on 0-1-3, testing on 5...\n",
      "0 2 0 1 3 0\n",
      "Fitting on 0-1-3, cross-validating on 0...\n",
      "0 0 0 1 4 0\n",
      "Fitting on 0-1-4, cross-validating on 0...\n",
      "0 1 0 1 2 1\n",
      "Fitting on 0-1-2, cross-validating on 1...\n",
      "0 1 0 1 2 2\n",
      "Fitting on 0-1-2, cross-validating on 2...\n",
      "0 1 0 1 2 3\n",
      "Fitting on 0-1-2, testing on 3...\n",
      "0 0 0 1 4 1\n",
      "Fitting on 0-1-4, cross-validating on 1...\n",
      "0 0 0 1 4 2\n",
      "Fitting on 0-1-4, testing on 2...\n",
      "0 0 0 1 4 3\n",
      "Fitting on 0-1-4, testing on 3...\n",
      "0 1 0 1 2 4\n",
      "Fitting on 0-1-2, testing on 4...\n",
      "0 0 0 1 4 4\n",
      "Fitting on 0-1-4, cross-validating on 4...\n",
      "0 0 0 1 4 5\n",
      "Fitting on 0-1-4, testing on 5...\n",
      "0 0 0 1 5 0\n",
      "Fitting on 0-1-5, cross-validating on 0...\n",
      "0 2 0 1 3 1\n",
      "Fitting on 0-1-3, cross-validating on 1...\n",
      "0 2 0 1 3 2\n",
      "Fitting on 0-1-3, testing on 2...\n",
      "0 3 0 1 2 1\n",
      "Fitting on 0-1-2, cross-validating on 1...\n",
      "0 3 0 1 2 2\n",
      "Fitting on 0-1-2, cross-validating on 2...\n",
      "0 3 0 1 2 3\n",
      "Fitting on 0-1-2, testing on 3...\n",
      "0 1 0 1 2 5\n",
      "Fitting on 0-1-2, testing on 5...\n",
      "0 2 0 1 3 3\n",
      "Fitting on 0-1-3, cross-validating on 3...\n",
      "0 2 0 1 3 4\n",
      "Fitting on 0-1-3, testing on 4...\n",
      "0 0 0 1 5 1\n",
      "Fitting on 0-1-5, cross-validating on 1...\n",
      "0 0 0 1 5 2\n",
      "Fitting on 0-1-5, testing on 2...\n",
      "0 2 0 1 3 5\n",
      "Fitting on 0-1-3, testing on 5...\n",
      "0 0 0 1 5 3\n",
      "Fitting on 0-1-5, testing on 3...\n",
      "0 1 0 1 3 0\n",
      "Fitting on 0-1-3, cross-validating on 0...\n",
      "0 0 0 1 5 4\n",
      "Fitting on 0-1-5, testing on 4...\n",
      "0 2 0 1 4 0\n",
      "Fitting on 0-1-4, cross-validating on 0...\n",
      "0 0 0 1 5 5\n",
      "Fitting on 0-1-5, cross-validating on 5...\n",
      "0 0 0 2 3 0\n",
      "Fitting on 0-2-3, cross-validating on 0...\n",
      "0 3 0 1 2 4\n",
      "Fitting on 0-1-2, testing on 4...\n",
      "0 0 0 2 3 1\n",
      "Fitting on 0-2-3, testing on 1...\n",
      "0 0 0 2 3 2\n",
      "Fitting on 0-2-3, cross-validating on 2...\n",
      "0 0 0 2 3 3\n",
      "Fitting on 0-2-3, cross-validating on 3...\n",
      "0 0 0 2 3 4\n",
      "Fitting on 0-2-3, testing on 4...\n",
      "0 0 0 2 3 5\n",
      "Fitting on 0-2-3, testing on 5...\n",
      "0 3 0 1 2 5\n",
      "Fitting on 0-1-2, testing on 5...\n",
      "0 0 0 2 4 0\n",
      "Fitting on 0-2-4, cross-validating on 0...\n",
      "0 2 0 1 4 1\n",
      "Fitting on 0-1-4, cross-validating on 1...\n",
      "0 2 0 1 4 2\n",
      "Fitting on 0-1-4, testing on 2...\n",
      "0 2 0 1 4 3\n",
      "Fitting on 0-1-4, testing on 3...\n",
      "0 0 0 2 4 1\n",
      "Fitting on 0-2-4, testing on 1...\n",
      "0 2 0 1 4 4\n",
      "Fitting on 0-1-4, cross-validating on 4...\n",
      "0 2 0 1 4 5\n",
      "Fitting on 0-1-4, testing on 5...\n",
      "0 0 0 2 4 2\n",
      "Fitting on 0-2-4, cross-validating on 2...\n",
      "0 0 0 2 4 3\n",
      "Fitting on 0-2-4, testing on 3...\n",
      "0 3 0 1 3 0\n",
      "Fitting on 0-1-3, cross-validating on 0...\n",
      "0 0 0 2 4 4\n",
      "Fitting on 0-2-4, cross-validating on 4...\n",
      "0 0 0 2 4 5\n",
      "Fitting on 0-2-4, testing on 5...\n",
      "0 2 0 1 5 0\n",
      "Fitting on 0-1-5, cross-validating on 0...\n",
      "0 0 0 2 5 0\n",
      "Fitting on 0-2-5, cross-validating on 0...\n",
      "0 1 0 1 3 1\n",
      "Fitting on 0-1-3, cross-validating on 1...\n",
      "0 1 0 1 3 2\n",
      "Fitting on 0-1-3, testing on 2...\n",
      "0 0 0 2 5 1\n",
      "Fitting on 0-2-5, testing on 1...\n",
      "0 1 0 1 3 3\n",
      "Fitting on 0-1-3, cross-validating on 3...\n",
      "0 1 0 1 3 4\n",
      "Fitting on 0-1-3, testing on 4...\n",
      "0 0 0 2 5 2\n",
      "Fitting on 0-2-5, cross-validating on 2...\n",
      "0 0 0 2 5 3\n",
      "Fitting on 0-2-5, testing on 3...\n",
      "0 0 0 2 5 4\n",
      "Fitting on 0-2-5, testing on 4...\n",
      "0 2 0 1 5 1\n",
      "Fitting on 0-1-5, cross-validating on 1...\n",
      "0 2 0 1 5 2\n",
      "Fitting on 0-1-5, testing on 2...\n",
      "0 0 0 2 5 5\n",
      "Fitting on 0-2-5, cross-validating on 5...\n",
      "0 0 0 3 4 0\n",
      "Fitting on 0-3-4, cross-validating on 0...\n",
      "0 1 0 1 3 5\n",
      "Fitting on 0-1-3, testing on 5...\n",
      "0 2 0 1 5 3\n",
      "Fitting on 0-1-5, testing on 3...\n",
      "0 2 0 1 5 4\n",
      "Fitting on 0-1-5, testing on 4...\n",
      "0 0 0 3 4 1\n",
      "Fitting on 0-3-4, testing on 1...\n",
      "0 1 0 1 4 0\n",
      "Fitting on 0-1-4, cross-validating on 0...\n",
      "0 0 0 3 4 2\n",
      "Fitting on 0-3-4, testing on 2...\n",
      "0 2 0 1 5 5\n",
      "Fitting on 0-1-5, cross-validating on 5...\n",
      "0 2 0 2 3 0\n",
      "Fitting on 0-2-3, cross-validating on 0...\n",
      "0 0 0 3 4 3\n",
      "Fitting on 0-3-4, cross-validating on 3...\n",
      "0 0 0 3 4 4\n",
      "Fitting on 0-3-4, cross-validating on 4...\n",
      "0 0 0 3 4 5\n",
      "Fitting on 0-3-4, testing on 5...\n",
      "0 0 0 3 5 0\n",
      "Fitting on 0-3-5, cross-validating on 0...\n",
      "0 0 0 3 5 1\n",
      "Fitting on 0-3-5, testing on 1...\n",
      "0 0 0 3 5 2\n",
      "Fitting on 0-3-5, testing on 2...\n",
      "0 0 0 3 5 3\n",
      "Fitting on 0-3-5, cross-validating on 3...\n",
      "0 0 0 3 5 4\n",
      "Fitting on 0-3-5, testing on 4...\n",
      "0 2 0 2 3 1\n",
      "Fitting on 0-2-3, testing on 1...\n",
      "0 3 0 1 3 1\n",
      "Fitting on 0-1-3, cross-validating on 1...\n",
      "0 3 0 1 3 2\n",
      "Fitting on 0-1-3, testing on 2...\n",
      "0 0 0 3 5 5\n",
      "Fitting on 0-3-5, cross-validating on 5...\n",
      "0 0 0 4 5 0\n",
      "Fitting on 0-4-5, cross-validating on 0...\n",
      "0 2 0 2 3 2\n",
      "Fitting on 0-2-3, cross-validating on 2...\n",
      "0 2 0 2 3 3\n",
      "Fitting on 0-2-3, cross-validating on 3...\n",
      "0 2 0 2 3 4\n",
      "Fitting on 0-2-3, testing on 4...\n",
      "0 2 0 2 3 5\n",
      "Fitting on 0-2-3, testing on 5...\n",
      "0 0 0 4 5 1\n",
      "Fitting on 0-4-5, testing on 1...\n",
      "0 0 0 4 5 2\n",
      "Fitting on 0-4-5, testing on 2...\n",
      "0 2 0 2 4 0\n",
      "Fitting on 0-2-4, cross-validating on 0...\n",
      "0 3 0 1 3 3\n",
      "Fitting on 0-1-3, cross-validating on 3...\n",
      "0 3 0 1 3 4\n",
      "Fitting on 0-1-3, testing on 4...\n",
      "0 1 0 1 4 1\n",
      "Fitting on 0-1-4, cross-validating on 1...\n",
      "0 1 0 1 4 2\n",
      "Fitting on 0-1-4, testing on 2...\n",
      "0 0 0 4 5 3\n",
      "Fitting on 0-4-5, testing on 3...\n",
      "0 0 0 4 5 4\n",
      "Fitting on 0-4-5, cross-validating on 4...\n",
      "0 0 0 4 5 5\n",
      "Fitting on 0-4-5, cross-validating on 5...\n",
      "0 0 1 2 3 0\n",
      "Fitting on 1-2-3, testing on 0...\n",
      "0 0 1 2 3 1\n",
      "Fitting on 1-2-3, cross-validating on 1...\n",
      "0 1 0 1 4 3\n",
      "Fitting on 0-1-4, testing on 3...\n",
      "0 3 0 1 3 5\n",
      "Fitting on 0-1-3, testing on 5...\n",
      "0 0 1 2 3 2\n",
      "Fitting on 1-2-3, cross-validating on 2...\n",
      "0 0 1 2 3 3\n",
      "Fitting on 1-2-3, cross-validating on 3...\n",
      "0 0 1 2 3 4\n",
      "Fitting on 1-2-3, testing on 4...\n",
      "0 2 0 2 4 1\n",
      "Fitting on 0-2-4, testing on 1...\n",
      "0 0 1 2 3 5\n",
      "Fitting on 1-2-3, testing on 5...\n",
      "0 1 0 1 4 4\n",
      "Fitting on 0-1-4, cross-validating on 4...\n",
      "0 1 0 1 4 5\n",
      "Fitting on 0-1-4, testing on 5...\n",
      "0 0 1 2 4 0\n",
      "Fitting on 1-2-4, testing on 0...\n",
      "0 2 0 2 4 2\n",
      "Fitting on 0-2-4, cross-validating on 2...\n",
      "0 2 0 2 4 3\n",
      "Fitting on 0-2-4, testing on 3...\n",
      "0 0 1 2 4 1\n",
      "Fitting on 1-2-4, cross-validating on 1...\n",
      "0 2 0 2 4 4\n",
      "Fitting on 0-2-4, cross-validating on 4...\n",
      "0 2 0 2 4 5\n",
      "Fitting on 0-2-4, testing on 5...\n",
      "0 3 0 1 4 0\n",
      "Fitting on 0-1-4, cross-validating on 0...\n",
      "0 1 0 1 5 0\n",
      "Fitting on 0-1-5, cross-validating on 0...\n",
      "0 2 0 2 5 0\n",
      "Fitting on 0-2-5, cross-validating on 0...\n",
      "0 0 1 2 4 2\n",
      "Fitting on 1-2-4, cross-validating on 2...\n",
      "0 0 1 2 4 3\n",
      "Fitting on 1-2-4, testing on 3...\n",
      "0 0 1 2 4 4\n",
      "Fitting on 1-2-4, cross-validating on 4...\n",
      "0 0 1 2 4 5\n",
      "Fitting on 1-2-4, testing on 5...\n",
      "0 0 1 2 5 0\n",
      "Fitting on 1-2-5, testing on 0...\n",
      "0 0 1 2 5 1\n",
      "Fitting on 1-2-5, cross-validating on 1...\n",
      "0 0 1 2 5 2\n",
      "Fitting on 1-2-5, cross-validating on 2...\n",
      "0 0 1 2 5 3\n",
      "Fitting on 1-2-5, testing on 3...\n",
      "0 2 0 2 5 1\n",
      "Fitting on 0-2-5, testing on 1...\n",
      "0 0 1 2 5 4\n",
      "Fitting on 1-2-5, testing on 4...\n",
      "0 0 1 2 5 5\n",
      "Fitting on 1-2-5, cross-validating on 5...\n",
      "0 0 1 3 4 0\n",
      "Fitting on 1-3-4, testing on 0...\n",
      "0 2 0 2 5 2\n",
      "Fitting on 0-2-5, cross-validating on 2...\n",
      "0 2 0 2 5 3\n",
      "Fitting on 0-2-5, testing on 3...\n",
      "0 0 1 3 4 1\n",
      "Fitting on 1-3-4, cross-validating on 1...\n",
      "0 2 0 2 5 4\n",
      "Fitting on 0-2-5, testing on 4...\n",
      "0 2 0 2 5 5\n",
      "Fitting on 0-2-5, cross-validating on 5...\n",
      "0 2 0 3 4 0\n",
      "Fitting on 0-3-4, cross-validating on 0...\n",
      "0 1 0 1 5 1\n",
      "Fitting on 0-1-5, cross-validating on 1...\n",
      "0 1 0 1 5 2\n",
      "Fitting on 0-1-5, testing on 2...\n",
      "0 0 1 3 4 2\n",
      "Fitting on 1-3-4, testing on 2...\n",
      "0 0 1 3 4 3\n",
      "Fitting on 1-3-4, cross-validating on 3...\n",
      "0 0 1 3 4 4\n",
      "Fitting on 1-3-4, cross-validating on 4...\n",
      "0 0 1 3 4 5\n",
      "Fitting on 1-3-4, testing on 5...\n",
      "0 0 1 3 5 0\n",
      "Fitting on 1-3-5, testing on 0...\n",
      "0 0 1 3 5 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting on 1-3-5, cross-validating on 1...\n",
      "0 1 0 1 5 3\n",
      "Fitting on 0-1-5, testing on 3...\n",
      "0 3 0 1 4 1\n",
      "Fitting on 0-1-4, cross-validating on 1...\n",
      "0 3 0 1 4 2\n",
      "Fitting on 0-1-4, testing on 2...\n",
      "0 0 1 3 5 2\n",
      "Fitting on 1-3-5, testing on 2...\n",
      "0 2 0 3 4 1\n",
      "Fitting on 0-3-4, testing on 1...\n",
      "0 1 0 1 5 4\n",
      "Fitting on 0-1-5, testing on 4...\n",
      "0 0 1 3 5 3\n",
      "Fitting on 1-3-5, cross-validating on 3...\n",
      "0 0 1 3 5 4\n",
      "Fitting on 1-3-5, testing on 4...\n",
      "0 0 1 3 5 5\n",
      "Fitting on 1-3-5, cross-validating on 5...\n",
      "0 0 1 4 5 0\n",
      "Fitting on 1-4-5, testing on 0...\n",
      "0 2 0 3 4 2\n",
      "Fitting on 0-3-4, testing on 2...\n",
      "0 0 1 4 5 1\n",
      "Fitting on 1-4-5, cross-validating on 1...\n",
      "0 2 0 3 4 3\n",
      "Fitting on 0-3-4, cross-validating on 3...\n",
      "0 2 0 3 4 4\n",
      "Fitting on 0-3-4, cross-validating on 4...\n",
      "0 2 0 3 4 5\n",
      "Fitting on 0-3-4, testing on 5...\n",
      "0 1 0 1 5 5\n",
      "Fitting on 0-1-5, cross-validating on 5...\n",
      "0 1 0 2 3 0\n",
      "Fitting on 0-2-3, cross-validating on 0...\n",
      "0 3 0 1 4 3\n",
      "Fitting on 0-1-4, testing on 3...\n",
      "0 2 0 3 5 0\n",
      "Fitting on 0-3-5, cross-validating on 0...\n",
      "0 0 1 4 5 2\n",
      "Fitting on 1-4-5, testing on 2...\n",
      "0 0 1 4 5 3\n",
      "Fitting on 1-4-5, testing on 3...\n",
      "0 0 1 4 5 4\n",
      "Fitting on 1-4-5, cross-validating on 4...\n",
      "0 0 1 4 5 5\n",
      "Fitting on 1-4-5, cross-validating on 5...\n",
      "0 0 2 3 4 0\n",
      "Fitting on 2-3-4, testing on 0...\n",
      "0 0 2 3 4 1\n",
      "Fitting on 2-3-4, testing on 1...\n",
      "0 0 2 3 4 2\n",
      "Fitting on 2-3-4, cross-validating on 2...\n",
      "0 3 0 1 4 4\n",
      "Fitting on 0-1-4, cross-validating on 4...\n",
      "0 3 0 1 4 5\n",
      "Fitting on 0-1-4, testing on 5...\n",
      "0 2 0 3 5 1\n",
      "Fitting on 0-3-5, testing on 1...\n",
      "0 0 2 3 4 3\n",
      "Fitting on 2-3-4, cross-validating on 3...\n",
      "0 0 2 3 4 4\n",
      "Fitting on 2-3-4, cross-validating on 4...\n",
      "0 0 2 3 4 5\n",
      "Fitting on 2-3-4, testing on 5...\n",
      "0 2 0 3 5 2\n",
      "Fitting on 0-3-5, testing on 2...\n",
      "0 0 2 3 5 0\n",
      "Fitting on 2-3-5, testing on 0...\n",
      "0 3 0 1 5 0\n",
      "Fitting on 0-1-5, cross-validating on 0...\n",
      "0 0 2 3 5 1\n",
      "Fitting on 2-3-5, testing on 1...\n",
      "0 2 0 3 5 3\n",
      "Fitting on 0-3-5, cross-validating on 3...\n",
      "0 2 0 3 5 4\n",
      "Fitting on 0-3-5, testing on 4...\n",
      "0 0 2 3 5 2\n",
      "Fitting on 2-3-5, cross-validating on 2...\n",
      "0 2 0 3 5 5\n",
      "Fitting on 0-3-5, cross-validating on 5...\n",
      "0 2 0 4 5 0\n",
      "Fitting on 0-4-5, cross-validating on 0...\n",
      "0 1 0 2 3 1\n",
      "Fitting on 0-2-3, testing on 1...\n",
      "0 0 2 3 5 3\n",
      "Fitting on 2-3-5, cross-validating on 3...\n",
      "0 0 2 3 5 4\n",
      "Fitting on 2-3-5, testing on 4...\n",
      "0 0 2 3 5 5\n",
      "Fitting on 2-3-5, cross-validating on 5...\n",
      "0 0 2 4 5 0\n",
      "Fitting on 2-4-5, testing on 0...\n",
      "0 1 0 2 3 2\n",
      "Fitting on 0-2-3, cross-validating on 2...\n",
      "0 1 0 2 3 3\n",
      "Fitting on 0-2-3, cross-validating on 3...\n",
      "0 1 0 2 3 4\n",
      "Fitting on 0-2-3, testing on 4...\n",
      "0 0 2 4 5 1\n",
      "Fitting on 2-4-5, testing on 1...\n",
      "0 0 2 4 5 2\n",
      "Fitting on 2-4-5, cross-validating on 2...\n",
      "0 2 0 4 5 1\n",
      "Fitting on 0-4-5, testing on 1...\n",
      "0 1 0 2 3 5\n",
      "Fitting on 0-2-3, testing on 5...\n",
      "0 0 2 4 5 3\n",
      "Fitting on 2-4-5, testing on 3...\n",
      "0 2 0 4 5 2\n",
      "Fitting on 0-4-5, testing on 2...\n",
      "0 0 2 4 5 4\n",
      "Fitting on 2-4-5, cross-validating on 4...\n",
      "0 0 2 4 5 5\n",
      "Fitting on 2-4-5, cross-validating on 5...\n",
      "0 0 3 4 5 0\n",
      "Fitting on 3-4-5, testing on 0...\n",
      "0 0 3 4 5 1\n",
      "Fitting on 3-4-5, testing on 1...\n",
      "0 1 0 2 4 0\n",
      "Fitting on 0-2-4, cross-validating on 0...\n",
      "0 2 0 4 5 3\n",
      "Fitting on 0-4-5, testing on 3...\n",
      "0 0 3 4 5 2\n",
      "Fitting on 3-4-5, testing on 2...\n",
      "0 0 3 4 5 3\n",
      "Fitting on 3-4-5, cross-validating on 3...\n",
      "0 2 0 4 5 4\n",
      "Fitting on 0-4-5, cross-validating on 4...\n",
      "0 2 0 4 5 5\n",
      "Fitting on 0-4-5, cross-validating on 5...\n",
      "0 2 1 2 3 0\n",
      "Fitting on 1-2-3, testing on 0...\n",
      "0 2 1 2 3 1\n",
      "Fitting on 1-2-3, cross-validating on 1...\n",
      "0 0 3 4 5 4\n",
      "Fitting on 3-4-5, cross-validating on 4...\n",
      "0 0 3 4 5 5\n",
      "Fitting on 3-4-5, cross-validating on 5...\n",
      "0 3 0 1 5 1\n",
      "Fitting on 0-1-5, cross-validating on 1...\n",
      "0 3 0 1 5 2\n",
      "Fitting on 0-1-5, testing on 2...\n",
      "0 2 1 2 3 2\n",
      "Fitting on 1-2-3, cross-validating on 2...\n",
      "0 2 1 2 3 3\n",
      "Fitting on 1-2-3, cross-validating on 3...\n",
      "0 2 1 2 3 4\n",
      "Fitting on 1-2-3, testing on 4...\n",
      "0 2 1 2 3 5\n",
      "Fitting on 1-2-3, testing on 5...\n",
      "0 3 0 1 5 3\n",
      "Fitting on 0-1-5, testing on 3...\n",
      "0 1 0 2 4 1\n",
      "Fitting on 0-2-4, testing on 1...\n",
      "0 2 1 2 4 0\n",
      "Fitting on 1-2-4, testing on 0...\n",
      "0 2 1 2 4 1\n",
      "Fitting on 1-2-4, cross-validating on 1...\n",
      "0 1 0 2 4 2\n",
      "Fitting on 0-2-4, cross-validating on 2...\n",
      "0 1 0 2 4 3\n",
      "Fitting on 0-2-4, testing on 3...\n",
      "0 3 0 1 5 4\n",
      "Fitting on 0-1-5, testing on 4...\n",
      "0 1 0 2 4 4\n",
      "Fitting on 0-2-4, cross-validating on 4...\n",
      "0 1 0 2 4 5\n",
      "Fitting on 0-2-4, testing on 5...\n",
      "0 2 1 2 4 2\n",
      "Fitting on 1-2-4, cross-validating on 2...\n",
      "0 2 1 2 4 3\n",
      "Fitting on 1-2-4, testing on 3...\n",
      "0 3 0 1 5 5\n",
      "Fitting on 0-1-5, cross-validating on 5...\n",
      "0 3 0 2 3 0\n",
      "Fitting on 0-2-3, cross-validating on 0...\n",
      "0 1 0 2 5 0\n",
      "Fitting on 0-2-5, cross-validating on 0...\n",
      "0 2 1 2 4 4\n",
      "Fitting on 1-2-4, cross-validating on 4...\n",
      "0 2 1 2 4 5\n",
      "Fitting on 1-2-4, testing on 5...\n",
      "0 2 1 2 5 0\n",
      "Fitting on 1-2-5, testing on 0...\n",
      "0 2 1 2 5 1\n",
      "Fitting on 1-2-5, cross-validating on 1...\n",
      "0 2 1 2 5 2\n",
      "Fitting on 1-2-5, cross-validating on 2...\n",
      "0 2 1 2 5 3\n",
      "Fitting on 1-2-5, testing on 3...\n",
      "0 2 1 2 5 4\n",
      "Fitting on 1-2-5, testing on 4...\n",
      "0 1 0 2 5 1\n",
      "Fitting on 0-2-5, testing on 1...\n",
      "0 2 1 2 5 5\n",
      "Fitting on 1-2-5, cross-validating on 5...\n",
      "0 2 1 3 4 0\n",
      "Fitting on 1-3-4, testing on 0...\n",
      "0 2 1 3 4 1\n",
      "Fitting on 1-3-4, cross-validating on 1...\n",
      "0 1 0 2 5 2\n",
      "Fitting on 0-2-5, cross-validating on 2...\n",
      "0 1 0 2 5 3\n",
      "Fitting on 0-2-5, testing on 3...\n",
      "0 3 0 2 3 1\n",
      "Fitting on 0-2-3, testing on 1...\n",
      "0 1 0 2 5 4\n",
      "Fitting on 0-2-5, testing on 4...\n",
      "0 2 1 3 4 2\n",
      "Fitting on 1-3-4, testing on 2...\n",
      "0 1 0 2 5 5\n",
      "Fitting on 0-2-5, cross-validating on 5...\n",
      "0 1 0 3 4 0\n",
      "Fitting on 0-3-4, cross-validating on 0...\n",
      "0 3 0 2 3 2\n",
      "Fitting on 0-2-3, cross-validating on 2...\n",
      "0 3 0 2 3 3\n",
      "Fitting on 0-2-3, cross-validating on 3...\n",
      "0 3 0 2 3 4\n",
      "Fitting on 0-2-3, testing on 4...\n",
      "0 2 1 3 4 3\n",
      "Fitting on 1-3-4, cross-validating on 3...\n",
      "0 2 1 3 4 4\n",
      "Fitting on 1-3-4, cross-validating on 4...\n",
      "0 2 1 3 4 5\n",
      "Fitting on 1-3-4, testing on 5...\n",
      "0 2 1 3 5 0\n",
      "Fitting on 1-3-5, testing on 0...\n",
      "0 2 1 3 5 1\n",
      "Fitting on 1-3-5, cross-validating on 1...\n",
      "0 3 0 2 3 5\n",
      "Fitting on 0-2-3, testing on 5...\n",
      "0 3 0 2 4 0\n",
      "Fitting on 0-2-4, cross-validating on 0...\n",
      "0 2 1 3 5 2\n",
      "Fitting on 1-3-5, testing on 2...\n",
      "0 2 1 3 5 3\n",
      "Fitting on 1-3-5, cross-validating on 3...\n",
      "0 2 1 3 5 4\n",
      "Fitting on 1-3-5, testing on 4...\n",
      "0 1 0 3 4 1\n",
      "Fitting on 0-3-4, testing on 1...\n",
      "0 2 1 3 5 5\n",
      "Fitting on 1-3-5, cross-validating on 5...\n",
      "0 2 1 4 5 0\n",
      "Fitting on 1-4-5, testing on 0...\n",
      "0 2 1 4 5 1\n",
      "Fitting on 1-4-5, cross-validating on 1...\n",
      "0 1 0 3 4 2\n",
      "Fitting on 0-3-4, testing on 2...\n",
      "0 1 0 3 4 3\n",
      "Fitting on 0-3-4, cross-validating on 3...\n",
      "0 1 0 3 4 4\n",
      "Fitting on 0-3-4, cross-validating on 4...\n",
      "0 1 0 3 4 5\n",
      "Fitting on 0-3-4, testing on 5...\n",
      "0 2 1 4 5 2\n",
      "Fitting on 1-4-5, testing on 2...\n",
      "0 1 0 3 5 0\n",
      "Fitting on 0-3-5, cross-validating on 0...\n",
      "0 2 1 4 5 3\n",
      "Fitting on 1-4-5, testing on 3...\n",
      "0 2 1 4 5 4\n",
      "Fitting on 1-4-5, cross-validating on 4...\n",
      "0 2 1 4 5 5\n",
      "Fitting on 1-4-5, cross-validating on 5...\n",
      "0 2 2 3 4 0\n",
      "Fitting on 2-3-4, testing on 0...\n",
      "0 2 2 3 4 1\n",
      "Fitting on 2-3-4, testing on 1...\n",
      "0 3 0 2 4 1\n",
      "Fitting on 0-2-4, testing on 1...\n",
      "0 2 2 3 4 2\n",
      "Fitting on 2-3-4, cross-validating on 2...\n",
      "0 3 0 2 4 2\n",
      "Fitting on 0-2-4, cross-validating on 2...\n",
      "0 3 0 2 4 3\n",
      "Fitting on 0-2-4, testing on 3...\n",
      "0 1 0 3 5 1\n",
      "Fitting on 0-3-5, testing on 1...\n",
      "0 2 2 3 4 3\n",
      "Fitting on 2-3-4, cross-validating on 3...\n",
      "0 2 2 3 4 4\n",
      "Fitting on 2-3-4, cross-validating on 4...\n",
      "0 2 2 3 4 5\n",
      "Fitting on 2-3-4, testing on 5...\n",
      "0 2 2 3 5 0\n",
      "Fitting on 2-3-5, testing on 0...\n",
      "0 1 0 3 5 2\n",
      "Fitting on 0-3-5, testing on 2...\n",
      "0 3 0 2 4 4\n",
      "Fitting on 0-2-4, cross-validating on 4...\n",
      "0 3 0 2 4 5\n",
      "Fitting on 0-2-4, testing on 5...\n",
      "0 2 2 3 5 1\n",
      "Fitting on 2-3-5, testing on 1...\n",
      "0 2 2 3 5 2\n",
      "Fitting on 2-3-5, cross-validating on 2...\n",
      "0 1 0 3 5 3\n",
      "Fitting on 0-3-5, cross-validating on 3...\n",
      "0 1 0 3 5 4\n",
      "Fitting on 0-3-5, testing on 4...\n",
      "0 3 0 2 5 0\n",
      "Fitting on 0-2-5, cross-validating on 0...\n",
      "0 1 0 3 5 5\n",
      "Fitting on 0-3-5, cross-validating on 5...\n",
      "0 1 0 4 5 0\n",
      "Fitting on 0-4-5, cross-validating on 0...\n",
      "0 2 2 3 5 3\n",
      "Fitting on 2-3-5, cross-validating on 3...\n",
      "0 2 2 3 5 4\n",
      "Fitting on 2-3-5, testing on 4...\n",
      "0 2 2 3 5 5\n",
      "Fitting on 2-3-5, cross-validating on 5...\n",
      "0 2 2 4 5 0\n",
      "Fitting on 2-4-5, testing on 0...\n",
      "0 2 2 4 5 1\n",
      "Fitting on 2-4-5, testing on 1...\n",
      "0 2 2 4 5 2\n",
      "Fitting on 2-4-5, cross-validating on 2...\n",
      "0 1 0 4 5 1\n",
      "Fitting on 0-4-5, testing on 1...\n",
      "0 2 2 4 5 3\n",
      "Fitting on 2-4-5, testing on 3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 2 4 5 4\n",
      "Fitting on 2-4-5, cross-validating on 4...\n",
      "0 2 2 4 5 5\n",
      "Fitting on 2-4-5, cross-validating on 5...\n",
      "0 2 3 4 5 0\n",
      "Fitting on 3-4-5, testing on 0...\n",
      "0 1 0 4 5 2\n",
      "Fitting on 0-4-5, testing on 2...\n",
      "0 2 3 4 5 1\n",
      "Fitting on 3-4-5, testing on 1...\n",
      "0 3 0 2 5 1\n",
      "Fitting on 0-2-5, testing on 1...\n",
      "0 2 3 4 5 2\n",
      "Fitting on 3-4-5, testing on 2...\n",
      "0 1 0 4 5 3\n",
      "Fitting on 0-4-5, testing on 3...\n",
      "0 2 3 4 5 3\n",
      "Fitting on 3-4-5, cross-validating on 3...\n",
      "0 3 0 2 5 2\n",
      "Fitting on 0-2-5, cross-validating on 2...\n",
      "0 3 0 2 5 3\n",
      "Fitting on 0-2-5, testing on 3...\n",
      "0 1 0 4 5 4\n",
      "Fitting on 0-4-5, cross-validating on 4...\n",
      "0 1 0 4 5 5\n",
      "Fitting on 0-4-5, cross-validating on 5...\n",
      "0 1 1 2 3 0\n",
      "Fitting on 1-2-3, testing on 0...\n",
      "0 1 1 2 3 1\n",
      "Fitting on 1-2-3, cross-validating on 1...\n",
      "0 2 3 4 5 4\n",
      "Fitting on 3-4-5, cross-validating on 4...\n",
      "0 2 3 4 5 5\n",
      "Fitting on 3-4-5, cross-validating on 5...\n",
      "0 3 0 2 5 4\n",
      "Fitting on 0-2-5, testing on 4...\n",
      "0 3 0 2 5 5\n",
      "Fitting on 0-2-5, cross-validating on 5...\n",
      "0 3 0 3 4 0\n",
      "Fitting on 0-3-4, cross-validating on 0...\n",
      "0 1 1 2 3 2\n",
      "Fitting on 1-2-3, cross-validating on 2...\n",
      "0 1 1 2 3 3\n",
      "Fitting on 1-2-3, cross-validating on 3...\n",
      "0 1 1 2 3 4\n",
      "Fitting on 1-2-3, testing on 4...\n",
      "0 1 1 2 3 5\n",
      "Fitting on 1-2-3, testing on 5...\n",
      "0 1 1 2 4 0\n",
      "Fitting on 1-2-4, testing on 0...\n",
      "0 1 1 2 4 1\n",
      "Fitting on 1-2-4, cross-validating on 1...\n",
      "0 3 0 3 4 1\n",
      "Fitting on 0-3-4, testing on 1...\n",
      "0 3 0 3 4 2\n",
      "Fitting on 0-3-4, testing on 2...\n",
      "0 3 0 3 4 3\n",
      "Fitting on 0-3-4, cross-validating on 3...\n",
      "0 3 0 3 4 4\n",
      "Fitting on 0-3-4, cross-validating on 4...\n",
      "0 3 0 3 4 5\n",
      "Fitting on 0-3-4, testing on 5...\n",
      "0 1 1 2 4 2\n",
      "Fitting on 1-2-4, cross-validating on 2...\n",
      "0 1 1 2 4 3\n",
      "Fitting on 1-2-4, testing on 3...\n",
      "0 1 1 2 4 4\n",
      "Fitting on 1-2-4, cross-validating on 4...\n",
      "0 1 1 2 4 5\n",
      "Fitting on 1-2-4, testing on 5...\n",
      "0 3 0 3 5 0\n",
      "Fitting on 0-3-5, cross-validating on 0...\n",
      "0 1 1 2 5 0\n",
      "Fitting on 1-2-5, testing on 0...\n",
      "0 1 1 2 5 1\n",
      "Fitting on 1-2-5, cross-validating on 1...\n",
      "0 1 1 2 5 2\n",
      "Fitting on 1-2-5, cross-validating on 2...\n",
      "0 1 1 2 5 3\n",
      "Fitting on 1-2-5, testing on 3...\n",
      "0 3 0 3 5 1\n",
      "Fitting on 0-3-5, testing on 1...\n",
      "0 1 1 2 5 4\n",
      "Fitting on 1-2-5, testing on 4...\n",
      "0 3 0 3 5 2\n",
      "Fitting on 0-3-5, testing on 2...\n",
      "0 1 1 2 5 5\n",
      "Fitting on 1-2-5, cross-validating on 5...\n",
      "0 1 1 3 4 0\n",
      "Fitting on 1-3-4, testing on 0...\n",
      "0 1 1 3 4 1\n",
      "Fitting on 1-3-4, cross-validating on 1...\n",
      "0 3 0 3 5 3\n",
      "Fitting on 0-3-5, cross-validating on 3...\n",
      "0 3 0 3 5 4\n",
      "Fitting on 0-3-5, testing on 4...\n",
      "0 3 0 3 5 5\n",
      "Fitting on 0-3-5, cross-validating on 5...\n",
      "0 3 0 4 5 0\n",
      "Fitting on 0-4-5, cross-validating on 0...\n",
      "0 1 1 3 4 2\n",
      "Fitting on 1-3-4, testing on 2...\n",
      "0 1 1 3 4 3\n",
      "Fitting on 1-3-4, cross-validating on 3...\n",
      "0 1 1 3 4 4\n",
      "Fitting on 1-3-4, cross-validating on 4...\n",
      "0 1 1 3 4 5\n",
      "Fitting on 1-3-4, testing on 5...\n",
      "0 1 1 3 5 0\n",
      "Fitting on 1-3-5, testing on 0...\n",
      "0 1 1 3 5 1\n",
      "Fitting on 1-3-5, cross-validating on 1...\n",
      "0 3 0 4 5 1\n",
      "Fitting on 0-4-5, testing on 1...\n",
      "0 3 0 4 5 2\n",
      "Fitting on 0-4-5, testing on 2...\n",
      "0 3 0 4 5 3\n",
      "Fitting on 0-4-5, testing on 3...\n",
      "0 1 1 3 5 2\n",
      "Fitting on 1-3-5, testing on 2...\n",
      "0 1 1 3 5 3\n",
      "Fitting on 1-3-5, cross-validating on 3...\n",
      "0 1 1 3 5 4\n",
      "Fitting on 1-3-5, testing on 4...\n",
      "0 3 0 4 5 4\n",
      "Fitting on 0-4-5, cross-validating on 4...\n",
      "0 3 0 4 5 5\n",
      "Fitting on 0-4-5, cross-validating on 5...\n",
      "0 3 1 2 3 0\n",
      "Fitting on 1-2-3, testing on 0...\n",
      "0 1 1 3 5 5\n",
      "Fitting on 1-3-5, cross-validating on 5...\n",
      "0 1 1 4 5 0\n",
      "Fitting on 1-4-5, testing on 0...\n",
      "0 3 1 2 3 1\n",
      "Fitting on 1-2-3, cross-validating on 1...\n",
      "0 1 1 4 5 1\n",
      "Fitting on 1-4-5, cross-validating on 1...\n",
      "0 1 1 4 5 2\n",
      "Fitting on 1-4-5, testing on 2...\n",
      "0 1 1 4 5 3\n",
      "Fitting on 1-4-5, testing on 3...\n",
      "0 3 1 2 3 2\n",
      "Fitting on 1-2-3, cross-validating on 2...\n",
      "0 3 1 2 3 3\n",
      "Fitting on 1-2-3, cross-validating on 3...\n",
      "0 3 1 2 3 4\n",
      "Fitting on 1-2-3, testing on 4...\n",
      "0 1 1 4 5 4\n",
      "Fitting on 1-4-5, cross-validating on 4...\n",
      "0 1 1 4 5 5\n",
      "Fitting on 1-4-5, cross-validating on 5...\n",
      "0 1 2 3 4 0\n",
      "Fitting on 2-3-4, testing on 0...\n",
      "0 1 2 3 4 1\n",
      "Fitting on 2-3-4, testing on 1...\n",
      "0 3 1 2 3 5\n",
      "Fitting on 1-2-3, testing on 5...\n",
      "0 1 2 3 4 2\n",
      "Fitting on 2-3-4, cross-validating on 2...\n",
      "0 3 1 2 4 0\n",
      "Fitting on 1-2-4, testing on 0...\n",
      "0 3 1 2 4 1\n",
      "Fitting on 1-2-4, cross-validating on 1...\n",
      "0 1 2 3 4 3\n",
      "Fitting on 2-3-4, cross-validating on 3...\n",
      "0 1 2 3 4 4\n",
      "Fitting on 2-3-4, cross-validating on 4...\n",
      "0 1 2 3 4 5\n",
      "Fitting on 2-3-4, testing on 5...\n",
      "0 1 2 3 5 0\n",
      "Fitting on 2-3-5, testing on 0...\n",
      "0 1 2 3 5 1\n",
      "Fitting on 2-3-5, testing on 1...\n",
      "0 1 2 3 5 2\n",
      "Fitting on 2-3-5, cross-validating on 2...\n",
      "0 3 1 2 4 2\n",
      "Fitting on 1-2-4, cross-validating on 2...\n",
      "0 3 1 2 4 3\n",
      "Fitting on 1-2-4, testing on 3...\n",
      "0 3 1 2 4 4\n",
      "Fitting on 1-2-4, cross-validating on 4...\n",
      "0 3 1 2 4 5\n",
      "Fitting on 1-2-4, testing on 5...\n",
      "0 1 2 3 5 3\n",
      "Fitting on 2-3-5, cross-validating on 3...\n",
      "0 1 2 3 5 4\n",
      "Fitting on 2-3-5, testing on 4...\n",
      "0 3 1 2 5 0\n",
      "Fitting on 1-2-5, testing on 0...\n",
      "0 1 2 3 5 5\n",
      "Fitting on 2-3-5, cross-validating on 5...\n",
      "0 1 2 4 5 0\n",
      "Fitting on 2-4-5, testing on 0...\n",
      "0 3 1 2 5 1\n",
      "Fitting on 1-2-5, cross-validating on 1...\n",
      "0 1 2 4 5 1\n",
      "Fitting on 2-4-5, testing on 1...\n",
      "0 1 2 4 5 2\n",
      "Fitting on 2-4-5, cross-validating on 2...\n",
      "0 1 2 4 5 3\n",
      "Fitting on 2-4-5, testing on 3...\n",
      "0 3 1 2 5 2\n",
      "Fitting on 1-2-5, cross-validating on 2...\n",
      "0 3 1 2 5 3\n",
      "Fitting on 1-2-5, testing on 3...\n",
      "0 1 2 4 5 4\n",
      "Fitting on 2-4-5, cross-validating on 4...\n",
      "0 1 2 4 5 5\n",
      "Fitting on 2-4-5, cross-validating on 5...\n",
      "0 1 3 4 5 0\n",
      "Fitting on 3-4-5, testing on 0...\n",
      "0 3 1 2 5 4\n",
      "Fitting on 1-2-5, testing on 4...\n",
      "0 1 3 4 5 1\n",
      "Fitting on 3-4-5, testing on 1...\n",
      "0 1 3 4 5 2\n",
      "Fitting on 3-4-5, testing on 2...\n",
      "0 3 1 2 5 5\n",
      "Fitting on 1-2-5, cross-validating on 5...\n",
      "0 3 1 3 4 0\n",
      "Fitting on 1-3-4, testing on 0...\n",
      "0 1 3 4 5 3\n",
      "Fitting on 3-4-5, cross-validating on 3...\n",
      "0 3 1 3 4 1\n",
      "Fitting on 1-3-4, cross-validating on 1...\n",
      "0 1 3 4 5 4\n",
      "Fitting on 3-4-5, cross-validating on 4...\n",
      "0 1 3 4 5 5\n",
      "Fitting on 3-4-5, cross-validating on 5...\n",
      "0 3 1 3 4 2\n",
      "Fitting on 1-3-4, testing on 2...\n",
      "0 3 1 3 4 3\n",
      "Fitting on 1-3-4, cross-validating on 3...\n",
      "0 3 1 3 4 4\n",
      "Fitting on 1-3-4, cross-validating on 4...\n",
      "0 3 1 3 4 5\n",
      "Fitting on 1-3-4, testing on 5...\n",
      "0 3 1 3 5 0\n",
      "Fitting on 1-3-5, testing on 0...\n",
      "0 3 1 3 5 1\n",
      "Fitting on 1-3-5, cross-validating on 1...\n",
      "0 3 1 3 5 2\n",
      "Fitting on 1-3-5, testing on 2...\n",
      "0 3 1 3 5 3\n",
      "Fitting on 1-3-5, cross-validating on 3...\n",
      "0 3 1 3 5 4\n",
      "Fitting on 1-3-5, testing on 4...\n",
      "0 3 1 3 5 5\n",
      "Fitting on 1-3-5, cross-validating on 5...\n",
      "0 3 1 4 5 0\n",
      "Fitting on 1-4-5, testing on 0...\n",
      "0 3 1 4 5 1\n",
      "Fitting on 1-4-5, cross-validating on 1...\n",
      "0 3 1 4 5 2\n",
      "Fitting on 1-4-5, testing on 2...\n",
      "0 3 1 4 5 3\n",
      "Fitting on 1-4-5, testing on 3...\n",
      "0 3 1 4 5 4\n",
      "Fitting on 1-4-5, cross-validating on 4...\n",
      "0 3 1 4 5 5\n",
      "Fitting on 1-4-5, cross-validating on 5...\n",
      "0 3 2 3 4 0\n",
      "Fitting on 2-3-4, testing on 0...\n",
      "0 3 2 3 4 1\n",
      "Fitting on 2-3-4, testing on 1...\n",
      "0 3 2 3 4 2\n",
      "Fitting on 2-3-4, cross-validating on 2...\n",
      "0 3 2 3 4 3\n",
      "Fitting on 2-3-4, cross-validating on 3...\n",
      "0 3 2 3 4 4\n",
      "Fitting on 2-3-4, cross-validating on 4...\n",
      "0 3 2 3 4 5\n",
      "Fitting on 2-3-4, testing on 5...\n",
      "0 3 2 3 5 0\n",
      "Fitting on 2-3-5, testing on 0...\n",
      "0 3 2 3 5 1\n",
      "Fitting on 2-3-5, testing on 1...\n",
      "0 3 2 3 5 2\n",
      "Fitting on 2-3-5, cross-validating on 2...\n",
      "0 3 2 3 5 3\n",
      "Fitting on 2-3-5, cross-validating on 3...\n",
      "0 3 2 3 5 4\n",
      "Fitting on 2-3-5, testing on 4...\n",
      "0 3 2 3 5 5\n",
      "Fitting on 2-3-5, cross-validating on 5...\n",
      "0 3 2 4 5 0\n",
      "Fitting on 2-4-5, testing on 0...\n",
      "0 3 2 4 5 1\n",
      "Fitting on 2-4-5, testing on 1...\n",
      "0 3 2 4 5 2\n",
      "Fitting on 2-4-5, cross-validating on 2...\n",
      "0 3 2 4 5 3\n",
      "Fitting on 2-4-5, testing on 3...\n",
      "0 3 2 4 5 4\n",
      "Fitting on 2-4-5, cross-validating on 4...\n",
      "0 3 2 4 5 5\n",
      "Fitting on 2-4-5, cross-validating on 5...\n",
      "0 3 3 4 5 0\n",
      "Fitting on 3-4-5, testing on 0...\n",
      "0 3 3 4 5 1\n",
      "Fitting on 3-4-5, testing on 1...\n",
      "0 3 3 4 5 2\n",
      "Fitting on 3-4-5, testing on 2...\n",
      "0 3 3 4 5 3\n",
      "Fitting on 3-4-5, cross-validating on 3...\n",
      "0 3 3 4 5 4\n",
      "Fitting on 3-4-5, cross-validating on 4...\n",
      "0 3 3 4 5 5\n",
      "Fitting on 3-4-5, cross-validating on 5...\n",
      "1 0 0 1 2 0\n",
      "Fitting on 0-1-2, cross-validating on 0...\n",
      "1 1 0 1 2 0\n",
      "Fitting on 0-1-2, cross-validating on 0...\n",
      "Fitting on 0-1-2, cross-validating on 0...\n",
      "1 2 0 1 2 0\n",
      "1 3 0 1 2 0\n",
      "Fitting on 0-1-2, cross-validating on 0...\n",
      "1 0 0 1 2 1\n",
      "Fitting on 0-1-2, cross-validating on 1...\n",
      "1 0 0 1 2 2\n",
      "Fitting on 0-1-2, cross-validating on 2...\n",
      "1 0 0 1 2 3\n",
      "Fitting on 0-1-2, testing on 3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 0 1 2 4\n",
      "Fitting on 0-1-2, testing on 4...\n",
      "1 0 0 1 2 5\n",
      "Fitting on 0-1-2, testing on 5...\n",
      "1 0 0 1 3 0\n",
      "Fitting on 0-1-3, cross-validating on 0...\n",
      "1 2 0 1 2 1\n",
      "Fitting on 0-1-2, cross-validating on 1...\n",
      "1 2 0 1 2 2\n",
      "Fitting on 0-1-2, cross-validating on 2...\n",
      "1 2 0 1 2 3\n",
      "Fitting on 0-1-2, testing on 3...\n",
      "1 2 0 1 2 4\n",
      "Fitting on 0-1-2, testing on 4...\n",
      "1 0 0 1 3 1\n",
      "Fitting on 0-1-3, cross-validating on 1...\n",
      "1 0 0 1 3 2\n",
      "Fitting on 0-1-3, testing on 2...\n",
      "1 2 0 1 2 5\n",
      "Fitting on 0-1-2, testing on 5...\n",
      "1 0 0 1 3 3\n",
      "Fitting on 0-1-3, cross-validating on 3...\n",
      "1 0 0 1 3 4\n",
      "Fitting on 0-1-3, testing on 4...\n",
      "1 0 0 1 3 5\n",
      "Fitting on 0-1-3, testing on 5...\n",
      "1 2 0 1 3 0\n",
      "Fitting on 0-1-3, cross-validating on 0...\n",
      "1 0 0 1 4 0\n",
      "Fitting on 0-1-4, cross-validating on 0...\n",
      "1 1 0 1 2 1\n",
      "Fitting on 0-1-2, cross-validating on 1...\n",
      "1 1 0 1 2 2\n",
      "Fitting on 0-1-2, cross-validating on 2...\n",
      "1 1 0 1 2 3\n",
      "Fitting on 0-1-2, testing on 3...\n",
      "1 0 0 1 4 1\n",
      "Fitting on 0-1-4, cross-validating on 1...\n",
      "1 0 0 1 4 2\n",
      "Fitting on 0-1-4, testing on 2...\n",
      "1 0 0 1 4 3\n",
      "Fitting on 0-1-4, testing on 3...\n",
      "1 1 0 1 2 4\n",
      "Fitting on 0-1-2, testing on 4...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b32b923f599a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m#         init_steps(i,j,surf[j][:][i],surfla[:][i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# for every subfeatureset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_steps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurfla\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jagrio/.local/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jagrio/.local/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Cross surface validation for 3 out of 6 surfaces\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ;\n",
    "decomp = PCA(n_components=20)\n",
    "def filename(i,j,k1,k2,k3,l):\n",
    "    return 'fs_'+str(i)+'_subfs_'+str(j)+'_tr1_'+str(k1)+'_tr2_'+str(k2)+'_tr3_'+str(k3)+'_ts_'+str(l)\n",
    "\n",
    "def cross_fit(i,j,k1,k2,k3,l,data,labels,data2,labels2,pipe):\n",
    "    fileid = 'tmpresults3_transtart/'+filename(i,j,k1,k2,k3,l)+'.npz'\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k1,k2,k3,l\n",
    "        if k1==l or k2==l or k3==l: # perform K-fold      \n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+', cross-validating on '+str(l)+'...'\n",
    "            if l == k1: # copy if existent from the other sibling file\n",
    "                tmpcopyfileid1 = 'tmpresults3_transtart/'+filename(i,j,k1,k2,k3,k2)+'.npz'\n",
    "                tmpcopyfileid2 = 'tmpresults3_transtart/'+filename(i,j,k1,k2,k3,k3)+'.npz'\n",
    "            elif l == k2:   # same as above\n",
    "                tmpcopyfileid1 = 'tmpresults3_transtart/'+filename(i,j,k1,k2,k3,k1)+'.npz'\n",
    "                tmpcopyfileid2 = 'tmpresults3_transtart/'+filename(i,j,k1,k2,k3,k3)+'.npz'\n",
    "            else:\n",
    "                tmpcopyfileid1 = 'tmpresults3_transtart/'+filename(i,j,k1,k2,k3,k1)+'.npz'\n",
    "                tmpcopyfileid2 = 'tmpresults3_transtart/'+filename(i,j,k1,k2,k3,k2)+'.npz'\n",
    "            if not os.path.isfile(tmpcopyfileid1) and not os.path.isfile(tmpcopyfileid2):\n",
    "                folds = cv.split(data, labels)\n",
    "                cm_all = np.zeros((2,2))\n",
    "                for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                    x_train, x_test = data[train_ind], data[test_ind]\n",
    "                    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                    model = pipe.fit(x_train,y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                    cm_all += cm/5.\n",
    "            else:\n",
    "                if os.path.isfile(tmpcopyfileid1):\n",
    "                    cm_all = np.load(tmpcopyfileid1)['cm']\n",
    "                    model = np.load(tmpcopyfileid1)['model'][0]\n",
    "                else:\n",
    "                    cm_all = np.load(tmpcopyfileid2)['cm']\n",
    "                    model = np.load(tmpcopyfileid2)['model'][0]\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+', testing on '+str(l)+'...'\n",
    "            model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps(i,j,jmax,surf,surfla):\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k1 in range(surf.shape[0]): # for every training surface1\n",
    "        for k2 in range(surf.shape[0]): # for every training surface2\n",
    "            if k2 > k1:\n",
    "                for k3 in range(surf.shape[0]):\n",
    "                    if k3 > k2:\n",
    "                        for l in range(surf.shape[0]): # for every testing surface\n",
    "        #                     if l != k1 and l != k2:\n",
    "                #             cross_fit(i,j,k,l,surf[k][::100,:],surfla[k][::100],surf[l][::100,:],surfla[l][::100],pipe)\n",
    "                            tr_surf, tr_surfla = np.concatenate((surf[k1],surf[k2],surf[k3]),axis=0), np.concatenate((surfla[:,k1],surfla[:,k2],surfla[:,k3]),axis=0)\n",
    "                            ts_surf, ts_surfla = surf[l], surfla[:,l]\n",
    "                #                 print tr_surf.shape, tr_surfla.shape\n",
    "                            cross_fit(i,j,k1,k2,k3,l,tr_surf,tr_surfla,ts_surf,ts_surfla,pipe)\n",
    "\n",
    "for i in range(surf.shape[2]): # for every featureset\n",
    "#     for j in range(surf.shape[0]): # for every subfeatureset\n",
    "#         if j==surf.shape[0]-1:\n",
    "#             featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "#         else:\n",
    "#             featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "#         pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "#         init_steps(i,j,surf[j][:][i],surfla[:][i])\n",
    "    # for every subfeatureset\n",
    "    [Parallel(n_jobs=-1)([delayed(init_steps) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) for j in range(surf.shape[0])])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 1 2 3 0\n",
      "Fitting on 0-1-2-3, cross-validating on 0...\n",
      "0 1 0 1 2 3 0\n",
      "Fitting on 0-1-2-3, cross-validating on 0...\n",
      "Fitting on 0-1-2-3, cross-validating on 0...\n",
      "0 2 0 1 2 3 0\n",
      "0 3 0 1 2 3 0\n",
      "Fitting on 0-1-2-3, cross-validating on 0...\n",
      "0 0 0 1 2 3 1\n",
      "Fitting on 0-1-2-3, cross-validating on 1...\n",
      "0 0 0 1 2 3 2\n",
      "Fitting on 0-1-2-3, cross-validating on 2...\n",
      "0 0 0 1 2 3 3\n",
      "Fitting on 0-1-2-3, cross-validating on 3...\n",
      "0 0 0 1 2 3 4\n",
      "Fitting on 0-1-2-3, testing on 4...\n",
      "0 0 0 1 2 3 5\n",
      "Fitting on 0-1-2-3, testing on 5...\n",
      "0 0 0 1 2 4 0\n",
      "Fitting on 0-1-2-4, cross-validating on 0...\n",
      "0 2 0 1 2 3 1\n",
      "Fitting on 0-1-2-3, cross-validating on 1...\n",
      "0 2 0 1 2 3 2\n",
      "Fitting on 0-1-2-3, cross-validating on 2...\n",
      "0 2 0 1 2 3 3\n",
      "Fitting on 0-1-2-3, cross-validating on 3...\n",
      "0 2 0 1 2 3 4\n",
      "Fitting on 0-1-2-3, testing on 4...\n",
      "0 2 0 1 2 3 5\n",
      "Fitting on 0-1-2-3, testing on 5...\n",
      "0 0 0 1 2 4 1\n",
      "Fitting on 0-1-2-4, cross-validating on 1...\n",
      "0 0 0 1 2 4 2\n",
      "Fitting on 0-1-2-4, cross-validating on 2...\n",
      "0 0 0 1 2 4 3\n",
      "Fitting on 0-1-2-4, testing on 3...\n",
      "0 0 0 1 2 4 4\n",
      "Fitting on 0-1-2-4, cross-validating on 4...\n",
      "0 0 0 1 2 4 5\n",
      "Fitting on 0-1-2-4, testing on 5...\n",
      "0 2 0 1 2 4 0\n",
      "Fitting on 0-1-2-4, cross-validating on 0...\n",
      "0 0 0 1 2 5 0\n",
      "Fitting on 0-1-2-5, cross-validating on 0...\n",
      "0 1 0 1 2 3 1\n",
      "Fitting on 0-1-2-3, cross-validating on 1...\n",
      "0 1 0 1 2 3 2\n",
      "Fitting on 0-1-2-3, cross-validating on 2...\n",
      "0 1 0 1 2 3 3\n",
      "Fitting on 0-1-2-3, cross-validating on 3...\n",
      "0 1 0 1 2 3 4\n",
      "Fitting on 0-1-2-3, testing on 4...\n",
      "0 0 0 1 2 5 1\n",
      "Fitting on 0-1-2-5, cross-validating on 1...\n",
      "0 0 0 1 2 5 2\n",
      "Fitting on 0-1-2-5, cross-validating on 2...\n",
      "0 0 0 1 2 5 3\n",
      "Fitting on 0-1-2-5, testing on 3...\n",
      "0 0 0 1 2 5 4\n",
      "Fitting on 0-1-2-5, testing on 4...\n",
      "0 0 0 1 2 5 5\n",
      "Fitting on 0-1-2-5, cross-validating on 5...\n",
      "0 0 0 1 3 4 0\n",
      "Fitting on 0-1-3-4, cross-validating on 0...\n",
      "0 1 0 1 2 3 5\n",
      "Fitting on 0-1-2-3, testing on 5...\n",
      "0 2 0 1 2 4 1\n",
      "Fitting on 0-1-2-4, cross-validating on 1...\n",
      "0 2 0 1 2 4 2\n",
      "Fitting on 0-1-2-4, cross-validating on 2...\n",
      "0 2 0 1 2 4 3\n",
      "Fitting on 0-1-2-4, testing on 3...\n",
      "0 2 0 1 2 4 4\n",
      "Fitting on 0-1-2-4, cross-validating on 4...\n",
      "0 2 0 1 2 4 5\n",
      "Fitting on 0-1-2-4, testing on 5...\n",
      "0 0 0 1 3 4 1\n",
      "Fitting on 0-1-3-4, cross-validating on 1...\n",
      "0 0 0 1 3 4 2\n",
      "Fitting on 0-1-3-4, testing on 2...\n",
      "0 1 0 1 2 4 0\n",
      "Fitting on 0-1-2-4, cross-validating on 0...\n",
      "0 3 0 1 2 3 1\n",
      "Fitting on 0-1-2-3, cross-validating on 1...\n",
      "0 3 0 1 2 3 2\n",
      "Fitting on 0-1-2-3, cross-validating on 2...\n",
      "0 3 0 1 2 3 3\n",
      "Fitting on 0-1-2-3, cross-validating on 3...\n",
      "0 3 0 1 2 3 4\n",
      "Fitting on 0-1-2-3, testing on 4...\n",
      "0 0 0 1 3 4 3\n",
      "Fitting on 0-1-3-4, cross-validating on 3...\n",
      "0 0 0 1 3 4 4\n",
      "Fitting on 0-1-3-4, cross-validating on 4...\n",
      "0 0 0 1 3 4 5\n",
      "Fitting on 0-1-3-4, testing on 5...\n",
      "0 2 0 1 2 5 0\n",
      "Fitting on 0-1-2-5, cross-validating on 0...\n",
      "0 0 0 1 3 5 0\n",
      "Fitting on 0-1-3-5, cross-validating on 0...\n",
      "0 0 0 1 3 5 1\n",
      "Fitting on 0-1-3-5, cross-validating on 1...\n",
      "0 0 0 1 3 5 2\n",
      "Fitting on 0-1-3-5, testing on 2...\n",
      "0 3 0 1 2 3 5\n",
      "Fitting on 0-1-2-3, testing on 5...\n",
      "0 0 0 1 3 5 3\n",
      "Fitting on 0-1-3-5, cross-validating on 3...\n",
      "0 0 0 1 3 5 4\n",
      "Fitting on 0-1-3-5, testing on 4...\n",
      "0 0 0 1 3 5 5\n",
      "Fitting on 0-1-3-5, cross-validating on 5...\n",
      "0 0 0 1 4 5 0\n",
      "Fitting on 0-1-4-5, cross-validating on 0...\n",
      "0 2 0 1 2 5 1\n",
      "Fitting on 0-1-2-5, cross-validating on 1...\n",
      "0 2 0 1 2 5 2\n",
      "Fitting on 0-1-2-5, cross-validating on 2...\n",
      "0 2 0 1 2 5 3\n",
      "Fitting on 0-1-2-5, testing on 3...\n",
      "0 2 0 1 2 5 4\n",
      "Fitting on 0-1-2-5, testing on 4...\n",
      "0 0 0 1 4 5 1\n",
      "Fitting on 0-1-4-5, cross-validating on 1...\n",
      "0 0 0 1 4 5 2\n",
      "Fitting on 0-1-4-5, testing on 2...\n",
      "0 3 0 1 2 4 0\n",
      "Fitting on 0-1-2-4, cross-validating on 0...\n",
      "0 2 0 1 2 5 5\n",
      "Fitting on 0-1-2-5, cross-validating on 5...\n",
      "0 2 0 1 3 4 0\n",
      "Fitting on 0-1-3-4, cross-validating on 0...\n",
      "0 0 0 1 4 5 3\n",
      "Fitting on 0-1-4-5, testing on 3...\n",
      "0 0 0 1 4 5 4\n",
      "Fitting on 0-1-4-5, cross-validating on 4...\n",
      "0 0 0 1 4 5 5\n",
      "Fitting on 0-1-4-5, cross-validating on 5...\n",
      "0 0 0 2 3 4 0\n",
      "Fitting on 0-2-3-4, cross-validating on 0...\n",
      "0 1 0 1 2 4 1\n",
      "Fitting on 0-1-2-4, cross-validating on 1...\n",
      "0 1 0 1 2 4 2\n",
      "Fitting on 0-1-2-4, cross-validating on 2...\n",
      "0 1 0 1 2 4 3\n",
      "Fitting on 0-1-2-4, testing on 3...\n",
      "0 0 0 2 3 4 1\n",
      "Fitting on 0-2-3-4, testing on 1...\n",
      "0 0 0 2 3 4 2\n",
      "Fitting on 0-2-3-4, cross-validating on 2...\n",
      "0 0 0 2 3 4 3\n",
      "Fitting on 0-2-3-4, cross-validating on 3...\n",
      "0 0 0 2 3 4 4\n",
      "Fitting on 0-2-3-4, cross-validating on 4...\n",
      "0 0 0 2 3 4 5\n",
      "Fitting on 0-2-3-4, testing on 5...\n",
      "0 1 0 1 2 4 4\n",
      "Fitting on 0-1-2-4, cross-validating on 4...\n",
      "0 1 0 1 2 4 5\n",
      "Fitting on 0-1-2-4, testing on 5...\n",
      "0 0 0 2 3 5 0\n",
      "Fitting on 0-2-3-5, cross-validating on 0...\n",
      "0 2 0 1 3 4 1\n",
      "Fitting on 0-1-3-4, cross-validating on 1...\n",
      "0 2 0 1 3 4 2\n",
      "Fitting on 0-1-3-4, testing on 2...\n",
      "0 2 0 1 3 4 3\n",
      "Fitting on 0-1-3-4, cross-validating on 3...\n",
      "0 2 0 1 3 4 4\n",
      "Fitting on 0-1-3-4, cross-validating on 4...\n",
      "0 2 0 1 3 4 5\n",
      "Fitting on 0-1-3-4, testing on 5...\n",
      "0 1 0 1 2 5 0\n",
      "Fitting on 0-1-2-5, cross-validating on 0...\n",
      "0 0 0 2 3 5 1\n",
      "Fitting on 0-2-3-5, testing on 1...\n",
      "0 2 0 1 3 5 0\n",
      "Fitting on 0-1-3-5, cross-validating on 0...\n",
      "0 0 0 2 3 5 2\n",
      "Fitting on 0-2-3-5, cross-validating on 2...\n",
      "0 0 0 2 3 5 3\n",
      "Fitting on 0-2-3-5, cross-validating on 3...\n",
      "0 0 0 2 3 5 4\n",
      "Fitting on 0-2-3-5, testing on 4...\n",
      "0 0 0 2 3 5 5\n",
      "Fitting on 0-2-3-5, cross-validating on 5...\n",
      "0 0 0 2 4 5 0\n",
      "Fitting on 0-2-4-5, cross-validating on 0...\n",
      "0 0 0 2 4 5 1\n",
      "Fitting on 0-2-4-5, testing on 1...\n",
      "0 0 0 2 4 5 2\n",
      "Fitting on 0-2-4-5, cross-validating on 2...\n",
      "0 0 0 2 4 5 3\n",
      "Fitting on 0-2-4-5, testing on 3...\n",
      "0 0 0 2 4 5 4\n",
      "Fitting on 0-2-4-5, cross-validating on 4...\n",
      "0 0 0 2 4 5 5\n",
      "Fitting on 0-2-4-5, cross-validating on 5...\n",
      "0 0 0 3 4 5 0\n",
      "Fitting on 0-3-4-5, cross-validating on 0...\n",
      "0 2 0 1 3 5 1\n",
      "Fitting on 0-1-3-5, cross-validating on 1...\n",
      "0 2 0 1 3 5 2\n",
      "Fitting on 0-1-3-5, testing on 2...\n",
      "0 2 0 1 3 5 3\n",
      "Fitting on 0-1-3-5, cross-validating on 3...\n",
      "0 2 0 1 3 5 4\n",
      "Fitting on 0-1-3-5, testing on 4...\n",
      "0 3 0 1 2 4 1\n",
      "Fitting on 0-1-2-4, cross-validating on 1...\n",
      "0 3 0 1 2 4 2\n",
      "Fitting on 0-1-2-4, cross-validating on 2...\n",
      "0 3 0 1 2 4 3\n",
      "Fitting on 0-1-2-4, testing on 3...\n",
      "0 0 0 3 4 5 1\n",
      "Fitting on 0-3-4-5, testing on 1...\n",
      "0 2 0 1 3 5 5\n",
      "Fitting on 0-1-3-5, cross-validating on 5...\n",
      "0 2 0 1 4 5 0\n",
      "Fitting on 0-1-4-5, cross-validating on 0...\n",
      "0 0 0 3 4 5 2\n",
      "Fitting on 0-3-4-5, testing on 2...\n",
      "0 0 0 3 4 5 3\n",
      "Fitting on 0-3-4-5, cross-validating on 3...\n",
      "0 0 0 3 4 5 4\n",
      "Fitting on 0-3-4-5, cross-validating on 4...\n",
      "0 0 0 3 4 5 5\n",
      "Fitting on 0-3-4-5, cross-validating on 5...\n",
      "0 0 1 2 3 4 0\n",
      "Fitting on 1-2-3-4, testing on 0...\n",
      "0 1 0 1 2 5 1\n",
      "Fitting on 0-1-2-5, cross-validating on 1...\n",
      "0 1 0 1 2 5 2\n",
      "Fitting on 0-1-2-5, cross-validating on 2...\n",
      "0 1 0 1 2 5 3\n",
      "Fitting on 0-1-2-5, testing on 3...\n",
      "0 0 1 2 3 4 1\n",
      "Fitting on 1-2-3-4, cross-validating on 1...\n",
      "0 3 0 1 2 4 4\n",
      "Fitting on 0-1-2-4, cross-validating on 4...\n",
      "0 3 0 1 2 4 5\n",
      "Fitting on 0-1-2-4, testing on 5...\n",
      "0 1 0 1 2 5 4\n",
      "Fitting on 0-1-2-5, testing on 4...\n",
      "0 0 1 2 3 4 2\n",
      "Fitting on 1-2-3-4, cross-validating on 2...\n",
      "0 0 1 2 3 4 3\n",
      "Fitting on 1-2-3-4, cross-validating on 3...\n",
      "0 0 1 2 3 4 4\n",
      "Fitting on 1-2-3-4, cross-validating on 4...\n",
      "0 0 1 2 3 4 5\n",
      "Fitting on 1-2-3-4, testing on 5...\n",
      "0 2 0 1 4 5 1\n",
      "Fitting on 0-1-4-5, cross-validating on 1...\n",
      "0 2 0 1 4 5 2\n",
      "Fitting on 0-1-4-5, testing on 2...\n",
      "0 0 1 2 3 5 0\n",
      "Fitting on 1-2-3-5, testing on 0...\n",
      "0 0 1 2 3 5 1\n",
      "Fitting on 1-2-3-5, cross-validating on 1...\n",
      "0 2 0 1 4 5 3\n",
      "Fitting on 0-1-4-5, testing on 3...\n",
      "0 1 0 1 2 5 5\n",
      "Fitting on 0-1-2-5, cross-validating on 5...\n",
      "0 1 0 1 3 4 0\n",
      "Fitting on 0-1-3-4, cross-validating on 0...\n",
      "0 3 0 1 2 5 0\n",
      "Fitting on 0-1-2-5, cross-validating on 0...\n",
      "0 2 0 1 4 5 4\n",
      "Fitting on 0-1-4-5, cross-validating on 4...\n",
      "0 2 0 1 4 5 5\n",
      "Fitting on 0-1-4-5, cross-validating on 5...\n",
      "0 2 0 2 3 4 0\n",
      "Fitting on 0-2-3-4, cross-validating on 0...\n",
      "0 0 1 2 3 5 2\n",
      "Fitting on 1-2-3-5, cross-validating on 2...\n",
      "0 0 1 2 3 5 3\n",
      "Fitting on 1-2-3-5, cross-validating on 3...\n",
      "0 0 1 2 3 5 4\n",
      "Fitting on 1-2-3-5, testing on 4...\n",
      "0 0 1 2 3 5 5\n",
      "Fitting on 1-2-3-5, cross-validating on 5...\n",
      "0 0 1 2 4 5 0\n",
      "Fitting on 1-2-4-5, testing on 0...\n",
      "0 0 1 2 4 5 1\n",
      "Fitting on 1-2-4-5, cross-validating on 1...\n",
      "0 0 1 2 4 5 2\n",
      "Fitting on 1-2-4-5, cross-validating on 2...\n",
      "0 0 1 2 4 5 3\n",
      "Fitting on 1-2-4-5, testing on 3...\n",
      "0 2 0 2 3 4 1\n",
      "Fitting on 0-2-3-4, testing on 1...\n",
      "0 0 1 2 4 5 4\n",
      "Fitting on 1-2-4-5, cross-validating on 4...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1 2 4 5 5\n",
      "Fitting on 1-2-4-5, cross-validating on 5...\n",
      "0 0 1 3 4 5 0\n",
      "Fitting on 1-3-4-5, testing on 0...\n",
      "0 0 1 3 4 5 1\n",
      "Fitting on 1-3-4-5, cross-validating on 1...\n",
      "0 2 0 2 3 4 2\n",
      "Fitting on 0-2-3-4, cross-validating on 2...\n",
      "0 2 0 2 3 4 3\n",
      "Fitting on 0-2-3-4, cross-validating on 3...\n",
      "0 2 0 2 3 4 4\n",
      "Fitting on 0-2-3-4, cross-validating on 4...\n",
      "0 2 0 2 3 4 5\n",
      "Fitting on 0-2-3-4, testing on 5...\n",
      "0 2 0 2 3 5 0\n",
      "Fitting on 0-2-3-5, cross-validating on 0...\n",
      "0 0 1 3 4 5 2\n",
      "Fitting on 1-3-4-5, testing on 2...\n",
      "0 1 0 1 3 4 1\n",
      "Fitting on 0-1-3-4, cross-validating on 1...\n",
      "0 1 0 1 3 4 2\n",
      "Fitting on 0-1-3-4, testing on 2...\n",
      "0 0 1 3 4 5 3\n",
      "Fitting on 1-3-4-5, cross-validating on 3...\n",
      "0 0 1 3 4 5 4\n",
      "Fitting on 1-3-4-5, cross-validating on 4...\n",
      "0 0 1 3 4 5 5\n",
      "Fitting on 1-3-4-5, cross-validating on 5...\n",
      "0 0 2 3 4 5 0\n",
      "Fitting on 2-3-4-5, testing on 0...\n",
      "0 0 2 3 4 5 1\n",
      "Fitting on 2-3-4-5, testing on 1...\n",
      "0 0 2 3 4 5 2\n",
      "Fitting on 2-3-4-5, cross-validating on 2...\n",
      "0 1 0 1 3 4 3\n",
      "Fitting on 0-1-3-4, cross-validating on 3...\n",
      "0 1 0 1 3 4 4\n",
      "Fitting on 0-1-3-4, cross-validating on 4...\n",
      "0 1 0 1 3 4 5\n",
      "Fitting on 0-1-3-4, testing on 5...\n",
      "0 2 0 2 3 5 1\n",
      "Fitting on 0-2-3-5, testing on 1...\n",
      "0 0 2 3 4 5 3\n",
      "Fitting on 2-3-4-5, cross-validating on 3...\n",
      "0 0 2 3 4 5 4\n",
      "Fitting on 2-3-4-5, cross-validating on 4...\n",
      "0 0 2 3 4 5 5\n",
      "Fitting on 2-3-4-5, cross-validating on 5...\n",
      "0 2 0 2 3 5 2\n",
      "Fitting on 0-2-3-5, cross-validating on 2...\n",
      "0 2 0 2 3 5 3\n",
      "Fitting on 0-2-3-5, cross-validating on 3...\n",
      "0 2 0 2 3 5 4\n",
      "Fitting on 0-2-3-5, testing on 4...\n",
      "0 1 0 1 3 5 0\n",
      "Fitting on 0-1-3-5, cross-validating on 0...\n",
      "0 3 0 1 2 5 1\n",
      "Fitting on 0-1-2-5, cross-validating on 1...\n",
      "0 3 0 1 2 5 2\n",
      "Fitting on 0-1-2-5, cross-validating on 2...\n",
      "0 3 0 1 2 5 3\n",
      "Fitting on 0-1-2-5, testing on 3...\n",
      "0 2 0 2 3 5 5\n",
      "Fitting on 0-2-3-5, cross-validating on 5...\n",
      "0 2 0 2 4 5 0\n",
      "Fitting on 0-2-4-5, cross-validating on 0...\n",
      "0 3 0 1 2 5 4\n",
      "Fitting on 0-1-2-5, testing on 4...\n",
      "0 2 0 2 4 5 1\n",
      "Fitting on 0-2-4-5, testing on 1...\n",
      "0 2 0 2 4 5 2\n",
      "Fitting on 0-2-4-5, cross-validating on 2...\n",
      "0 2 0 2 4 5 3\n",
      "Fitting on 0-2-4-5, testing on 3...\n",
      "0 3 0 1 2 5 5\n",
      "Fitting on 0-1-2-5, cross-validating on 5...\n",
      "0 3 0 1 3 4 0\n",
      "Fitting on 0-1-3-4, cross-validating on 0...\n",
      "0 2 0 2 4 5 4\n",
      "Fitting on 0-2-4-5, cross-validating on 4...\n",
      "0 2 0 2 4 5 5\n",
      "Fitting on 0-2-4-5, cross-validating on 5...\n",
      "0 2 0 3 4 5 0\n",
      "Fitting on 0-3-4-5, cross-validating on 0...\n",
      "0 1 0 1 3 5 1\n",
      "Fitting on 0-1-3-5, cross-validating on 1...\n",
      "0 1 0 1 3 5 2\n",
      "Fitting on 0-1-3-5, testing on 2...\n",
      "0 1 0 1 3 5 3\n",
      "Fitting on 0-1-3-5, cross-validating on 3...\n",
      "0 1 0 1 3 5 4\n",
      "Fitting on 0-1-3-5, testing on 4...\n",
      "0 2 0 3 4 5 1\n",
      "Fitting on 0-3-4-5, testing on 1...\n",
      "0 1 0 1 3 5 5\n",
      "Fitting on 0-1-3-5, cross-validating on 5...\n",
      "0 1 0 1 4 5 0\n",
      "Fitting on 0-1-4-5, cross-validating on 0...\n",
      "0 2 0 3 4 5 2\n",
      "Fitting on 0-3-4-5, testing on 2...\n",
      "0 2 0 3 4 5 3\n",
      "Fitting on 0-3-4-5, cross-validating on 3...\n",
      "0 2 0 3 4 5 4\n",
      "Fitting on 0-3-4-5, cross-validating on 4...\n",
      "0 2 0 3 4 5 5\n",
      "Fitting on 0-3-4-5, cross-validating on 5...\n",
      "0 2 1 2 3 4 0\n",
      "Fitting on 1-2-3-4, testing on 0...\n",
      "0 2 1 2 3 4 1\n",
      "Fitting on 1-2-3-4, cross-validating on 1...\n",
      "0 2 1 2 3 4 2\n",
      "Fitting on 1-2-3-4, cross-validating on 2...\n",
      "0 2 1 2 3 4 3\n",
      "Fitting on 1-2-3-4, cross-validating on 3...\n",
      "0 2 1 2 3 4 4\n",
      "Fitting on 1-2-3-4, cross-validating on 4...\n",
      "0 2 1 2 3 4 5\n",
      "Fitting on 1-2-3-4, testing on 5...\n",
      "0 3 0 1 3 4 1\n",
      "Fitting on 0-1-3-4, cross-validating on 1...\n",
      "0 3 0 1 3 4 2\n",
      "Fitting on 0-1-3-4, testing on 2...\n",
      "0 2 1 2 3 5 0\n",
      "Fitting on 1-2-3-5, testing on 0...\n",
      "0 1 0 1 4 5 1\n",
      "Fitting on 0-1-4-5, cross-validating on 1...\n",
      "0 1 0 1 4 5 2\n",
      "Fitting on 0-1-4-5, testing on 2...\n",
      "0 2 1 2 3 5 1\n",
      "Fitting on 1-2-3-5, cross-validating on 1...\n",
      "0 3 0 1 3 4 3\n",
      "Fitting on 0-1-3-4, cross-validating on 3...\n",
      "0 3 0 1 3 4 4\n",
      "Fitting on 0-1-3-4, cross-validating on 4...\n",
      "0 3 0 1 3 4 5\n",
      "Fitting on 0-1-3-4, testing on 5...\n",
      "0 1 0 1 4 5 3\n",
      "Fitting on 0-1-4-5, testing on 3...\n",
      "0 1 0 1 4 5 4\n",
      "Fitting on 0-1-4-5, cross-validating on 4...\n",
      "0 1 0 1 4 5 5\n",
      "Fitting on 0-1-4-5, cross-validating on 5...\n",
      "0 1 0 2 3 4 0\n",
      "Fitting on 0-2-3-4, cross-validating on 0...\n",
      "0 2 1 2 3 5 2\n",
      "Fitting on 1-2-3-5, cross-validating on 2...\n",
      "0 2 1 2 3 5 3\n",
      "Fitting on 1-2-3-5, cross-validating on 3...\n",
      "0 2 1 2 3 5 4\n",
      "Fitting on 1-2-3-5, testing on 4...\n",
      "0 3 0 1 3 5 0\n",
      "Fitting on 0-1-3-5, cross-validating on 0...\n",
      "0 2 1 2 3 5 5\n",
      "Fitting on 1-2-3-5, cross-validating on 5...\n",
      "0 2 1 2 4 5 0\n",
      "Fitting on 1-2-4-5, testing on 0...\n",
      "0 2 1 2 4 5 1\n",
      "Fitting on 1-2-4-5, cross-validating on 1...\n",
      "0 2 1 2 4 5 2\n",
      "Fitting on 1-2-4-5, cross-validating on 2...\n",
      "0 2 1 2 4 5 3\n",
      "Fitting on 1-2-4-5, testing on 3...\n",
      "0 2 1 2 4 5 4\n",
      "Fitting on 1-2-4-5, cross-validating on 4...\n",
      "0 2 1 2 4 5 5\n",
      "Fitting on 1-2-4-5, cross-validating on 5...\n",
      "0 2 1 3 4 5 0\n",
      "Fitting on 1-3-4-5, testing on 0...\n",
      "0 1 0 2 3 4 1\n",
      "Fitting on 0-2-3-4, testing on 1...\n",
      "0 2 1 3 4 5 1\n",
      "Fitting on 1-3-4-5, cross-validating on 1...\n",
      "0 1 0 2 3 4 2\n",
      "Fitting on 0-2-3-4, cross-validating on 2...\n",
      "0 1 0 2 3 4 3\n",
      "Fitting on 0-2-3-4, cross-validating on 3...\n",
      "0 1 0 2 3 4 4\n",
      "Fitting on 0-2-3-4, cross-validating on 4...\n",
      "0 1 0 2 3 4 5\n",
      "Fitting on 0-2-3-4, testing on 5...\n",
      "0 1 0 2 3 5 0\n",
      "Fitting on 0-2-3-5, cross-validating on 0...\n",
      "0 3 0 1 3 5 1\n",
      "Fitting on 0-1-3-5, cross-validating on 1...\n",
      "0 3 0 1 3 5 2\n",
      "Fitting on 0-1-3-5, testing on 2...\n",
      "0 2 1 3 4 5 2\n",
      "Fitting on 1-3-4-5, testing on 2...\n",
      "0 2 1 3 4 5 3\n",
      "Fitting on 1-3-4-5, cross-validating on 3...\n",
      "0 2 1 3 4 5 4\n",
      "Fitting on 1-3-4-5, cross-validating on 4...\n",
      "0 2 1 3 4 5 5\n",
      "Fitting on 1-3-4-5, cross-validating on 5...\n",
      "0 2 2 3 4 5 0\n",
      "Fitting on 2-3-4-5, testing on 0...\n",
      "0 2 2 3 4 5 1\n",
      "Fitting on 2-3-4-5, testing on 1...\n",
      "0 3 0 1 3 5 3\n",
      "Fitting on 0-1-3-5, cross-validating on 3...\n",
      "0 3 0 1 3 5 4\n",
      "Fitting on 0-1-3-5, testing on 4...\n",
      "0 2 2 3 4 5 2\n",
      "Fitting on 2-3-4-5, cross-validating on 2...\n",
      "0 3 0 1 3 5 5\n",
      "Fitting on 0-1-3-5, cross-validating on 5...\n",
      "0 3 0 1 4 5 0\n",
      "Fitting on 0-1-4-5, cross-validating on 0...\n",
      "0 2 2 3 4 5 3\n",
      "Fitting on 2-3-4-5, cross-validating on 3...\n",
      "0 2 2 3 4 5 4\n",
      "Fitting on 2-3-4-5, cross-validating on 4...\n",
      "0 2 2 3 4 5 5\n",
      "Fitting on 2-3-4-5, cross-validating on 5...\n",
      "0 1 0 2 3 5 1\n",
      "Fitting on 0-2-3-5, testing on 1...\n",
      "0 1 0 2 3 5 2\n",
      "Fitting on 0-2-3-5, cross-validating on 2...\n",
      "0 1 0 2 3 5 3\n",
      "Fitting on 0-2-3-5, cross-validating on 3...\n",
      "0 1 0 2 3 5 4\n",
      "Fitting on 0-2-3-5, testing on 4...\n",
      "0 1 0 2 3 5 5\n",
      "Fitting on 0-2-3-5, cross-validating on 5...\n",
      "0 1 0 2 4 5 0\n",
      "Fitting on 0-2-4-5, cross-validating on 0...\n",
      "0 3 0 1 4 5 1\n",
      "Fitting on 0-1-4-5, cross-validating on 1...\n",
      "0 3 0 1 4 5 2\n",
      "Fitting on 0-1-4-5, testing on 2...\n",
      "0 1 0 2 4 5 1\n",
      "Fitting on 0-2-4-5, testing on 1...\n",
      "0 3 0 1 4 5 3\n",
      "Fitting on 0-1-4-5, testing on 3...\n",
      "0 1 0 2 4 5 2\n",
      "Fitting on 0-2-4-5, cross-validating on 2...\n",
      "0 1 0 2 4 5 3\n",
      "Fitting on 0-2-4-5, testing on 3...\n",
      "0 1 0 2 4 5 4\n",
      "Fitting on 0-2-4-5, cross-validating on 4...\n",
      "0 1 0 2 4 5 5\n",
      "Fitting on 0-2-4-5, cross-validating on 5...\n",
      "0 1 0 3 4 5 0\n",
      "Fitting on 0-3-4-5, cross-validating on 0...\n",
      "0 3 0 1 4 5 4\n",
      "Fitting on 0-1-4-5, cross-validating on 4...\n",
      "0 3 0 1 4 5 5\n",
      "Fitting on 0-1-4-5, cross-validating on 5...\n",
      "0 3 0 2 3 4 0\n",
      "Fitting on 0-2-3-4, cross-validating on 0...\n",
      "0 1 0 3 4 5 1\n",
      "Fitting on 0-3-4-5, testing on 1...\n",
      "0 1 0 3 4 5 2\n",
      "Fitting on 0-3-4-5, testing on 2...\n",
      "0 1 0 3 4 5 3\n",
      "Fitting on 0-3-4-5, cross-validating on 3...\n",
      "0 1 0 3 4 5 4\n",
      "Fitting on 0-3-4-5, cross-validating on 4...\n",
      "0 1 0 3 4 5 5\n",
      "Fitting on 0-3-4-5, cross-validating on 5...\n",
      "0 1 1 2 3 4 0\n",
      "Fitting on 1-2-3-4, testing on 0...\n",
      "0 3 0 2 3 4 1\n",
      "Fitting on 0-2-3-4, testing on 1...\n",
      "0 1 1 2 3 4 1\n",
      "Fitting on 1-2-3-4, cross-validating on 1...\n",
      "0 3 0 2 3 4 2\n",
      "Fitting on 0-2-3-4, cross-validating on 2...\n",
      "0 3 0 2 3 4 3\n",
      "Fitting on 0-2-3-4, cross-validating on 3...\n",
      "0 3 0 2 3 4 4\n",
      "Fitting on 0-2-3-4, cross-validating on 4...\n",
      "0 3 0 2 3 4 5\n",
      "Fitting on 0-2-3-4, testing on 5...\n",
      "0 3 0 2 3 5 0\n",
      "Fitting on 0-2-3-5, cross-validating on 0...\n",
      "0 1 1 2 3 4 2\n",
      "Fitting on 1-2-3-4, cross-validating on 2...\n",
      "0 1 1 2 3 4 3\n",
      "Fitting on 1-2-3-4, cross-validating on 3...\n",
      "0 1 1 2 3 4 4\n",
      "Fitting on 1-2-3-4, cross-validating on 4...\n",
      "0 1 1 2 3 4 5\n",
      "Fitting on 1-2-3-4, testing on 5...\n",
      "0 1 1 2 3 5 0\n",
      "Fitting on 1-2-3-5, testing on 0...\n",
      "0 1 1 2 3 5 1\n",
      "Fitting on 1-2-3-5, cross-validating on 1...\n",
      "0 3 0 2 3 5 1\n",
      "Fitting on 0-2-3-5, testing on 1...\n",
      "0 3 0 2 3 5 2\n",
      "Fitting on 0-2-3-5, cross-validating on 2...\n",
      "0 3 0 2 3 5 3\n",
      "Fitting on 0-2-3-5, cross-validating on 3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 0 2 3 5 4\n",
      "Fitting on 0-2-3-5, testing on 4...\n",
      "0 1 1 2 3 5 2\n",
      "Fitting on 1-2-3-5, cross-validating on 2...\n",
      "0 1 1 2 3 5 3\n",
      "Fitting on 1-2-3-5, cross-validating on 3...\n",
      "0 1 1 2 3 5 4\n",
      "Fitting on 1-2-3-5, testing on 4...\n",
      "0 1 1 2 3 5 5\n",
      "Fitting on 1-2-3-5, cross-validating on 5...\n",
      "0 1 1 2 4 5 0\n",
      "Fitting on 1-2-4-5, testing on 0...\n",
      "0 3 0 2 3 5 5\n",
      "Fitting on 0-2-3-5, cross-validating on 5...\n",
      "0 3 0 2 4 5 0\n",
      "Fitting on 0-2-4-5, cross-validating on 0...\n",
      "0 1 1 2 4 5 1\n",
      "Fitting on 1-2-4-5, cross-validating on 1...\n",
      "0 1 1 2 4 5 2\n",
      "Fitting on 1-2-4-5, cross-validating on 2...\n",
      "0 1 1 2 4 5 3\n",
      "Fitting on 1-2-4-5, testing on 3...\n",
      "0 1 1 2 4 5 4\n",
      "Fitting on 1-2-4-5, cross-validating on 4...\n",
      "0 1 1 2 4 5 5\n",
      "Fitting on 1-2-4-5, cross-validating on 5...\n",
      "0 1 1 3 4 5 0\n",
      "Fitting on 1-3-4-5, testing on 0...\n",
      "0 3 0 2 4 5 1\n",
      "Fitting on 0-2-4-5, testing on 1...\n",
      "0 1 1 3 4 5 1\n",
      "Fitting on 1-3-4-5, cross-validating on 1...\n",
      "0 3 0 2 4 5 2\n",
      "Fitting on 0-2-4-5, cross-validating on 2...\n",
      "0 3 0 2 4 5 3\n",
      "Fitting on 0-2-4-5, testing on 3...\n",
      "0 3 0 2 4 5 4\n",
      "Fitting on 0-2-4-5, cross-validating on 4...\n",
      "0 3 0 2 4 5 5\n",
      "Fitting on 0-2-4-5, cross-validating on 5...\n",
      "0 3 0 3 4 5 0\n",
      "Fitting on 0-3-4-5, cross-validating on 0...\n",
      "0 1 1 3 4 5 2\n",
      "Fitting on 1-3-4-5, testing on 2...\n",
      "0 1 1 3 4 5 3\n",
      "Fitting on 1-3-4-5, cross-validating on 3...\n",
      "0 1 1 3 4 5 4\n",
      "Fitting on 1-3-4-5, cross-validating on 4...\n",
      "0 1 1 3 4 5 5\n",
      "Fitting on 1-3-4-5, cross-validating on 5...\n",
      "0 1 2 3 4 5 0\n",
      "Fitting on 2-3-4-5, testing on 0...\n",
      "0 1 2 3 4 5 1\n",
      "Fitting on 2-3-4-5, testing on 1...\n",
      "0 1 2 3 4 5 2\n",
      "Fitting on 2-3-4-5, cross-validating on 2...\n",
      "0 3 0 3 4 5 1\n",
      "Fitting on 0-3-4-5, testing on 1...\n",
      "0 3 0 3 4 5 2\n",
      "Fitting on 0-3-4-5, testing on 2...\n",
      "0 1 2 3 4 5 3\n",
      "Fitting on 2-3-4-5, cross-validating on 3...\n",
      "0 1 2 3 4 5 4\n",
      "Fitting on 2-3-4-5, cross-validating on 4...\n",
      "0 1 2 3 4 5 5\n",
      "Fitting on 2-3-4-5, cross-validating on 5...\n",
      "0 3 0 3 4 5 3\n",
      "Fitting on 0-3-4-5, cross-validating on 3...\n",
      "0 3 0 3 4 5 4\n",
      "Fitting on 0-3-4-5, cross-validating on 4...\n",
      "0 3 0 3 4 5 5\n",
      "Fitting on 0-3-4-5, cross-validating on 5...\n",
      "0 3 1 2 3 4 0\n",
      "Fitting on 1-2-3-4, testing on 0...\n",
      "0 3 1 2 3 4 1\n",
      "Fitting on 1-2-3-4, cross-validating on 1...\n",
      "0 3 1 2 3 4 2\n",
      "Fitting on 1-2-3-4, cross-validating on 2...\n",
      "0 3 1 2 3 4 3\n",
      "Fitting on 1-2-3-4, cross-validating on 3...\n",
      "0 3 1 2 3 4 4\n",
      "Fitting on 1-2-3-4, cross-validating on 4...\n",
      "0 3 1 2 3 4 5\n",
      "Fitting on 1-2-3-4, testing on 5...\n",
      "0 3 1 2 3 5 0\n",
      "Fitting on 1-2-3-5, testing on 0...\n",
      "0 3 1 2 3 5 1\n",
      "Fitting on 1-2-3-5, cross-validating on 1...\n",
      "0 3 1 2 3 5 2\n",
      "Fitting on 1-2-3-5, cross-validating on 2...\n",
      "0 3 1 2 3 5 3\n",
      "Fitting on 1-2-3-5, cross-validating on 3...\n",
      "0 3 1 2 3 5 4\n",
      "Fitting on 1-2-3-5, testing on 4...\n",
      "0 3 1 2 3 5 5\n",
      "Fitting on 1-2-3-5, cross-validating on 5...\n",
      "0 3 1 2 4 5 0\n",
      "Fitting on 1-2-4-5, testing on 0...\n",
      "0 3 1 2 4 5 1\n",
      "Fitting on 1-2-4-5, cross-validating on 1...\n",
      "0 3 1 2 4 5 2\n",
      "Fitting on 1-2-4-5, cross-validating on 2...\n",
      "0 3 1 2 4 5 3\n",
      "Fitting on 1-2-4-5, testing on 3...\n",
      "0 3 1 2 4 5 4\n",
      "Fitting on 1-2-4-5, cross-validating on 4...\n",
      "0 3 1 2 4 5 5\n",
      "Fitting on 1-2-4-5, cross-validating on 5...\n",
      "0 3 1 3 4 5 0\n",
      "Fitting on 1-3-4-5, testing on 0...\n",
      "0 3 1 3 4 5 1\n",
      "Fitting on 1-3-4-5, cross-validating on 1...\n",
      "0 3 1 3 4 5 2\n",
      "Fitting on 1-3-4-5, testing on 2...\n",
      "0 3 1 3 4 5 3\n",
      "Fitting on 1-3-4-5, cross-validating on 3...\n",
      "0 3 1 3 4 5 4\n",
      "Fitting on 1-3-4-5, cross-validating on 4...\n",
      "0 3 1 3 4 5 5\n",
      "Fitting on 1-3-4-5, cross-validating on 5...\n",
      "0 3 2 3 4 5 0\n",
      "Fitting on 2-3-4-5, testing on 0...\n",
      "0 3 2 3 4 5 1\n",
      "Fitting on 2-3-4-5, testing on 1...\n",
      "0 3 2 3 4 5 2\n",
      "Fitting on 2-3-4-5, cross-validating on 2...\n",
      "0 3 2 3 4 5 3\n",
      "Fitting on 2-3-4-5, cross-validating on 3...\n",
      "0 3 2 3 4 5 4\n",
      "Fitting on 2-3-4-5, cross-validating on 4...\n",
      "0 3 2 3 4 5 5\n",
      "Fitting on 2-3-4-5, cross-validating on 5...\n"
     ]
    }
   ],
   "source": [
    "## Cross surface validation for 4 out of 6 surfaces\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ;\n",
    "decomp = PCA(n_components=20)\n",
    "def filename(i,j,k1,k2,k3,k4,l):\n",
    "    return 'fs_'+str(i)+'_subfs_'+str(j)+'_tr1_'+str(k1)+'_tr2_'+str(k2)+'_tr3_'+str(k3)+'_tr4_'+str(k4)+'_ts_'+str(l)\n",
    "\n",
    "def cross_fit(i,j,k1,k2,k3,k4,l,data,labels,data2,labels2,pipe):\n",
    "    fileid = 'tmpresults4_transtart/'+filename(i,j,k1,k2,k3,k4,l)+'.npz'\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k1,k2,k3,k4,l\n",
    "        if k1==l or k2==l or k3==l or k4==l: # perform K-fold      \n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+\"-\"+str(k4)+', cross-validating on '+str(l)+'...'\n",
    "            if l == k1: # copy if existent from the other sibling file\n",
    "                tmpcopyfileid1 = 'tmpresults4_transtart/'+filename(i,j,k1,k2,k3,k4,k2)+'.npz'\n",
    "                tmpcopyfileid2 = 'tmpresults4_transtart/'+filename(i,j,k1,k2,k3,k4,k3)+'.npz'\n",
    "                tmpcopyfileid3 = 'tmpresults4_transtart/'+filename(i,j,k1,k2,k3,k4,k4)+'.npz'\n",
    "            elif l == k2:   # same as above\n",
    "                tmpcopyfileid1 = 'tmpresults4_transtart/'+filename(i,j,k1,k2,k3,k4,k1)+'.npz'\n",
    "                tmpcopyfileid2 = 'tmpresults4_transtart/'+filename(i,j,k1,k2,k3,k4,k3)+'.npz'\n",
    "                tmpcopyfileid3 = 'tmpresults4_transtart/'+filename(i,j,k1,k2,k3,k4,k4)+'.npz'\n",
    "            elif l == k3:   # same as above\n",
    "                tmpcopyfileid1 = 'tmpresults4_transtart/'+filename(i,j,k1,k2,k3,k4,k1)+'.npz'\n",
    "                tmpcopyfileid2 = 'tmpresults4_transtart/'+filename(i,j,k1,k2,k3,k4,k2)+'.npz'\n",
    "                tmpcopyfileid3 = 'tmpresults4_transtart/'+filename(i,j,k1,k2,k3,k4,k4)+'.npz'\n",
    "            else:\n",
    "                tmpcopyfileid1 = 'tmpresults4_transtart/'+filename(i,j,k1,k2,k3,k4,k1)+'.npz'\n",
    "                tmpcopyfileid2 = 'tmpresults4_transtart/'+filename(i,j,k1,k2,k3,k4,k2)+'.npz'\n",
    "                tmpcopyfileid3 = 'tmpresults4_transtart/'+filename(i,j,k1,k2,k3,k4,k3)+'.npz'\n",
    "            if not os.path.isfile(tmpcopyfileid1) and not os.path.isfile(tmpcopyfileid2) and not os.path.isfile(tmpcopyfileid3):\n",
    "                folds = cv.split(data, labels)\n",
    "                cm_all = np.zeros((2,2))\n",
    "                for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                    x_train, x_test = data[train_ind], data[test_ind]\n",
    "                    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                    model = pipe.fit(x_train,y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                    cm_all += cm/5.\n",
    "            else:\n",
    "                if os.path.isfile(tmpcopyfileid1):\n",
    "                    cm_all = np.load(tmpcopyfileid1)['cm']\n",
    "                    model = np.load(tmpcopyfileid1)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid2):\n",
    "                    cm_all = np.load(tmpcopyfileid2)['cm']\n",
    "                    model = np.load(tmpcopyfileid2)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid3):\n",
    "                    cm_all = np.load(tmpcopyfileid3)['cm']\n",
    "                    model = np.load(tmpcopyfileid3)['model'][0]\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+\"-\"+str(k4)+', testing on '+str(l)+'...'\n",
    "            model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps(i,j,jmax,surf,surfla):\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k1 in range(surf.shape[0]): # for every training surface1\n",
    "        for k2 in range(surf.shape[0]): # for every training surface2\n",
    "            if k2 > k1:\n",
    "                for k3 in range(surf.shape[0]):\n",
    "                    if k3 > k2:\n",
    "                        for k4 in range(surf.shape[0]):\n",
    "                            if k4 > k3:\n",
    "                                for l in range(surf.shape[0]): # for every testing surface\n",
    "        #                     if l != k1 and l != k2:\n",
    "                #             cross_fit(i,j,k,l,surf[k][::100,:],surfla[k][::100],surf[l][::100,:],surfla[l][::100],pipe)\n",
    "                                    tr_surf, tr_surfla = np.concatenate((surf[k1],surf[k2],surf[k3]),axis=0), np.concatenate((surfla[:,k1],surfla[:,k2],surfla[:,k3]),axis=0)\n",
    "                                    ts_surf, ts_surfla = surf[l], surfla[:,l]\n",
    "                #                 print tr_surf.shape, tr_surfla.shape\n",
    "                                    cross_fit(i,j,k1,k2,k3,k4,l,tr_surf,tr_surfla,ts_surf,ts_surfla,pipe)\n",
    "\n",
    "for i in [0]:#range(surf.shape[2]): # for every featureset\n",
    "#     for j in range(surf.shape[0]): # for every subfeatureset\n",
    "#         if j==surf.shape[0]-1:\n",
    "#             featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "#         else:\n",
    "#             featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "#         pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "#         init_steps(i,j,surf[j][:][i],surfla[:][i])\n",
    "    # for every subfeatureset\n",
    "    [Parallel(n_jobs=-1)([delayed(init_steps) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) for j in range(surf.shape[0])])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 1 2 3 4 0\n",
      "Fitting on 0-1-2-3-4, cross-validating on 0...\n",
      "0 1 0 1 2 3 4 0\n",
      "Fitting on 0-1-2-3-4, cross-validating on 0...\n",
      "Fitting on 0-1-2-3-4, cross-validating on 0...\n",
      "0 2 0 1 2 3 4 0\n",
      "0 3 0 1 2 3 4 0\n",
      "Fitting on 0-1-2-3-4, cross-validating on 0...\n",
      "0 0 0 1 2 3 4 1\n",
      "Fitting on 0-1-2-3-4, cross-validating on 1...\n",
      "0 0 0 1 2 3 4 2\n",
      "Fitting on 0-1-2-3-4, cross-validating on 2...\n",
      "0 0 0 1 2 3 4 3\n",
      "Fitting on 0-1-2-3-4, cross-validating on 3...\n",
      "0 0 0 1 2 3 4 4\n",
      "Fitting on 0-1-2-3-4, cross-validating on 4...\n",
      "0 0 0 1 2 3 4 5\n",
      "Fitting on 0-1-2-3-4, testing on 5...\n",
      "0 0 0 1 2 3 5 0\n",
      "Fitting on 0-1-2-3-5, cross-validating on 0...\n",
      "0 2 0 1 2 3 4 1\n",
      "Fitting on 0-1-2-3-4, cross-validating on 1...\n",
      "0 2 0 1 2 3 4 2\n",
      "Fitting on 0-1-2-3-4, cross-validating on 2...\n",
      "0 2 0 1 2 3 4 3\n",
      "Fitting on 0-1-2-3-4, cross-validating on 3...\n",
      "0 2 0 1 2 3 4 4\n",
      "Fitting on 0-1-2-3-4, cross-validating on 4...\n",
      "0 2 0 1 2 3 4 5\n",
      "Fitting on 0-1-2-3-4, testing on 5...\n",
      "0 0 0 1 2 3 5 1\n",
      "Fitting on 0-1-2-3-5, cross-validating on 1...\n",
      "0 0 0 1 2 3 5 2\n",
      "Fitting on 0-1-2-3-5, cross-validating on 2...\n",
      "0 0 0 1 2 3 5 3\n",
      "Fitting on 0-1-2-3-5, cross-validating on 3...\n",
      "0 0 0 1 2 3 5 4\n",
      "Fitting on 0-1-2-3-5, testing on 4...\n",
      "0 2 0 1 2 3 5 0\n",
      "Fitting on 0-1-2-3-5, cross-validating on 0...\n",
      "0 0 0 1 2 3 5 5\n",
      "Fitting on 0-1-2-3-5, cross-validating on 5...\n",
      "0 0 0 1 2 4 5 0\n",
      "Fitting on 0-1-2-4-5, cross-validating on 0...\n",
      "0 0 0 1 2 4 5 1\n",
      "Fitting on 0-1-2-4-5, cross-validating on 1...\n",
      "0 0 0 1 2 4 5 2\n",
      "Fitting on 0-1-2-4-5, cross-validating on 2...\n",
      "0 0 0 1 2 4 5 3\n",
      "Fitting on 0-1-2-4-5, testing on 3...\n",
      "0 0 0 1 2 4 5 4\n",
      "Fitting on 0-1-2-4-5, cross-validating on 4...\n",
      "0 0 0 1 2 4 5 5\n",
      "Fitting on 0-1-2-4-5, cross-validating on 5...\n",
      "0 0 0 1 3 4 5 0\n",
      "Fitting on 0-1-3-4-5, cross-validating on 0...\n",
      "0 1 0 1 2 3 4 1\n",
      "Fitting on 0-1-2-3-4, cross-validating on 1...\n",
      "0 1 0 1 2 3 4 2\n",
      "Fitting on 0-1-2-3-4, cross-validating on 2...\n",
      "0 1 0 1 2 3 4 3\n",
      "Fitting on 0-1-2-3-4, cross-validating on 3...\n",
      "0 1 0 1 2 3 4 4\n",
      "Fitting on 0-1-2-3-4, cross-validating on 4...\n",
      "0 1 0 1 2 3 4 5\n",
      "Fitting on 0-1-2-3-4, testing on 5...\n",
      "0 2 0 1 2 3 5 1\n",
      "Fitting on 0-1-2-3-5, cross-validating on 1...\n",
      "0 2 0 1 2 3 5 2\n",
      "Fitting on 0-1-2-3-5, cross-validating on 2...\n",
      "0 2 0 1 2 3 5 3\n",
      "Fitting on 0-1-2-3-5, cross-validating on 3...\n",
      "0 2 0 1 2 3 5 4\n",
      "Fitting on 0-1-2-3-5, testing on 4...\n",
      "0 0 0 1 3 4 5 1\n",
      "Fitting on 0-1-3-4-5, cross-validating on 1...\n",
      "0 0 0 1 3 4 5 2\n",
      "Fitting on 0-1-3-4-5, testing on 2...\n",
      "0 1 0 1 2 3 5 0\n",
      "Fitting on 0-1-2-3-5, cross-validating on 0...\n",
      "0 2 0 1 2 3 5 5\n",
      "Fitting on 0-1-2-3-5, cross-validating on 5...\n",
      "0 2 0 1 2 4 5 0\n",
      "Fitting on 0-1-2-4-5, cross-validating on 0...\n",
      "0 0 0 1 3 4 5 3\n",
      "Fitting on 0-1-3-4-5, cross-validating on 3...\n",
      "0 0 0 1 3 4 5 4\n",
      "Fitting on 0-1-3-4-5, cross-validating on 4...\n",
      "0 0 0 1 3 4 5 5\n",
      "Fitting on 0-1-3-4-5, cross-validating on 5...\n",
      "0 0 0 2 3 4 5 0\n",
      "Fitting on 0-2-3-4-5, cross-validating on 0...\n",
      "0 3 0 1 2 3 4 1\n",
      "Fitting on 0-1-2-3-4, cross-validating on 1...\n",
      "0 3 0 1 2 3 4 2\n",
      "Fitting on 0-1-2-3-4, cross-validating on 2...\n",
      "0 3 0 1 2 3 4 3\n",
      "Fitting on 0-1-2-3-4, cross-validating on 3...\n",
      "0 3 0 1 2 3 4 4\n",
      "Fitting on 0-1-2-3-4, cross-validating on 4...\n",
      "0 3 0 1 2 3 4 5\n",
      "Fitting on 0-1-2-3-4, testing on 5...\n",
      "0 0 0 2 3 4 5 1\n",
      "Fitting on 0-2-3-4-5, testing on 1...\n",
      "0 0 0 2 3 4 5 2\n",
      "Fitting on 0-2-3-4-5, cross-validating on 2...\n",
      "0 0 0 2 3 4 5 3\n",
      "Fitting on 0-2-3-4-5, cross-validating on 3...\n",
      "0 0 0 2 3 4 5 4\n",
      "Fitting on 0-2-3-4-5, cross-validating on 4...\n",
      "0 0 0 2 3 4 5 5\n",
      "Fitting on 0-2-3-4-5, cross-validating on 5...\n",
      "0 0 1 2 3 4 5 0\n",
      "Fitting on 1-2-3-4-5, testing on 0...\n",
      "0 0 1 2 3 4 5 1\n",
      "Fitting on 1-2-3-4-5, cross-validating on 1...\n",
      "0 2 0 1 2 4 5 1\n",
      "Fitting on 0-1-2-4-5, cross-validating on 1...\n",
      "0 2 0 1 2 4 5 2\n",
      "Fitting on 0-1-2-4-5, cross-validating on 2...\n",
      "0 2 0 1 2 4 5 3\n",
      "Fitting on 0-1-2-4-5, testing on 3...\n",
      "0 3 0 1 2 3 5 0\n",
      "Fitting on 0-1-2-3-5, cross-validating on 0...\n",
      "0 2 0 1 2 4 5 4\n",
      "Fitting on 0-1-2-4-5, cross-validating on 4...\n",
      "0 2 0 1 2 4 5 5\n",
      "Fitting on 0-1-2-4-5, cross-validating on 5...\n",
      "0 2 0 1 3 4 5 0\n",
      "Fitting on 0-1-3-4-5, cross-validating on 0...\n",
      "0 0 1 2 3 4 5 2\n",
      "Fitting on 1-2-3-4-5, cross-validating on 2...\n",
      "0 0 1 2 3 4 5 3\n",
      "Fitting on 1-2-3-4-5, cross-validating on 3...\n",
      "0 0 1 2 3 4 5 4\n",
      "Fitting on 1-2-3-4-5, cross-validating on 4...\n",
      "0 0 1 2 3 4 5 5\n",
      "Fitting on 1-2-3-4-5, cross-validating on 5...\n",
      "0 1 0 1 2 3 5 1\n",
      "Fitting on 0-1-2-3-5, cross-validating on 1...\n",
      "0 1 0 1 2 3 5 2\n",
      "Fitting on 0-1-2-3-5, cross-validating on 2...\n",
      "0 1 0 1 2 3 5 3\n",
      "Fitting on 0-1-2-3-5, cross-validating on 3...\n",
      "0 1 0 1 2 3 5 4\n",
      "Fitting on 0-1-2-3-5, testing on 4...\n",
      "0 2 0 1 3 4 5 1\n",
      "Fitting on 0-1-3-4-5, cross-validating on 1...\n",
      "0 2 0 1 3 4 5 2\n",
      "Fitting on 0-1-3-4-5, testing on 2...\n",
      "0 1 0 1 2 3 5 5\n",
      "Fitting on 0-1-2-3-5, cross-validating on 5...\n",
      "0 1 0 1 2 4 5 0\n",
      "Fitting on 0-1-2-4-5, cross-validating on 0...\n",
      "0 2 0 1 3 4 5 3\n",
      "Fitting on 0-1-3-4-5, cross-validating on 3...\n",
      "0 2 0 1 3 4 5 4\n",
      "Fitting on 0-1-3-4-5, cross-validating on 4...\n",
      "0 2 0 1 3 4 5 5\n",
      "Fitting on 0-1-3-4-5, cross-validating on 5...\n",
      "0 2 0 2 3 4 5 0\n",
      "Fitting on 0-2-3-4-5, cross-validating on 0...\n",
      "0 2 0 2 3 4 5 1\n",
      "Fitting on 0-2-3-4-5, testing on 1...\n",
      "0 2 0 2 3 4 5 2\n",
      "Fitting on 0-2-3-4-5, cross-validating on 2...\n",
      "0 2 0 2 3 4 5 3\n",
      "Fitting on 0-2-3-4-5, cross-validating on 3...\n",
      "0 2 0 2 3 4 5 4\n",
      "Fitting on 0-2-3-4-5, cross-validating on 4...\n",
      "0 2 0 2 3 4 5 5\n",
      "Fitting on 0-2-3-4-5, cross-validating on 5...\n",
      "0 2 1 2 3 4 5 0\n",
      "Fitting on 1-2-3-4-5, testing on 0...\n",
      "0 2 1 2 3 4 5 1\n",
      "Fitting on 1-2-3-4-5, cross-validating on 1...\n",
      "0 3 0 1 2 3 5 1\n",
      "Fitting on 0-1-2-3-5, cross-validating on 1...\n",
      "0 3 0 1 2 3 5 2\n",
      "Fitting on 0-1-2-3-5, cross-validating on 2...\n",
      "0 3 0 1 2 3 5 3\n",
      "Fitting on 0-1-2-3-5, cross-validating on 3...\n",
      "0 3 0 1 2 3 5 4\n",
      "Fitting on 0-1-2-3-5, testing on 4...\n",
      "0 1 0 1 2 4 5 1\n",
      "Fitting on 0-1-2-4-5, cross-validating on 1...\n",
      "0 1 0 1 2 4 5 2\n",
      "Fitting on 0-1-2-4-5, cross-validating on 2...\n",
      "0 1 0 1 2 4 5 3\n",
      "Fitting on 0-1-2-4-5, testing on 3...\n",
      "0 3 0 1 2 3 5 5\n",
      "Fitting on 0-1-2-3-5, cross-validating on 5...\n",
      "0 3 0 1 2 4 5 0\n",
      "Fitting on 0-1-2-4-5, cross-validating on 0...\n",
      "0 1 0 1 2 4 5 4\n",
      "Fitting on 0-1-2-4-5, cross-validating on 4...\n",
      "0 1 0 1 2 4 5 5\n",
      "Fitting on 0-1-2-4-5, cross-validating on 5...\n",
      "0 1 0 1 3 4 5 0\n",
      "Fitting on 0-1-3-4-5, cross-validating on 0...\n",
      "0 2 1 2 3 4 5 2\n",
      "Fitting on 1-2-3-4-5, cross-validating on 2...\n",
      "0 2 1 2 3 4 5 3\n",
      "Fitting on 1-2-3-4-5, cross-validating on 3...\n",
      "0 2 1 2 3 4 5 4\n",
      "Fitting on 1-2-3-4-5, cross-validating on 4...\n",
      "0 2 1 2 3 4 5 5\n",
      "Fitting on 1-2-3-4-5, cross-validating on 5...\n",
      "0 1 0 1 3 4 5 1\n",
      "Fitting on 0-1-3-4-5, cross-validating on 1...\n",
      "0 1 0 1 3 4 5 2\n",
      "Fitting on 0-1-3-4-5, testing on 2...\n",
      "0 1 0 1 3 4 5 3\n",
      "Fitting on 0-1-3-4-5, cross-validating on 3...\n",
      "0 1 0 1 3 4 5 4\n",
      "Fitting on 0-1-3-4-5, cross-validating on 4...\n",
      "0 1 0 1 3 4 5 5\n",
      "Fitting on 0-1-3-4-5, cross-validating on 5...\n",
      "0 1 0 2 3 4 5 0\n",
      "Fitting on 0-2-3-4-5, cross-validating on 0...\n",
      "0 3 0 1 2 4 5 1\n",
      "Fitting on 0-1-2-4-5, cross-validating on 1...\n",
      "0 3 0 1 2 4 5 2\n",
      "Fitting on 0-1-2-4-5, cross-validating on 2...\n",
      "0 3 0 1 2 4 5 3\n",
      "Fitting on 0-1-2-4-5, testing on 3...\n",
      "0 3 0 1 2 4 5 4\n",
      "Fitting on 0-1-2-4-5, cross-validating on 4...\n",
      "0 3 0 1 2 4 5 5\n",
      "Fitting on 0-1-2-4-5, cross-validating on 5...\n",
      "0 3 0 1 3 4 5 0\n",
      "Fitting on 0-1-3-4-5, cross-validating on 0...\n",
      "0 1 0 2 3 4 5 1\n",
      "Fitting on 0-2-3-4-5, testing on 1...\n",
      "0 1 0 2 3 4 5 2\n",
      "Fitting on 0-2-3-4-5, cross-validating on 2...\n",
      "0 1 0 2 3 4 5 3\n",
      "Fitting on 0-2-3-4-5, cross-validating on 3...\n",
      "0 1 0 2 3 4 5 4\n",
      "Fitting on 0-2-3-4-5, cross-validating on 4...\n",
      "0 1 0 2 3 4 5 5\n",
      "Fitting on 0-2-3-4-5, cross-validating on 5...\n",
      "0 1 1 2 3 4 5 0\n",
      "Fitting on 1-2-3-4-5, testing on 0...\n",
      "0 1 1 2 3 4 5 1\n",
      "Fitting on 1-2-3-4-5, cross-validating on 1...\n",
      "0 3 0 1 3 4 5 1\n",
      "Fitting on 0-1-3-4-5, cross-validating on 1...\n",
      "0 3 0 1 3 4 5 2\n",
      "Fitting on 0-1-3-4-5, testing on 2...\n",
      "0 3 0 1 3 4 5 3\n",
      "Fitting on 0-1-3-4-5, cross-validating on 3...\n",
      "0 3 0 1 3 4 5 4\n",
      "Fitting on 0-1-3-4-5, cross-validating on 4...\n",
      "0 3 0 1 3 4 5 5\n",
      "Fitting on 0-1-3-4-5, cross-validating on 5...\n",
      "0 3 0 2 3 4 5 0\n",
      "Fitting on 0-2-3-4-5, cross-validating on 0...\n",
      "0 1 1 2 3 4 5 2\n",
      "Fitting on 1-2-3-4-5, cross-validating on 2...\n",
      "0 1 1 2 3 4 5 3\n",
      "Fitting on 1-2-3-4-5, cross-validating on 3...\n",
      "0 1 1 2 3 4 5 4\n",
      "Fitting on 1-2-3-4-5, cross-validating on 4...\n",
      "0 1 1 2 3 4 5 5\n",
      "Fitting on 1-2-3-4-5, cross-validating on 5...\n",
      "0 3 0 2 3 4 5 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting on 0-2-3-4-5, testing on 1...\n",
      "0 3 0 2 3 4 5 2\n",
      "Fitting on 0-2-3-4-5, cross-validating on 2...\n",
      "0 3 0 2 3 4 5 3\n",
      "Fitting on 0-2-3-4-5, cross-validating on 3...\n",
      "0 3 0 2 3 4 5 4\n",
      "Fitting on 0-2-3-4-5, cross-validating on 4...\n",
      "0 3 0 2 3 4 5 5\n",
      "Fitting on 0-2-3-4-5, cross-validating on 5...\n",
      "0 3 1 2 3 4 5 0\n",
      "Fitting on 1-2-3-4-5, testing on 0...\n",
      "0 3 1 2 3 4 5 1\n",
      "Fitting on 1-2-3-4-5, cross-validating on 1...\n",
      "0 3 1 2 3 4 5 2\n",
      "Fitting on 1-2-3-4-5, cross-validating on 2...\n",
      "0 3 1 2 3 4 5 3\n",
      "Fitting on 1-2-3-4-5, cross-validating on 3...\n",
      "0 3 1 2 3 4 5 4\n",
      "Fitting on 1-2-3-4-5, cross-validating on 4...\n",
      "0 3 1 2 3 4 5 5\n",
      "Fitting on 1-2-3-4-5, cross-validating on 5...\n"
     ]
    }
   ],
   "source": [
    "## Cross surface validation for 5 out of 6 surfaces, or leave one out\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ;\n",
    "decomp = PCA(n_components=20)\n",
    "def filename(i,j,k1,k2,k3,k4,k5,l):\n",
    "    return 'fs_'+str(i)+'_subfs_'+str(j)+'_tr1_'+str(k1)+'_tr2_'+str(k2)+'_tr3_'+str(k3)+'_tr4_'+str(k4)+'_tr5_'+str(k5)+'_ts_'+str(l)\n",
    "\n",
    "def cross_fit(i,j,k1,k2,k3,k4,k5,l,data,labels,data2,labels2,pipe):\n",
    "    fileid = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,l)+'.npz'\n",
    "    if not os.path.isfile(fileid):\n",
    "        print i,j,k1,k2,k3,k4,k5,l\n",
    "        if k1==l or k2==l or k3==l or k4==l or k5==l: # perform K-fold      \n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+\"-\"+str(k4)+\"-\"+str(k5)+', cross-validating on '+str(l)+'...'\n",
    "            if l == k1: # copy if existent from the other sibling file\n",
    "                tmpcopyfileid1 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k2)+'.npz'\n",
    "                tmpcopyfileid2 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k3)+'.npz'\n",
    "                tmpcopyfileid3 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k4)+'.npz'\n",
    "                tmpcopyfileid4 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k5)+'.npz'\n",
    "            elif l == k2:   # same as above\n",
    "                tmpcopyfileid1 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k1)+'.npz'\n",
    "                tmpcopyfileid2 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k3)+'.npz'\n",
    "                tmpcopyfileid3 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k4)+'.npz'\n",
    "                tmpcopyfileid4 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k5)+'.npz'\n",
    "            elif l == k3:   # same as above\n",
    "                tmpcopyfileid1 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k1)+'.npz'\n",
    "                tmpcopyfileid2 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k2)+'.npz'\n",
    "                tmpcopyfileid3 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k4)+'.npz'\n",
    "                tmpcopyfileid4 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k5)+'.npz'\n",
    "            elif l == k4:   # same as above\n",
    "                tmpcopyfileid1 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k1)+'.npz'\n",
    "                tmpcopyfileid2 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k2)+'.npz'\n",
    "                tmpcopyfileid3 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k3)+'.npz'\n",
    "                tmpcopyfileid4 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k5)+'.npz'\n",
    "            else:\n",
    "                tmpcopyfileid1 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k1)+'.npz'\n",
    "                tmpcopyfileid2 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k2)+'.npz'\n",
    "                tmpcopyfileid3 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k3)+'.npz'\n",
    "                tmpcopyfileid4 = 'tmpresults5_transtart/'+filename(i,j,k1,k2,k3,k4,k5,k4)+'.npz'\n",
    "            if not os.path.isfile(tmpcopyfileid1) and not os.path.isfile(tmpcopyfileid2) and not os.path.isfile(tmpcopyfileid3) and not os.path.isfile(tmpcopyfileid4):\n",
    "                folds = cv.split(data, labels)\n",
    "                cm_all = np.zeros((2,2))\n",
    "                for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "                    x_train, x_test = data[train_ind], data[test_ind]\n",
    "                    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "                    model = pipe.fit(x_train,y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "                    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                    cm_all += cm/5.\n",
    "            else:\n",
    "                if os.path.isfile(tmpcopyfileid1):\n",
    "                    cm_all = np.load(tmpcopyfileid1)['cm']\n",
    "                    model = np.load(tmpcopyfileid1)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid2):\n",
    "                    cm_all = np.load(tmpcopyfileid2)['cm']\n",
    "                    model = np.load(tmpcopyfileid2)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid3):\n",
    "                    cm_all = np.load(tmpcopyfileid3)['cm']\n",
    "                    model = np.load(tmpcopyfileid3)['model'][0]\n",
    "                elif os.path.isfile(tmpcopyfileid4):\n",
    "                    cm_all = np.load(tmpcopyfileid4)['cm']\n",
    "                    model = np.load(tmpcopyfileid4)['model'][0]\n",
    "            np.savez(fileid,cm=cm_all,model=np.array([model]))\n",
    "        else: # perform cross-check\n",
    "            tr_data = data\n",
    "            tr_labels = labels\n",
    "            ts_data = data2\n",
    "            ts_labels = labels2\n",
    "            print 'Fitting on '+str(k1)+\"-\"+str(k2)+\"-\"+str(k3)+\"-\"+str(k4)+\"-\"+str(k5)+', testing on '+str(l)+'...'\n",
    "            model = pipe.fit(tr_data,tr_labels)\n",
    "            y_pred = model.predict(ts_data)\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=ts_labels)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            np.savez(fileid,cm=cm,model=np.array([model]))\n",
    "\n",
    "def init_steps(i,j,jmax,surf,surfla):\n",
    "    if j==jmax:\n",
    "        featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "    else:\n",
    "        featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "    pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "    for k1 in range(surf.shape[0]): # for every training surface1\n",
    "        for k2 in range(surf.shape[0]): # for every training surface2\n",
    "            if k2 > k1:\n",
    "                for k3 in range(surf.shape[0]):\n",
    "                    if k3 > k2:\n",
    "                        for k4 in range(surf.shape[0]):\n",
    "                            if k4 > k3:\n",
    "                                for k5 in range(surf.shape[0]):\n",
    "                                    if k5 > k4:\n",
    "                                        for l in range(surf.shape[0]): # for every testing surface\n",
    "        #                     if l != k1 and l != k2:\n",
    "                #             cross_fit(i,j,k,l,surf[k][::100,:],surfla[k][::100],surf[l][::100,:],surfla[l][::100],pipe)\n",
    "                                            tr_surf, tr_surfla = np.concatenate((surf[k1],surf[k2],surf[k3]),axis=0), np.concatenate((surfla[:,k1],surfla[:,k2],surfla[:,k3]),axis=0)\n",
    "                                            ts_surf, ts_surfla = surf[l], surfla[:,l]\n",
    "                #                 print tr_surf.shape, tr_surfla.shape\n",
    "                                            cross_fit(i,j,k1,k2,k3,k4,k5,l,tr_surf,tr_surfla,ts_surf,ts_surfla,pipe)\n",
    "\n",
    "for i in [0]:#range(surf.shape[2]): # for every featureset\n",
    "#     for j in range(surf.shape[0]): # for every subfeatureset\n",
    "#         if j==surf.shape[0]-1:\n",
    "#             featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "#         else:\n",
    "#             featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "#         pipe = make_pipe_clf(scaler, featsel, decomp, classifiers[2])\n",
    "#         init_steps(i,j,surf[j][:][i],surfla[:][i])\n",
    "    # for every subfeatureset\n",
    "    [Parallel(n_jobs=-1)([delayed(init_steps) (i,j,surf.shape[0]-1,surf[j,:,i],surfla[:,:,i]) for j in range(surf.shape[0])])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = cv.split(data, labels)\n",
    "for fold, (train_ind, test_ind) in enumerate(folds):\n",
    "    x_train, x_test = data[train_ind] data[test_ind]\n",
    "    y_train, y_test = labels[train_ind], labels[test_ind]\n",
    "    pipe.fit(x_train,y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "=============================================================\n",
      "Object : 0, classifier : KNei, 5-fold avg score = 0.903840\n",
      "[ 0.94168096  0.88507719  0.89690722  0.91752577  0.87800687]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   59.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : SVC(, 5-fold avg score = 0.921018\n",
      "[ 0.94339623  0.89536878  0.90893471  0.9467354   0.91065292]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   58.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : MLPC, 5-fold avg score = 0.934064\n",
      "[ 0.95883362  0.91595197  0.93298969  0.94501718  0.91752577]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : Rand, 5-fold avg score = 0.893896\n",
      "[ 0.93310463  0.83018868  0.895189    0.92783505  0.88316151]\n",
      "=============================================================\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   58.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : KNei, 5-fold avg score = 0.892178\n",
      "[ 0.90909091  0.8542024   0.90378007  0.88831615  0.90549828]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   58.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : SVC(, 5-fold avg score = 0.896980\n",
      "[ 0.91423671  0.87307033  0.90034364  0.91237113  0.88487973]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   60.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : MLPC, 5-fold avg score = 0.918593\n",
      "[ 0.95883362  0.9348199   0.89690722  0.90378007  0.89862543]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   59.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : Rand, 5-fold avg score = 0.864358\n",
      "[ 0.89365352  0.82332762  0.85223368  0.87800687  0.87457045]\n",
      "=============================================================\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   57.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : KNei, 5-fold avg score = 0.921365\n",
      "[ 0.92281304  0.90394511  0.94329897  0.90034364  0.93642612]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   57.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : SVC(, 5-fold avg score = 0.941272\n",
      "[ 0.95711835  0.93996569  0.93986254  0.92955326  0.93986254]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   55.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : MLPC, 5-fold avg score = 0.946764\n",
      "[ 0.95883362  0.95711835  0.95189003  0.94158076  0.92439863]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   56.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : Rand, 5-fold avg score = 0.883585\n",
      "[ 0.88850772  0.87821612  0.92268041  0.87628866  0.85223368]\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   55.3s finished\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# ====================== 24/07  5-fold CV for the split datasets\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "scores = []\n",
    "\n",
    "for surf_ind, surf_data in enumerate(surfaces):\n",
    "    print(surf_ind)\n",
    "    data = surf_data\n",
    "    labels = surf_labels[surf_ind]\n",
    "    for pipe in pipe_list:\n",
    "        score = cross_val_score(estimator = pipe, X = data, y = labels, cv = cv, verbose = 1, n_jobs=-1)\n",
    "        scores.append(score)\n",
    "        print (\"=============================================================\")\n",
    "        print(\"Object : %d, classifier : %0.4s, 5-fold avg score = %f\" %(surf_ind, pipe.named_steps['classifier'], np.mean(score)))\n",
    "        print(score)\n",
    "        print (\"=============================================================\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on surface no. 0\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with KNei\n",
      "Prediction accuracy 0.800824\n",
      "[[ 0.96946565  0.03053435]\n",
      " [ 0.39701493  0.60298507]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.74      0.97      0.84      1572\n",
      "        1.0       0.94      0.60      0.74      1340\n",
      "\n",
      "avg / total       0.83      0.80      0.79      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with KNei\n",
      "Prediction accuracy 0.776786\n",
      "[[ 0.96882952  0.03117048]\n",
      " [ 0.44850746  0.55149254]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.72      0.97      0.82      1572\n",
      "        1.0       0.94      0.55      0.69      1340\n",
      "\n",
      "avg / total       0.82      0.78      0.76      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with SVC(\n",
      "Prediction accuracy 0.831044\n",
      "[[ 0.96882952  0.03117048]\n",
      " [ 0.33059701  0.66940299]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.77      0.97      0.86      1572\n",
      "        1.0       0.95      0.67      0.78      1340\n",
      "\n",
      "avg / total       0.85      0.83      0.83      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with SVC(\n",
      "Prediction accuracy 0.804602\n",
      "[[ 0.96183206  0.03816794]\n",
      " [ 0.37985075  0.62014925]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.75      0.96      0.84      1572\n",
      "        1.0       0.93      0.62      0.74      1340\n",
      "\n",
      "avg / total       0.83      0.80      0.80      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with MLPC\n",
      "Prediction accuracy 0.865385\n",
      "[[ 0.9764631   0.0235369 ]\n",
      " [ 0.26492537  0.73507463]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.81      0.98      0.89      1572\n",
      "        1.0       0.96      0.74      0.83      1340\n",
      "\n",
      "avg / total       0.88      0.87      0.86      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with MLPC\n",
      "Prediction accuracy 0.842033\n",
      "[[ 0.98918575  0.01081425]\n",
      " [ 0.33059701  0.66940299]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.78      0.99      0.87      1572\n",
      "        1.0       0.98      0.67      0.80      1340\n",
      "\n",
      "avg / total       0.87      0.84      0.84      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with Rand\n",
      "Prediction accuracy 0.728022\n",
      "[[ 0.98982188  0.01017812]\n",
      " [ 0.57910448  0.42089552]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.67      0.99      0.80      1572\n",
      "        1.0       0.97      0.42      0.59      1340\n",
      "\n",
      "avg / total       0.81      0.73      0.70      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with Rand\n",
      "Prediction accuracy 0.711882\n",
      "[[ 0.99109415  0.00890585]\n",
      " [ 0.61567164  0.38432836]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.65      0.99      0.79      1572\n",
      "        1.0       0.97      0.38      0.55      1340\n",
      "\n",
      "avg / total       0.80      0.71      0.68      2912\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 1\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with KNei\n",
      "Prediction accuracy 0.746909\n",
      "[[ 0.65667915  0.34332085]\n",
      " [ 0.14274809  0.85725191]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.66      0.74      1602\n",
      "        1.0       0.67      0.86      0.75      1310\n",
      "\n",
      "avg / total       0.77      0.75      0.75      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with KNei\n",
      "Prediction accuracy 0.878434\n",
      "[[ 0.94020356  0.05979644]\n",
      " [ 0.19402985  0.80597015]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.85      0.94      0.89      1572\n",
      "        1.0       0.92      0.81      0.86      1340\n",
      "\n",
      "avg / total       0.88      0.88      0.88      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with SVC(\n",
      "Prediction accuracy 0.766140\n",
      "[[ 0.58988764  0.41011236]\n",
      " [ 0.01832061  0.98167939]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.59      0.74      1602\n",
      "        1.0       0.66      0.98      0.79      1310\n",
      "\n",
      "avg / total       0.83      0.77      0.76      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with SVC(\n",
      "Prediction accuracy 0.926854\n",
      "[[ 0.93193384  0.06806616]\n",
      " [ 0.07910448  0.92089552]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.93      0.93      0.93      1572\n",
      "        1.0       0.92      0.92      0.92      1340\n",
      "\n",
      "avg / total       0.93      0.93      0.93      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with MLPC\n",
      "Prediction accuracy 0.825549\n",
      "[[ 0.77465668  0.22534332]\n",
      " [ 0.11221374  0.88778626]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.77      0.83      1602\n",
      "        1.0       0.76      0.89      0.82      1310\n",
      "\n",
      "avg / total       0.84      0.83      0.83      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with MLPC\n",
      "Prediction accuracy 0.944368\n",
      "[[ 0.96119593  0.03880407]\n",
      " [ 0.07537313  0.92462687]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.94      0.96      0.95      1572\n",
      "        1.0       0.95      0.92      0.94      1340\n",
      "\n",
      "avg / total       0.94      0.94      0.94      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with Rand\n",
      "Prediction accuracy 0.787775\n",
      "[[ 0.65043695  0.34956305]\n",
      " [ 0.04427481  0.95572519]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.65      0.77      1602\n",
      "        1.0       0.69      0.96      0.80      1310\n",
      "\n",
      "avg / total       0.83      0.79      0.79      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with Rand\n",
      "Prediction accuracy 0.857486\n",
      "[[ 0.90776081  0.09223919]\n",
      " [ 0.20149254  0.79850746]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.84      0.91      0.87      1572\n",
      "        1.0       0.88      0.80      0.84      1340\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2912\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 2\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with KNei\n",
      "Prediction accuracy 0.769231\n",
      "[[ 0.70349563  0.29650437]\n",
      " [ 0.15038168  0.84961832]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.70      0.77      1602\n",
      "        1.0       0.70      0.85      0.77      1310\n",
      "\n",
      "avg / total       0.78      0.77      0.77      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with KNei\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy 0.902473\n",
      "[[ 0.94274809  0.05725191]\n",
      " [ 0.14477612  0.85522388]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.88      0.94      0.91      1572\n",
      "        1.0       0.93      0.86      0.89      1340\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with SVC(\n",
      "Prediction accuracy 0.729396\n",
      "[[ 0.52496879  0.47503121]\n",
      " [ 0.02061069  0.97938931]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.52      0.68      1602\n",
      "        1.0       0.63      0.98      0.77      1310\n",
      "\n",
      "avg / total       0.82      0.73      0.72      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with SVC(\n",
      "Prediction accuracy 0.908310\n",
      "[[ 0.89949109  0.10050891]\n",
      " [ 0.08134328  0.91865672]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.93      0.90      0.91      1572\n",
      "        1.0       0.89      0.92      0.90      1340\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with MLPC\n",
      "Prediction accuracy 0.808036\n",
      "[[ 0.71410737  0.28589263]\n",
      " [ 0.07709924  0.92290076]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.71      0.80      1602\n",
      "        1.0       0.73      0.92      0.81      1310\n",
      "\n",
      "avg / total       0.83      0.81      0.81      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with MLPC\n",
      "Prediction accuracy 0.907967\n",
      "[[ 0.93002545  0.06997455]\n",
      " [ 0.11791045  0.88208955]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.90      0.93      0.92      1572\n",
      "        1.0       0.91      0.88      0.90      1340\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2912\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with Rand\n",
      "Prediction accuracy 0.675824\n",
      "[[ 0.4650437   0.5349563 ]\n",
      " [ 0.06641221  0.93358779]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.47      0.61      1602\n",
      "        1.0       0.59      0.93      0.72      1310\n",
      "\n",
      "avg / total       0.76      0.68      0.66      2912\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with Rand\n",
      "Prediction accuracy 0.840316\n",
      "[[ 0.82061069  0.17938931]\n",
      " [ 0.13656716  0.86343284]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -0.0       0.88      0.82      0.85      1572\n",
      "        1.0       0.80      0.86      0.83      1340\n",
      "\n",
      "avg / total       0.84      0.84      0.84      2912\n",
      "\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# ====================== 24/07  cross-surf for the split datasets\n",
    "# feat_mask = []\n",
    "\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k='all',score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "pipe = pipe_list[2]\n",
    "\n",
    "for surf_ind, surf_dat in enumerate(surfaces):\n",
    "    print(\"Training on surface no. %d\" %surf_ind)\n",
    "    ind_mask = [True, True, True] \n",
    "    ind_mask[surf_ind] = False #  the training dataset is flagged by False\n",
    "    solely_for_printing_mask = [i for i, x in enumerate(ind_mask) if x == True]\n",
    "    train_x = surf_dat#[::100]\n",
    "    train_y = surf_labels[surf_ind]#[::100]\n",
    "    test_x = list(compress(surfaces, ind_mask)) # the rest splits, flagged by True, are kept for testing\n",
    "    test_y = list(compress(surf_labels,ind_mask))\n",
    "    \n",
    "#     for pipe_ind,pipe in enumerate(pipe_list):\n",
    "#     print(\"Fitting classifier no. %d...\" %pipe_ind)\n",
    "    pipe.fit(train_x,train_y) # fit the pipeline for every train set and every clf\n",
    "    print (\"...done fitting\")\n",
    "    feat = list(pipe.named_steps['feature_selection'].get_support(indices = True))\n",
    "    feat_mask+=feat\n",
    "    for test_ind, test_d in enumerate(test_x):\n",
    "        y_pred = pipe.predict(test_d)\n",
    "        y_true = test_y[test_ind]\n",
    "        cm = confusion_matrix(y_pred=y_pred, y_true=y_true)\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print (\"=============================================================\")\n",
    "        print(\"Trained on %d, testing on %d with %0.4s\" %(surf_ind, solely_for_printing_mask[test_ind], pipe.named_steps['classifier']))\n",
    "        print(\"Prediction accuracy %f\" %pipe.score(test_d,y_true))\n",
    "        print(cm)\n",
    "        print(classification_report(y_pred=y_pred, y_true = y_true))        \n",
    "        print (\"=============================================================\")\n",
    "\n",
    "tot_occs = get_feat_occ(feat_mask)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "Started fitting...\n",
      "...done fitting\n",
      "1\n",
      "Started fitting...\n",
      "...done fitting\n",
      "2\n",
      "Started fitting...\n",
      "...done fitting\n",
      "3\n",
      "Started fitting...\n",
      "...done fitting\n",
      "1\n",
      "0\n",
      "Started fitting...\n",
      "...done fitting\n",
      "1\n",
      "Started fitting...\n",
      "...done fitting\n",
      "2\n",
      "Started fitting...\n",
      "...done fitting\n",
      "3\n",
      "Started fitting...\n",
      "...done fitting\n",
      "2\n",
      "0\n",
      "Started fitting...\n",
      "...done fitting\n",
      "1\n",
      "Started fitting...\n",
      "...done fitting\n",
      "2\n",
      "Started fitting...\n",
      "...done fitting\n",
      "3\n",
      "Started fitting...\n",
      "...done fitting\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# ====================== 21/07 MONO AMFFT \n",
    "datapath = 'AMFFT_pipes_1b1/'\n",
    "for surf in range(len(surfaces)):\n",
    "    print(surf)\n",
    "    train_x = surfaces[surf]\n",
    "    for pipe_id, pipe in enumerate(pipe_list):\n",
    "        filename = 'surf'+'_'+str(surf)+'_'+'clf'+'_'+str(pipe_id)+'_'+'fs'+str(fs)\n",
    "        print(pipe_id)\n",
    "        pipefile = datapath+filename+'.npz'\n",
    "        print(\"Started fitting...\")\n",
    "        model = pipe.fit(train_x, surf_labels[surf])\n",
    "#         models.append(model)\n",
    "        print(\"...done fitting\")\n",
    "        np.savez(pipefile,model=np.array([model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.996479, total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.994709, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.992958, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.1min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.992958, total= 4.1min\n",
      "[CV] ................................. , score=0.996473, total= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : KNei, 5-fold avg score = 0.994715\n",
      "[ 0.99295775  0.99295775  0.99647887  0.99470899  0.99647266]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.984155, total= 4.1min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.991182, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.985915, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.1min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.987676, total= 4.1min\n",
      "[CV] ................................. , score=0.971781, total= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : SVC(, 5-fold avg score = 0.984142\n",
      "[ 0.98591549  0.98415493  0.98767606  0.99118166  0.97178131]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.989437, total= 4.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.996479, total= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.2min remaining:  6.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.994709, total= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.3min remaining:  2.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.998239, total= 4.3min\n",
      "[CV] ................................. , score=0.998236, total= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : MLPC, 5-fold avg score = 0.995420\n",
      "[ 0.99823944  0.98943662  0.99647887  0.99470899  0.99823633]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.992958, total= 5.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.992945, total= 5.2min\n",
      "[CV] ................................. , score=0.961268, total= 5.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  5.2min remaining:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  5.2min remaining:  3.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.984155, total= 5.2min\n",
      "[CV] ................................. , score=0.989418, total= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  7.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 0, classifier : Rand, 5-fold avg score = 0.984149\n",
      "[ 0.96126761  0.98415493  0.99295775  0.99294533  0.98941799]\n",
      "=============================================================\n",
      "1\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.996479, total= 4.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.991197, total= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.3min remaining:  6.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.998239, total= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.3min remaining:  2.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.994709, total= 4.3min\n",
      "[CV] ................................. , score=1.000000, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : KNei, 5-fold avg score = 0.996125\n",
      "[ 0.99647887  0.99823944  0.99119718  0.99470899  1.        ]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.994718, total= 4.4min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.989437, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.5min remaining:  6.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.989437, total= 4.5min\n",
      "[CV] ................................. , score=0.987654, total= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.5min remaining:  3.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.982363, total= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : SVC(, 5-fold avg score = 0.988722\n",
      "[ 0.99471831  0.98943662  0.98943662  0.98765432  0.98236332]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.994709, total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.998239, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.994718, total= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.2min remaining:  2.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.994718, total= 4.2min\n",
      "[CV] ................................. , score=0.991182, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : MLPC, 5-fold avg score = 0.994713\n",
      "[ 0.99823944  0.99471831  0.99471831  0.99470899  0.99118166]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.982363, total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.982394, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.985915, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.1min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.985915, total= 4.1min\n",
      "[CV] ................................. , score=0.989418, total= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 1, classifier : Rand, 5-fold avg score = 0.985201\n",
      "[ 0.98591549  0.98591549  0.98239437  0.98236332  0.98941799]\n",
      "=============================================================\n",
      "2\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.971831, total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.998239, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.998236, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.1min remaining:  2.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.947183, total= 4.2min\n",
      "[CV] ................................. , score=0.998236, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : KNei, 5-fold avg score = 0.982745\n",
      "[ 0.99823944  0.97183099  0.9471831   0.99823633  0.99823633]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.933099, total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.947183, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.0min remaining:  6.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.933099, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.0min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.925926, total= 4.0min\n",
      "[CV] ................................. , score=0.954145, total= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : SVC(, 5-fold avg score = 0.938690\n",
      "[ 0.93309859  0.9471831   0.93309859  0.92592593  0.95414462]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.982394, total= 4.1min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.936620, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.982363, total= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.2min remaining:  2.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.952465, total= 4.2min\n",
      "[CV] ................................. , score=0.996473, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : MLPC, 5-fold avg score = 0.970063\n",
      "[ 0.98239437  0.95246479  0.93661972  0.98236332  0.99647266]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.961268, total= 4.0min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.998236, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.1min remaining:  6.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.941901, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.1min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.941901, total= 4.1min\n",
      "[CV] ................................. , score=0.998236, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Object : 2, classifier : Rand, 5-fold avg score = 0.968309\n",
      "[ 0.94190141  0.96126761  0.94190141  0.99823633  0.99823633]\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============ 21/07\n",
    "\n",
    "# cross-validate on the different objects using the dataset from both fingers\n",
    "\n",
    "# data_X = deepcopy(X[2][2]) # choose the featureset\n",
    "# data_Y = deepcopy(Y[2])\n",
    "# surfaces = np.split(data_X,3)\n",
    "# surf_labels = np.split(data_Y,3)\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "scores = []\n",
    "\n",
    "for surf_ind, surf_data in enumerate(surfaces):\n",
    "    print(surf_ind)\n",
    "    data = surf_data\n",
    "    labels = surf_labels[surf_ind]\n",
    "    for pipe in pipe_list:\n",
    "        score = cross_val_score(estimator = pipe, X = data, y = labels, cv = cv, verbose = 10, n_jobs=-1)\n",
    "        scores.append(score)\n",
    "        print (\"=============================================================\")\n",
    "        print(\"Object : %d, classifier : %0.4s, 5-fold avg score = %f\" %(surf_ind, pipe.named_steps['classifier'], np.mean(score)))\n",
    "        print(score)\n",
    "        print (\"=============================================================\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on surface no. 0\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with KNei\n",
      "Prediction accuracy 0.987667\n",
      "[[ 0.9986755  0.0013245]\n",
      " [ 0.0248494  0.9751506]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      1510\n",
      "        1.0       1.00      0.98      0.99      1328\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with KNei\n",
      "Prediction accuracy 0.976744\n",
      "[[ 0.97100515  0.02899485]\n",
      " [ 0.0163297   0.9836703 ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.97      0.98      1552\n",
      "        1.0       0.97      0.98      0.97      1286\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with SVC(\n",
      "Prediction accuracy 0.986258\n",
      "[[ 0.9807947   0.0192053 ]\n",
      " [ 0.00753012  0.99246988]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.98      0.99      1510\n",
      "        1.0       0.98      0.99      0.99      1328\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with SVC(\n",
      "Prediction accuracy 0.967935\n",
      "[[ 0.94780928  0.05219072]\n",
      " [ 0.00777605  0.99222395]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.95      0.97      1552\n",
      "        1.0       0.94      0.99      0.97      1286\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with MLPC\n",
      "Prediction accuracy 0.980973\n",
      "[[ 0.99801325  0.00198675]\n",
      " [ 0.03840361  0.96159639]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98      1510\n",
      "        1.0       1.00      0.96      0.98      1328\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with MLPC\n",
      "Prediction accuracy 0.982030\n",
      "[[ 0.99162371  0.00837629]\n",
      " [ 0.02954899  0.97045101]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.98      1552\n",
      "        1.0       0.99      0.97      0.98      1286\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with Rand\n",
      "Prediction accuracy 0.991543\n",
      "[[ 0.98874172  0.01125828]\n",
      " [ 0.00527108  0.99472892]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      0.99      1510\n",
      "        1.0       0.99      0.99      0.99      1328\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with Rand\n",
      "Prediction accuracy 0.965469\n",
      "[[ 0.94201031  0.05798969]\n",
      " [ 0.00622084  0.99377916]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.94      0.97      1552\n",
      "        1.0       0.93      0.99      0.96      1286\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2838\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 1\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with KNei\n",
      "Prediction accuracy 0.990134\n",
      "[[ 0.98672566  0.01327434]\n",
      " [ 0.00557325  0.99442675]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      0.99      1582\n",
      "        1.0       0.98      0.99      0.99      1256\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with KNei\n",
      "Prediction accuracy 0.979915\n",
      "[[ 0.96585052  0.03414948]\n",
      " [ 0.00311042  0.99688958]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.97      0.98      1552\n",
      "        1.0       0.96      1.00      0.98      1286\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with SVC(\n",
      "Prediction accuracy 0.985201\n",
      "[[ 0.97914033  0.02085967]\n",
      " [ 0.00716561  0.99283439]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.98      0.99      1582\n",
      "        1.0       0.97      0.99      0.98      1256\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with SVC(\n",
      "Prediction accuracy 0.972868\n",
      "[[ 0.95489691  0.04510309]\n",
      " [ 0.00544323  0.99455677]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.95      0.97      1552\n",
      "        1.0       0.95      0.99      0.97      1286\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with MLPC\n",
      "Prediction accuracy 0.991543\n",
      "[[ 0.99051833  0.00948167]\n",
      " [ 0.00716561  0.99283439]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      1582\n",
      "        1.0       0.99      0.99      0.99      1256\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with MLPC\n",
      "Prediction accuracy 0.994715\n",
      "[[ 0.99420103  0.00579897]\n",
      " [ 0.00466563  0.99533437]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00      1552\n",
      "        1.0       0.99      1.00      0.99      1286\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with Rand\n",
      "Prediction accuracy 0.979915\n",
      "[[ 0.96523388  0.03476612]\n",
      " [ 0.00159236  0.99840764]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.97      0.98      1582\n",
      "        1.0       0.96      1.00      0.98      1256\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with Rand\n",
      "Prediction accuracy 0.966526\n",
      "[[ 0.94072165  0.05927835]\n",
      " [ 0.00233281  0.99766719]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.94      0.97      1552\n",
      "        1.0       0.93      1.00      0.96      1286\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2838\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 2\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with KNei\n",
      "Prediction accuracy 0.924947\n",
      "[[ 0.90834387  0.09165613]\n",
      " [ 0.05414013  0.94585987]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.91      0.93      1582\n",
      "        1.0       0.89      0.95      0.92      1256\n",
      "\n",
      "avg / total       0.93      0.92      0.93      2838\n",
      "\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Trained on 2, testing on 1 with KNei\n",
      "Prediction accuracy 0.961945\n",
      "[[ 0.96490066  0.03509934]\n",
      " [ 0.04141566  0.95858434]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.96      0.96      1510\n",
      "        1.0       0.96      0.96      0.96      1328\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with SVC(\n",
      "Prediction accuracy 0.955250\n",
      "[[ 0.97281922  0.02718078]\n",
      " [ 0.06687898  0.93312102]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.97      0.96      1582\n",
      "        1.0       0.96      0.93      0.95      1256\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with SVC(\n",
      "Prediction accuracy 0.945736\n",
      "[[ 0.97417219  0.02582781]\n",
      " [ 0.08659639  0.91340361]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.97      0.95      1510\n",
      "        1.0       0.97      0.91      0.94      1328\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with MLPC\n",
      "Prediction accuracy 0.952079\n",
      "[[ 0.96144121  0.03855879]\n",
      " [ 0.05971338  0.94028662]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.96      0.96      1582\n",
      "        1.0       0.95      0.94      0.95      1256\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with MLPC\n",
      "Prediction accuracy 0.948203\n",
      "[[ 0.9602649   0.0397351 ]\n",
      " [ 0.06551205  0.93448795]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.96      0.95      1510\n",
      "        1.0       0.95      0.93      0.94      1328\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2838\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with Rand\n",
      "Prediction accuracy 0.955250\n",
      "[[ 0.94247788  0.05752212]\n",
      " [ 0.02866242  0.97133758]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.94      0.96      1582\n",
      "        1.0       0.93      0.97      0.95      1256\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2838\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with Rand\n",
      "Prediction accuracy 0.959479\n",
      "[[ 0.95165563  0.04834437]\n",
      " [ 0.03162651  0.96837349]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.95      0.96      1510\n",
      "        1.0       0.95      0.97      0.96      1328\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2838\n",
      "\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# =========================== 21/07\n",
    "\n",
    "\n",
    "\n",
    "# %%time\n",
    "# validate between the different objects using the dataset from both fingers\n",
    "\n",
    "# Version 1: keep alternatively one for training and test on the rest\n",
    "\n",
    "\n",
    "# data_X = deepcopy(X[2][1]) #[:-1]\n",
    "# data_Y = deepcopy(Y[2]) #[:-1]\n",
    "# print(data_X.shape)\n",
    "# surfaces = np.split(data_X,3)\n",
    "# surf_labels = np.split(data_Y,3) \n",
    "feat_mask = []\n",
    "\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "\n",
    "for surf_ind, surf_dat in enumerate(surfaces):\n",
    "    print(\"Training on surface no. %d\" %surf_ind)\n",
    "    ind_mask = [True, True, True] \n",
    "    ind_mask[surf_ind] = False #  the training dataset is flagged by False\n",
    "    solely_for_printing_mask = [i for i, x in enumerate(ind_mask) if x == True]\n",
    "    train_x = surf_dat#[::100]\n",
    "    train_y = surf_labels[surf_ind]#[::100]\n",
    "    test_x = list(compress(surfaces, ind_mask)) # the rest splits, flagged by True, are kept for testing\n",
    "    test_y = list(compress(surf_labels,ind_mask))\n",
    "    \n",
    "    for pipe_ind,pipe in enumerate(pipe_list):\n",
    "        print(\"Fitting classifier no. %d...\" %pipe_ind)\n",
    "        pipe.fit(train_x,train_y) # fit the pipeline for every train set and every clf\n",
    "        print (\"...done fitting\")\n",
    "        feat = list(pipe.named_steps['feature_selection'].get_support(indices = True))\n",
    "        feat_mask+=feat\n",
    "        for test_ind, test_d in enumerate(test_x):\n",
    "            y_pred = pipe.predict(test_d)\n",
    "            y_true = test_y[test_ind]\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=y_true)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print (\"=============================================================\")\n",
    "            print(\"Trained on %d, testing on %d with %0.4s\" %(surf_ind, solely_for_printing_mask[test_ind], pipe.named_steps['classifier']))\n",
    "            print(\"Prediction accuracy %f\" %pipe.score(test_d,y_true))\n",
    "            print(cm)\n",
    "            print(classification_report(y_pred=y_pred, y_true = y_true))        \n",
    "            print (\"=============================================================\")\n",
    "    \n",
    "tot_occs = get_feat_occ(feat_mask)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.895564, total= 6.5min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  6.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3302bd8c3db1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpipe_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"=============================================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mscore_func_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/mutual_info_.pyc\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     return _estimate_mi(X, y, discrete_features, True, n_neighbors,\n\u001b[0;32m--> 438\u001b[0;31m                         copy, random_state)\n\u001b[0m",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/mutual_info_.pyc\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target) for\n\u001b[0;32m--> 285\u001b[0;31m           x, discrete_feature in moves.zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/mutual_info_.pyc\u001b[0m in \u001b[0;36m_compute_mi\u001b[0;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx_discrete\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my_discrete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/mutual_info_.pyc\u001b[0m in \u001b[0;36m_compute_mi_cd\u001b[0;34m(c, d, n_neighbors)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kd_tree'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0mm_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mradius_neighbors\u001b[0;34m(self, X, radius, return_distance)\u001b[0m\n\u001b[1;32m    619\u001b[0m                     \"or set algorithm='brute'\" % self._fit_method)\n\u001b[1;32m    620\u001b[0m             results = self._tree.query_radius(X, radius,\n\u001b[0;32m--> 621\u001b[0;31m                                               return_distance=return_distance)\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# i: iterating over finger, j: over featureset \n",
    "# (consider keeping only the second featureset and discarding the rest to save some space)\n",
    "# Performing cross validation for each finger on the second feature set \n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "# set the pipeline\n",
    "# def make_pipe_clf(scaler,feature_selection,decomp,clf):\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "scores = []\n",
    "for i in range(len(X)):\n",
    "    data = deepcopy(X[i][2])\n",
    "    print(i)\n",
    "    labels = deepcopy(Y[i])\n",
    "    for pipe in pipe_list:\n",
    "        score = cross_val_score(estimator = pipe, X = data, y = labels, cv = cv, verbose = 100)\n",
    "        scores.append(score)\n",
    "        print (\"=============================================================\")\n",
    "        print(\"Datasets : %d, classifier : %0.4s, 5-fold avg score = %f\" %(i, pipe.named_steps['classifier'], np.mean(score)))\n",
    "        print(score)\n",
    "        print (\"=============================================================\")\n",
    "        \n",
    "# print pipe_list[1].named_steps['classifier']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.887205, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.924115, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.9min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.905565, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.3min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.934233, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.7min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.881956, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.1min finished\n",
      "=============================================================\n",
      "Object : 0, classifier : KNei, 5-fold avg score = 0.906615\n",
      "[ 0.88720539  0.92411467  0.90556492  0.93423272  0.88195616]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.932660, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.913997, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.951096, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.2min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.961214, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.7min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.890388, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min finished\n",
      "=============================================================\n",
      "Object : 0, classifier : SVC(, 5-fold avg score = 0.929871\n",
      "[ 0.93265993  0.91399663  0.95109612  0.96121417  0.89038786]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.957912, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.939292, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.905565, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.2min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.981450, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.915683, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.0min finished\n",
      "=============================================================\n",
      "Object : 0, classifier : MLPC, 5-fold avg score = 0.939980\n",
      "[ 0.95791246  0.93929174  0.90556492  0.98145025  0.91568297]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.919192, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.927487, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.954469, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.2min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.989882, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.919056, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min finished\n",
      "=============================================================\n",
      "Object : 0, classifier : Rand, 5-fold avg score = 0.942017\n",
      "[ 0.91919192  0.92748735  0.9544688   0.98988196  0.91905565]\n",
      "=============================================================\n",
      "1\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.627946, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.895447, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.767285, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.7min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.893761, total= 3.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 10.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.902192, total= 4.2min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 15.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 15.0min finished\n",
      "=============================================================\n",
      "Object : 1, classifier : KNei, 5-fold avg score = 0.817326\n",
      "[ 0.62794613  0.89544688  0.76728499  0.89376054  0.90219224]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.638047, total= 4.2min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.2min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.947723, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.770658, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 10.3min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.890388, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 12.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.883642, total= 2.2min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 14.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 14.9min finished\n",
      "=============================================================\n",
      "Object : 1, classifier : SVC(, 5-fold avg score = 0.826092\n",
      "[ 0.63804714  0.94772344  0.77065767  0.89038786  0.8836425 ]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.784512, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.967960, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.777403, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.917369, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.920742, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.9min finished\n",
      "=============================================================\n",
      "Object : 1, classifier : MLPC, 5-fold avg score = 0.873597\n",
      "[ 0.78451178  0.96795953  0.77740304  0.91736931  0.92074199]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.969697, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.966273, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.772344, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.903879, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.915683, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.9min finished\n",
      "=============================================================\n",
      "Object : 1, classifier : Rand, 5-fold avg score = 0.905575\n",
      "[ 0.96969697  0.96627319  0.77234401  0.90387858  0.91568297]\n",
      "=============================================================\n",
      "2\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.764310, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.951096, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.856661, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.961214, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.770658, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min finished\n",
      "=============================================================\n",
      "Object : 2, classifier : KNei, 5-fold avg score = 0.860788\n",
      "[ 0.76430976  0.95109612  0.85666105  0.96121417  0.77065767]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.695286, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.929174, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.905565, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.984823, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.775717, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min finished\n",
      "=============================================================\n",
      "Object : 2, classifier : SVC(, 5-fold avg score = 0.858113\n",
      "[ 0.6952862   0.92917369  0.90556492  0.98482293  0.77571669]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.818182, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.946037, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.915683, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.964587, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.812816, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min finished\n",
      "=============================================================\n",
      "Object : 2, classifier : MLPC, 5-fold avg score = 0.891461\n",
      "[ 0.81818182  0.9460371   0.91568297  0.96458685  0.81281619]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.966330, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.974705, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.915683, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.984823, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.770658, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min finished\n",
      "=============================================================\n",
      "Object : 2, classifier : Rand, 5-fold avg score = 0.922440\n",
      "[ 0.96632997  0.97470489  0.91568297  0.98482293  0.77065767]\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# cross-validate on the different objects using the dataset from both fingers\n",
    "data_X = deepcopy(X[2][2]) # choose the featureset\n",
    "data_Y = deepcopy(Y[2])\n",
    "surfaces = np.split(data_X,3)\n",
    "surf_labels = np.split(data_Y,3)\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "scores = []\n",
    "\n",
    "for surf_ind, surf_data in enumerate(surfaces):\n",
    "    print(surf_ind)\n",
    "    data = surf_data\n",
    "    labels = surf_labels[surf_ind]\n",
    "    for pipe in pipe_list:\n",
    "        score = cross_val_score(estimator = pipe, X = data, y = labels, cv = cv, verbose = 100)\n",
    "        scores.append(score)\n",
    "        print (\"=============================================================\")\n",
    "        print(\"Object : %d, classifier : %0.4s, 5-fold avg score = %f\" %(surf_ind, pipe.named_steps['classifier'], np.mean(score)))\n",
    "        print(score)\n",
    "        print (\"=============================================================\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started fitting...\n",
      "...done fitting\n",
      "Started fitting...\n",
      "...done fitting\n",
      "Started fitting...\n",
      "...done fitting\n"
     ]
    }
   ],
   "source": [
    "data_X = deepcopy(X[2][1]) # choose the featureset\n",
    "data_Y = deepcopy(Y[2])\n",
    "surfaces = np.split(data_X,3)\n",
    "surf_labels = np.split(data_Y,3)\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "clf = pipe_list[2]\n",
    "datapath = 'surf_pipe/'\n",
    "\n",
    "for surf_ind, surf_data in enumerate(surfaces):\n",
    "    data = surf_data\n",
    "    labels = surf_labels[surf_ind]\n",
    "    print(\"Started fitting...\")\n",
    "    surf_model = clf.fit(data,labels)\n",
    "    filename = 'surf_pipe'+'_'+str(surf_ind)\n",
    "    pipefile = datapath+filename+'.npz'\n",
    "    print(\"...done fitting\")\n",
    "    np.savez(pipefile,surf_model=np.array([surf_model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8898, 3107)\n",
      "Training on surface no. 0\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with KNei\n",
      "Prediction accuracy 0.860081\n",
      "[[ 0.92158134  0.07841866]\n",
      " [ 0.20660576  0.79339424]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.92      0.87      1543\n",
      "        1.0       0.90      0.79      0.84      1423\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with KNei\n",
      "Prediction accuracy 0.827040\n",
      "[[ 0.92875318  0.07124682]\n",
      " [ 0.28766141  0.71233859]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.93      0.85      1572\n",
      "        1.0       0.90      0.71      0.79      1394\n",
      "\n",
      "avg / total       0.84      0.83      0.82      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with SVC(\n",
      "Prediction accuracy 0.913014\n",
      "[[ 0.96759559  0.03240441]\n",
      " [ 0.14617006  0.85382994]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.97      0.92      1543\n",
      "        1.0       0.96      0.85      0.90      1423\n",
      "\n",
      "avg / total       0.92      0.91      0.91      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with SVC(\n",
      "Prediction accuracy 0.879299\n",
      "[[ 0.99236641  0.00763359]\n",
      " [ 0.2482066   0.7517934 ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.99      0.90      1572\n",
      "        1.0       0.99      0.75      0.85      1394\n",
      "\n",
      "avg / total       0.90      0.88      0.88      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with MLPC\n",
      "Prediction accuracy 0.880647\n",
      "[[ 0.80622165  0.19377835]\n",
      " [ 0.03865074  0.96134926]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.81      0.88      1543\n",
      "        1.0       0.82      0.96      0.89      1423\n",
      "\n",
      "avg / total       0.89      0.88      0.88      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with MLPC\n",
      "Prediction accuracy 0.891773\n",
      "[[ 0.87531807  0.12468193]\n",
      " [ 0.08967001  0.91032999]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.88      0.90      1572\n",
      "        1.0       0.87      0.91      0.89      1394\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0, testing on 1 with Rand\n",
      "Prediction accuracy 0.894808\n",
      "[[ 0.91315619  0.08684381]\n",
      " [ 0.12508784  0.87491216]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.91      0.90      1543\n",
      "        1.0       0.90      0.87      0.89      1423\n",
      "\n",
      "avg / total       0.90      0.89      0.89      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0, testing on 2 with Rand\n",
      "Prediction accuracy 0.903574\n",
      "[[ 0.9586514   0.0413486 ]\n",
      " [ 0.15853659  0.84146341]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.96      0.91      1572\n",
      "        1.0       0.95      0.84      0.89      1394\n",
      "\n",
      "avg / total       0.91      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 1\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with KNei\n",
      "Prediction accuracy 0.911666\n",
      "[[ 0.99085565  0.00914435]\n",
      " [ 0.1728223   0.8271777 ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.99      0.92      1531\n",
      "        1.0       0.99      0.83      0.90      1435\n",
      "\n",
      "avg / total       0.92      0.91      0.91      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with KNei\n",
      "Prediction accuracy 0.839852\n",
      "[[ 0.94338422  0.05661578]\n",
      " [ 0.276901    0.723099  ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.94      0.86      1572\n",
      "        1.0       0.92      0.72      0.81      1394\n",
      "\n",
      "avg / total       0.85      0.84      0.84      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with SVC(\n",
      "Prediction accuracy 0.909643\n",
      "[[ 0.96080993  0.03919007]\n",
      " [ 0.14494774  0.85505226]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.96      0.92      1531\n",
      "        1.0       0.95      0.86      0.90      1435\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with SVC(\n",
      "Prediction accuracy 0.859744\n",
      "[[ 0.9980916   0.0019084 ]\n",
      " [ 0.29626973  0.70373027]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      1.00      0.88      1572\n",
      "        1.0       1.00      0.70      0.83      1394\n",
      "\n",
      "avg / total       0.89      0.86      0.86      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with MLPC\n",
      "Prediction accuracy 0.925152\n",
      "[[ 0.97452645  0.02547355]\n",
      " [ 0.12752613  0.87247387]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.97      0.93      1531\n",
      "        1.0       0.97      0.87      0.92      1435\n",
      "\n",
      "avg / total       0.93      0.93      0.92      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with MLPC\n",
      "Prediction accuracy 0.864464\n",
      "[[ 0.94083969  0.05916031]\n",
      " [ 0.22166428  0.77833572]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.94      0.88      1572\n",
      "        1.0       0.92      0.78      0.84      1394\n",
      "\n",
      "avg / total       0.87      0.86      0.86      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1, testing on 0 with Rand\n",
      "Prediction accuracy 0.922117\n",
      "[[ 0.9268452   0.0731548 ]\n",
      " [ 0.08292683  0.91707317]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.93      0.92      1531\n",
      "        1.0       0.92      0.92      0.92      1435\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1, testing on 2 with Rand\n",
      "Prediction accuracy 0.906608\n",
      "[[ 0.96819338  0.03180662]\n",
      " [ 0.16284075  0.83715925]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.97      0.92      1572\n",
      "        1.0       0.96      0.84      0.89      1394\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2966\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 2\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with KNei\n",
      "Prediction accuracy 0.899865\n",
      "[[ 0.910516    0.089484  ]\n",
      " [ 0.11149826  0.88850174]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.91      0.90      1531\n",
      "        1.0       0.90      0.89      0.90      1435\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Trained on 2, testing on 1 with KNei\n",
      "Prediction accuracy 0.863452\n",
      "[[ 0.8198315   0.1801685 ]\n",
      " [ 0.08924807  0.91075193]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.82      0.86      1543\n",
      "        1.0       0.82      0.91      0.86      1423\n",
      "\n",
      "avg / total       0.87      0.86      0.86      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with SVC(\n",
      "Prediction accuracy 0.889751\n",
      "[[ 0.86348792  0.13651208]\n",
      " [ 0.08222997  0.91777003]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.86      0.89      1531\n",
      "        1.0       0.86      0.92      0.89      1435\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with SVC(\n",
      "Prediction accuracy 0.866150\n",
      "[[ 0.78742709  0.21257291]\n",
      " [ 0.04848911  0.95151089]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.79      0.86      1543\n",
      "        1.0       0.80      0.95      0.87      1423\n",
      "\n",
      "avg / total       0.88      0.87      0.87      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with MLPC\n",
      "Prediction accuracy 0.887728\n",
      "[[ 0.89353364  0.10646636]\n",
      " [ 0.1184669   0.8815331 ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.89      0.89      1531\n",
      "        1.0       0.89      0.88      0.88      1435\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with MLPC\n",
      "Prediction accuracy 0.867161\n",
      "[[ 0.83279326  0.16720674]\n",
      " [ 0.09557273  0.90442727]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.83      0.87      1543\n",
      "        1.0       0.83      0.90      0.87      1423\n",
      "\n",
      "avg / total       0.87      0.87      0.87      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2, testing on 0 with Rand\n",
      "Prediction accuracy 0.899191\n",
      "[[ 0.87459177  0.12540823]\n",
      " [ 0.07456446  0.92543554]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.87      0.90      1531\n",
      "        1.0       0.87      0.93      0.90      1435\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2, testing on 1 with Rand\n",
      "Prediction accuracy 0.876264\n",
      "[[ 0.808814    0.191186  ]\n",
      " [ 0.05059733  0.94940267]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.81      0.87      1543\n",
      "        1.0       0.82      0.95      0.88      1423\n",
      "\n",
      "avg / total       0.89      0.88      0.88      2966\n",
      "\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# validate between the different objects using the dataset from both fingers\n",
    "\n",
    "# Version 1: keep alternatively one for training and test on the rest\n",
    "\n",
    "\n",
    "data_X = deepcopy(X[2][1]) #[:-1]\n",
    "data_Y = deepcopy(Y[2]) #[:-1]\n",
    "print(data_X.shape)\n",
    "surfaces = np.split(data_X,3)\n",
    "surf_labels = np.split(data_Y,3) \n",
    "feat_mask = []\n",
    "\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "\n",
    "for surf_ind, surf_dat in enumerate(surfaces):\n",
    "    print(\"Training on surface no. %d\" %surf_ind)\n",
    "    ind_mask = [True, True, True] \n",
    "    ind_mask[surf_ind] = False #  the training dataset is flagged by False\n",
    "    solely_for_printing_mask = [i for i, x in enumerate(ind_mask) if x == True]\n",
    "    train_x = surf_dat#[::100]\n",
    "    train_y = surf_labels[surf_ind]#[::100]\n",
    "    test_x = list(compress(surfaces, ind_mask)) # the rest splits, flagged by True, are kept for testing\n",
    "    test_y = list(compress(surf_labels,ind_mask))\n",
    "    \n",
    "    for pipe_ind,pipe in enumerate(pipe_list):\n",
    "        print(\"Fitting classifier no. %d...\" %pipe_ind)\n",
    "        pipe.fit(train_x,train_y) # fit the pipeline for every train set and every clf\n",
    "        print (\"...done fitting\")\n",
    "        feat = list(pipe.named_steps['feature_selection'].get_support(indices = True))\n",
    "        feat_mask+=feat\n",
    "        for test_ind, test_d in enumerate(test_x):\n",
    "            y_pred = pipe.predict(test_d)\n",
    "            y_true = test_y[test_ind]\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=y_true)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print (\"=============================================================\")\n",
    "            print(\"Trained on %d, testing on %d with %0.4s\" %(surf_ind, solely_for_printing_mask[test_ind], pipe.named_steps['classifier']))\n",
    "            print(\"Prediction accuracy %f\" %pipe.score(test_d,y_true))\n",
    "            print(cm)\n",
    "            print(classification_report(y_pred=y_pred, y_true = y_true))        \n",
    "            print (\"=============================================================\")\n",
    "    \n",
    "tot_occs = get_feat_occ(feat_mask)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n",
      "(3111, 'var', 'Phin', 'Time', 'Ft/Fn')\n",
      "(3112, 'rms', 'Phin', 'Time', 'Ft/Fn')\n",
      "(3113, 'rng', 'Phin', 'Time', 'Ft/Fn')\n",
      "(3114, 'wavl', 'Phin', 'Time', 'Ft/Fn')\n",
      "(3127, 'mmdf', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3128, 'reFFT000', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3130, 'reFFT002', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3131, 'reFFT003', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3132, 'reFFT004', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3133, 'reFFT005', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3134, 'reFFT006', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3135, 'reFFT007', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3136, 'reFFT008', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3137, 'reFFT009', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3138, 'reFFT010', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3139, 'reFFT011', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3140, 'reFFT012', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3141, 'reFFT013', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3146, 'reFFT018', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3148, 'reFFT020', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3644, 'imFFT003', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3649, 'imFFT008', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3651, 'imFFT010', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(3665, 'imFFT024', 'Phin', 'Freq', 'Ft/Fn')\n",
      "(4156, 'mx', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4157, 'rngx', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4159, 'med', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4160, 'hjorth', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4163, 'ssk', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4165, 'acrol0001', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4166, 'acrol0002', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4167, 'acrol0003', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4168, 'acrol0004', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4169, 'acrol0005', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4170, 'acrol0006', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4171, 'acrol0007', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4172, 'acrol0008', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4173, 'acrol0009', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4174, 'acrol0010', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4175, 'acrol0011', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4176, 'acrol0012', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4177, 'acrol0013', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4178, 'acrol0014', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4179, 'acrol0015', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4180, 'acrol0016', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4181, 'acrol0017', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4182, 'acrol0018', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4183, 'acrol0019', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4184, 'acrol0020', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4185, 'acrol0021', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4186, 'acrol0022', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4187, 'acrol0023', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4188, 'acrol0024', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4194, 'acrol0030', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4195, 'acrol0031', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4197, 'acrol0033', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4198, 'acrol0034', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4199, 'acrol0035', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4200, 'acrol0036', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4201, 'acrol0037', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4202, 'acrol0038', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4203, 'acrol0039', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4204, 'acrol0040', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4205, 'acrol0041', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4206, 'acrol0042', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4207, 'acrol0043', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4208, 'acrol0044', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4209, 'acrol0045', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4210, 'acrol0046', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4211, 'acrol0047', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4212, 'acrol0048', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4213, 'acrol0049', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4214, 'acrol0050', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4215, 'acrol0051', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4216, 'acrol0052', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4217, 'acrol0053', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4218, 'acrol0054', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4219, 'acrol0055', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4220, 'acrol0056', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4221, 'acrol0057', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4222, 'acrol0058', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4223, 'acrol0059', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4224, 'acrol0060', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4225, 'acrol0061', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4226, 'acrol0062', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4227, 'acrol0063', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4228, 'acrol0064', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4229, 'acrol0065', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4230, 'acrol0066', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4231, 'acrol0067', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4232, 'acrol0068', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4233, 'acrol0069', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4234, 'acrol0070', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4235, 'acrol0071', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4236, 'acrol0072', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4237, 'acrol0073', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4238, 'acrol0074', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4239, 'acrol0075', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4240, 'acrol0076', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4241, 'acrol0077', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4242, 'acrol0078', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4243, 'acrol0079', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4244, 'acrol0080', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4245, 'acrol0081', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4246, 'acrol0082', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4247, 'acrol0083', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4248, 'acrol0084', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4249, 'acrol0085', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4250, 'acrol0086', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4251, 'acrol0087', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4252, 'acrol0088', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4253, 'acrol0089', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4254, 'acrol0090', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4255, 'acrol0091', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4256, 'acrol0092', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4257, 'acrol0093', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4258, 'acrol0094', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4259, 'acrol0095', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4260, 'acrol0096', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4261, 'acrol0097', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4262, 'acrol0098', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4263, 'acrol0099', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4264, 'acrol0100', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4265, 'acrol0101', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4266, 'acrol0102', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4267, 'acrol0103', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4268, 'acrol0104', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4269, 'acrol0105', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4270, 'acrol0106', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4271, 'acrol0107', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4272, 'acrol0108', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4273, 'acrol0109', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4274, 'acrol0110', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4275, 'acrol0111', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4276, 'acrol0112', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4277, 'acrol0113', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4278, 'acrol0114', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4279, 'acrol0115', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4280, 'acrol0116', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4281, 'acrol0117', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4282, 'acrol0118', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4283, 'acrol0119', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4284, 'acrol0120', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4285, 'acrol0121', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4286, 'acrol0122', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4287, 'acrol0123', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4288, 'acrol0124', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4289, 'acrol0125', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4290, 'acrol0126', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4291, 'acrol0127', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4292, 'acrol0128', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4293, 'acrol0129', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4294, 'acrol0130', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4295, 'acrol0131', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4296, 'acrol0132', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4297, 'acrol0133', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4298, 'acrol0134', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4299, 'acrol0135', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4300, 'acrol0136', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4301, 'acrol0137', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4302, 'acrol0138', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4303, 'acrol0139', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4304, 'acrol0140', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4305, 'acrol0141', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4306, 'acrol0142', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4307, 'acrol0143', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4308, 'acrol0144', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4309, 'acrol0145', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4310, 'acrol0146', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4311, 'acrol0147', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4312, 'acrol0148', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4313, 'acrol0149', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4314, 'acrol0150', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4315, 'acrol0151', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4316, 'acrol0152', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4317, 'acrol0153', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4318, 'acrol0154', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4319, 'acrol0155', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4320, 'acrol0156', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4321, 'acrol0157', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4322, 'acrol0158', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4323, 'acrol0159', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4324, 'acrol0160', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4325, 'acrol0161', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4326, 'acrol0162', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4327, 'acrol0163', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4328, 'acrol0164', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4329, 'acrol0165', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4330, 'acrol0166', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4331, 'acrol0167', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4332, 'acrol0168', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4333, 'acrol0169', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4334, 'acrol0170', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4335, 'acrol0171', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4336, 'acrol0172', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4337, 'acrol0173', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4338, 'acrol0174', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4339, 'acrol0175', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4340, 'acrol0176', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4341, 'acrol0177', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4342, 'acrol0178', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4343, 'acrol0179', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4344, 'acrol0180', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4345, 'acrol0181', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4346, 'acrol0182', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4347, 'acrol0183', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4348, 'acrol0184', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4349, 'acrol0185', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4350, 'acrol0186', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4351, 'acrol0187', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4352, 'acrol0188', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4353, 'acrol0189', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4354, 'acrol0190', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4355, 'acrol0191', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4356, 'acrol0192', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4357, 'acrol0193', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4358, 'acrol0194', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4361, 'acrol0197', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4362, 'acrol0198', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4363, 'acrol0199', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4364, 'acrol0200', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4365, 'acrol0201', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4366, 'acrol0202', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4367, 'acrol0203', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4368, 'acrol0204', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4369, 'acrol0205', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4370, 'acrol0206', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4371, 'acrol0207', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4375, 'acrol0211', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4376, 'acrol0212', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4377, 'acrol0213', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4378, 'acrol0214', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4379, 'acrol0215', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4380, 'acrol0216', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4381, 'acrol0217', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4394, 'acrol0230', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4395, 'acrol0231', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4396, 'acrol0232', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4397, 'acrol0233', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4398, 'acrol0234', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4399, 'acrol0235', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4400, 'acrol0236', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4401, 'acrol0237', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4402, 'acrol0238', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4403, 'acrol0239', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4404, 'acrol0240', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4405, 'acrol0241', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4406, 'acrol0242', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4408, 'acrol0244', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4409, 'acrol0245', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4411, 'acrol0247', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4412, 'acrol0248', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4413, 'acrol0249', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4414, 'acrol0250', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4415, 'acrol0251', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4416, 'acrol0252', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4417, 'acrol0253', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4418, 'acrol0254', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4419, 'acrol0255', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4420, 'acrol0256', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4422, 'acrol0258', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4423, 'acrol0259', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4424, 'acrol0260', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4428, 'acrol0264', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4429, 'acrol0265', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4430, 'acrol0266', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4431, 'acrol0267', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4432, 'acrol0268', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4433, 'acrol0269', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4434, 'acrol0270', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4435, 'acrol0271', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4437, 'acrol0273', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4441, 'acrol0277', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4442, 'acrol0278', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4443, 'acrol0279', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4482, 'acrol0318', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4484, 'acrol0320', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4485, 'acrol0321', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4486, 'acrol0322', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4487, 'acrol0323', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4535, 'acrol0371', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4536, 'acrol0372', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4537, 'acrol0373', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4538, 'acrol0374', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4539, 'acrol0375', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4540, 'acrol0376', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4546, 'acrol0382', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4547, 'acrol0383', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4548, 'acrol0384', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4549, 'acrol0385', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4550, 'acrol0386', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4551, 'acrol0387', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4553, 'acrol0389', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4554, 'acrol0390', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4555, 'acrol0391', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4556, 'acrol0392', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4558, 'acrol0394', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4559, 'acrol0395', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4565, 'acrol0401', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4573, 'acrol0409', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4574, 'acrol0410', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4575, 'acrol0411', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4576, 'acrol0412', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4577, 'acrol0413', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4578, 'acrol0414', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4579, 'acrol0415', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4580, 'acrol0416', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4581, 'acrol0417', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4582, 'acrol0418', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4583, 'acrol0419', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4584, 'acrol0420', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4585, 'acrol0421', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4586, 'acrol0422', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4587, 'acrol0423', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4588, 'acrol0424', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4589, 'acrol0425', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4590, 'acrol0426', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4591, 'acrol0427', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4592, 'acrol0428', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4593, 'acrol0429', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4594, 'acrol0430', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4595, 'acrol0431', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4596, 'acrol0432', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4597, 'acrol0433', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4601, 'acrol0437', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4602, 'acrol0438', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4603, 'acrol0439', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4604, 'acrol0440', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4605, 'acrol0441', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4606, 'acrol0442', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4607, 'acrol0443', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4608, 'acrol0444', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4610, 'acrol0446', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4611, 'acrol0447', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4612, 'acrol0448', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4613, 'acrol0449', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4614, 'acrol0450', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4615, 'acrol0451', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4616, 'acrol0452', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4617, 'acrol0453', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4618, 'acrol0454', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4619, 'acrol0455', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4620, 'acrol0456', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4624, 'acrol0460', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4626, 'acrol0462', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4627, 'acrol0463', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4632, 'acrol0468', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4633, 'acrol0469', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4635, 'acrol0471', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4638, 'acrol0474', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4639, 'acrol0475', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4640, 'acrol0476', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4641, 'acrol0477', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4642, 'acrol0478', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4643, 'acrol0479', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4644, 'acrol0480', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4646, 'acrol0482', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4651, 'acrol0487', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4658, 'acrol0494', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4663, 'acrol0499', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4664, 'acrol0500', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4665, 'acrol0501', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4666, 'acrol0502', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4667, 'acrol0503', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4669, 'acrol0505', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4673, 'acrol0509', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4674, 'acrol0510', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4675, 'acrol0511', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4676, 'acrol0512', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4677, 'acrol0513', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4678, 'acrol0514', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4679, 'acrol0515', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4680, 'acrol0516', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4681, 'acrol0517', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4682, 'acrol0518', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4683, 'acrol0519', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4684, 'acrol0520', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4685, 'acrol0521', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4686, 'acrol0522', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4688, 'acrol0524', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4689, 'acrol0525', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4690, 'acrol0526', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4699, 'acrol0535', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4726, 'acrol0562', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4727, 'acrol0563', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4728, 'acrol0564', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4729, 'acrol0565', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4730, 'acrol0566', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4731, 'acrol0567', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4732, 'acrol0568', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4734, 'acrol0570', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4736, 'acrol0572', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4808, 'acrol0644', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4817, 'acrol0653', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4818, 'acrol0654', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4821, 'acrol0657', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4822, 'acrol0658', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4823, 'acrol0659', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4824, 'acrol0660', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4825, 'acrol0661', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4826, 'acrol0662', 'Golz', 'Time', 'Ft/Fn')\n",
      "(4844, 'acrol0680', 'Golz', 'Time', 'Ft/Fn')\n",
      "(5043, 'acrol0879', 'Golz', 'Time', 'Ft/Fn')\n",
      "(5183, 'acrol1019', 'Golz', 'Time', 'Ft/Fn')\n",
      "(5198, 'amFFT010', 'Golz', 'Freq', 'Ft/Fn')\n",
      "(5199, 'amFFT011', 'Golz', 'Freq', 'Ft/Fn')\n",
      "(5200, 'amFFT012', 'Golz', 'Freq', 'Ft/Fn')\n",
      "(5711, 'phFFT010', 'Golz', 'Freq', 'Ft/Fn')\n",
      "(5712, 'phFFT011', 'Golz', 'Freq', 'Ft/Fn')\n",
      "(5713, 'phFFT012', 'Golz', 'Freq', 'Ft/Fn')\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################################\n",
    "# ==================== use this with Ft/Fn datasets ====================\n",
    "voi = 12   \n",
    "always_there = []\n",
    "offset = 3108\n",
    "off_feats = [feat_mask[i]+offset for i in range(len(feat_mask))]\n",
    "off_occs = get_feat_occ(off_feats)\n",
    "feat_list = []\n",
    "# print(off_occs)\n",
    "off_ordered = OrderedDict(sorted(off_occs.items(), key=lambda off_occs: off_occs[1]))\n",
    "for k,v in off_ordered.items():\n",
    "    feat_list.append(k)\n",
    "off_ids = get_feat_id(feat_list,printit = 0)\n",
    "\n",
    "for k, v in off_ordered.items():\n",
    "    if v == voi:\n",
    "        always_there.append(k)\n",
    "print(len(always_there))\n",
    "always_there_ids = get_feat_id(always_there, printit = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049, 'acrol0992', 'Golz', 'Time', 'Norm')\n",
      "(2057, 'acrol1000', 'Golz', 'Time', 'Norm')\n",
      "(2058, 'acrol1001', 'Golz', 'Time', 'Norm')\n",
      "(2059, 'acrol1002', 'Golz', 'Time', 'Norm')\n",
      "(2060, 'acrol1003', 'Golz', 'Time', 'Norm')\n",
      "(2061, 'acrol1004', 'Golz', 'Time', 'Norm')\n",
      "(2063, 'acrol1006', 'Golz', 'Time', 'Norm')\n",
      "(18, 'mdf', 'Phin', 'Freq', 'Norm')\n",
      "(34, 'reFFT013', 'Phin', 'Freq', 'Norm')\n",
      "(37, 'reFFT016', 'Phin', 'Freq', 'Norm')\n",
      "(38, 'reFFT017', 'Phin', 'Freq', 'Norm')\n",
      "(40, 'reFFT019', 'Phin', 'Freq', 'Norm')\n",
      "(41, 'reFFT020', 'Phin', 'Freq', 'Norm')\n",
      "(42, 'reFFT021', 'Phin', 'Freq', 'Norm')\n",
      "(43, 'reFFT022', 'Phin', 'Freq', 'Norm')\n",
      "(2105, 'amFFT024', 'Golz', 'Freq', 'Norm')\n",
      "(2106, 'amFFT025', 'Golz', 'Freq', 'Norm')\n",
      "(2107, 'amFFT026', 'Golz', 'Freq', 'Norm')\n",
      "(2108, 'amFFT027', 'Golz', 'Freq', 'Norm')\n",
      "(2109, 'amFFT028', 'Golz', 'Freq', 'Norm')\n",
      "(2110, 'amFFT029', 'Golz', 'Freq', 'Norm')\n",
      "(2111, 'amFFT030', 'Golz', 'Freq', 'Norm')\n",
      "(2112, 'amFFT031', 'Golz', 'Freq', 'Norm')\n",
      "(2113, 'amFFT032', 'Golz', 'Freq', 'Norm')\n",
      "(2, 'meanabsslp', 'Phin', 'Time', 'Norm')\n",
      "(2115, 'amFFT034', 'Golz', 'Freq', 'Norm')\n",
      "(2116, 'amFFT035', 'Golz', 'Freq', 'Norm')\n",
      "(2117, 'amFFT036', 'Golz', 'Freq', 'Norm')\n",
      "(2118, 'amFFT037', 'Golz', 'Freq', 'Norm')\n",
      "(2119, 'amFFT038', 'Golz', 'Freq', 'Norm')\n",
      "(2120, 'amFFT039', 'Golz', 'Freq', 'Norm')\n",
      "(2121, 'amFFT040', 'Golz', 'Freq', 'Norm')\n",
      "(2122, 'amFFT041', 'Golz', 'Freq', 'Norm')\n",
      "(2123, 'amFFT042', 'Golz', 'Freq', 'Norm')\n",
      "(2124, 'amFFT043', 'Golz', 'Freq', 'Norm')\n",
      "(2125, 'amFFT044', 'Golz', 'Freq', 'Norm')\n",
      "(2126, 'amFFT045', 'Golz', 'Freq', 'Norm')\n",
      "(2127, 'amFFT046', 'Golz', 'Freq', 'Norm')\n",
      "(2128, 'amFFT047', 'Golz', 'Freq', 'Norm')\n",
      "(2129, 'amFFT048', 'Golz', 'Freq', 'Norm')\n",
      "(2130, 'amFFT049', 'Golz', 'Freq', 'Norm')\n",
      "(2131, 'amFFT050', 'Golz', 'Freq', 'Norm')\n",
      "(2132, 'amFFT051', 'Golz', 'Freq', 'Norm')\n",
      "(2133, 'amFFT052', 'Golz', 'Freq', 'Norm')\n",
      "(2134, 'amFFT053', 'Golz', 'Freq', 'Norm')\n",
      "(2065, 'acrol1008', 'Golz', 'Time', 'Norm')\n",
      "(2067, 'acrol1010', 'Golz', 'Time', 'Norm')\n",
      "(2069, 'acrol1012', 'Golz', 'Time', 'Norm')\n",
      "(2070, 'acrol1013', 'Golz', 'Time', 'Norm')\n",
      "(550, 'imFFT016', 'Phin', 'Freq', 'Norm')\n",
      "(2074, 'acrol1017', 'Golz', 'Time', 'Norm')\n",
      "(2076, 'acrol1019', 'Golz', 'Time', 'Norm')\n",
      "(2077, 'acrol1020', 'Golz', 'Time', 'Norm')\n",
      "(2078, 'acrol1021', 'Golz', 'Time', 'Norm')\n",
      "(2052, 'acrol0995', 'Golz', 'Time', 'Norm')\n",
      "(2080, 'acrol1023', 'Golz', 'Time', 'Norm')\n",
      "(2053, 'acrol0996', 'Golz', 'Time', 'Norm')\n",
      "(2054, 'acrol0997', 'Golz', 'Time', 'Norm')\n",
      "(2055, 'acrol0998', 'Golz', 'Time', 'Norm')\n",
      "(555, 'imFFT021', 'Phin', 'Freq', 'Norm')\n",
      "(2114, 'amFFT033', 'Golz', 'Freq', 'Norm')\n",
      "(559, 'imFFT025', 'Phin', 'Freq', 'Norm')\n",
      "(560, 'imFFT026', 'Phin', 'Freq', 'Norm')\n",
      "(563, 'imFFT029', 'Phin', 'Freq', 'Norm')\n",
      "(535, 'imFFT001', 'Phin', 'Freq', 'Norm')\n",
      "(2618, 'phFFT024', 'Golz', 'Freq', 'Norm')\n",
      "(2619, 'phFFT025', 'Golz', 'Freq', 'Norm')\n",
      "(2620, 'phFFT026', 'Golz', 'Freq', 'Norm')\n",
      "(2621, 'phFFT027', 'Golz', 'Freq', 'Norm')\n",
      "(2622, 'phFFT028', 'Golz', 'Freq', 'Norm')\n",
      "(2623, 'phFFT029', 'Golz', 'Freq', 'Norm')\n",
      "(2624, 'phFFT030', 'Golz', 'Freq', 'Norm')\n",
      "(2625, 'phFFT031', 'Golz', 'Freq', 'Norm')\n",
      "(2626, 'phFFT032', 'Golz', 'Freq', 'Norm')\n",
      "(2627, 'phFFT033', 'Golz', 'Freq', 'Norm')\n",
      "(2628, 'phFFT034', 'Golz', 'Freq', 'Norm')\n",
      "(2629, 'phFFT035', 'Golz', 'Freq', 'Norm')\n",
      "(2630, 'phFFT036', 'Golz', 'Freq', 'Norm')\n",
      "(2631, 'phFFT037', 'Golz', 'Freq', 'Norm')\n",
      "(2632, 'phFFT038', 'Golz', 'Freq', 'Norm')\n",
      "(2633, 'phFFT039', 'Golz', 'Freq', 'Norm')\n",
      "(2634, 'phFFT040', 'Golz', 'Freq', 'Norm')\n",
      "(2635, 'phFFT041', 'Golz', 'Freq', 'Norm')\n",
      "(2636, 'phFFT042', 'Golz', 'Freq', 'Norm')\n",
      "(2637, 'phFFT043', 'Golz', 'Freq', 'Norm')\n",
      "(2638, 'phFFT044', 'Golz', 'Freq', 'Norm')\n",
      "(2639, 'phFFT045', 'Golz', 'Freq', 'Norm')\n",
      "(2640, 'phFFT046', 'Golz', 'Freq', 'Norm')\n",
      "(2641, 'phFFT047', 'Golz', 'Freq', 'Norm')\n",
      "(2642, 'phFFT048', 'Golz', 'Freq', 'Norm')\n",
      "(2643, 'phFFT049', 'Golz', 'Freq', 'Norm')\n",
      "(2644, 'phFFT050', 'Golz', 'Freq', 'Norm')\n",
      "(2645, 'phFFT051', 'Golz', 'Freq', 'Norm')\n",
      "(2646, 'phFFT052', 'Golz', 'Freq', 'Norm')\n",
      "(2647, 'phFFT053', 'Golz', 'Freq', 'Norm')\n",
      "(566, 'imFFT032', 'Phin', 'Freq', 'Norm')\n",
      "(567, 'imFFT033', 'Phin', 'Freq', 'Norm')\n",
      "(568, 'imFFT034', 'Phin', 'Freq', 'Norm')\n",
      "(564, 'imFFT030', 'Phin', 'Freq', 'Norm')\n",
      "(551, 'imFFT017', 'Phin', 'Freq', 'Norm')\n",
      "(1514, 'acrol0457', 'Golz', 'Time', 'Norm')\n",
      "(1620, 'acrol0563', 'Golz', 'Time', 'Norm')\n",
      "(1621, 'acrol0564', 'Golz', 'Time', 'Norm')\n",
      "(1623, 'acrol0566', 'Golz', 'Time', 'Norm')\n",
      "(1632, 'acrol0575', 'Golz', 'Time', 'Norm')\n",
      "(1636, 'acrol0579', 'Golz', 'Time', 'Norm')\n",
      "(1699, 'acrol0642', 'Golz', 'Time', 'Norm')\n",
      "(1704, 'acrol0647', 'Golz', 'Time', 'Norm')\n",
      "(1887, 'acrol0830', 'Golz', 'Time', 'Norm')\n",
      "(1904, 'acrol0847', 'Golz', 'Time', 'Norm')\n",
      "(1905, 'acrol0848', 'Golz', 'Time', 'Norm')\n",
      "(1914, 'acrol0857', 'Golz', 'Time', 'Norm')\n",
      "(1922, 'acrol0865', 'Golz', 'Time', 'Norm')\n",
      "(1960, 'acrol0903', 'Golz', 'Time', 'Norm')\n",
      "(1967, 'acrol0910', 'Golz', 'Time', 'Norm')\n",
      "(1968, 'acrol0911', 'Golz', 'Time', 'Norm')\n",
      "(553, 'imFFT019', 'Phin', 'Freq', 'Norm')\n",
      "(1984, 'acrol0927', 'Golz', 'Time', 'Norm')\n",
      "(1988, 'acrol0931', 'Golz', 'Time', 'Norm')\n",
      "(1989, 'acrol0932', 'Golz', 'Time', 'Norm')\n",
      "(1990, 'acrol0933', 'Golz', 'Time', 'Norm')\n",
      "(1998, 'acrol0941', 'Golz', 'Time', 'Norm')\n",
      "(1999, 'acrol0942', 'Golz', 'Time', 'Norm')\n",
      "(2000, 'acrol0943', 'Golz', 'Time', 'Norm')\n",
      "(2002, 'acrol0945', 'Golz', 'Time', 'Norm')\n",
      "(2008, 'acrol0951', 'Golz', 'Time', 'Norm')\n",
      "(2009, 'acrol0952', 'Golz', 'Time', 'Norm')\n",
      "(2010, 'acrol0953', 'Golz', 'Time', 'Norm')\n",
      "(2011, 'acrol0954', 'Golz', 'Time', 'Norm')\n",
      "(2012, 'acrol0955', 'Golz', 'Time', 'Norm')\n",
      "(2013, 'acrol0956', 'Golz', 'Time', 'Norm')\n",
      "(2014, 'acrol0957', 'Golz', 'Time', 'Norm')\n",
      "(2015, 'acrol0958', 'Golz', 'Time', 'Norm')\n",
      "(2016, 'acrol0959', 'Golz', 'Time', 'Norm')\n",
      "(2017, 'acrol0960', 'Golz', 'Time', 'Norm')\n",
      "(2018, 'acrol0961', 'Golz', 'Time', 'Norm')\n",
      "(2019, 'acrol0962', 'Golz', 'Time', 'Norm')\n",
      "(2020, 'acrol0963', 'Golz', 'Time', 'Norm')\n",
      "(2021, 'acrol0964', 'Golz', 'Time', 'Norm')\n",
      "(2025, 'acrol0968', 'Golz', 'Time', 'Norm')\n",
      "(2026, 'acrol0969', 'Golz', 'Time', 'Norm')\n",
      "(2028, 'acrol0971', 'Golz', 'Time', 'Norm')\n",
      "(2029, 'acrol0972', 'Golz', 'Time', 'Norm')\n",
      "(2030, 'acrol0973', 'Golz', 'Time', 'Norm')\n",
      "(2032, 'acrol0975', 'Golz', 'Time', 'Norm')\n",
      "(2033, 'acrol0976', 'Golz', 'Time', 'Norm')\n",
      "(2036, 'acrol0979', 'Golz', 'Time', 'Norm')\n",
      "(2041, 'acrol0984', 'Golz', 'Time', 'Norm')\n",
      "(2044, 'acrol0987', 'Golz', 'Time', 'Norm')\n",
      "(2045, 'acrol0988', 'Golz', 'Time', 'Norm')\n",
      "(2046, 'acrol0989', 'Golz', 'Time', 'Norm')\n",
      "(2047, 'acrol0990', 'Golz', 'Time', 'Norm')\n",
      "(2050, 'acrol0993', 'Golz', 'Time', 'Norm')\n",
      "(2056, 'acrol0999', 'Golz', 'Time', 'Norm')\n",
      "(2084, 'amFFT003', 'Golz', 'Freq', 'Norm')\n",
      "(39, 'reFFT018', 'Phin', 'Freq', 'Norm')\n",
      "(2099, 'amFFT018', 'Golz', 'Freq', 'Norm')\n",
      "(2100, 'amFFT019', 'Golz', 'Freq', 'Norm')\n",
      "(2101, 'amFFT020', 'Golz', 'Freq', 'Norm')\n",
      "(546, 'imFFT012', 'Phin', 'Freq', 'Norm')\n",
      "(2595, 'phFFT001', 'Golz', 'Freq', 'Norm')\n",
      "(2051, 'acrol0994', 'Golz', 'Time', 'Norm')\n",
      "(2075, 'acrol1018', 'Golz', 'Time', 'Norm')\n",
      "(2597, 'phFFT003', 'Golz', 'Freq', 'Norm')\n",
      "(2082, 'amFFT001', 'Golz', 'Freq', 'Norm')\n",
      "(539, 'imFFT005', 'Phin', 'Freq', 'Norm')\n",
      "(540, 'imFFT006', 'Phin', 'Freq', 'Norm')\n",
      "(547, 'imFFT013', 'Phin', 'Freq', 'Norm')\n",
      "(549, 'imFFT015', 'Phin', 'Freq', 'Norm')\n",
      "(556, 'imFFT022', 'Phin', 'Freq', 'Norm')\n",
      "(557, 'imFFT023', 'Phin', 'Freq', 'Norm')\n",
      "(561, 'imFFT027', 'Phin', 'Freq', 'Norm')\n",
      "(2612, 'phFFT018', 'Golz', 'Freq', 'Norm')\n",
      "(2613, 'phFFT019', 'Golz', 'Freq', 'Norm')\n",
      "(2614, 'phFFT020', 'Golz', 'Freq', 'Norm')\n",
      "(1052, 'med', 'Golz', 'Time', 'Norm')\n",
      "(1056, 'ssk', 'Golz', 'Time', 'Norm')\n",
      "(1199, 'acrol0142', 'Golz', 'Time', 'Norm')\n",
      "(1200, 'acrol0143', 'Golz', 'Time', 'Norm')\n",
      "(1203, 'acrol0146', 'Golz', 'Time', 'Norm')\n",
      "(1204, 'acrol0147', 'Golz', 'Time', 'Norm')\n",
      "(1205, 'acrol0148', 'Golz', 'Time', 'Norm')\n",
      "(1251, 'acrol0194', 'Golz', 'Time', 'Norm')\n",
      "(1253, 'acrol0196', 'Golz', 'Time', 'Norm')\n",
      "(1340, 'acrol0283', 'Golz', 'Time', 'Norm')\n",
      "(1344, 'acrol0287', 'Golz', 'Time', 'Norm')\n",
      "(1345, 'acrol0288', 'Golz', 'Time', 'Norm')\n",
      "(1349, 'acrol0292', 'Golz', 'Time', 'Norm')\n",
      "(1351, 'acrol0294', 'Golz', 'Time', 'Norm')\n",
      "(1353, 'acrol0296', 'Golz', 'Time', 'Norm')\n",
      "(1354, 'acrol0297', 'Golz', 'Time', 'Norm')\n",
      "(1355, 'acrol0298', 'Golz', 'Time', 'Norm')\n",
      "(1356, 'acrol0299', 'Golz', 'Time', 'Norm')\n",
      "(1357, 'acrol0300', 'Golz', 'Time', 'Norm')\n",
      "(1358, 'acrol0301', 'Golz', 'Time', 'Norm')\n",
      "(1359, 'acrol0302', 'Golz', 'Time', 'Norm')\n",
      "(1360, 'acrol0303', 'Golz', 'Time', 'Norm')\n",
      "(1381, 'acrol0324', 'Golz', 'Time', 'Norm')\n",
      "(1395, 'acrol0338', 'Golz', 'Time', 'Norm')\n",
      "(1401, 'acrol0344', 'Golz', 'Time', 'Norm')\n",
      "(1404, 'acrol0347', 'Golz', 'Time', 'Norm')\n",
      "(1405, 'acrol0348', 'Golz', 'Time', 'Norm')\n",
      "(1406, 'acrol0349', 'Golz', 'Time', 'Norm')\n",
      "(1442, 'acrol0385', 'Golz', 'Time', 'Norm')\n",
      "(1473, 'acrol0416', 'Golz', 'Time', 'Norm')\n",
      "(1482, 'acrol0425', 'Golz', 'Time', 'Norm')\n",
      "(1483, 'acrol0426', 'Golz', 'Time', 'Norm')\n",
      "(1487, 'acrol0430', 'Golz', 'Time', 'Norm')\n",
      "(1490, 'acrol0433', 'Golz', 'Time', 'Norm')\n",
      "(1496, 'acrol0439', 'Golz', 'Time', 'Norm')\n",
      "(1497, 'acrol0440', 'Golz', 'Time', 'Norm')\n",
      "(1498, 'acrol0441', 'Golz', 'Time', 'Norm')\n",
      "(1499, 'acrol0442', 'Golz', 'Time', 'Norm')\n",
      "(1500, 'acrol0443', 'Golz', 'Time', 'Norm')\n",
      "(1507, 'acrol0450', 'Golz', 'Time', 'Norm')\n",
      "(1508, 'acrol0451', 'Golz', 'Time', 'Norm')\n",
      "(1511, 'acrol0454', 'Golz', 'Time', 'Norm')\n",
      "(1513, 'acrol0456', 'Golz', 'Time', 'Norm')\n",
      "(1515, 'acrol0458', 'Golz', 'Time', 'Norm')\n",
      "(1517, 'acrol0460', 'Golz', 'Time', 'Norm')\n",
      "(1518, 'acrol0461', 'Golz', 'Time', 'Norm')\n",
      "(1519, 'acrol0462', 'Golz', 'Time', 'Norm')\n",
      "(1520, 'acrol0463', 'Golz', 'Time', 'Norm')\n",
      "(1521, 'acrol0464', 'Golz', 'Time', 'Norm')\n",
      "(1522, 'acrol0465', 'Golz', 'Time', 'Norm')\n",
      "(1523, 'acrol0466', 'Golz', 'Time', 'Norm')\n",
      "(1524, 'acrol0467', 'Golz', 'Time', 'Norm')\n",
      "(1525, 'acrol0468', 'Golz', 'Time', 'Norm')\n",
      "(1526, 'acrol0469', 'Golz', 'Time', 'Norm')\n",
      "(1528, 'acrol0471', 'Golz', 'Time', 'Norm')\n",
      "(1532, 'acrol0475', 'Golz', 'Time', 'Norm')\n",
      "(1533, 'acrol0476', 'Golz', 'Time', 'Norm')\n",
      "(1535, 'acrol0478', 'Golz', 'Time', 'Norm')\n",
      "(1537, 'acrol0480', 'Golz', 'Time', 'Norm')\n",
      "(1538, 'acrol0481', 'Golz', 'Time', 'Norm')\n",
      "(1539, 'acrol0482', 'Golz', 'Time', 'Norm')\n",
      "(1541, 'acrol0484', 'Golz', 'Time', 'Norm')\n",
      "(1542, 'acrol0485', 'Golz', 'Time', 'Norm')\n",
      "(1543, 'acrol0486', 'Golz', 'Time', 'Norm')\n",
      "(1544, 'acrol0487', 'Golz', 'Time', 'Norm')\n",
      "(1545, 'acrol0488', 'Golz', 'Time', 'Norm')\n",
      "(1573, 'acrol0516', 'Golz', 'Time', 'Norm')\n",
      "(1575, 'acrol0518', 'Golz', 'Time', 'Norm')\n",
      "(1579, 'acrol0522', 'Golz', 'Time', 'Norm')\n",
      "(1589, 'acrol0532', 'Golz', 'Time', 'Norm')\n",
      "(1600, 'acrol0543', 'Golz', 'Time', 'Norm')\n",
      "(1601, 'acrol0544', 'Golz', 'Time', 'Norm')\n",
      "(1614, 'acrol0557', 'Golz', 'Time', 'Norm')\n",
      "(1622, 'acrol0565', 'Golz', 'Time', 'Norm')\n",
      "(1624, 'acrol0567', 'Golz', 'Time', 'Norm')\n",
      "(1626, 'acrol0569', 'Golz', 'Time', 'Norm')\n",
      "(1628, 'acrol0571', 'Golz', 'Time', 'Norm')\n",
      "(1631, 'acrol0574', 'Golz', 'Time', 'Norm')\n",
      "(1635, 'acrol0578', 'Golz', 'Time', 'Norm')\n",
      "(1638, 'acrol0581', 'Golz', 'Time', 'Norm')\n",
      "(1640, 'acrol0583', 'Golz', 'Time', 'Norm')\n",
      "(1643, 'acrol0586', 'Golz', 'Time', 'Norm')\n",
      "(1647, 'acrol0590', 'Golz', 'Time', 'Norm')\n",
      "(1648, 'acrol0591', 'Golz', 'Time', 'Norm')\n",
      "(1649, 'acrol0592', 'Golz', 'Time', 'Norm')\n",
      "(1651, 'acrol0594', 'Golz', 'Time', 'Norm')\n",
      "(1653, 'acrol0596', 'Golz', 'Time', 'Norm')\n",
      "(1657, 'acrol0600', 'Golz', 'Time', 'Norm')\n",
      "(1658, 'acrol0601', 'Golz', 'Time', 'Norm')\n",
      "(1662, 'acrol0605', 'Golz', 'Time', 'Norm')\n",
      "(1663, 'acrol0606', 'Golz', 'Time', 'Norm')\n",
      "(1664, 'acrol0607', 'Golz', 'Time', 'Norm')\n",
      "(1669, 'acrol0612', 'Golz', 'Time', 'Norm')\n",
      "(1670, 'acrol0613', 'Golz', 'Time', 'Norm')\n",
      "(1671, 'acrol0614', 'Golz', 'Time', 'Norm')\n",
      "(1674, 'acrol0617', 'Golz', 'Time', 'Norm')\n",
      "(1690, 'acrol0633', 'Golz', 'Time', 'Norm')\n",
      "(1691, 'acrol0634', 'Golz', 'Time', 'Norm')\n",
      "(1692, 'acrol0635', 'Golz', 'Time', 'Norm')\n",
      "(1693, 'acrol0636', 'Golz', 'Time', 'Norm')\n",
      "(1694, 'acrol0637', 'Golz', 'Time', 'Norm')\n",
      "(1695, 'acrol0638', 'Golz', 'Time', 'Norm')\n",
      "(1696, 'acrol0639', 'Golz', 'Time', 'Norm')\n",
      "(1697, 'acrol0640', 'Golz', 'Time', 'Norm')\n",
      "(1698, 'acrol0641', 'Golz', 'Time', 'Norm')\n",
      "(1700, 'acrol0643', 'Golz', 'Time', 'Norm')\n",
      "(1703, 'acrol0646', 'Golz', 'Time', 'Norm')\n",
      "(1705, 'acrol0648', 'Golz', 'Time', 'Norm')\n",
      "(1724, 'acrol0667', 'Golz', 'Time', 'Norm')\n",
      "(1726, 'acrol0669', 'Golz', 'Time', 'Norm')\n",
      "(1729, 'acrol0672', 'Golz', 'Time', 'Norm')\n",
      "(1730, 'acrol0673', 'Golz', 'Time', 'Norm')\n",
      "(1734, 'acrol0677', 'Golz', 'Time', 'Norm')\n",
      "(1736, 'acrol0679', 'Golz', 'Time', 'Norm')\n",
      "(1743, 'acrol0686', 'Golz', 'Time', 'Norm')\n",
      "(1745, 'acrol0688', 'Golz', 'Time', 'Norm')\n",
      "(1747, 'acrol0690', 'Golz', 'Time', 'Norm')\n",
      "(1749, 'acrol0692', 'Golz', 'Time', 'Norm')\n",
      "(1751, 'acrol0694', 'Golz', 'Time', 'Norm')\n",
      "(1758, 'acrol0701', 'Golz', 'Time', 'Norm')\n",
      "(1778, 'acrol0721', 'Golz', 'Time', 'Norm')\n",
      "(1779, 'acrol0722', 'Golz', 'Time', 'Norm')\n",
      "(1780, 'acrol0723', 'Golz', 'Time', 'Norm')\n",
      "(1781, 'acrol0724', 'Golz', 'Time', 'Norm')\n",
      "(1784, 'acrol0727', 'Golz', 'Time', 'Norm')\n",
      "(1786, 'acrol0729', 'Golz', 'Time', 'Norm')\n",
      "(1789, 'acrol0732', 'Golz', 'Time', 'Norm')\n",
      "(1790, 'acrol0733', 'Golz', 'Time', 'Norm')\n",
      "(1792, 'acrol0735', 'Golz', 'Time', 'Norm')\n",
      "(1800, 'acrol0743', 'Golz', 'Time', 'Norm')\n",
      "(1802, 'acrol0745', 'Golz', 'Time', 'Norm')\n",
      "(1807, 'acrol0750', 'Golz', 'Time', 'Norm')\n",
      "(1808, 'acrol0751', 'Golz', 'Time', 'Norm')\n",
      "(1810, 'acrol0753', 'Golz', 'Time', 'Norm')\n",
      "(1811, 'acrol0754', 'Golz', 'Time', 'Norm')\n",
      "(1813, 'acrol0756', 'Golz', 'Time', 'Norm')\n",
      "(1814, 'acrol0757', 'Golz', 'Time', 'Norm')\n",
      "(1818, 'acrol0761', 'Golz', 'Time', 'Norm')\n",
      "(1822, 'acrol0765', 'Golz', 'Time', 'Norm')\n",
      "(1824, 'acrol0767', 'Golz', 'Time', 'Norm')\n",
      "(1827, 'acrol0770', 'Golz', 'Time', 'Norm')\n",
      "(1828, 'acrol0771', 'Golz', 'Time', 'Norm')\n",
      "(1829, 'acrol0772', 'Golz', 'Time', 'Norm')\n",
      "(1831, 'acrol0774', 'Golz', 'Time', 'Norm')\n",
      "(1834, 'acrol0777', 'Golz', 'Time', 'Norm')\n",
      "(1835, 'acrol0778', 'Golz', 'Time', 'Norm')\n",
      "(1836, 'acrol0779', 'Golz', 'Time', 'Norm')\n",
      "(1837, 'acrol0780', 'Golz', 'Time', 'Norm')\n",
      "(1838, 'acrol0781', 'Golz', 'Time', 'Norm')\n",
      "(1843, 'acrol0786', 'Golz', 'Time', 'Norm')\n",
      "(1889, 'acrol0832', 'Golz', 'Time', 'Norm')\n",
      "(1896, 'acrol0839', 'Golz', 'Time', 'Norm')\n",
      "(1899, 'acrol0842', 'Golz', 'Time', 'Norm')\n",
      "(1902, 'acrol0845', 'Golz', 'Time', 'Norm')\n",
      "(1906, 'acrol0849', 'Golz', 'Time', 'Norm')\n",
      "(1907, 'acrol0850', 'Golz', 'Time', 'Norm')\n",
      "(1908, 'acrol0851', 'Golz', 'Time', 'Norm')\n",
      "(1909, 'acrol0852', 'Golz', 'Time', 'Norm')\n",
      "(1912, 'acrol0855', 'Golz', 'Time', 'Norm')\n",
      "(1913, 'acrol0856', 'Golz', 'Time', 'Norm')\n",
      "(1923, 'acrol0866', 'Golz', 'Time', 'Norm')\n",
      "(1929, 'acrol0872', 'Golz', 'Time', 'Norm')\n",
      "(1934, 'acrol0877', 'Golz', 'Time', 'Norm')\n",
      "(1936, 'acrol0879', 'Golz', 'Time', 'Norm')\n",
      "(1942, 'acrol0885', 'Golz', 'Time', 'Norm')\n",
      "(1943, 'acrol0886', 'Golz', 'Time', 'Norm')\n",
      "(1945, 'acrol0888', 'Golz', 'Time', 'Norm')\n",
      "(1946, 'acrol0889', 'Golz', 'Time', 'Norm')\n",
      "(1947, 'acrol0890', 'Golz', 'Time', 'Norm')\n",
      "(1948, 'acrol0891', 'Golz', 'Time', 'Norm')\n",
      "(1949, 'acrol0892', 'Golz', 'Time', 'Norm')\n",
      "(1950, 'acrol0893', 'Golz', 'Time', 'Norm')\n",
      "(1951, 'acrol0894', 'Golz', 'Time', 'Norm')\n",
      "(1952, 'acrol0895', 'Golz', 'Time', 'Norm')\n",
      "(1953, 'acrol0896', 'Golz', 'Time', 'Norm')\n",
      "(1954, 'acrol0897', 'Golz', 'Time', 'Norm')\n",
      "(1955, 'acrol0898', 'Golz', 'Time', 'Norm')\n",
      "(1961, 'acrol0904', 'Golz', 'Time', 'Norm')\n",
      "(1962, 'acrol0905', 'Golz', 'Time', 'Norm')\n",
      "(1965, 'acrol0908', 'Golz', 'Time', 'Norm')\n",
      "(1970, 'acrol0913', 'Golz', 'Time', 'Norm')\n",
      "(1971, 'acrol0914', 'Golz', 'Time', 'Norm')\n",
      "(1972, 'acrol0915', 'Golz', 'Time', 'Norm')\n",
      "(1979, 'acrol0922', 'Golz', 'Time', 'Norm')\n",
      "(1981, 'acrol0924', 'Golz', 'Time', 'Norm')\n",
      "(1982, 'acrol0925', 'Golz', 'Time', 'Norm')\n",
      "(1985, 'acrol0928', 'Golz', 'Time', 'Norm')\n",
      "(1994, 'acrol0937', 'Golz', 'Time', 'Norm')\n",
      "(1995, 'acrol0938', 'Golz', 'Time', 'Norm')\n",
      "(1996, 'acrol0939', 'Golz', 'Time', 'Norm')\n",
      "(1997, 'acrol0940', 'Golz', 'Time', 'Norm')\n",
      "(2001, 'acrol0944', 'Golz', 'Time', 'Norm')\n",
      "(2031, 'acrol0974', 'Golz', 'Time', 'Norm')\n",
      "(2037, 'acrol0980', 'Golz', 'Time', 'Norm')\n",
      "(2038, 'acrol0981', 'Golz', 'Time', 'Norm')\n",
      "(2039, 'acrol0982', 'Golz', 'Time', 'Norm')\n",
      "(2040, 'acrol0983', 'Golz', 'Time', 'Norm')\n",
      "(2042, 'acrol0985', 'Golz', 'Time', 'Norm')\n",
      "(0, 'intsgnl', 'Phin', 'Time', 'Norm')\n",
      "(1, 'meanabs', 'Phin', 'Time', 'Norm')\n",
      "(3, 'ssi', 'Phin', 'Time', 'Norm')\n",
      "(4, 'var', 'Phin', 'Time', 'Norm')\n",
      "(5, 'rms', 'Phin', 'Time', 'Norm')\n",
      "(6, 'rng', 'Phin', 'Time', 'Norm')\n",
      "(17, 'mnf', 'Phin', 'Freq', 'Norm')\n",
      "(19, 'mmnf', 'Phin', 'Freq', 'Norm')\n",
      "(20, 'mmdf', 'Phin', 'Freq', 'Norm')\n",
      "(21, 'reFFT000', 'Phin', 'Freq', 'Norm')\n",
      "(22, 'reFFT001', 'Phin', 'Freq', 'Norm')\n",
      "(23, 'reFFT002', 'Phin', 'Freq', 'Norm')\n",
      "(24, 'reFFT003', 'Phin', 'Freq', 'Norm')\n",
      "(25, 'reFFT004', 'Phin', 'Freq', 'Norm')\n",
      "(26, 'reFFT005', 'Phin', 'Freq', 'Norm')\n",
      "(27, 'reFFT006', 'Phin', 'Freq', 'Norm')\n",
      "(28, 'reFFT007', 'Phin', 'Freq', 'Norm')\n",
      "(29, 'reFFT008', 'Phin', 'Freq', 'Norm')\n",
      "(30, 'reFFT009', 'Phin', 'Freq', 'Norm')\n",
      "(31, 'reFFT010', 'Phin', 'Freq', 'Norm')\n",
      "(32, 'reFFT011', 'Phin', 'Freq', 'Norm')\n",
      "(33, 'reFFT012', 'Phin', 'Freq', 'Norm')\n",
      "(35, 'reFFT014', 'Phin', 'Freq', 'Norm')\n",
      "(2092, 'amFFT011', 'Golz', 'Freq', 'Norm')\n",
      "(2093, 'amFFT012', 'Golz', 'Freq', 'Norm')\n",
      "(2094, 'amFFT013', 'Golz', 'Freq', 'Norm')\n",
      "(2095, 'amFFT014', 'Golz', 'Freq', 'Norm')\n",
      "(2096, 'amFFT015', 'Golz', 'Freq', 'Norm')\n",
      "(2097, 'amFFT016', 'Golz', 'Freq', 'Norm')\n",
      "(2098, 'amFFT017', 'Golz', 'Freq', 'Norm')\n",
      "(2102, 'amFFT021', 'Golz', 'Freq', 'Norm')\n",
      "(2103, 'amFFT022', 'Golz', 'Freq', 'Norm')\n",
      "(2104, 'amFFT023', 'Golz', 'Freq', 'Norm')\n",
      "(2596, 'phFFT002', 'Golz', 'Freq', 'Norm')\n",
      "(2081, 'amFFT000', 'Golz', 'Freq', 'Norm')\n",
      "(2083, 'amFFT002', 'Golz', 'Freq', 'Norm')\n",
      "(2085, 'amFFT004', 'Golz', 'Freq', 'Norm')\n",
      "(2086, 'amFFT005', 'Golz', 'Freq', 'Norm')\n",
      "(2087, 'amFFT006', 'Golz', 'Freq', 'Norm')\n",
      "(2088, 'amFFT007', 'Golz', 'Freq', 'Norm')\n",
      "(2089, 'amFFT008', 'Golz', 'Freq', 'Norm')\n",
      "(2090, 'amFFT009', 'Golz', 'Freq', 'Norm')\n",
      "(2091, 'amFFT010', 'Golz', 'Freq', 'Norm')\n",
      "(2600, 'phFFT006', 'Golz', 'Freq', 'Norm')\n",
      "(2602, 'phFFT008', 'Golz', 'Freq', 'Norm')\n",
      "(2604, 'phFFT010', 'Golz', 'Freq', 'Norm')\n",
      "(2605, 'phFFT011', 'Golz', 'Freq', 'Norm')\n",
      "(2609, 'phFFT015', 'Golz', 'Freq', 'Norm')\n",
      "(536, 'imFFT002', 'Phin', 'Freq', 'Norm')\n",
      "(537, 'imFFT003', 'Phin', 'Freq', 'Norm')\n",
      "(538, 'imFFT004', 'Phin', 'Freq', 'Norm')\n",
      "(541, 'imFFT007', 'Phin', 'Freq', 'Norm')\n",
      "(542, 'imFFT008', 'Phin', 'Freq', 'Norm')\n",
      "(543, 'imFFT009', 'Phin', 'Freq', 'Norm')\n",
      "(544, 'imFFT010', 'Phin', 'Freq', 'Norm')\n",
      "(545, 'imFFT011', 'Phin', 'Freq', 'Norm')\n",
      "(2594, 'phFFT000', 'Golz', 'Freq', 'Norm')\n",
      "(548, 'imFFT014', 'Phin', 'Freq', 'Norm')\n",
      "(2598, 'phFFT004', 'Golz', 'Freq', 'Norm')\n",
      "(2599, 'phFFT005', 'Golz', 'Freq', 'Norm')\n",
      "(552, 'imFFT018', 'Phin', 'Freq', 'Norm')\n",
      "(2601, 'phFFT007', 'Golz', 'Freq', 'Norm')\n",
      "(554, 'imFFT020', 'Phin', 'Freq', 'Norm')\n",
      "(2603, 'phFFT009', 'Golz', 'Freq', 'Norm')\n",
      "(2606, 'phFFT012', 'Golz', 'Freq', 'Norm')\n",
      "(2607, 'phFFT013', 'Golz', 'Freq', 'Norm')\n",
      "(2608, 'phFFT014', 'Golz', 'Freq', 'Norm')\n",
      "(2610, 'phFFT016', 'Golz', 'Freq', 'Norm')\n",
      "(2611, 'phFFT017', 'Golz', 'Freq', 'Norm')\n",
      "(2615, 'phFFT021', 'Golz', 'Freq', 'Norm')\n",
      "(2616, 'phFFT022', 'Golz', 'Freq', 'Norm')\n",
      "(2617, 'phFFT023', 'Golz', 'Freq', 'Norm')\n",
      "(1047, 'meanv', 'Golz', 'Time', 'Norm')\n",
      "(1048, 'stdr', 'Golz', 'Time', 'Norm')\n",
      "(1049, 'mx', 'Golz', 'Time', 'Norm')\n",
      "(1051, 'rngy', 'Golz', 'Time', 'Norm')\n",
      "(1053, 'hjorth', 'Golz', 'Time', 'Norm')\n",
      "(1055, 'se', 'Golz', 'Time', 'Norm')\n",
      "(1057, 'acrol0000', 'Golz', 'Time', 'Norm')\n",
      "(1058, 'acrol0001', 'Golz', 'Time', 'Norm')\n",
      "(1059, 'acrol0002', 'Golz', 'Time', 'Norm')\n",
      "(1060, 'acrol0003', 'Golz', 'Time', 'Norm')\n",
      "(1061, 'acrol0004', 'Golz', 'Time', 'Norm')\n",
      "(1062, 'acrol0005', 'Golz', 'Time', 'Norm')\n",
      "(1063, 'acrol0006', 'Golz', 'Time', 'Norm')\n",
      "(1064, 'acrol0007', 'Golz', 'Time', 'Norm')\n",
      "(1065, 'acrol0008', 'Golz', 'Time', 'Norm')\n",
      "(1066, 'acrol0009', 'Golz', 'Time', 'Norm')\n",
      "(1067, 'acrol0010', 'Golz', 'Time', 'Norm')\n",
      "(1068, 'acrol0011', 'Golz', 'Time', 'Norm')\n",
      "(1069, 'acrol0012', 'Golz', 'Time', 'Norm')\n",
      "(1070, 'acrol0013', 'Golz', 'Time', 'Norm')\n",
      "(1071, 'acrol0014', 'Golz', 'Time', 'Norm')\n",
      "(1072, 'acrol0015', 'Golz', 'Time', 'Norm')\n",
      "(1073, 'acrol0016', 'Golz', 'Time', 'Norm')\n",
      "(1074, 'acrol0017', 'Golz', 'Time', 'Norm')\n",
      "(1075, 'acrol0018', 'Golz', 'Time', 'Norm')\n",
      "(1076, 'acrol0019', 'Golz', 'Time', 'Norm')\n",
      "(1077, 'acrol0020', 'Golz', 'Time', 'Norm')\n",
      "(1078, 'acrol0021', 'Golz', 'Time', 'Norm')\n",
      "(1079, 'acrol0022', 'Golz', 'Time', 'Norm')\n",
      "(1080, 'acrol0023', 'Golz', 'Time', 'Norm')\n",
      "(1081, 'acrol0024', 'Golz', 'Time', 'Norm')\n",
      "(1082, 'acrol0025', 'Golz', 'Time', 'Norm')\n",
      "(1083, 'acrol0026', 'Golz', 'Time', 'Norm')\n",
      "(1084, 'acrol0027', 'Golz', 'Time', 'Norm')\n",
      "(1085, 'acrol0028', 'Golz', 'Time', 'Norm')\n",
      "(1086, 'acrol0029', 'Golz', 'Time', 'Norm')\n",
      "(1087, 'acrol0030', 'Golz', 'Time', 'Norm')\n",
      "(1088, 'acrol0031', 'Golz', 'Time', 'Norm')\n",
      "(1089, 'acrol0032', 'Golz', 'Time', 'Norm')\n",
      "(1090, 'acrol0033', 'Golz', 'Time', 'Norm')\n",
      "(1091, 'acrol0034', 'Golz', 'Time', 'Norm')\n",
      "(1092, 'acrol0035', 'Golz', 'Time', 'Norm')\n",
      "(1093, 'acrol0036', 'Golz', 'Time', 'Norm')\n",
      "(1094, 'acrol0037', 'Golz', 'Time', 'Norm')\n",
      "(1095, 'acrol0038', 'Golz', 'Time', 'Norm')\n",
      "(1096, 'acrol0039', 'Golz', 'Time', 'Norm')\n",
      "(1097, 'acrol0040', 'Golz', 'Time', 'Norm')\n",
      "(1098, 'acrol0041', 'Golz', 'Time', 'Norm')\n",
      "(1099, 'acrol0042', 'Golz', 'Time', 'Norm')\n",
      "(1100, 'acrol0043', 'Golz', 'Time', 'Norm')\n",
      "(1101, 'acrol0044', 'Golz', 'Time', 'Norm')\n",
      "(1102, 'acrol0045', 'Golz', 'Time', 'Norm')\n",
      "(1103, 'acrol0046', 'Golz', 'Time', 'Norm')\n",
      "(1104, 'acrol0047', 'Golz', 'Time', 'Norm')\n",
      "(1105, 'acrol0048', 'Golz', 'Time', 'Norm')\n",
      "(1106, 'acrol0049', 'Golz', 'Time', 'Norm')\n",
      "(1107, 'acrol0050', 'Golz', 'Time', 'Norm')\n",
      "(1108, 'acrol0051', 'Golz', 'Time', 'Norm')\n",
      "(1109, 'acrol0052', 'Golz', 'Time', 'Norm')\n",
      "(1110, 'acrol0053', 'Golz', 'Time', 'Norm')\n",
      "(1111, 'acrol0054', 'Golz', 'Time', 'Norm')\n",
      "(1112, 'acrol0055', 'Golz', 'Time', 'Norm')\n",
      "(1113, 'acrol0056', 'Golz', 'Time', 'Norm')\n",
      "(1114, 'acrol0057', 'Golz', 'Time', 'Norm')\n",
      "(1115, 'acrol0058', 'Golz', 'Time', 'Norm')\n",
      "(1116, 'acrol0059', 'Golz', 'Time', 'Norm')\n",
      "(1117, 'acrol0060', 'Golz', 'Time', 'Norm')\n",
      "(1118, 'acrol0061', 'Golz', 'Time', 'Norm')\n",
      "(1119, 'acrol0062', 'Golz', 'Time', 'Norm')\n",
      "(1120, 'acrol0063', 'Golz', 'Time', 'Norm')\n",
      "(1121, 'acrol0064', 'Golz', 'Time', 'Norm')\n",
      "(1122, 'acrol0065', 'Golz', 'Time', 'Norm')\n",
      "(1123, 'acrol0066', 'Golz', 'Time', 'Norm')\n",
      "(1124, 'acrol0067', 'Golz', 'Time', 'Norm')\n",
      "(1125, 'acrol0068', 'Golz', 'Time', 'Norm')\n",
      "(1126, 'acrol0069', 'Golz', 'Time', 'Norm')\n",
      "(1127, 'acrol0070', 'Golz', 'Time', 'Norm')\n",
      "(1128, 'acrol0071', 'Golz', 'Time', 'Norm')\n",
      "(1129, 'acrol0072', 'Golz', 'Time', 'Norm')\n",
      "(1130, 'acrol0073', 'Golz', 'Time', 'Norm')\n",
      "(1131, 'acrol0074', 'Golz', 'Time', 'Norm')\n",
      "(1132, 'acrol0075', 'Golz', 'Time', 'Norm')\n",
      "(1133, 'acrol0076', 'Golz', 'Time', 'Norm')\n",
      "(1134, 'acrol0077', 'Golz', 'Time', 'Norm')\n",
      "(1135, 'acrol0078', 'Golz', 'Time', 'Norm')\n",
      "(1136, 'acrol0079', 'Golz', 'Time', 'Norm')\n",
      "(1137, 'acrol0080', 'Golz', 'Time', 'Norm')\n",
      "(1138, 'acrol0081', 'Golz', 'Time', 'Norm')\n",
      "(1139, 'acrol0082', 'Golz', 'Time', 'Norm')\n",
      "(1140, 'acrol0083', 'Golz', 'Time', 'Norm')\n",
      "(1141, 'acrol0084', 'Golz', 'Time', 'Norm')\n",
      "(1142, 'acrol0085', 'Golz', 'Time', 'Norm')\n",
      "(1143, 'acrol0086', 'Golz', 'Time', 'Norm')\n",
      "(1144, 'acrol0087', 'Golz', 'Time', 'Norm')\n",
      "(1145, 'acrol0088', 'Golz', 'Time', 'Norm')\n",
      "(1146, 'acrol0089', 'Golz', 'Time', 'Norm')\n",
      "(1147, 'acrol0090', 'Golz', 'Time', 'Norm')\n",
      "(1148, 'acrol0091', 'Golz', 'Time', 'Norm')\n",
      "(1149, 'acrol0092', 'Golz', 'Time', 'Norm')\n",
      "(1150, 'acrol0093', 'Golz', 'Time', 'Norm')\n",
      "(1151, 'acrol0094', 'Golz', 'Time', 'Norm')\n",
      "(1152, 'acrol0095', 'Golz', 'Time', 'Norm')\n",
      "(1153, 'acrol0096', 'Golz', 'Time', 'Norm')\n",
      "(1154, 'acrol0097', 'Golz', 'Time', 'Norm')\n",
      "(1155, 'acrol0098', 'Golz', 'Time', 'Norm')\n",
      "(1156, 'acrol0099', 'Golz', 'Time', 'Norm')\n",
      "(1157, 'acrol0100', 'Golz', 'Time', 'Norm')\n",
      "(1158, 'acrol0101', 'Golz', 'Time', 'Norm')\n",
      "(1159, 'acrol0102', 'Golz', 'Time', 'Norm')\n",
      "(1160, 'acrol0103', 'Golz', 'Time', 'Norm')\n",
      "(1161, 'acrol0104', 'Golz', 'Time', 'Norm')\n",
      "(1162, 'acrol0105', 'Golz', 'Time', 'Norm')\n",
      "(1163, 'acrol0106', 'Golz', 'Time', 'Norm')\n",
      "(1164, 'acrol0107', 'Golz', 'Time', 'Norm')\n",
      "(1165, 'acrol0108', 'Golz', 'Time', 'Norm')\n",
      "(1166, 'acrol0109', 'Golz', 'Time', 'Norm')\n",
      "(1167, 'acrol0110', 'Golz', 'Time', 'Norm')\n",
      "(1168, 'acrol0111', 'Golz', 'Time', 'Norm')\n",
      "(1169, 'acrol0112', 'Golz', 'Time', 'Norm')\n",
      "(1170, 'acrol0113', 'Golz', 'Time', 'Norm')\n",
      "(1171, 'acrol0114', 'Golz', 'Time', 'Norm')\n",
      "(1172, 'acrol0115', 'Golz', 'Time', 'Norm')\n",
      "(1173, 'acrol0116', 'Golz', 'Time', 'Norm')\n",
      "(1174, 'acrol0117', 'Golz', 'Time', 'Norm')\n",
      "(1175, 'acrol0118', 'Golz', 'Time', 'Norm')\n",
      "(1176, 'acrol0119', 'Golz', 'Time', 'Norm')\n",
      "(1177, 'acrol0120', 'Golz', 'Time', 'Norm')\n",
      "(1178, 'acrol0121', 'Golz', 'Time', 'Norm')\n",
      "(1179, 'acrol0122', 'Golz', 'Time', 'Norm')\n",
      "(1180, 'acrol0123', 'Golz', 'Time', 'Norm')\n",
      "(1181, 'acrol0124', 'Golz', 'Time', 'Norm')\n",
      "(1182, 'acrol0125', 'Golz', 'Time', 'Norm')\n",
      "(1183, 'acrol0126', 'Golz', 'Time', 'Norm')\n",
      "(1184, 'acrol0127', 'Golz', 'Time', 'Norm')\n",
      "(1185, 'acrol0128', 'Golz', 'Time', 'Norm')\n",
      "(1186, 'acrol0129', 'Golz', 'Time', 'Norm')\n",
      "(1187, 'acrol0130', 'Golz', 'Time', 'Norm')\n",
      "(1188, 'acrol0131', 'Golz', 'Time', 'Norm')\n",
      "(1189, 'acrol0132', 'Golz', 'Time', 'Norm')\n",
      "(1190, 'acrol0133', 'Golz', 'Time', 'Norm')\n",
      "(1191, 'acrol0134', 'Golz', 'Time', 'Norm')\n",
      "(1192, 'acrol0135', 'Golz', 'Time', 'Norm')\n",
      "(1193, 'acrol0136', 'Golz', 'Time', 'Norm')\n",
      "(1194, 'acrol0137', 'Golz', 'Time', 'Norm')\n",
      "(1195, 'acrol0138', 'Golz', 'Time', 'Norm')\n",
      "(1196, 'acrol0139', 'Golz', 'Time', 'Norm')\n",
      "(1197, 'acrol0140', 'Golz', 'Time', 'Norm')\n",
      "(1198, 'acrol0141', 'Golz', 'Time', 'Norm')\n",
      "(1201, 'acrol0144', 'Golz', 'Time', 'Norm')\n",
      "(1202, 'acrol0145', 'Golz', 'Time', 'Norm')\n",
      "(1206, 'acrol0149', 'Golz', 'Time', 'Norm')\n",
      "(1207, 'acrol0150', 'Golz', 'Time', 'Norm')\n",
      "(1208, 'acrol0151', 'Golz', 'Time', 'Norm')\n",
      "(1209, 'acrol0152', 'Golz', 'Time', 'Norm')\n",
      "(1210, 'acrol0153', 'Golz', 'Time', 'Norm')\n",
      "(1211, 'acrol0154', 'Golz', 'Time', 'Norm')\n",
      "(1212, 'acrol0155', 'Golz', 'Time', 'Norm')\n",
      "(1213, 'acrol0156', 'Golz', 'Time', 'Norm')\n",
      "(1214, 'acrol0157', 'Golz', 'Time', 'Norm')\n",
      "(1215, 'acrol0158', 'Golz', 'Time', 'Norm')\n",
      "(1216, 'acrol0159', 'Golz', 'Time', 'Norm')\n",
      "(1217, 'acrol0160', 'Golz', 'Time', 'Norm')\n",
      "(1218, 'acrol0161', 'Golz', 'Time', 'Norm')\n",
      "(1219, 'acrol0162', 'Golz', 'Time', 'Norm')\n",
      "(1220, 'acrol0163', 'Golz', 'Time', 'Norm')\n",
      "(1221, 'acrol0164', 'Golz', 'Time', 'Norm')\n",
      "(1222, 'acrol0165', 'Golz', 'Time', 'Norm')\n",
      "(1223, 'acrol0166', 'Golz', 'Time', 'Norm')\n",
      "(1224, 'acrol0167', 'Golz', 'Time', 'Norm')\n",
      "(1225, 'acrol0168', 'Golz', 'Time', 'Norm')\n",
      "(1226, 'acrol0169', 'Golz', 'Time', 'Norm')\n",
      "(1227, 'acrol0170', 'Golz', 'Time', 'Norm')\n",
      "(1228, 'acrol0171', 'Golz', 'Time', 'Norm')\n",
      "(1229, 'acrol0172', 'Golz', 'Time', 'Norm')\n",
      "(1230, 'acrol0173', 'Golz', 'Time', 'Norm')\n",
      "(1231, 'acrol0174', 'Golz', 'Time', 'Norm')\n",
      "(1232, 'acrol0175', 'Golz', 'Time', 'Norm')\n",
      "(1233, 'acrol0176', 'Golz', 'Time', 'Norm')\n",
      "(1234, 'acrol0177', 'Golz', 'Time', 'Norm')\n",
      "(1235, 'acrol0178', 'Golz', 'Time', 'Norm')\n",
      "(1236, 'acrol0179', 'Golz', 'Time', 'Norm')\n",
      "(1237, 'acrol0180', 'Golz', 'Time', 'Norm')\n",
      "(1238, 'acrol0181', 'Golz', 'Time', 'Norm')\n",
      "(1239, 'acrol0182', 'Golz', 'Time', 'Norm')\n",
      "(1240, 'acrol0183', 'Golz', 'Time', 'Norm')\n",
      "(1241, 'acrol0184', 'Golz', 'Time', 'Norm')\n",
      "(1242, 'acrol0185', 'Golz', 'Time', 'Norm')\n",
      "(1243, 'acrol0186', 'Golz', 'Time', 'Norm')\n",
      "(1244, 'acrol0187', 'Golz', 'Time', 'Norm')\n",
      "(1245, 'acrol0188', 'Golz', 'Time', 'Norm')\n",
      "(1246, 'acrol0189', 'Golz', 'Time', 'Norm')\n",
      "(1247, 'acrol0190', 'Golz', 'Time', 'Norm')\n",
      "(1248, 'acrol0191', 'Golz', 'Time', 'Norm')\n",
      "(1249, 'acrol0192', 'Golz', 'Time', 'Norm')\n",
      "(1250, 'acrol0193', 'Golz', 'Time', 'Norm')\n",
      "(1252, 'acrol0195', 'Golz', 'Time', 'Norm')\n",
      "(1254, 'acrol0197', 'Golz', 'Time', 'Norm')\n",
      "(1255, 'acrol0198', 'Golz', 'Time', 'Norm')\n",
      "(1256, 'acrol0199', 'Golz', 'Time', 'Norm')\n",
      "(1257, 'acrol0200', 'Golz', 'Time', 'Norm')\n",
      "(1258, 'acrol0201', 'Golz', 'Time', 'Norm')\n",
      "(1259, 'acrol0202', 'Golz', 'Time', 'Norm')\n",
      "(1260, 'acrol0203', 'Golz', 'Time', 'Norm')\n",
      "(1261, 'acrol0204', 'Golz', 'Time', 'Norm')\n",
      "(1262, 'acrol0205', 'Golz', 'Time', 'Norm')\n",
      "(1263, 'acrol0206', 'Golz', 'Time', 'Norm')\n",
      "(1264, 'acrol0207', 'Golz', 'Time', 'Norm')\n",
      "(1265, 'acrol0208', 'Golz', 'Time', 'Norm')\n",
      "(1266, 'acrol0209', 'Golz', 'Time', 'Norm')\n",
      "(1267, 'acrol0210', 'Golz', 'Time', 'Norm')\n",
      "(1268, 'acrol0211', 'Golz', 'Time', 'Norm')\n",
      "(1269, 'acrol0212', 'Golz', 'Time', 'Norm')\n",
      "(1270, 'acrol0213', 'Golz', 'Time', 'Norm')\n",
      "(1271, 'acrol0214', 'Golz', 'Time', 'Norm')\n",
      "(1272, 'acrol0215', 'Golz', 'Time', 'Norm')\n",
      "(1273, 'acrol0216', 'Golz', 'Time', 'Norm')\n",
      "(1274, 'acrol0217', 'Golz', 'Time', 'Norm')\n",
      "(1275, 'acrol0218', 'Golz', 'Time', 'Norm')\n",
      "(1276, 'acrol0219', 'Golz', 'Time', 'Norm')\n",
      "(1277, 'acrol0220', 'Golz', 'Time', 'Norm')\n",
      "(1278, 'acrol0221', 'Golz', 'Time', 'Norm')\n",
      "(1279, 'acrol0222', 'Golz', 'Time', 'Norm')\n",
      "(1280, 'acrol0223', 'Golz', 'Time', 'Norm')\n",
      "(1281, 'acrol0224', 'Golz', 'Time', 'Norm')\n",
      "(1282, 'acrol0225', 'Golz', 'Time', 'Norm')\n",
      "(1283, 'acrol0226', 'Golz', 'Time', 'Norm')\n",
      "(1284, 'acrol0227', 'Golz', 'Time', 'Norm')\n",
      "(1285, 'acrol0228', 'Golz', 'Time', 'Norm')\n",
      "(1286, 'acrol0229', 'Golz', 'Time', 'Norm')\n",
      "(1287, 'acrol0230', 'Golz', 'Time', 'Norm')\n",
      "(1288, 'acrol0231', 'Golz', 'Time', 'Norm')\n",
      "(1289, 'acrol0232', 'Golz', 'Time', 'Norm')\n",
      "(1290, 'acrol0233', 'Golz', 'Time', 'Norm')\n",
      "(1291, 'acrol0234', 'Golz', 'Time', 'Norm')\n",
      "(1292, 'acrol0235', 'Golz', 'Time', 'Norm')\n",
      "(1293, 'acrol0236', 'Golz', 'Time', 'Norm')\n",
      "(1294, 'acrol0237', 'Golz', 'Time', 'Norm')\n",
      "(1295, 'acrol0238', 'Golz', 'Time', 'Norm')\n",
      "(1296, 'acrol0239', 'Golz', 'Time', 'Norm')\n",
      "(1297, 'acrol0240', 'Golz', 'Time', 'Norm')\n",
      "(1298, 'acrol0241', 'Golz', 'Time', 'Norm')\n",
      "(1299, 'acrol0242', 'Golz', 'Time', 'Norm')\n",
      "(1300, 'acrol0243', 'Golz', 'Time', 'Norm')\n",
      "(1301, 'acrol0244', 'Golz', 'Time', 'Norm')\n",
      "(1302, 'acrol0245', 'Golz', 'Time', 'Norm')\n",
      "(1303, 'acrol0246', 'Golz', 'Time', 'Norm')\n",
      "(1304, 'acrol0247', 'Golz', 'Time', 'Norm')\n",
      "(1305, 'acrol0248', 'Golz', 'Time', 'Norm')\n",
      "(1306, 'acrol0249', 'Golz', 'Time', 'Norm')\n",
      "(1307, 'acrol0250', 'Golz', 'Time', 'Norm')\n",
      "(1308, 'acrol0251', 'Golz', 'Time', 'Norm')\n",
      "(1309, 'acrol0252', 'Golz', 'Time', 'Norm')\n",
      "(1310, 'acrol0253', 'Golz', 'Time', 'Norm')\n",
      "(1311, 'acrol0254', 'Golz', 'Time', 'Norm')\n",
      "(1312, 'acrol0255', 'Golz', 'Time', 'Norm')\n",
      "(1313, 'acrol0256', 'Golz', 'Time', 'Norm')\n",
      "(1314, 'acrol0257', 'Golz', 'Time', 'Norm')\n",
      "(1315, 'acrol0258', 'Golz', 'Time', 'Norm')\n",
      "(1316, 'acrol0259', 'Golz', 'Time', 'Norm')\n",
      "(1317, 'acrol0260', 'Golz', 'Time', 'Norm')\n",
      "(1318, 'acrol0261', 'Golz', 'Time', 'Norm')\n",
      "(1319, 'acrol0262', 'Golz', 'Time', 'Norm')\n",
      "(1320, 'acrol0263', 'Golz', 'Time', 'Norm')\n",
      "(1321, 'acrol0264', 'Golz', 'Time', 'Norm')\n",
      "(1322, 'acrol0265', 'Golz', 'Time', 'Norm')\n",
      "(1323, 'acrol0266', 'Golz', 'Time', 'Norm')\n",
      "(1324, 'acrol0267', 'Golz', 'Time', 'Norm')\n",
      "(1325, 'acrol0268', 'Golz', 'Time', 'Norm')\n",
      "(1326, 'acrol0269', 'Golz', 'Time', 'Norm')\n",
      "(1327, 'acrol0270', 'Golz', 'Time', 'Norm')\n",
      "(1328, 'acrol0271', 'Golz', 'Time', 'Norm')\n",
      "(1329, 'acrol0272', 'Golz', 'Time', 'Norm')\n",
      "(1330, 'acrol0273', 'Golz', 'Time', 'Norm')\n",
      "(1331, 'acrol0274', 'Golz', 'Time', 'Norm')\n",
      "(1332, 'acrol0275', 'Golz', 'Time', 'Norm')\n",
      "(1333, 'acrol0276', 'Golz', 'Time', 'Norm')\n",
      "(1334, 'acrol0277', 'Golz', 'Time', 'Norm')\n",
      "(1335, 'acrol0278', 'Golz', 'Time', 'Norm')\n",
      "(1336, 'acrol0279', 'Golz', 'Time', 'Norm')\n",
      "(1337, 'acrol0280', 'Golz', 'Time', 'Norm')\n",
      "(1338, 'acrol0281', 'Golz', 'Time', 'Norm')\n",
      "(1339, 'acrol0282', 'Golz', 'Time', 'Norm')\n",
      "(1341, 'acrol0284', 'Golz', 'Time', 'Norm')\n",
      "(1342, 'acrol0285', 'Golz', 'Time', 'Norm')\n",
      "(1343, 'acrol0286', 'Golz', 'Time', 'Norm')\n",
      "(1346, 'acrol0289', 'Golz', 'Time', 'Norm')\n",
      "(1347, 'acrol0290', 'Golz', 'Time', 'Norm')\n",
      "(1348, 'acrol0291', 'Golz', 'Time', 'Norm')\n",
      "(1350, 'acrol0293', 'Golz', 'Time', 'Norm')\n",
      "(1352, 'acrol0295', 'Golz', 'Time', 'Norm')\n",
      "(1361, 'acrol0304', 'Golz', 'Time', 'Norm')\n",
      "(1362, 'acrol0305', 'Golz', 'Time', 'Norm')\n",
      "(1363, 'acrol0306', 'Golz', 'Time', 'Norm')\n",
      "(1364, 'acrol0307', 'Golz', 'Time', 'Norm')\n",
      "(1365, 'acrol0308', 'Golz', 'Time', 'Norm')\n",
      "(1366, 'acrol0309', 'Golz', 'Time', 'Norm')\n",
      "(1367, 'acrol0310', 'Golz', 'Time', 'Norm')\n",
      "(1368, 'acrol0311', 'Golz', 'Time', 'Norm')\n",
      "(1369, 'acrol0312', 'Golz', 'Time', 'Norm')\n",
      "(1370, 'acrol0313', 'Golz', 'Time', 'Norm')\n",
      "(1371, 'acrol0314', 'Golz', 'Time', 'Norm')\n",
      "(1372, 'acrol0315', 'Golz', 'Time', 'Norm')\n",
      "(1373, 'acrol0316', 'Golz', 'Time', 'Norm')\n",
      "(1374, 'acrol0317', 'Golz', 'Time', 'Norm')\n",
      "(1375, 'acrol0318', 'Golz', 'Time', 'Norm')\n",
      "(1376, 'acrol0319', 'Golz', 'Time', 'Norm')\n",
      "(1377, 'acrol0320', 'Golz', 'Time', 'Norm')\n",
      "(1378, 'acrol0321', 'Golz', 'Time', 'Norm')\n",
      "(1379, 'acrol0322', 'Golz', 'Time', 'Norm')\n",
      "(1380, 'acrol0323', 'Golz', 'Time', 'Norm')\n",
      "(1382, 'acrol0325', 'Golz', 'Time', 'Norm')\n",
      "(1383, 'acrol0326', 'Golz', 'Time', 'Norm')\n",
      "(1384, 'acrol0327', 'Golz', 'Time', 'Norm')\n",
      "(1385, 'acrol0328', 'Golz', 'Time', 'Norm')\n",
      "(1386, 'acrol0329', 'Golz', 'Time', 'Norm')\n",
      "(1387, 'acrol0330', 'Golz', 'Time', 'Norm')\n",
      "(1388, 'acrol0331', 'Golz', 'Time', 'Norm')\n",
      "(1389, 'acrol0332', 'Golz', 'Time', 'Norm')\n",
      "(1390, 'acrol0333', 'Golz', 'Time', 'Norm')\n",
      "(1391, 'acrol0334', 'Golz', 'Time', 'Norm')\n",
      "(1392, 'acrol0335', 'Golz', 'Time', 'Norm')\n",
      "(1393, 'acrol0336', 'Golz', 'Time', 'Norm')\n",
      "(1394, 'acrol0337', 'Golz', 'Time', 'Norm')\n",
      "(1396, 'acrol0339', 'Golz', 'Time', 'Norm')\n",
      "(1397, 'acrol0340', 'Golz', 'Time', 'Norm')\n",
      "(1398, 'acrol0341', 'Golz', 'Time', 'Norm')\n",
      "(1399, 'acrol0342', 'Golz', 'Time', 'Norm')\n",
      "(1400, 'acrol0343', 'Golz', 'Time', 'Norm')\n",
      "(1402, 'acrol0345', 'Golz', 'Time', 'Norm')\n",
      "(1403, 'acrol0346', 'Golz', 'Time', 'Norm')\n",
      "(1407, 'acrol0350', 'Golz', 'Time', 'Norm')\n",
      "(1408, 'acrol0351', 'Golz', 'Time', 'Norm')\n",
      "(1409, 'acrol0352', 'Golz', 'Time', 'Norm')\n",
      "(1410, 'acrol0353', 'Golz', 'Time', 'Norm')\n",
      "(1411, 'acrol0354', 'Golz', 'Time', 'Norm')\n",
      "(1412, 'acrol0355', 'Golz', 'Time', 'Norm')\n",
      "(1413, 'acrol0356', 'Golz', 'Time', 'Norm')\n",
      "(1414, 'acrol0357', 'Golz', 'Time', 'Norm')\n",
      "(1415, 'acrol0358', 'Golz', 'Time', 'Norm')\n",
      "(1416, 'acrol0359', 'Golz', 'Time', 'Norm')\n",
      "(1417, 'acrol0360', 'Golz', 'Time', 'Norm')\n",
      "(1418, 'acrol0361', 'Golz', 'Time', 'Norm')\n",
      "(1419, 'acrol0362', 'Golz', 'Time', 'Norm')\n",
      "(1420, 'acrol0363', 'Golz', 'Time', 'Norm')\n",
      "(1421, 'acrol0364', 'Golz', 'Time', 'Norm')\n",
      "(1422, 'acrol0365', 'Golz', 'Time', 'Norm')\n",
      "(1423, 'acrol0366', 'Golz', 'Time', 'Norm')\n",
      "(1424, 'acrol0367', 'Golz', 'Time', 'Norm')\n",
      "(1425, 'acrol0368', 'Golz', 'Time', 'Norm')\n",
      "(1426, 'acrol0369', 'Golz', 'Time', 'Norm')\n",
      "(1427, 'acrol0370', 'Golz', 'Time', 'Norm')\n",
      "(1428, 'acrol0371', 'Golz', 'Time', 'Norm')\n",
      "(1429, 'acrol0372', 'Golz', 'Time', 'Norm')\n",
      "(1430, 'acrol0373', 'Golz', 'Time', 'Norm')\n",
      "(1431, 'acrol0374', 'Golz', 'Time', 'Norm')\n",
      "(1432, 'acrol0375', 'Golz', 'Time', 'Norm')\n",
      "(1433, 'acrol0376', 'Golz', 'Time', 'Norm')\n",
      "(1434, 'acrol0377', 'Golz', 'Time', 'Norm')\n",
      "(1435, 'acrol0378', 'Golz', 'Time', 'Norm')\n",
      "(1436, 'acrol0379', 'Golz', 'Time', 'Norm')\n",
      "(1437, 'acrol0380', 'Golz', 'Time', 'Norm')\n",
      "(1438, 'acrol0381', 'Golz', 'Time', 'Norm')\n",
      "(1439, 'acrol0382', 'Golz', 'Time', 'Norm')\n",
      "(1440, 'acrol0383', 'Golz', 'Time', 'Norm')\n",
      "(1441, 'acrol0384', 'Golz', 'Time', 'Norm')\n",
      "(1443, 'acrol0386', 'Golz', 'Time', 'Norm')\n",
      "(1444, 'acrol0387', 'Golz', 'Time', 'Norm')\n",
      "(1445, 'acrol0388', 'Golz', 'Time', 'Norm')\n",
      "(1446, 'acrol0389', 'Golz', 'Time', 'Norm')\n",
      "(1447, 'acrol0390', 'Golz', 'Time', 'Norm')\n",
      "(1448, 'acrol0391', 'Golz', 'Time', 'Norm')\n",
      "(1449, 'acrol0392', 'Golz', 'Time', 'Norm')\n",
      "(1450, 'acrol0393', 'Golz', 'Time', 'Norm')\n",
      "(1451, 'acrol0394', 'Golz', 'Time', 'Norm')\n",
      "(1452, 'acrol0395', 'Golz', 'Time', 'Norm')\n",
      "(1453, 'acrol0396', 'Golz', 'Time', 'Norm')\n",
      "(1454, 'acrol0397', 'Golz', 'Time', 'Norm')\n",
      "(1455, 'acrol0398', 'Golz', 'Time', 'Norm')\n",
      "(1456, 'acrol0399', 'Golz', 'Time', 'Norm')\n",
      "(1457, 'acrol0400', 'Golz', 'Time', 'Norm')\n",
      "(1458, 'acrol0401', 'Golz', 'Time', 'Norm')\n",
      "(1459, 'acrol0402', 'Golz', 'Time', 'Norm')\n",
      "(1460, 'acrol0403', 'Golz', 'Time', 'Norm')\n",
      "(1461, 'acrol0404', 'Golz', 'Time', 'Norm')\n",
      "(1462, 'acrol0405', 'Golz', 'Time', 'Norm')\n",
      "(1463, 'acrol0406', 'Golz', 'Time', 'Norm')\n",
      "(1464, 'acrol0407', 'Golz', 'Time', 'Norm')\n",
      "(1465, 'acrol0408', 'Golz', 'Time', 'Norm')\n",
      "(1466, 'acrol0409', 'Golz', 'Time', 'Norm')\n",
      "(1467, 'acrol0410', 'Golz', 'Time', 'Norm')\n",
      "(1468, 'acrol0411', 'Golz', 'Time', 'Norm')\n",
      "(1469, 'acrol0412', 'Golz', 'Time', 'Norm')\n",
      "(1470, 'acrol0413', 'Golz', 'Time', 'Norm')\n",
      "(1471, 'acrol0414', 'Golz', 'Time', 'Norm')\n",
      "(1472, 'acrol0415', 'Golz', 'Time', 'Norm')\n",
      "(1474, 'acrol0417', 'Golz', 'Time', 'Norm')\n",
      "(1475, 'acrol0418', 'Golz', 'Time', 'Norm')\n",
      "(1476, 'acrol0419', 'Golz', 'Time', 'Norm')\n",
      "(1477, 'acrol0420', 'Golz', 'Time', 'Norm')\n",
      "(1478, 'acrol0421', 'Golz', 'Time', 'Norm')\n",
      "(1479, 'acrol0422', 'Golz', 'Time', 'Norm')\n",
      "(1480, 'acrol0423', 'Golz', 'Time', 'Norm')\n",
      "(1481, 'acrol0424', 'Golz', 'Time', 'Norm')\n",
      "(1484, 'acrol0427', 'Golz', 'Time', 'Norm')\n",
      "(1485, 'acrol0428', 'Golz', 'Time', 'Norm')\n",
      "(1486, 'acrol0429', 'Golz', 'Time', 'Norm')\n",
      "(1488, 'acrol0431', 'Golz', 'Time', 'Norm')\n",
      "(1489, 'acrol0432', 'Golz', 'Time', 'Norm')\n",
      "(1491, 'acrol0434', 'Golz', 'Time', 'Norm')\n",
      "(1492, 'acrol0435', 'Golz', 'Time', 'Norm')\n",
      "(1493, 'acrol0436', 'Golz', 'Time', 'Norm')\n",
      "(1494, 'acrol0437', 'Golz', 'Time', 'Norm')\n",
      "(1495, 'acrol0438', 'Golz', 'Time', 'Norm')\n",
      "(1501, 'acrol0444', 'Golz', 'Time', 'Norm')\n",
      "(1502, 'acrol0445', 'Golz', 'Time', 'Norm')\n",
      "(1503, 'acrol0446', 'Golz', 'Time', 'Norm')\n",
      "(1504, 'acrol0447', 'Golz', 'Time', 'Norm')\n",
      "(1505, 'acrol0448', 'Golz', 'Time', 'Norm')\n",
      "(1506, 'acrol0449', 'Golz', 'Time', 'Norm')\n",
      "(1509, 'acrol0452', 'Golz', 'Time', 'Norm')\n",
      "(1510, 'acrol0453', 'Golz', 'Time', 'Norm')\n",
      "(1512, 'acrol0455', 'Golz', 'Time', 'Norm')\n",
      "(1516, 'acrol0459', 'Golz', 'Time', 'Norm')\n",
      "(1527, 'acrol0470', 'Golz', 'Time', 'Norm')\n",
      "(1529, 'acrol0472', 'Golz', 'Time', 'Norm')\n",
      "(1530, 'acrol0473', 'Golz', 'Time', 'Norm')\n",
      "(1531, 'acrol0474', 'Golz', 'Time', 'Norm')\n",
      "(1534, 'acrol0477', 'Golz', 'Time', 'Norm')\n",
      "(1536, 'acrol0479', 'Golz', 'Time', 'Norm')\n",
      "(1540, 'acrol0483', 'Golz', 'Time', 'Norm')\n",
      "(1546, 'acrol0489', 'Golz', 'Time', 'Norm')\n",
      "(1547, 'acrol0490', 'Golz', 'Time', 'Norm')\n",
      "(1548, 'acrol0491', 'Golz', 'Time', 'Norm')\n",
      "(1549, 'acrol0492', 'Golz', 'Time', 'Norm')\n",
      "(1550, 'acrol0493', 'Golz', 'Time', 'Norm')\n",
      "(1551, 'acrol0494', 'Golz', 'Time', 'Norm')\n",
      "(1552, 'acrol0495', 'Golz', 'Time', 'Norm')\n",
      "(1553, 'acrol0496', 'Golz', 'Time', 'Norm')\n",
      "(1554, 'acrol0497', 'Golz', 'Time', 'Norm')\n",
      "(1555, 'acrol0498', 'Golz', 'Time', 'Norm')\n",
      "(1556, 'acrol0499', 'Golz', 'Time', 'Norm')\n",
      "(1557, 'acrol0500', 'Golz', 'Time', 'Norm')\n",
      "(1558, 'acrol0501', 'Golz', 'Time', 'Norm')\n",
      "(1559, 'acrol0502', 'Golz', 'Time', 'Norm')\n",
      "(1560, 'acrol0503', 'Golz', 'Time', 'Norm')\n",
      "(1561, 'acrol0504', 'Golz', 'Time', 'Norm')\n",
      "(1562, 'acrol0505', 'Golz', 'Time', 'Norm')\n",
      "(1563, 'acrol0506', 'Golz', 'Time', 'Norm')\n",
      "(1564, 'acrol0507', 'Golz', 'Time', 'Norm')\n",
      "(1565, 'acrol0508', 'Golz', 'Time', 'Norm')\n",
      "(1566, 'acrol0509', 'Golz', 'Time', 'Norm')\n",
      "(1567, 'acrol0510', 'Golz', 'Time', 'Norm')\n",
      "(1568, 'acrol0511', 'Golz', 'Time', 'Norm')\n",
      "(1569, 'acrol0512', 'Golz', 'Time', 'Norm')\n",
      "(1570, 'acrol0513', 'Golz', 'Time', 'Norm')\n",
      "(1571, 'acrol0514', 'Golz', 'Time', 'Norm')\n",
      "(1572, 'acrol0515', 'Golz', 'Time', 'Norm')\n",
      "(1574, 'acrol0517', 'Golz', 'Time', 'Norm')\n",
      "(1576, 'acrol0519', 'Golz', 'Time', 'Norm')\n",
      "(1577, 'acrol0520', 'Golz', 'Time', 'Norm')\n",
      "(1578, 'acrol0521', 'Golz', 'Time', 'Norm')\n",
      "(1580, 'acrol0523', 'Golz', 'Time', 'Norm')\n",
      "(1581, 'acrol0524', 'Golz', 'Time', 'Norm')\n",
      "(1582, 'acrol0525', 'Golz', 'Time', 'Norm')\n",
      "(1583, 'acrol0526', 'Golz', 'Time', 'Norm')\n",
      "(1584, 'acrol0527', 'Golz', 'Time', 'Norm')\n",
      "(1585, 'acrol0528', 'Golz', 'Time', 'Norm')\n",
      "(1586, 'acrol0529', 'Golz', 'Time', 'Norm')\n",
      "(1587, 'acrol0530', 'Golz', 'Time', 'Norm')\n",
      "(1588, 'acrol0531', 'Golz', 'Time', 'Norm')\n",
      "(1590, 'acrol0533', 'Golz', 'Time', 'Norm')\n",
      "(1591, 'acrol0534', 'Golz', 'Time', 'Norm')\n",
      "(1592, 'acrol0535', 'Golz', 'Time', 'Norm')\n",
      "(1593, 'acrol0536', 'Golz', 'Time', 'Norm')\n",
      "(1594, 'acrol0537', 'Golz', 'Time', 'Norm')\n",
      "(1595, 'acrol0538', 'Golz', 'Time', 'Norm')\n",
      "(1596, 'acrol0539', 'Golz', 'Time', 'Norm')\n",
      "(1597, 'acrol0540', 'Golz', 'Time', 'Norm')\n",
      "(1598, 'acrol0541', 'Golz', 'Time', 'Norm')\n",
      "(1599, 'acrol0542', 'Golz', 'Time', 'Norm')\n",
      "(1602, 'acrol0545', 'Golz', 'Time', 'Norm')\n",
      "(1603, 'acrol0546', 'Golz', 'Time', 'Norm')\n",
      "(1604, 'acrol0547', 'Golz', 'Time', 'Norm')\n",
      "(1605, 'acrol0548', 'Golz', 'Time', 'Norm')\n",
      "(1606, 'acrol0549', 'Golz', 'Time', 'Norm')\n",
      "(1607, 'acrol0550', 'Golz', 'Time', 'Norm')\n",
      "(1608, 'acrol0551', 'Golz', 'Time', 'Norm')\n",
      "(1609, 'acrol0552', 'Golz', 'Time', 'Norm')\n",
      "(1610, 'acrol0553', 'Golz', 'Time', 'Norm')\n",
      "(1611, 'acrol0554', 'Golz', 'Time', 'Norm')\n",
      "(1612, 'acrol0555', 'Golz', 'Time', 'Norm')\n",
      "(1613, 'acrol0556', 'Golz', 'Time', 'Norm')\n",
      "(1615, 'acrol0558', 'Golz', 'Time', 'Norm')\n",
      "(1616, 'acrol0559', 'Golz', 'Time', 'Norm')\n",
      "(1617, 'acrol0560', 'Golz', 'Time', 'Norm')\n",
      "(1618, 'acrol0561', 'Golz', 'Time', 'Norm')\n",
      "(1619, 'acrol0562', 'Golz', 'Time', 'Norm')\n",
      "(1625, 'acrol0568', 'Golz', 'Time', 'Norm')\n",
      "(1627, 'acrol0570', 'Golz', 'Time', 'Norm')\n",
      "(1629, 'acrol0572', 'Golz', 'Time', 'Norm')\n",
      "(1630, 'acrol0573', 'Golz', 'Time', 'Norm')\n",
      "(1633, 'acrol0576', 'Golz', 'Time', 'Norm')\n",
      "(1634, 'acrol0577', 'Golz', 'Time', 'Norm')\n",
      "(1637, 'acrol0580', 'Golz', 'Time', 'Norm')\n",
      "(1639, 'acrol0582', 'Golz', 'Time', 'Norm')\n",
      "(1641, 'acrol0584', 'Golz', 'Time', 'Norm')\n",
      "(1642, 'acrol0585', 'Golz', 'Time', 'Norm')\n",
      "(1644, 'acrol0587', 'Golz', 'Time', 'Norm')\n",
      "(1645, 'acrol0588', 'Golz', 'Time', 'Norm')\n",
      "(1646, 'acrol0589', 'Golz', 'Time', 'Norm')\n",
      "(1650, 'acrol0593', 'Golz', 'Time', 'Norm')\n",
      "(1652, 'acrol0595', 'Golz', 'Time', 'Norm')\n",
      "(1654, 'acrol0597', 'Golz', 'Time', 'Norm')\n",
      "(1655, 'acrol0598', 'Golz', 'Time', 'Norm')\n",
      "(1656, 'acrol0599', 'Golz', 'Time', 'Norm')\n",
      "(1659, 'acrol0602', 'Golz', 'Time', 'Norm')\n",
      "(1660, 'acrol0603', 'Golz', 'Time', 'Norm')\n",
      "(1661, 'acrol0604', 'Golz', 'Time', 'Norm')\n",
      "(1665, 'acrol0608', 'Golz', 'Time', 'Norm')\n",
      "(1666, 'acrol0609', 'Golz', 'Time', 'Norm')\n",
      "(1667, 'acrol0610', 'Golz', 'Time', 'Norm')\n",
      "(1668, 'acrol0611', 'Golz', 'Time', 'Norm')\n",
      "(1672, 'acrol0615', 'Golz', 'Time', 'Norm')\n",
      "(1673, 'acrol0616', 'Golz', 'Time', 'Norm')\n",
      "(1675, 'acrol0618', 'Golz', 'Time', 'Norm')\n",
      "(1676, 'acrol0619', 'Golz', 'Time', 'Norm')\n",
      "(1677, 'acrol0620', 'Golz', 'Time', 'Norm')\n",
      "(1678, 'acrol0621', 'Golz', 'Time', 'Norm')\n",
      "(1679, 'acrol0622', 'Golz', 'Time', 'Norm')\n",
      "(1680, 'acrol0623', 'Golz', 'Time', 'Norm')\n",
      "(1681, 'acrol0624', 'Golz', 'Time', 'Norm')\n",
      "(1682, 'acrol0625', 'Golz', 'Time', 'Norm')\n",
      "(1683, 'acrol0626', 'Golz', 'Time', 'Norm')\n",
      "(1684, 'acrol0627', 'Golz', 'Time', 'Norm')\n",
      "(1685, 'acrol0628', 'Golz', 'Time', 'Norm')\n",
      "(1686, 'acrol0629', 'Golz', 'Time', 'Norm')\n",
      "(1687, 'acrol0630', 'Golz', 'Time', 'Norm')\n",
      "(1688, 'acrol0631', 'Golz', 'Time', 'Norm')\n",
      "(1689, 'acrol0632', 'Golz', 'Time', 'Norm')\n",
      "(1701, 'acrol0644', 'Golz', 'Time', 'Norm')\n",
      "(1702, 'acrol0645', 'Golz', 'Time', 'Norm')\n",
      "(1706, 'acrol0649', 'Golz', 'Time', 'Norm')\n",
      "(1707, 'acrol0650', 'Golz', 'Time', 'Norm')\n",
      "(1708, 'acrol0651', 'Golz', 'Time', 'Norm')\n",
      "(1709, 'acrol0652', 'Golz', 'Time', 'Norm')\n",
      "(1710, 'acrol0653', 'Golz', 'Time', 'Norm')\n",
      "(1711, 'acrol0654', 'Golz', 'Time', 'Norm')\n",
      "(1712, 'acrol0655', 'Golz', 'Time', 'Norm')\n",
      "(1713, 'acrol0656', 'Golz', 'Time', 'Norm')\n",
      "(1714, 'acrol0657', 'Golz', 'Time', 'Norm')\n",
      "(1715, 'acrol0658', 'Golz', 'Time', 'Norm')\n",
      "(1716, 'acrol0659', 'Golz', 'Time', 'Norm')\n",
      "(1717, 'acrol0660', 'Golz', 'Time', 'Norm')\n",
      "(1718, 'acrol0661', 'Golz', 'Time', 'Norm')\n",
      "(1719, 'acrol0662', 'Golz', 'Time', 'Norm')\n",
      "(1720, 'acrol0663', 'Golz', 'Time', 'Norm')\n",
      "(1721, 'acrol0664', 'Golz', 'Time', 'Norm')\n",
      "(1722, 'acrol0665', 'Golz', 'Time', 'Norm')\n",
      "(1723, 'acrol0666', 'Golz', 'Time', 'Norm')\n",
      "(1725, 'acrol0668', 'Golz', 'Time', 'Norm')\n",
      "(1727, 'acrol0670', 'Golz', 'Time', 'Norm')\n",
      "(1728, 'acrol0671', 'Golz', 'Time', 'Norm')\n",
      "(1731, 'acrol0674', 'Golz', 'Time', 'Norm')\n",
      "(1732, 'acrol0675', 'Golz', 'Time', 'Norm')\n",
      "(1733, 'acrol0676', 'Golz', 'Time', 'Norm')\n",
      "(1735, 'acrol0678', 'Golz', 'Time', 'Norm')\n",
      "(1737, 'acrol0680', 'Golz', 'Time', 'Norm')\n",
      "(1738, 'acrol0681', 'Golz', 'Time', 'Norm')\n",
      "(1739, 'acrol0682', 'Golz', 'Time', 'Norm')\n",
      "(1740, 'acrol0683', 'Golz', 'Time', 'Norm')\n",
      "(1741, 'acrol0684', 'Golz', 'Time', 'Norm')\n",
      "(1742, 'acrol0685', 'Golz', 'Time', 'Norm')\n",
      "(1744, 'acrol0687', 'Golz', 'Time', 'Norm')\n",
      "(1746, 'acrol0689', 'Golz', 'Time', 'Norm')\n",
      "(1748, 'acrol0691', 'Golz', 'Time', 'Norm')\n",
      "(1750, 'acrol0693', 'Golz', 'Time', 'Norm')\n",
      "(1752, 'acrol0695', 'Golz', 'Time', 'Norm')\n",
      "(1753, 'acrol0696', 'Golz', 'Time', 'Norm')\n",
      "(1754, 'acrol0697', 'Golz', 'Time', 'Norm')\n",
      "(1755, 'acrol0698', 'Golz', 'Time', 'Norm')\n",
      "(1756, 'acrol0699', 'Golz', 'Time', 'Norm')\n",
      "(1757, 'acrol0700', 'Golz', 'Time', 'Norm')\n",
      "(1759, 'acrol0702', 'Golz', 'Time', 'Norm')\n",
      "(1760, 'acrol0703', 'Golz', 'Time', 'Norm')\n",
      "(1761, 'acrol0704', 'Golz', 'Time', 'Norm')\n",
      "(1762, 'acrol0705', 'Golz', 'Time', 'Norm')\n",
      "(1763, 'acrol0706', 'Golz', 'Time', 'Norm')\n",
      "(1764, 'acrol0707', 'Golz', 'Time', 'Norm')\n",
      "(1765, 'acrol0708', 'Golz', 'Time', 'Norm')\n",
      "(1766, 'acrol0709', 'Golz', 'Time', 'Norm')\n",
      "(1767, 'acrol0710', 'Golz', 'Time', 'Norm')\n",
      "(1768, 'acrol0711', 'Golz', 'Time', 'Norm')\n",
      "(1769, 'acrol0712', 'Golz', 'Time', 'Norm')\n",
      "(1770, 'acrol0713', 'Golz', 'Time', 'Norm')\n",
      "(1771, 'acrol0714', 'Golz', 'Time', 'Norm')\n",
      "(1772, 'acrol0715', 'Golz', 'Time', 'Norm')\n",
      "(1773, 'acrol0716', 'Golz', 'Time', 'Norm')\n",
      "(1774, 'acrol0717', 'Golz', 'Time', 'Norm')\n",
      "(1775, 'acrol0718', 'Golz', 'Time', 'Norm')\n",
      "(1776, 'acrol0719', 'Golz', 'Time', 'Norm')\n",
      "(1777, 'acrol0720', 'Golz', 'Time', 'Norm')\n",
      "(1782, 'acrol0725', 'Golz', 'Time', 'Norm')\n",
      "(1783, 'acrol0726', 'Golz', 'Time', 'Norm')\n",
      "(1785, 'acrol0728', 'Golz', 'Time', 'Norm')\n",
      "(1787, 'acrol0730', 'Golz', 'Time', 'Norm')\n",
      "(1788, 'acrol0731', 'Golz', 'Time', 'Norm')\n",
      "(1791, 'acrol0734', 'Golz', 'Time', 'Norm')\n",
      "(1793, 'acrol0736', 'Golz', 'Time', 'Norm')\n",
      "(1794, 'acrol0737', 'Golz', 'Time', 'Norm')\n",
      "(1795, 'acrol0738', 'Golz', 'Time', 'Norm')\n",
      "(1796, 'acrol0739', 'Golz', 'Time', 'Norm')\n",
      "(1797, 'acrol0740', 'Golz', 'Time', 'Norm')\n",
      "(1798, 'acrol0741', 'Golz', 'Time', 'Norm')\n",
      "(1799, 'acrol0742', 'Golz', 'Time', 'Norm')\n",
      "(1801, 'acrol0744', 'Golz', 'Time', 'Norm')\n",
      "(1803, 'acrol0746', 'Golz', 'Time', 'Norm')\n",
      "(1804, 'acrol0747', 'Golz', 'Time', 'Norm')\n",
      "(1805, 'acrol0748', 'Golz', 'Time', 'Norm')\n",
      "(1806, 'acrol0749', 'Golz', 'Time', 'Norm')\n",
      "(1809, 'acrol0752', 'Golz', 'Time', 'Norm')\n",
      "(1812, 'acrol0755', 'Golz', 'Time', 'Norm')\n",
      "(1815, 'acrol0758', 'Golz', 'Time', 'Norm')\n",
      "(1816, 'acrol0759', 'Golz', 'Time', 'Norm')\n",
      "(1817, 'acrol0760', 'Golz', 'Time', 'Norm')\n",
      "(1819, 'acrol0762', 'Golz', 'Time', 'Norm')\n",
      "(1820, 'acrol0763', 'Golz', 'Time', 'Norm')\n",
      "(1821, 'acrol0764', 'Golz', 'Time', 'Norm')\n",
      "(1823, 'acrol0766', 'Golz', 'Time', 'Norm')\n",
      "(1825, 'acrol0768', 'Golz', 'Time', 'Norm')\n",
      "(1826, 'acrol0769', 'Golz', 'Time', 'Norm')\n",
      "(1832, 'acrol0775', 'Golz', 'Time', 'Norm')\n",
      "(1833, 'acrol0776', 'Golz', 'Time', 'Norm')\n",
      "(1839, 'acrol0782', 'Golz', 'Time', 'Norm')\n",
      "(1840, 'acrol0783', 'Golz', 'Time', 'Norm')\n",
      "(1841, 'acrol0784', 'Golz', 'Time', 'Norm')\n",
      "(1842, 'acrol0785', 'Golz', 'Time', 'Norm')\n",
      "(1844, 'acrol0787', 'Golz', 'Time', 'Norm')\n",
      "(1845, 'acrol0788', 'Golz', 'Time', 'Norm')\n",
      "(1846, 'acrol0789', 'Golz', 'Time', 'Norm')\n",
      "(1847, 'acrol0790', 'Golz', 'Time', 'Norm')\n",
      "(1848, 'acrol0791', 'Golz', 'Time', 'Norm')\n",
      "(1849, 'acrol0792', 'Golz', 'Time', 'Norm')\n",
      "(1850, 'acrol0793', 'Golz', 'Time', 'Norm')\n",
      "(1851, 'acrol0794', 'Golz', 'Time', 'Norm')\n",
      "(1852, 'acrol0795', 'Golz', 'Time', 'Norm')\n",
      "(1853, 'acrol0796', 'Golz', 'Time', 'Norm')\n",
      "(1854, 'acrol0797', 'Golz', 'Time', 'Norm')\n",
      "(1855, 'acrol0798', 'Golz', 'Time', 'Norm')\n",
      "(1856, 'acrol0799', 'Golz', 'Time', 'Norm')\n",
      "(1857, 'acrol0800', 'Golz', 'Time', 'Norm')\n",
      "(1858, 'acrol0801', 'Golz', 'Time', 'Norm')\n",
      "(1859, 'acrol0802', 'Golz', 'Time', 'Norm')\n",
      "(1860, 'acrol0803', 'Golz', 'Time', 'Norm')\n",
      "(1861, 'acrol0804', 'Golz', 'Time', 'Norm')\n",
      "(1862, 'acrol0805', 'Golz', 'Time', 'Norm')\n",
      "(1863, 'acrol0806', 'Golz', 'Time', 'Norm')\n",
      "(1864, 'acrol0807', 'Golz', 'Time', 'Norm')\n",
      "(1865, 'acrol0808', 'Golz', 'Time', 'Norm')\n",
      "(1866, 'acrol0809', 'Golz', 'Time', 'Norm')\n",
      "(1867, 'acrol0810', 'Golz', 'Time', 'Norm')\n",
      "(1868, 'acrol0811', 'Golz', 'Time', 'Norm')\n",
      "(1869, 'acrol0812', 'Golz', 'Time', 'Norm')\n",
      "(1870, 'acrol0813', 'Golz', 'Time', 'Norm')\n",
      "(1871, 'acrol0814', 'Golz', 'Time', 'Norm')\n",
      "(1872, 'acrol0815', 'Golz', 'Time', 'Norm')\n",
      "(1873, 'acrol0816', 'Golz', 'Time', 'Norm')\n",
      "(1874, 'acrol0817', 'Golz', 'Time', 'Norm')\n",
      "(1875, 'acrol0818', 'Golz', 'Time', 'Norm')\n",
      "(1876, 'acrol0819', 'Golz', 'Time', 'Norm')\n",
      "(1877, 'acrol0820', 'Golz', 'Time', 'Norm')\n",
      "(1878, 'acrol0821', 'Golz', 'Time', 'Norm')\n",
      "(1879, 'acrol0822', 'Golz', 'Time', 'Norm')\n",
      "(1880, 'acrol0823', 'Golz', 'Time', 'Norm')\n",
      "(1881, 'acrol0824', 'Golz', 'Time', 'Norm')\n",
      "(1882, 'acrol0825', 'Golz', 'Time', 'Norm')\n",
      "(1883, 'acrol0826', 'Golz', 'Time', 'Norm')\n",
      "(1884, 'acrol0827', 'Golz', 'Time', 'Norm')\n",
      "(1885, 'acrol0828', 'Golz', 'Time', 'Norm')\n",
      "(1886, 'acrol0829', 'Golz', 'Time', 'Norm')\n",
      "(1888, 'acrol0831', 'Golz', 'Time', 'Norm')\n",
      "(1890, 'acrol0833', 'Golz', 'Time', 'Norm')\n",
      "(1891, 'acrol0834', 'Golz', 'Time', 'Norm')\n",
      "(1892, 'acrol0835', 'Golz', 'Time', 'Norm')\n",
      "(1893, 'acrol0836', 'Golz', 'Time', 'Norm')\n",
      "(1894, 'acrol0837', 'Golz', 'Time', 'Norm')\n",
      "(1895, 'acrol0838', 'Golz', 'Time', 'Norm')\n",
      "(1897, 'acrol0840', 'Golz', 'Time', 'Norm')\n",
      "(1898, 'acrol0841', 'Golz', 'Time', 'Norm')\n",
      "(1900, 'acrol0843', 'Golz', 'Time', 'Norm')\n",
      "(1901, 'acrol0844', 'Golz', 'Time', 'Norm')\n",
      "(1903, 'acrol0846', 'Golz', 'Time', 'Norm')\n",
      "(1910, 'acrol0853', 'Golz', 'Time', 'Norm')\n",
      "(1911, 'acrol0854', 'Golz', 'Time', 'Norm')\n",
      "(1915, 'acrol0858', 'Golz', 'Time', 'Norm')\n",
      "(1916, 'acrol0859', 'Golz', 'Time', 'Norm')\n",
      "(1917, 'acrol0860', 'Golz', 'Time', 'Norm')\n",
      "(1918, 'acrol0861', 'Golz', 'Time', 'Norm')\n",
      "(1919, 'acrol0862', 'Golz', 'Time', 'Norm')\n",
      "(1920, 'acrol0863', 'Golz', 'Time', 'Norm')\n",
      "(1921, 'acrol0864', 'Golz', 'Time', 'Norm')\n",
      "(1924, 'acrol0867', 'Golz', 'Time', 'Norm')\n",
      "(1925, 'acrol0868', 'Golz', 'Time', 'Norm')\n",
      "(1926, 'acrol0869', 'Golz', 'Time', 'Norm')\n",
      "(1927, 'acrol0870', 'Golz', 'Time', 'Norm')\n",
      "(1930, 'acrol0873', 'Golz', 'Time', 'Norm')\n",
      "(1931, 'acrol0874', 'Golz', 'Time', 'Norm')\n",
      "(1932, 'acrol0875', 'Golz', 'Time', 'Norm')\n",
      "(1933, 'acrol0876', 'Golz', 'Time', 'Norm')\n",
      "(1935, 'acrol0878', 'Golz', 'Time', 'Norm')\n",
      "(1937, 'acrol0880', 'Golz', 'Time', 'Norm')\n",
      "(1938, 'acrol0881', 'Golz', 'Time', 'Norm')\n",
      "(1939, 'acrol0882', 'Golz', 'Time', 'Norm')\n",
      "(1940, 'acrol0883', 'Golz', 'Time', 'Norm')\n",
      "(1941, 'acrol0884', 'Golz', 'Time', 'Norm')\n",
      "(1944, 'acrol0887', 'Golz', 'Time', 'Norm')\n",
      "(1956, 'acrol0899', 'Golz', 'Time', 'Norm')\n",
      "(1957, 'acrol0900', 'Golz', 'Time', 'Norm')\n",
      "(1958, 'acrol0901', 'Golz', 'Time', 'Norm')\n",
      "(1959, 'acrol0902', 'Golz', 'Time', 'Norm')\n",
      "(1963, 'acrol0906', 'Golz', 'Time', 'Norm')\n",
      "(1964, 'acrol0907', 'Golz', 'Time', 'Norm')\n",
      "(1966, 'acrol0909', 'Golz', 'Time', 'Norm')\n",
      "(1973, 'acrol0916', 'Golz', 'Time', 'Norm')\n",
      "(1974, 'acrol0917', 'Golz', 'Time', 'Norm')\n",
      "(1975, 'acrol0918', 'Golz', 'Time', 'Norm')\n",
      "(1976, 'acrol0919', 'Golz', 'Time', 'Norm')\n",
      "(1977, 'acrol0920', 'Golz', 'Time', 'Norm')\n",
      "(1978, 'acrol0921', 'Golz', 'Time', 'Norm')\n",
      "(1980, 'acrol0923', 'Golz', 'Time', 'Norm')\n",
      "(1983, 'acrol0926', 'Golz', 'Time', 'Norm')\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "# they're sorted in ascending order !!!!\n",
    "\n",
    "feat_list = []\n",
    "asd = OrderedDict(sorted(tot_occs.items(), key=lambda tot_occs: tot_occs[1]))\n",
    "for k,v in asd.items():\n",
    "    feat_list.append(k)\n",
    "nio = get_feat_id(feat_list,printit = 1)\n",
    "# print feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_self_file = 'feat_sel_1_2.npz'\n",
    "np.savez(feat_self_file,ids = nio, feat_mask = feat_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8898, 3107)\n",
      "(5932, 3107)\n",
      "...done fitting\n",
      "=============================================================\n",
      "Testing with classifier KNei\n",
      "Prediction accuracy 0.876601\n",
      "[[ 0.88917693  0.11082307]\n",
      " [ 0.13703443  0.86296557]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.89      0.88      1543\n",
      "        1.0       0.88      0.86      0.87      1423\n",
      "\n",
      "avg / total       0.88      0.88      0.88      2966\n",
      "\n",
      "=============================================================\n",
      "...done fitting\n",
      "=============================================================\n",
      "Testing with classifier SVC(\n",
      "Prediction accuracy 0.903574\n",
      "[[ 0.94426442  0.05573558]\n",
      " [ 0.14054814  0.85945186]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.94      0.91      1543\n",
      "        1.0       0.93      0.86      0.90      1423\n",
      "\n",
      "avg / total       0.91      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n",
      "...done fitting\n",
      "=============================================================\n",
      "Testing with classifier MLPC\n",
      "Prediction accuracy 0.915374\n",
      "[[ 0.94491251  0.05508749]\n",
      " [ 0.11665495  0.88334505]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.94      0.92      1543\n",
      "        1.0       0.94      0.88      0.91      1423\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2966\n",
      "\n",
      "=============================================================\n",
      "...done fitting\n",
      "=============================================================\n",
      "Testing with classifier Rand\n",
      "Prediction accuracy 0.918746\n",
      "[[ 0.96824368  0.03175632]\n",
      " [ 0.13492621  0.86507379]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.97      0.93      1543\n",
      "        1.0       0.96      0.87      0.91      1423\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2966\n",
      "\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# validate between the different objects using the dataset from both fingers\n",
    "\n",
    "# Version 2: keep alternatively one for testing and train on the rest\n",
    "\n",
    "# ===================================== Hard-code this shit\n",
    "\n",
    "data_X = deepcopy(X[2][0]) #[:-1]\n",
    "data_Y = deepcopy(Y[2]) #[:-1]\n",
    "print(data_X.shape)\n",
    "surfaces = np.split(data_X,3)\n",
    "surf_labels = np.split(data_Y,3) \n",
    "# feat_mask = []\n",
    "temp1 = surfaces[0] \n",
    "train_x = np.concatenate((surfaces[2], surfaces[0]), axis = 0) ; test_x = surfaces[1]\n",
    "train_y = np.concatenate((surf_labels[2], surf_labels[0]), axis = 0) ; test_y = surf_labels[1]\n",
    "print(train_x.shape)\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "\n",
    "for pipe_ind, pipe in enumerate(pipe_list):\n",
    "    pipe.fit(train_x, train_y)\n",
    "    print(\"...done fitting\")\n",
    "    y_pred = pipe.predict(test_x)\n",
    "    y_true = test_y\n",
    "    cm = confusion_matrix(y_pred=y_pred, y_true=y_true)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print (\"=============================================================\")\n",
    "    print(\"Testing with classifier %0.4s\" %pipe.named_steps['classifier'])\n",
    "    print(\"Prediction accuracy %f\" %pipe.score(test_x,y_true))\n",
    "    print(cm)\n",
    "    print(classification_report(y_pred=y_pred, y_true = y_true))        \n",
    "    print (\"=============================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for surf_ind, surf_dat in enumerate(surfaces):\n",
    "#     print(\"Testing on surface no. %d\" %surf_ind)\n",
    "#     ind_mask = [True, True, True] \n",
    "#     ind_mask[surf_ind] = False #  the testing dataset is flagged by False\n",
    "#     solely_for_printing_mask = [i for i, x in enumerate(ind_mask) if x == True]\n",
    "#     test_x = surf_dat\n",
    "#     test_y = surf_labels[surf_ind]\n",
    "# #     print(ind_mask)\n",
    "#     train_x = list(compress(surfaces, ind_mask)) # the rest splits, flagged by True, are kept for training\n",
    "#     train_y = list(compress(surf_labels,ind_mask))\n",
    "#     train_d = np.vstack((train_x[0],train_x[1])) ; train_d = train_d[::200]\n",
    "#     train_l = np.hstack((train_y[0], train_y[1])) ; train_l = train_l[::200]\n",
    "# #     print(train_d.shape, surf_dat.shape, train_l.shape)\n",
    "#     for pipe_ind,pipe in enumerate(pipe_list):\n",
    "        \n",
    "# #         for train_ind, train_d in enumerate(train_x):\n",
    "# #             print(\"Fitting classifier no. %d...\" %solely_for_printing_mask[train_ind])\n",
    "#             pipe.fit(train_d,train_l) # fit the pipeline for every train set and every clf\n",
    "#             print (\"...done fitting\")\n",
    "#             feat = list(pipe.named_steps['feature_selection'].get_support(indices = True))\n",
    "#             feat_mask+=feat\n",
    "#             y_pred = pipe.predict(test_x)\n",
    "#             y_true = test_y\n",
    "#             cm = confusion_matrix(y_pred=y_pred, y_true=y_true)\n",
    "#             cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#             print (\"=============================================================\")\n",
    "# #             print(\"Trained on %d, testing on %d with %0.4s\" %(surf_ind, solely_for_printing_mask[test_ind], pipe.named_steps['classifier']))\n",
    "#             print(\"Prediction accuracy %f\" %pipe.score(test_x,y_true))\n",
    "#             print(cm)\n",
    "#             print(classification_report(y_pred=y_pred, y_true = y_true))        \n",
    "#             print (\"=============================================================\")\n",
    "    \n",
    "# # tot_occs = get_feat_occ(feat_mask)\n",
    "# # ids = get_feat_id(tot_occs[:20],printit=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[(8902, 3107), (8902, 3107), (8902, 6214), (8898, 3107), (8898, 3107), (8898, 6214)]\n",
      "[(8902, 3107), (8902, 3107), (8902, 6214), (8902, 3107), (8902, 3107), (8902, 6214), (8898, 3107), (8898, 3107), (8898, 6214)]\n"
     ]
    }
   ],
   "source": [
    "ind_list = [1,0,1]\n",
    "bool_ind = [bool(ind_list[i]) for i in range(len(ind_list))]\n",
    "bool_result = X[bool_ind]\n",
    "print (len(X),len(bool_result))\n",
    "print([ bool_result[i][j].shape for i in range(len(bool_result)) for j in range(len(bool_result[i]))])\n",
    "print([ X[i][j].shape for i in range(len(X)) for j in range(len(X[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started fitting...\n",
      "...done fitting\n"
     ]
    }
   ],
   "source": [
    "# Training the classifiers for the real time validation \n",
    "data_X = deepcopy(X[2]) #[:-1]\n",
    "data_Y = deepcopy(Y[2]) #[:-1]\n",
    "datapath = 'trained_pipes/'\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "\n",
    "for fs in range(len(data_X)):\n",
    "    print(fs)\n",
    "    train_x = data_X[fs]\n",
    "    for pipe_id, pipe in enumerate(pipe_list):\n",
    "        print(pipe_id)\n",
    "        filename = 'fs1'+'_'+str(fs)+'_'+str(pipe_id)\n",
    "        pipefile = datapath+filename+'.npz'\n",
    "        print(\"Started fitting...\")\n",
    "        model = pipe.fit(train_x, data_Y)\n",
    "        print(\"...done fitting\")\n",
    "#         masdas = model.predict(train_x)\n",
    "        np.savez(pipefile,model=np.array([model]))\n",
    "# train_x = data_X[1]\n",
    "# filename = 'fs1'+'_'+str(11)+'_'+str(11)\n",
    "# pipefile = datapath+filename+'.npz'\n",
    "# print(\"Started fitting...\")\n",
    "# model = pipe_list[3].fit(train_x, data_Y)\n",
    "# print(\"...done fitting\")\n",
    "# #         masdas = model.predict(train_x)\n",
    "# np.savez(pipefile,model=np.array([model]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 3107) (1500,)\n",
      "Started fitting...\n",
      "...done fitting\n"
     ]
    }
   ],
   "source": [
    "# Training the classifiers for the real time validation \n",
    "data_X = deepcopy(surf[3,0,1]) #[:-1]\n",
    "data_Y = deepcopy(surfla[:,0,1]) #[:-1]\n",
    "print data_X.shape, data_Y.shape\n",
    "datapath = 'tmp/trained_pipes_trans_1b1/'\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "filename2 = 'overall_models'\n",
    "models = []\n",
    "# for fs in range(len(data_X)):\n",
    "#     print(fs)\n",
    "#     train_x = data_X[fs]\n",
    "#     for pipe_id, pipe in enumerate(pipe_list):\n",
    "pipe = pipe_list[2]\n",
    "filename = 'fs'+'_'+str(1)+'_'+str(2)\n",
    "#     print(pipe_id)\n",
    "pipefile = datapath+filename+'.npz'\n",
    "print(\"Started fitting...\")\n",
    "model = pipe.fit(data_X, data_Y)\n",
    "models.append(model)\n",
    "print(\"...done fitting\")\n",
    "np.savez(pipefile,model=np.array([model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file2 = datapath + filename2 + '.npz'\n",
    "np.savez(file2, models = np.array(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8898,3107) (6214,) (8898,3107) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-e6c01426a181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# lasttry = [last + [mdl[i]] for i in range(len(mdl))]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# anot[1].predict(trmp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0manot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/utils/metaestimators.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y, copy)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (8898,3107) (6214,) (8898,3107) "
     ]
    }
   ],
   "source": [
    "anot = np.load(file2)['models']\n",
    "# print[mdl[i] for i in range(len(mdl))]\n",
    "# lasttry = [last + [mdl[i]] for i in range(len(mdl))]\n",
    "# anot[1].predict(trmp)\n",
    "anot[1].predict(trmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5dd5560c10>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIsAAAJCCAYAAABAuEcoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5e0c5d9110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nasougamhsw = np.load('trained_pipes2/fs_2_2.npz')\n",
    "clf = nasougamhsw['model']\n",
    "# clf2 = np.array([gamhmene['model']])\n",
    "feat = list(clf[0].named_steps['feature_selection'].get_support(indices = True))\n",
    "\n",
    "feat_score = list(clf[0].named_steps['feature_selection'].scores_)\n",
    "# print(feat_score)\n",
    "plt.figure(figsize= (20,10))\n",
    "plt.plot(feat_score)\n",
    "\n",
    "# asd = get_feat_id(feat,1)\n",
    "# ftfn =[]\n",
    "# for i in range(len(feat)):\n",
    "#     if feat[i]>=3107:\n",
    "#         ftfn.append(feat[i])\n",
    "# print(len(ftfn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('feature_selection', SelectKBest(k=1000,\n",
      "      score_func=<function mutual_info_classif at 0x7fa94e82d410>)), ('decomp', PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'))])\n",
      "[ 0.  0.  0. ...,  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "data_X = deepcopy(X[2]) ; data_Y = deepcopy(Y[2])\n",
    "trmp = data_X[1]\n",
    "# trmp.shape\n",
    "# asda = clf[0].predict(trmp)\n",
    "print clf[0]\n",
    "print clf[0].predict(trmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
